{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "(40, 370, 370)\n",
      "WARNING:tensorflow:From <ipython-input-1-5ce0c34ec3fb>:39: conv2d (from tensorflow.python.keras.legacy_tf_layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/legacy_tf_layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "x (228, 19, 370, 370, 1) \n",
      "y (228, 370, 370, 1) \n",
      "x_cha (228, 19, 2) \n",
      "y_cha (228, 2)\n"
     ]
    }
   ],
   "source": [
    "from utils.graph import GraphConstruct\n",
    "from utils.metrics import compute_acc\n",
    "from utils.data_prepare import get_data\n",
    "from utils.batch_generate import Batch_iter\n",
    "\n",
    "import numpy as np\n",
    "\"\"\"\n",
    "num_nodes=370\n",
    "edge=np.load(\"./data/edge.npy\")\n",
    "\n",
    "Graph=GraphConstruct(num_nodes,edge,max_hop=40,strategy='distance')\n",
    "A=Graph.A\n",
    " \n",
    "\"\"\"\n",
    "A=np.load(\"A.npy\")\n",
    "print(A.shape)\n",
    "\n",
    "######################################搭建网络######################################\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='0' \n",
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "def conv2d(x,num_filter,kernel_size=(1,1),padding='same',activation=tf.nn.relu,use_bn=False):\n",
    "    if use_bn:\n",
    "        x=layers.BatchNormalization(axis=1)(x)\n",
    "    x=tf.layers.conv2d( x,\n",
    "                    filters=num_filter,   \n",
    "                    kernel_size=kernel_size,        \n",
    "                    strides=(1, 1),\n",
    "                    padding=padding,\n",
    "                    activation=activation,\n",
    "                          )\n",
    "    return x\n",
    "\n",
    "def point_importance(x):\n",
    "    \n",
    "    Im=tf.Variable(tf.ones(x.shape))\n",
    "    x=Im*x\n",
    "    \n",
    "    return x\n",
    "\n",
    "def gcn_block(x,A,name=\"O_vision\",is_training=True):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x : (n,t,h,w,c)\n",
    "        A : (k,h,w)        \n",
    "    return\n",
    "        x : (n,t,h,w,c)\n",
    "    \"\"\"   \n",
    "    n,t,h,w,c=x.shape\n",
    "\n",
    "    k,h,w = A.shape\n",
    "\n",
    "    # forward feature when x, backwards when x=transpose(x)\n",
    "    with tf.variable_scope(\"gcn_block_%s\"%name):\n",
    "        \n",
    "#         x=tf.layers.batch_normalization(x, training=is_training) \n",
    "        \n",
    "        A=point_importance(A)        \n",
    "        x=tf.einsum('nthwc, khw -> nthwc',x,A)\n",
    "        b=tf.Variable(tf.zeros([t,h,w,c]))\n",
    "        x=x+b\n",
    "          \n",
    "        \n",
    "        x_o = conv2d(x,1,(1,w),'valid',activation=None)\n",
    "        x_o = tf.tile(x_o,[1,1,1,w,1])\n",
    "        w_o=tf.Variable(tf.ones([t,h,w,c]))\n",
    "        x_o = tf.einsum('nthwc, thwc -> nthwc',x_o,w_o)\n",
    "        b_o=tf.Variable(tf.zeros([t,h,w,c]))\n",
    "        x_o = x_o+b_o\n",
    "        \n",
    "        x_d  = conv2d(x,1,(h,1),'valid',activation=None)\n",
    "        x_d = tf.tile(x_d,[1,1,h,1,1])\n",
    "        w_d=tf.Variable(tf.ones([t,h,w,c]))\n",
    "        x_d = tf.einsum('nthwc, thwc -> nthwc',x_d,w_d)\n",
    "        b_d=tf.Variable(tf.zeros([t,h,w,c]))\n",
    "        x_d = x_d+b_d\n",
    "        \n",
    "        x=tf.add(x_o,x_d)\n",
    "#         x=tf.nn.relu(x)\n",
    "        \n",
    "\n",
    "    return x\n",
    "\n",
    "def tcn_block(x,num_filter=1,kernel_size=(19,1,1),padding='same',is_training=True,blockId='0'):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x : (n,t,h,w,c)       \n",
    "    return\n",
    "        x : (n,t,h,w,c)\n",
    "    \"\"\"\n",
    "    n,t,h,w,c=x.shape\n",
    "    \n",
    "    with tf.variable_scope(\"tcn_block%s\"%blockId):\n",
    "#         x=tf.layers.batch_normalization(x, training=is_training)  \n",
    "#         x=layers.ConvLSTM2D(num_filter,kernel_size=kernel_size, padding='same',data_format='channels_last',)(x)\n",
    "        w_3d = tf.Variable(tf.ones([t,h,w,c,num_filter]))\n",
    "        if padding=='same':\n",
    "            x =  tf.einsum('nthwc, thwcf -> nthwf',x,w_3d)\n",
    "            n,t,h,w,f=x.shape\n",
    "            b_3d = tf.Variable(tf.zeros([t,h,w,f]))\n",
    "            x=x+b_3d\n",
    "        elif padding=='valid':\n",
    "            x =  tf.einsum('nthwc, thwcf -> nhwf',x,w_3d/(t.value))\n",
    "            n,h,w,f=x.shape\n",
    "            b_3d = tf.Variable(tf.zeros([h,w,f]))\n",
    "            x=x+b_3d\n",
    "            x=tf.reshape(x,[-1,1,h,w,f])\n",
    "        x=tf.nn.relu(x)\n",
    "        \n",
    "    return x\n",
    "\n",
    "\n",
    "def embed_his_chara_block(x,cha):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x : (n,t,h,w,c)  \n",
    "        cha : (n,t,hc)\n",
    "    return\n",
    "        x : (n,t,h,w,c+hc)\n",
    "    \"\"\"\n",
    "    n,t,h,w,c = x.shape\n",
    "\n",
    "    nc,tc,hc = cha.shape\n",
    "    \n",
    "    with tf.variable_scope(\"embed_his_chara_block\"):\n",
    "        cha = tf.reshape(cha,[-1,tc,1,1,hc])\n",
    "        cha = tf.tile(cha,(1,1,h,w,1))\n",
    "        x=tf.concat([x,cha],4)\n",
    "\n",
    "    return x\n",
    "\n",
    "def embed_fur_chara_block(x,cha):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x : (n,t,h,w,1)  \n",
    "        cha : (n,hc)\n",
    "    return\n",
    "        x : (n,t+hc,h,w,1)\n",
    "    \"\"\"\n",
    "    n,t,h,w,c = x.shape\n",
    "\n",
    "    nc,hc = cha.shape\n",
    "    \n",
    "    with tf.variable_scope(\"embed_fur_chara_block\"):\n",
    "        cha = tf.reshape(cha,[-1,hc,1,1,1])\n",
    "        cha = tf.tile(cha,(1,1,h,w,1))\n",
    "        x=tf.concat([x,cha],1)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "timestep=19\n",
    "c=1\n",
    "hc=2\n",
    "\n",
    "\n",
    "#########################################构造网络#################################\n",
    "tf.reset_default_graph()\n",
    "\n",
    "x_batch=tf.placeholder(tf.float32,[None,timestep,370,370,c])\n",
    "y_batch=tf.placeholder(tf.float32,[None,370,370,c])\n",
    "x_cha_batch=tf.placeholder(tf.float32,[None,timestep,hc])\n",
    "y_cha_batch=tf.placeholder(tf.float32,[None,hc])\n",
    "\n",
    "A_=tf.placeholder(tf.float32,[40,370,370])\n",
    "is_training=tf.placeholder(tf.bool)\n",
    "\n",
    "\n",
    "#########################################gcn\n",
    "output=gcn_block(x_batch,A_,is_training=is_training) #(n,t,h,w,c)  \n",
    "# output=tf.nn.dropout(output, 0.1)\n",
    "\n",
    "x_T=tf.transpose(x_batch,(0,1,3,2,4))  #(n,t,h,w,c)  \n",
    "output_T=gcn_block(x_T,A_,\"D_vision\",is_training=is_training) #(n,t,h,w,c)  \n",
    "# output=tf.nn.dropout(output, 0.1)\n",
    "\n",
    "output=tf.add(output,output_T) #(n,t,h,w,c)  \n",
    "output=tf.nn.relu(output) #(n,t,h,w,c)  \n",
    "\n",
    "#########################################tcn\n",
    "#embed_his_chara\n",
    "output=embed_his_chara_block(output,x_cha_batch) #(n,t,h,w,c+hc)  \n",
    "\n",
    "#tcn_embed_fur_chara\n",
    "output=tcn_block(output,3,kernel_size=(timestep,1,1),is_training=is_training,blockId=0) #(n,t,h,w,3)  \n",
    "# output=tf.nn.dropout(output, 0.1)\n",
    "output=tcn_block(output,1,kernel_size=(timestep,1,1),is_training=is_training,blockId=1) #(n,t,h,w,1)  \n",
    "# output=tf.nn.dropout(output, 0.1)\n",
    "\n",
    "\n",
    "\n",
    "output=embed_fur_chara_block(output,y_cha_batch)  #(n,t+hc,h,w,1)  \n",
    "\n",
    "\n",
    "#tcn_inference\n",
    "t_new=output.get_shape()[1].value\n",
    "output=tcn_block(output,1,kernel_size=(t_new,1,1),padding='valid',is_training=is_training,blockId=2) #(n,1,h,w,1)  \n",
    "# output=tf.nn.dropout(output, 0.1)\n",
    "output=tf.squeeze(output,1) #(n,h,w,1)  \n",
    "\n",
    "\n",
    "\n",
    "hubers = tf.losses.huber_loss(y_batch, output , delta=1.35)\n",
    "loss = tf.reduce_sum(hubers)\n",
    "\n",
    "# loss = tf.reduce_sum(tf.square(y_batch - output))\n",
    "\n",
    "\n",
    "global_step = tf.Variable(0)\n",
    "learning_rate = tf.train.piecewise_constant(\n",
    "    global_step,\n",
    "    [1500],\n",
    "    [0.01,0.001])\n",
    "\n",
    "# train=tf.train.GradientDescentOptimizer(learning_rate).minimize(loss,global_step=global_step)\n",
    "train=tf.train.AdamOptimizer(learning_rate).minimize(loss,global_step=global_step)\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "train = tf.group([train, update_ops])\n",
    "\n",
    "accurancy,accurancy1 = compute_acc(y_batch,output)\n",
    "mse = tf.reduce_sum(tf.square(y_batch - output))\n",
    "\n",
    "train_x,train_y,train_x_cha,train_y_cha, test_x,test_y,test_x_cha,test_y_cha = \\\n",
    "    get_data(timestep,road_od_file=\"./data/road_od_array.npy\",chara_file=\"./data/chara_array_week_period.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-30 08:06:16\n",
      "[1, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "[31, 31, 31, 31, 31, 31, 31, 31, 31, 31]\n",
      "###### 0 batch Train loss:44.6669 acc:-15.1969 acc1:-15.1969 mse:1017191104 Test loss:40.6640 acc:-13.7241 acc1:-13.7241 mse:6389537280\n",
      "\n",
      "2020-10-30 08:06:23\n",
      "[7, 8, 10, 9, 13, 35, 27, 13, 5, 6]\n",
      "[30, 30, 30, 30, 30, 30, 30, 30, 30, 30]\n",
      "###### 1 batch Train loss:44.0869 acc:-16.5161 acc1:-16.5161 mse:950486976 Test loss:39.4208 acc:-13.2676 acc1:-13.2676 mse:6037121536\n",
      "\n",
      "2020-10-30 08:06:26\n",
      "[6, 14, 11, 18, 13, 44, 17, 10, 9, 7]\n",
      "[35, 35, 35, 35, 35, 37, 36, 35, 35, 35]\n",
      "###### 2 batch Train loss:43.4439 acc:-14.9181 acc1:-14.9181 mse:930113536 Test loss:38.1937 acc:-12.8160 acc1:-12.8160 mse:5699590144\n",
      "\n",
      "2020-10-30 08:06:28\n",
      "[16, 10, 29, 16, 18, 86, 53, 41, 35, 30]\n",
      "[35, 35, 35, 35, 35, 38, 36, 35, 35, 35]\n",
      "###### 3 batch Train loss:44.7953 acc:-14.0979 acc1:-14.0979 mse:1029355968 Test loss:36.9838 acc:-12.3707 acc1:-12.3707 mse:5376901632\n",
      "\n",
      "2020-10-30 08:06:31\n",
      "[17, 12, 34, 15, 37, 79, 38, 27, 28, 37]\n",
      "[27, 27, 27, 27, 27, 30, 28, 27, 27, 27]\n",
      "###### 4 batch Train loss:39.4272 acc:-13.5667 acc1:-13.5667 mse:801181504 Test loss:35.8049 acc:-11.9365 acc1:-11.9365 mse:5072315392\n",
      "\n",
      "2020-10-30 08:06:33\n",
      "[7, 9, 5, 6, 7, 13, 8, 3, 1, 1]\n",
      "[28, 28, 28, 28, 28, 31, 29, 28, 28, 28]\n",
      "###### 5 batch Train loss:41.4675 acc:-14.2949 acc1:-14.2949 mse:878759232 Test loss:34.6481 acc:-11.5099 acc1:-11.5099 mse:4783083008\n",
      "\n",
      "2020-10-30 08:06:36\n",
      "[8, 5, 26, 16, 11, 96, 29, 14, 3, 10]\n",
      "[26, 26, 26, 26, 26, 32, 27, 26, 26, 26]\n",
      "###### 6 batch Train loss:36.7936 acc:-13.6455 acc1:-13.6455 mse:663399552 Test loss:33.5185 acc:-11.0929 acc1:-11.0929 mse:4509762560\n",
      "\n",
      "2020-10-30 08:06:38\n",
      "[15, 8, 19, 12, 12, 61, 30, 26, 16, 12]\n",
      "[27, 27, 27, 27, 27, 35, 29, 27, 27, 27]\n",
      "###### 7 batch Train loss:34.9048 acc:-11.3972 acc1:-11.3972 mse:621657024 Test loss:32.4174 acc:-10.6864 acc1:-10.6864 mse:4251994112\n",
      "\n",
      "2020-10-30 08:06:41\n",
      "[3, 0, 6, 9, 8, 7, 6, 19, 14, 10]\n",
      "[25, 25, 25, 26, 26, 32, 27, 25, 25, 25]\n",
      "###### 8 batch Train loss:35.3844 acc:-11.9626 acc1:-11.9626 mse:652507008 Test loss:31.3419 acc:-10.2891 acc1:-10.2891 mse:4008376576\n",
      "\n",
      "2020-10-30 08:06:43\n",
      "[21, 11, 19, 17, 17, 33, 11, 9, 10, 9]\n",
      "[30, 30, 31, 31, 31, 42, 33, 30, 30, 30]\n",
      "###### 9 batch Train loss:33.8885 acc:-9.7397 acc1:-9.7397 mse:684367744 Test loss:30.2946 acc:-9.9028 acc1:-9.9028 mse:3778570752\n",
      "\n",
      "2020-10-30 08:06:46\n",
      "[8, 8, 17, 18, 17, 45, 21, 6, 5, 6]\n",
      "[26, 26, 26, 26, 27, 38, 28, 26, 26, 26]\n",
      "###### 10 batch Train loss:32.5944 acc:-10.7090 acc1:-10.7090 mse:589532672 Test loss:29.2741 acc:-9.5261 acc1:-9.5261 mse:3561962752\n",
      "\n",
      "2020-10-30 08:06:48\n",
      "[5, 7, 7, 12, 10, 19, 14, 7, 4, 3]\n",
      "[29, 29, 30, 30, 30, 42, 32, 29, 29, 29]\n",
      "###### 11 batch Train loss:33.5030 acc:-12.4124 acc1:-12.4124 mse:552815360 Test loss:28.2766 acc:-9.1571 acc1:-9.1571 mse:3357392896\n",
      "\n",
      "2020-10-30 08:06:51\n",
      "[46, 17, 86, 53, 140, 282, 181, 113, 153, 177]\n",
      "[21, 20, 21, 21, 22, 33, 23, 21, 21, 21]\n",
      "###### 12 batch Train loss:28.0685 acc:-8.3612 acc1:-8.3612 mse:452331648 Test loss:27.3123 acc:-8.8006 acc1:-8.8006 mse:3166111232\n",
      "\n",
      "2020-10-30 08:06:53\n",
      "[13, 15, 22, 15, 16, 19, 5, 8, 7, 4]\n",
      "[27, 27, 28, 28, 29, 43, 30, 28, 27, 27]\n",
      "###### 13 batch Train loss:31.2288 acc:-9.7477 acc1:-9.7477 mse:544771008 Test loss:26.3708 acc:-8.4526 acc1:-8.4526 mse:2985494272\n",
      "\n",
      "2020-10-30 08:06:56\n",
      "[6, 1, 3, 7, 8, 13, 3, 22, 12, 8]\n",
      "[19, 19, 20, 20, 20, 32, 22, 19, 19, 19]\n",
      "###### 14 batch Train loss:28.0583 acc:-9.2640 acc1:-9.2640 mse:448302912 Test loss:25.4563 acc:-8.1142 acc1:-8.1142 mse:2816026624\n",
      "\n",
      "2020-10-30 08:06:58\n",
      "[10, 7, 11, 20, 11, 93, 28, 13, 6, 14]\n",
      "[25, 24, 26, 26, 26, 46, 29, 25, 25, 25]\n",
      "###### 15 batch Train loss:29.5620 acc:-9.5597 acc1:-9.5597 mse:488655520 Test loss:24.5645 acc:-7.7837 acc1:-7.7837 mse:2656486400\n",
      "\n",
      "2020-10-30 08:07:01\n",
      "[8, 8, 30, 8, 19, 49, 40, 30, 8, 13]\n",
      "[22, 21, 23, 23, 23, 42, 26, 22, 22, 22]\n",
      "###### 16 batch Train loss:26.5682 acc:-7.9305 acc1:-7.9305 mse:417641184 Test loss:23.6994 acc:-7.4630 acc1:-7.4630 mse:2506963968\n",
      "\n",
      "2020-10-30 08:07:03\n",
      "[42, 12, 30, 34, 50, 114, 49, 76, 75, 83]\n",
      "[19, 19, 21, 21, 21, 37, 23, 20, 20, 20]\n",
      "###### 17 batch Train loss:24.3634 acc:-7.7167 acc1:-7.7167 mse:341512192 Test loss:22.8624 acc:-7.1526 acc1:-7.1526 mse:2367247616\n",
      "\n",
      "2020-10-30 08:07:06\n",
      "[4, 1, 6, 10, 6, 21, 5, 22, 16, 13]\n",
      "[23, 23, 26, 26, 26, 46, 28, 24, 24, 24]\n",
      "###### 18 batch Train loss:24.9846 acc:-8.3481 acc1:-8.3481 mse:370509216 Test loss:22.0509 acc:-6.8511 acc1:-6.8511 mse:2236737792\n",
      "\n",
      "2020-10-30 08:07:08\n",
      "[1, 2, 0, 0, 0, 0, 0, 1, 0, 0]\n",
      "[23, 23, 26, 26, 26, 46, 29, 24, 24, 24]\n",
      "###### 19 batch Train loss:24.9008 acc:-7.7569 acc1:-7.7569 mse:335827296 Test loss:21.2625 acc:-6.5577 acc1:-6.5577 mse:2114550528\n",
      "\n",
      "2020-10-30 08:07:11\n",
      "[5, 11, 13, 10, 17, 17, 9, 3, 7, 7]\n",
      "[17, 17, 20, 19, 20, 36, 22, 18, 18, 18]\n",
      "###### 20 batch Train loss:21.8402 acc:-7.6968 acc1:-7.6968 mse:257840240 Test loss:20.5000 acc:-6.2733 acc1:-6.2733 mse:2000605568\n",
      "\n",
      "2020-10-30 08:07:13\n",
      "[8, 10, 13, 17, 12, 44, 33, 17, 13, 11]\n",
      "[17, 17, 20, 20, 20, 43, 24, 19, 18, 18]\n",
      "###### 21 batch Train loss:21.6788 acc:-7.7275 acc1:-7.7275 mse:244166112 Test loss:19.7623 acc:-5.9975 acc1:-5.9975 mse:1894451968\n",
      "\n",
      "2020-10-30 08:07:16\n",
      "[5, 11, 2, 14, 12, 47, 25, 13, 15, 12]\n",
      "[17, 16, 19, 19, 20, 43, 24, 18, 17, 17]\n",
      "###### 22 batch Train loss:21.7078 acc:-7.3916 acc1:-7.3916 mse:257054544 Test loss:19.0478 acc:-5.7297 acc1:-5.7297 mse:1795473664\n",
      "\n",
      "2020-10-30 08:07:18\n",
      "[0, 5, 3, 4, 3, 7, 2, 1, 1, 1]\n",
      "[16, 16, 19, 19, 19, 36, 22, 17, 17, 17]\n",
      "###### 23 batch Train loss:21.2007 acc:-7.8764 acc1:-7.8764 mse:239490400 Test loss:18.3554 acc:-5.4698 acc1:-5.4698 mse:1703141632\n",
      "\n",
      "2020-10-30 08:07:21\n",
      "[6, 4, 6, 9, 14, 13, 4, 4, 3, 1]\n",
      "[17, 16, 20, 19, 20, 39, 23, 18, 17, 17]\n",
      "###### 24 batch Train loss:19.9067 acc:-5.7853 acc1:-5.7853 mse:238561504 Test loss:17.6863 acc:-5.2185 acc1:-5.2185 mse:1617139328\n",
      "\n",
      "2020-10-30 08:07:24\n",
      "[10, 11, 14, 12, 18, 37, 33, 21, 15, 12]\n",
      "[18, 18, 22, 21, 22, 49, 26, 20, 19, 19]\n",
      "###### 25 batch Train loss:19.9273 acc:-5.8642 acc1:-5.8642 mse:264793472 Test loss:17.0389 acc:-4.9755 acc1:-4.9755 mse:1536854016\n",
      "\n",
      "2020-10-30 08:07:26\n",
      "[17, 12, 32, 16, 28, 79, 36, 43, 32, 27]\n",
      "[14, 13, 16, 16, 17, 39, 21, 15, 14, 14]\n",
      "###### 26 batch Train loss:18.7550 acc:-5.6911 acc1:-5.6911 mse:265567184 Test loss:16.4142 acc:-4.7410 acc1:-4.7410 mse:1462179584\n",
      "\n",
      "2020-10-30 08:07:29\n",
      "[5, 7, 7, 13, 13, 13, 8, 2, 8, 2]\n",
      "[18, 17, 22, 21, 22, 44, 26, 19, 18, 18]\n",
      "###### 27 batch Train loss:19.5418 acc:-6.1819 acc1:-6.1819 mse:230739168 Test loss:15.8087 acc:-4.5135 acc1:-4.5135 mse:1392525056\n",
      "\n",
      "2020-10-30 08:07:31\n",
      "[34, 11, 23, 32, 41, 124, 55, 73, 86, 86]\n",
      "[15, 14, 18, 18, 19, 41, 24, 17, 16, 15]\n",
      "###### 28 batch Train loss:17.2405 acc:-4.9035 acc1:-4.9035 mse:189865984 Test loss:15.2241 acc:-4.2939 acc1:-4.2939 mse:1327598336\n",
      "\n",
      "2020-10-30 08:07:34\n",
      "[2, 6, 4, 1, 2, 2, 4, 2, 1, 4]\n",
      "[15, 14, 18, 18, 19, 38, 23, 16, 16, 15]\n",
      "###### 29 batch Train loss:16.0055 acc:-4.3730 acc1:-4.3730 mse:227869696 Test loss:14.6630 acc:-4.0834 acc1:-4.0834 mse:1267542272\n",
      "\n",
      "2020-10-30 08:07:36\n",
      "[15, 12, 15, 12, 15, 40, 27, 16, 12, 11]\n",
      "[15, 14, 18, 17, 19, 45, 24, 16, 15, 15]\n",
      "###### 30 batch Train loss:16.8723 acc:-5.5344 acc1:-5.5344 mse:51181240 Test loss:14.1198 acc:-3.8790 acc1:-3.8790 mse:1211744256\n",
      "\n",
      "2020-10-30 08:07:40\n",
      "[13, 7, 13, 14, 24, 48, 39, 23, 11, 14]\n",
      "[14, 13, 18, 17, 19, 46, 26, 16, 15, 15]\n",
      "###### 31 batch Train loss:15.2797 acc:-4.6675 acc1:-4.6675 mse:201082816 Test loss:13.5975 acc:-3.6823 acc1:-3.6823 mse:1160124928\n",
      "\n",
      "2020-10-30 08:07:42\n",
      "[6, 1, 3, 7, 8, 13, 3, 22, 12, 8]\n",
      "[11, 10, 14, 14, 15, 33, 20, 13, 12, 12]\n",
      "###### 32 batch Train loss:15.0736 acc:-3.7660 acc1:-3.7660 mse:220155488 Test loss:13.0962 acc:-3.4940 acc1:-3.4940 mse:1112401280\n",
      "\n",
      "2020-10-30 08:07:45\n",
      "[24, 43, 105, 77, 126, 203, 199, 121, 111, 115]\n",
      "[13, 11, 16, 15, 17, 41, 24, 15, 14, 13]\n",
      "###### 33 batch Train loss:14.7432 acc:-3.4931 acc1:-3.4931 mse:215256928 Test loss:12.6140 acc:-3.3132 acc1:-3.3132 mse:1068147456\n",
      "\n",
      "2020-10-30 08:07:47\n",
      "[10, 9, 22, 11, 11, 105, 22, 23, 12, 9]\n",
      "[13, 12, 16, 16, 18, 46, 25, 15, 14, 13]\n",
      "###### 34 batch Train loss:14.2145 acc:-4.0470 acc1:-4.0470 mse:162343440 Test loss:12.1493 acc:-3.1387 acc1:-3.1387 mse:1027161024\n",
      "\n",
      "2020-10-30 08:07:50\n",
      "[8, 8, 30, 8, 19, 49, 40, 30, 8, 13]\n",
      "[13, 11, 16, 15, 17, 45, 25, 15, 13, 13]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### 35 batch Train loss:13.1456 acc:-4.2387 acc1:-4.2387 mse:101380688 Test loss:11.7006 acc:-2.9696 acc1:-2.9696 mse:989154176\n",
      "\n",
      "2020-10-30 08:07:52\n",
      "[11, 6, 14, 18, 11, 31, 13, 6, 10, 9]\n",
      "[11, 10, 14, 13, 15, 38, 22, 13, 12, 11]\n",
      "###### 36 batch Train loss:12.0810 acc:-3.4053 acc1:-3.4053 mse:110375760 Test loss:11.2688 acc:-2.8067 acc1:-2.8067 mse:953808192\n",
      "\n",
      "2020-10-30 08:07:55\n",
      "[15, 14, 36, 17, 33, 95, 58, 29, 79, 23]\n",
      "[14, 12, 17, 17, 20, 49, 29, 17, 15, 14]\n",
      "###### 37 batch Train loss:12.1932 acc:-3.3001 acc1:-3.3001 mse:114738240 Test loss:10.8536 acc:-2.6502 acc1:-2.6502 mse:921052608\n",
      "\n",
      "2020-10-30 08:07:57\n",
      "[2, 6, 4, 1, 2, 2, 4, 2, 1, 4]\n",
      "[12, 11, 16, 15, 17, 38, 24, 15, 14, 12]\n",
      "###### 38 batch Train loss:12.2390 acc:-3.8451 acc1:-3.8451 mse:103202528 Test loss:10.4531 acc:-2.4986 acc1:-2.4986 mse:890798272\n",
      "\n",
      "2020-10-30 08:08:00\n",
      "[13, 12, 42, 56, 50, 79, 38, 13, 15, 19]\n",
      "[11, 10, 15, 14, 16, 40, 24, 14, 12, 11]\n",
      "###### 39 batch Train loss:10.8209 acc:-2.6908 acc1:-2.6908 mse:104229280 Test loss:10.0683 acc:-2.3533 acc1:-2.3533 mse:862663040\n",
      "\n",
      "2020-10-30 08:08:02\n",
      "[0, 5, 3, 4, 3, 7, 2, 1, 1, 1]\n",
      "[11, 9, 14, 14, 16, 34, 22, 14, 12, 11]\n",
      "###### 40 batch Train loss:10.7057 acc:-3.0339 acc1:-3.0339 mse:67525464 Test loss:9.6980 acc:-2.2128 acc1:-2.2128 mse:836830976\n",
      "\n",
      "2020-10-30 08:08:05\n",
      "[4, 11, 16, 14, 20, 38, 29, 17, 20, 9]\n",
      "[12, 10, 16, 15, 18, 50, 30, 17, 14, 12]\n",
      "###### 41 batch Train loss:10.5290 acc:-3.1113 acc1:-3.1113 mse:78774832 Test loss:9.3409 acc:-2.0768 acc1:-2.0768 mse:812870272\n",
      "\n",
      "2020-10-30 08:08:08\n",
      "[32, 30, 100, 63, 117, 209, 186, 117, 112, 121]\n",
      "[10, 8, 13, 12, 15, 38, 24, 14, 11, 10]\n",
      "###### 42 batch Train loss:10.5152 acc:-2.0086 acc1:-2.0086 mse:256336576 Test loss:9.0001 acc:-1.9480 acc1:-1.9480 mse:790673664\n",
      "\n",
      "2020-10-30 08:08:10\n",
      "[0, 1, 0, 0, 0, 0, 0, 2, 0, 0]\n",
      "[12, 9, 15, 14, 17, 38, 25, 16, 13, 11]\n",
      "###### 43 batch Train loss:10.3838 acc:-2.2675 acc1:-2.2675 mse:99138136 Test loss:8.6721 acc:-1.8242 acc1:-1.8242 mse:770235456\n",
      "\n",
      "2020-10-30 08:08:13\n",
      "[5, 12, 23, 16, 23, 29, 13, 7, 6, 3]\n",
      "[11, 9, 14, 14, 16, 36, 23, 14, 12, 10]\n",
      "###### 44 batch Train loss:8.8473 acc:-2.0906 acc1:-2.0906 mse:74736608 Test loss:8.3574 acc:-1.7056 acc1:-1.7056 mse:751302080\n",
      "\n",
      "2020-10-30 08:08:15\n",
      "[16, 9, 54, 51, 54, 59, 43, 5, 16, 16]\n",
      "[11, 9, 15, 14, 17, 42, 26, 15, 13, 11]\n",
      "###### 45 batch Train loss:9.6175 acc:-1.9850 acc1:-1.9850 mse:105980224 Test loss:8.0545 acc:-1.5922 acc1:-1.5922 mse:733617920\n",
      "\n",
      "2020-10-30 08:08:18\n",
      "[37, 12, 91, 52, 124, 265, 142, 115, 139, 151]\n",
      "[12, 9, 16, 15, 19, 45, 29, 17, 14, 12]\n",
      "###### 46 batch Train loss:9.4410 acc:-1.3960 acc1:-1.3960 mse:174753680 Test loss:7.7650 acc:-1.4851 acc1:-1.4851 mse:717158848\n",
      "\n",
      "2020-10-30 08:08:20\n",
      "[10, 10, 40, 53, 50, 55, 41, 12, 17, 21]\n",
      "[10, 8, 14, 13, 16, 39, 24, 13, 11, 10]\n",
      "###### 47 batch Train loss:8.7851 acc:-2.1709 acc1:-2.1709 mse:68522184 Test loss:7.4852 acc:-1.3814 acc1:-1.3814 mse:701867776\n",
      "\n",
      "2020-10-30 08:08:23\n",
      "[6, 9, 5, 17, 26, 38, 29, 13, 13, 10]\n",
      "[9, 7, 12, 11, 14, 39, 23, 13, 10, 9]\n",
      "###### 48 batch Train loss:7.9467 acc:-2.1306 acc1:-2.1306 mse:45122612 Test loss:7.2148 acc:-1.2806 acc1:-1.2806 mse:687684480\n",
      "\n",
      "2020-10-30 08:08:25\n",
      "[35, 36, 111, 76, 138, 228, 172, 111, 103, 105]\n",
      "[12, 9, 16, 15, 19, 47, 30, 17, 14, 12]\n",
      "###### 49 batch Train loss:7.8863 acc:-1.4592 acc1:-1.4592 mse:119047144 Test loss:6.9556 acc:-1.1840 acc1:-1.1840 mse:674639488\n",
      "\n",
      "2020-10-30 08:08:28\n",
      "[24, 7, 16, 31, 47, 132, 57, 89, 73, 83]\n",
      "[12, 9, 16, 16, 20, 45, 30, 17, 14, 12]\n",
      "###### 50 batch Train loss:7.6115 acc:-1.5357 acc1:-1.5357 mse:92815048 Test loss:6.7078 acc:-1.0920 acc1:-1.0920 mse:662682880\n",
      "\n",
      "2020-10-30 08:08:30\n",
      "[3, 7, 3, 5, 5, 6, 9, 5, 3, 3]\n",
      "[11, 9, 15, 14, 18, 37, 26, 15, 13, 11]\n",
      "###### 51 batch Train loss:6.9379 acc:-1.5597 acc1:-1.5597 mse:54553336 Test loss:6.4687 acc:-1.0032 acc1:-1.0032 mse:651481408\n",
      "\n",
      "2020-10-30 08:08:33\n",
      "[0, 8, 12, 4, 7, 5, 9, 1, 2, 3]\n",
      "[12, 9, 16, 15, 19, 40, 27, 17, 14, 12]\n",
      "###### 52 batch Train loss:6.3874 acc:-1.5026 acc1:-1.5026 mse:32855340 Test loss:6.2390 acc:-0.9176 acc1:-0.9176 mse:641168192\n",
      "\n",
      "2020-10-30 08:08:35\n",
      "[4, 4, 8, 13, 13, 7, 7, 3, 7, 3]\n",
      "[10, 8, 14, 13, 16, 34, 23, 14, 12, 10]\n",
      "###### 53 batch Train loss:6.5749 acc:-1.1140 acc1:-1.1140 mse:75772872 Test loss:6.0181 acc:-0.8360 acc1:-0.8360 mse:631429824\n",
      "\n",
      "2020-10-30 08:08:38\n",
      "[18, 10, 13, 18, 18, 33, 16, 9, 15, 4]\n",
      "[8, 7, 12, 11, 14, 36, 22, 12, 10, 8]\n",
      "###### 54 batch Train loss:6.7210 acc:-1.3303 acc1:-1.3303 mse:57823344 Test loss:5.8052 acc:-0.7572 acc1:-0.7572 mse:622408896\n",
      "\n",
      "2020-10-30 08:08:40\n",
      "[37, 46, 119, 70, 157, 235, 203, 151, 101, 126]\n",
      "[11, 8, 16, 15, 20, 48, 31, 17, 14, 12]\n",
      "###### 55 batch Train loss:7.2197 acc:-0.9268 acc1:-0.9268 mse:166887440 Test loss:5.6017 acc:-0.6829 acc1:-0.6829 mse:614076544\n",
      "\n",
      "2020-10-30 08:08:43\n",
      "[2, 7, 8, 8, 8, 7, 7, 5, 1, 3]\n",
      "[10, 8, 14, 14, 17, 37, 25, 15, 13, 11]\n",
      "###### 56 batch Train loss:6.5270 acc:-0.8637 acc1:-0.8637 mse:161834960 Test loss:5.4068 acc:-0.6124 acc1:-0.6124 mse:606274304\n",
      "\n",
      "2020-10-30 08:08:46\n",
      "[7, 6, 17, 14, 15, 46, 23, 19, 18, 17]\n",
      "[9, 7, 13, 12, 15, 41, 25, 13, 11, 9]\n",
      "###### 57 batch Train loss:5.5891 acc:-0.6992 acc1:-0.6992 mse:65272992 Test loss:5.2191 acc:-0.5452 acc1:-0.5452 mse:598774016\n",
      "\n",
      "2020-10-30 08:08:48\n",
      "[36, 10, 28, 31, 44, 118, 51, 72, 61, 79]\n",
      "[9, 6, 13, 12, 16, 37, 24, 14, 12, 9]\n",
      "###### 58 batch Train loss:5.6514 acc:-0.5617 acc1:-0.5617 mse:104177952 Test loss:5.0397 acc:-0.4819 acc1:-0.4819 mse:591713856\n",
      "\n",
      "2020-10-30 08:08:51\n",
      "[8, 7, 3, 9, 12, 16, 6, 3, 4, 6]\n",
      "[10, 8, 15, 14, 17, 37, 24, 14, 13, 10]\n",
      "###### 59 batch Train loss:5.3959 acc:-0.5732 acc1:-0.5732 mse:70764352 Test loss:4.8673 acc:-0.4218 acc1:-0.4218 mse:584977152\n",
      "\n",
      "2020-10-30 08:08:53\n",
      "[7, 10, 21, 9, 8, 20, 6, 7, 5, 5]\n",
      "[8, 7, 13, 12, 15, 32, 20, 12, 10, 9]\n",
      "###### 60 batch Train loss:5.8707 acc:-0.5593 acc1:-0.5593 mse:115825856 Test loss:4.7015 acc:-0.3650 acc1:-0.3650 mse:578565952\n",
      "\n",
      "2020-10-30 08:08:55\n",
      "[6, 10, 21, 13, 17, 47, 18, 19, 11, 9]\n",
      "[10, 8, 16, 14, 18, 47, 28, 15, 13, 11]\n",
      "###### 61 batch Train loss:4.5197 acc:-0.8238 acc1:-0.8238 mse:7813013 Test loss:4.5415 acc:-0.3098 acc1:-0.3098 mse:572705024\n",
      "\n",
      "2020-10-30 08:08:59\n",
      "[5, 7, 7, 13, 13, 13, 8, 2, 8, 2]\n",
      "[11, 9, 16, 15, 18, 39, 25, 15, 14, 11]\n",
      "###### 62 batch Train loss:5.8970 acc:-0.2712 acc1:-0.2712 mse:205635696 Test loss:4.3891 acc:-0.2585 acc1:-0.2585 mse:567095488\n",
      "\n",
      "2020-10-30 08:09:02\n",
      "[9, 15, 30, 15, 29, 72, 52, 39, 41, 29]\n",
      "[9, 7, 14, 13, 17, 42, 26, 15, 12, 10]\n",
      "###### 63 batch Train loss:3.9929 acc:-0.5482 acc1:-0.5482 mse:39506972 Test loss:4.2429 acc:-0.2091 acc1:-0.2091 mse:562050112\n",
      "\n",
      "2020-10-30 08:09:04\n",
      "[12, 5, 12, 13, 21, 53, 25, 25, 15, 9]\n",
      "[8, 6, 13, 12, 15, 39, 24, 14, 11, 9]\n",
      "###### 64 batch Train loss:4.2137 acc:-0.4322 acc1:-0.4322 mse:42084016 Test loss:4.1021 acc:-0.1616 acc1:-0.1616 mse:557387136\n",
      "\n",
      "2020-10-30 08:09:07\n",
      "[13, 7, 13, 14, 24, 48, 39, 23, 11, 14]\n",
      "[10, 8, 15, 14, 17, 45, 28, 16, 13, 10]\n",
      "###### 65 batch Train loss:4.2609 acc:-0.5824 acc1:-0.5824 mse:38912656 Test loss:3.9663 acc:-0.1156 acc1:-0.1156 mse:553191040\n",
      "\n",
      "2020-10-30 08:09:10\n",
      "[14, 11, 13, 11, 15, 46, 27, 7, 13, 18]\n",
      "[9, 8, 15, 14, 16, 42, 25, 14, 12, 10]\n",
      "###### 66 batch Train loss:4.3279 acc:-0.1712 acc1:-0.1712 mse:64873888 Test loss:3.8360 acc:-0.0727 acc1:-0.0727 mse:549167680\n",
      "\n",
      "2020-10-30 08:09:12\n",
      "[6, 15, 30, 32, 33, 44, 34, 13, 12, 6]\n",
      "[8, 7, 14, 12, 15, 34, 20, 11, 10, 8]\n",
      "###### 67 batch Train loss:4.0244 acc:-0.1137 acc1:-0.1137 mse:57052024 Test loss:3.7108 acc:-0.0326 acc1:-0.0326 mse:545218944\n",
      "\n",
      "2020-10-30 08:09:15\n",
      "[32, 30, 100, 63, 117, 209, 186, 117, 112, 121]\n",
      "[8, 6, 14, 12, 15, 39, 23, 14, 12, 9]\n",
      "###### 68 batch Train loss:3.8043 acc:0.0078 acc1:0.0078 mse:106496864 Test loss:3.5923 acc:0.0043 acc1:0.0043 mse:541534336\n",
      "\n",
      "2020-10-30 08:09:17\n",
      "[36, 10, 28, 31, 44, 118, 51, 72, 61, 79]\n",
      "[9, 7, 15, 13, 16, 38, 23, 15, 12, 9]\n",
      "###### 69 batch Train loss:3.9755 acc:-0.1997 acc1:-0.1997 mse:50629512 Test loss:3.4781 acc:0.0397 acc1:0.0397 mse:538201984\n",
      "\n",
      "2020-10-30 08:09:20\n",
      "[7, 8, 17, 12, 13, 42, 26, 20, 10, 8]\n",
      "[10, 8, 17, 15, 18, 48, 28, 16, 14, 11]\n",
      "###### 70 batch Train loss:3.9361 acc:-0.2963 acc1:-0.2963 mse:60078220 Test loss:3.3680 acc:0.0740 acc1:0.0740 mse:535142016\n",
      "\n",
      "2020-10-30 08:09:22\n",
      "[8, 10, 40, 41, 39, 61, 40, 19, 17, 17]\n",
      "[8, 7, 14, 12, 15, 36, 20, 11, 10, 8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### 71 batch Train loss:4.0246 acc:-0.1311 acc1:-0.1311 mse:66445892 Test loss:3.2628 acc:0.1061 acc1:0.1061 mse:532342432\n",
      "\n",
      "2020-10-30 08:09:25\n",
      "[35, 36, 111, 76, 138, 228, 172, 111, 103, 105]\n",
      "[11, 8, 18, 16, 19, 48, 28, 18, 15, 12]\n",
      "###### 72 batch Train loss:3.2482 acc:-0.1337 acc1:-0.1337 mse:73986232 Test loss:3.1620 acc:0.1370 acc1:0.1370 mse:529853312\n",
      "\n",
      "2020-10-30 08:09:27\n",
      "[42, 29, 108, 77, 133, 234, 205, 111, 96, 96]\n",
      "[9, 7, 16, 14, 17, 43, 25, 16, 13, 10]\n",
      "###### 73 batch Train loss:4.1835 acc:-0.0366 acc1:-0.0366 mse:121179320 Test loss:3.0647 acc:0.1657 acc1:0.1657 mse:527392448\n",
      "\n",
      "2020-10-30 08:09:30\n",
      "[30, 41, 99, 82, 134, 202, 228, 92, 115, 102]\n",
      "[10, 8, 17, 15, 18, 46, 27, 17, 14, 11]\n",
      "###### 74 batch Train loss:4.2827 acc:0.1233 acc1:0.1233 mse:157880448 Test loss:2.9719 acc:0.1915 acc1:0.1915 mse:524901888\n",
      "\n",
      "2020-10-30 08:09:32\n",
      "[8, 5, 26, 16, 11, 96, 29, 14, 3, 10]\n",
      "[8, 6, 13, 11, 14, 40, 21, 12, 10, 8]\n",
      "###### 75 batch Train loss:3.8340 acc:-0.0380 acc1:-0.0380 mse:87306288 Test loss:2.8833 acc:0.2152 acc1:0.2152 mse:522672192\n",
      "\n",
      "2020-10-30 08:09:35\n",
      "[19, 7, 13, 11, 19, 61, 32, 20, 14, 10]\n",
      "[8, 6, 14, 12, 15, 42, 24, 14, 12, 9]\n",
      "###### 76 batch Train loss:2.7812 acc:-0.1683 acc1:-0.1683 mse:27314986 Test loss:2.7978 acc:0.2379 acc1:0.2379 mse:520803392\n",
      "\n",
      "2020-10-30 08:09:37\n",
      "[13, 7, 9, 9, 14, 33, 31, 10, 15, 10]\n",
      "[9, 7, 15, 13, 16, 44, 25, 15, 12, 9]\n",
      "###### 77 batch Train loss:2.2462 acc:0.0659 acc1:0.0659 mse:31139154 Test loss:2.7160 acc:0.2591 acc1:0.2591 mse:519238016\n",
      "\n",
      "2020-10-30 08:09:40\n",
      "[17, 12, 32, 16, 28, 79, 36, 43, 32, 27]\n",
      "[8, 7, 15, 13, 16, 42, 25, 15, 12, 9]\n",
      "###### 78 batch Train loss:3.0586 acc:0.2576 acc1:0.2576 mse:82856536 Test loss:2.6380 acc:0.2781 acc1:0.2781 mse:517590048\n",
      "\n",
      "2020-10-30 08:09:43\n",
      "[3, 12, 5, 4, 5, 8, 10, 5, 7, 5]\n",
      "[9, 8, 15, 13, 15, 34, 21, 14, 12, 10]\n",
      "###### 79 batch Train loss:3.1920 acc:0.2568 acc1:0.2568 mse:146899760 Test loss:2.5639 acc:0.2954 acc1:0.2954 mse:516065856\n",
      "\n",
      "2020-10-30 08:09:45\n",
      "[10, 8, 21, 19, 9, 103, 25, 15, 16, 11]\n",
      "[9, 8, 16, 14, 16, 46, 25, 15, 13, 10]\n",
      "###### 80 batch Train loss:2.9337 acc:0.1112 acc1:0.1112 mse:65488432 Test loss:2.4939 acc:0.3116 acc1:0.3116 mse:514758624\n",
      "\n",
      "2020-10-30 08:09:48\n",
      "[1, 2, 0, 1, 0, 0, 0, 1, 1, 0]\n",
      "[9, 8, 15, 14, 16, 37, 23, 15, 13, 10]\n",
      "###### 81 batch Train loss:1.9465 acc:0.2149 acc1:0.2149 mse:12000402 Test loss:2.4279 acc:0.3275 acc1:0.3275 mse:513822944\n",
      "\n",
      "2020-10-30 08:09:50\n",
      "[3, 2, 1, 2, 2, 1, 0, 0, 0, 0]\n",
      "[11, 9, 18, 16, 19, 43, 27, 17, 15, 12]\n",
      "###### 82 batch Train loss:2.7533 acc:0.1434 acc1:0.1434 mse:47644088 Test loss:2.3656 acc:0.3429 acc1:0.3429 mse:513090112\n",
      "\n",
      "2020-10-30 08:09:53\n",
      "[8, 10, 13, 17, 12, 44, 33, 17, 13, 11]\n",
      "[9, 7, 15, 13, 17, 45, 27, 16, 13, 10]\n",
      "###### 83 batch Train loss:3.8033 acc:0.2648 acc1:0.2648 mse:162296416 Test loss:2.3095 acc:0.3560 acc1:0.3560 mse:512403744\n",
      "\n",
      "2020-10-30 08:09:55\n",
      "[8, 7, 13, 17, 27, 25, 23, 9, 5, 14]\n",
      "[10, 8, 16, 14, 18, 49, 29, 17, 14, 11]\n",
      "###### 84 batch Train loss:2.4088 acc:0.2547 acc1:0.2547 mse:52070820 Test loss:2.2574 acc:0.3677 acc1:0.3677 mse:511645824\n",
      "\n",
      "2020-10-30 08:09:58\n",
      "[9, 15, 13, 23, 32, 35, 25, 13, 24, 16]\n",
      "[10, 9, 18, 16, 19, 45, 25, 14, 14, 11]\n",
      "###### 85 batch Train loss:1.8450 acc:0.3840 acc1:0.3840 mse:19965552 Test loss:2.2099 acc:0.3774 acc1:0.3774 mse:510840128\n",
      "\n",
      "2020-10-30 08:10:00\n",
      "[7, 11, 12, 8, 21, 27, 17, 11, 13, 7]\n",
      "[11, 9, 17, 15, 19, 48, 29, 18, 15, 12]\n",
      "###### 86 batch Train loss:1.8451 acc:0.1982 acc1:0.1982 mse:30730084 Test loss:2.1662 acc:0.3855 acc1:0.3855 mse:510122496\n",
      "\n",
      "2020-10-30 08:10:03\n",
      "[1, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "[8, 6, 13, 12, 14, 31, 20, 13, 12, 9]\n",
      "###### 87 batch Train loss:1.7118 acc:0.3848 acc1:0.3848 mse:37854800 Test loss:2.1270 acc:0.3914 acc1:0.3914 mse:509467520\n",
      "\n",
      "2020-10-30 08:10:05\n",
      "[4, 4, 9, 9, 8, 13, 8, 2, 4, 5]\n",
      "[10, 9, 17, 16, 18, 38, 24, 16, 15, 12]\n",
      "###### 88 batch Train loss:2.0944 acc:0.3842 acc1:0.3842 mse:52589036 Test loss:2.0917 acc:0.3945 acc1:0.3945 mse:508729216\n",
      "\n",
      "2020-10-30 08:10:08\n",
      "[13, 15, 22, 15, 16, 19, 5, 8, 7, 4]\n",
      "[10, 9, 18, 16, 18, 39, 24, 15, 14, 11]\n",
      "###### 89 batch Train loss:1.9197 acc:0.4534 acc1:0.4534 mse:49130720 Test loss:2.0602 acc:0.3953 acc1:0.3953 mse:507881920\n",
      "\n",
      "2020-10-30 08:10:10\n",
      "[25, 36, 106, 85, 123, 195, 209, 111, 84, 103]\n",
      "[11, 9, 18, 17, 20, 47, 29, 19, 17, 13]\n",
      "###### 90 batch Train loss:3.2940 acc:0.4091 acc1:0.4091 mse:153790896 Test loss:2.0326 acc:0.3940 acc1:0.3940 mse:506996480\n",
      "\n",
      "2020-10-30 08:10:13\n",
      "[15, 10, 17, 14, 9, 25, 17, 8, 8, 8]\n",
      "[9, 9, 16, 15, 17, 40, 23, 13, 13, 10]\n",
      "###### 91 batch Train loss:1.8863 acc:0.2364 acc1:0.2364 mse:23902666 Test loss:2.0083 acc:0.3922 acc1:0.3922 mse:506440320\n",
      "\n",
      "2020-10-30 08:10:15\n",
      "[8, 1, 3, 10, 6, 10, 6, 24, 21, 8]\n",
      "[9, 8, 15, 14, 17, 36, 23, 16, 14, 11]\n",
      "###### 92 batch Train loss:1.0798 acc:0.1174 acc1:0.1174 mse:2331908 Test loss:1.9876 acc:0.3901 acc1:0.3901 mse:506292224\n",
      "\n",
      "2020-10-30 08:10:19\n",
      "[5, 9, 14, 14, 15, 40, 24, 19, 14, 7]\n",
      "[10, 9, 16, 14, 17, 44, 26, 15, 14, 11]\n",
      "###### 93 batch Train loss:2.7337 acc:0.3672 acc1:0.3672 mse:80670944 Test loss:1.9693 acc:0.3873 acc1:0.3873 mse:505993216\n",
      "\n",
      "2020-10-30 08:10:21\n",
      "[0, 1, 0, 0, 0, 0, 0, 2, 0, 0]\n",
      "[9, 8, 15, 14, 16, 34, 22, 15, 14, 11]\n",
      "###### 94 batch Train loss:2.4217 acc:0.2701 acc1:0.2701 mse:69022760 Test loss:1.9530 acc:0.3842 acc1:0.3842 mse:505817536\n",
      "\n",
      "2020-10-30 08:10:24\n",
      "[3, 4, 17, 10, 14, 94, 25, 21, 13, 8]\n",
      "[9, 8, 15, 13, 15, 39, 23, 14, 12, 10]\n",
      "###### 95 batch Train loss:0.9955 acc:0.3453 acc1:0.3453 mse:8337519 Test loss:1.9391 acc:0.3810 acc1:0.3810 mse:505878432\n",
      "\n",
      "2020-10-30 08:10:26\n",
      "[14, 10, 7, 25, 19, 34, 14, 14, 7, 13]\n",
      "[10, 9, 17, 15, 17, 39, 23, 13, 13, 10]\n",
      "###### 96 batch Train loss:2.2161 acc:0.3852 acc1:0.3852 mse:110178920 Test loss:1.9270 acc:0.3774 acc1:0.3774 mse:505765088\n",
      "\n",
      "2020-10-30 08:10:29\n",
      "[8, 1, 3, 10, 6, 10, 6, 24, 21, 8]\n",
      "[9, 8, 15, 14, 16, 35, 23, 16, 14, 10]\n",
      "###### 97 batch Train loss:1.2178 acc:0.3157 acc1:0.3157 mse:26898644 Test loss:1.9169 acc:0.3737 acc1:0.3737 mse:505880864\n",
      "\n",
      "2020-10-30 08:10:31\n",
      "[10, 8, 16, 16, 15, 39, 13, 5, 9, 17]\n",
      "[9, 8, 16, 14, 16, 38, 21, 12, 11, 9]\n",
      "###### 98 batch Train loss:3.0029 acc:0.3599 acc1:0.3599 mse:115146408 Test loss:1.9082 acc:0.3697 acc1:0.3697 mse:505869312\n",
      "\n",
      "2020-10-30 08:10:34\n",
      "[9, 15, 15, 13, 27, 76, 16, 6, 26, 11]\n",
      "[9, 8, 16, 14, 16, 37, 20, 11, 11, 9]\n",
      "###### 99 batch Train loss:1.4997 acc:0.4246 acc1:0.4246 mse:28579998 Test loss:1.9004 acc:0.3657 acc1:0.3657 mse:505693888\n",
      "\n",
      "2020-10-30 08:10:36\n",
      "[4, 6, 6, 3, 8, 10, 6, 1, 0, 2]\n",
      "[10, 9, 16, 16, 17, 35, 23, 17, 15, 11]\n",
      "###### 100 batch Train loss:1.7162 acc:0.2046 acc1:0.2046 mse:28845764 Test loss:1.8936 acc:0.3618 acc1:0.3618 mse:505591040\n",
      "\n",
      "2020-10-30 08:10:39\n",
      "[5, 6, 8, 1, 2, 2, 5, 5, 3, 3]\n",
      "[10, 9, 16, 16, 17, 35, 23, 17, 15, 11]\n",
      "###### 101 batch Train loss:2.6646 acc:0.2664 acc1:0.2664 mse:119031064 Test loss:1.8879 acc:0.3580 acc1:0.3580 mse:505482048\n",
      "\n",
      "2020-10-30 08:10:41\n",
      "[5, 7, 7, 12, 10, 19, 14, 7, 4, 3]\n",
      "[10, 9, 16, 15, 17, 34, 21, 15, 14, 11]\n",
      "###### 102 batch Train loss:2.6546 acc:0.3546 acc1:0.3546 mse:95618176 Test loss:1.8832 acc:0.3540 acc1:0.3540 mse:505225664\n",
      "\n",
      "2020-10-30 08:10:44\n",
      "[28, 6, 24, 34, 51, 122, 44, 68, 76, 86]\n",
      "[11, 9, 18, 17, 19, 41, 26, 19, 16, 12]\n",
      "###### 103 batch Train loss:2.5372 acc:0.3720 acc1:0.3720 mse:83206328 Test loss:1.8790 acc:0.3633 acc1:0.3499 mse:504758752\n",
      "\n",
      "2020-10-30 08:10:47\n",
      "[35, 40, 127, 76, 149, 239, 187, 140, 93, 114]\n",
      "[11, 10, 19, 17, 20, 45, 28, 20, 17, 13]\n",
      "###### 104 batch Train loss:2.3941 acc:0.4028 acc1:0.4028 mse:103198288 Test loss:1.8753 acc:0.3905 acc1:0.3457 mse:504096736\n",
      "\n",
      "2020-10-30 08:10:49\n",
      "[13, 15, 22, 15, 16, 19, 5, 8, 7, 4]\n",
      "[10, 10, 17, 16, 18, 35, 21, 15, 14, 11]\n",
      "###### 105 batch Train loss:1.8254 acc:0.4176 acc1:0.2994 mse:69647840 Test loss:1.8720 acc:0.4153 acc1:0.3417 mse:503425344\n",
      "\n",
      "2020-10-30 08:10:52\n",
      "[21, 12, 38, 23, 35, 106, 60, 26, 31, 23]\n",
      "[11, 9, 17, 16, 19, 43, 27, 20, 16, 12]\n",
      "###### 106 batch Train loss:1.7790 acc:0.5297 acc1:0.3444 mse:67627968 Test loss:1.8695 acc:0.4804 acc1:0.3381 mse:502916160\n",
      "\n",
      "2020-10-30 08:10:54\n",
      "[4, 1, 3, 7, 5, 16, 7, 20, 16, 10]\n",
      "[11, 9, 17, 16, 19, 39, 25, 19, 16, 12]\n",
      "###### 107 batch Train loss:2.7346 acc:0.3725 acc1:0.2561 mse:140723264 Test loss:1.8674 acc:0.5021 acc1:0.3346 mse:502393824\n",
      "\n",
      "2020-10-30 08:10:57\n",
      "[11, 22, 42, 28, 33, 90, 53, 35, 23, 26]\n",
      "[11, 9, 17, 16, 19, 44, 27, 20, 16, 12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### 108 batch Train loss:1.6813 acc:0.2125 acc1:0.2125 mse:41021836 Test loss:1.8654 acc:0.5296 acc1:0.3315 mse:501890624\n",
      "\n",
      "2020-10-30 08:10:59\n",
      "[8, 4, 9, 10, 4, 29, 24, 18, 13, 7]\n",
      "[9, 7, 13, 12, 15, 37, 23, 15, 12, 9]\n",
      "###### 109 batch Train loss:2.3220 acc:0.5775 acc1:0.3514 mse:123056200 Test loss:1.8636 acc:0.5538 acc1:0.3285 mse:501305536\n",
      "\n",
      "2020-10-30 08:11:02\n",
      "[11, 11, 19, 12, 17, 45, 27, 28, 15, 11]\n",
      "[11, 10, 17, 16, 20, 46, 29, 21, 17, 13]\n",
      "###### 110 batch Train loss:0.9294 acc:0.4252 acc1:0.4252 mse:7863290 Test loss:1.8624 acc:0.5837 acc1:0.3256 mse:500867968\n",
      "\n",
      "2020-10-30 08:11:04\n",
      "[15, 8, 19, 12, 12, 61, 30, 26, 16, 12]\n",
      "[10, 8, 15, 14, 17, 41, 26, 19, 15, 11]\n",
      "###### 111 batch Train loss:0.8941 acc:0.5104 acc1:0.4048 mse:11588162 Test loss:1.8614 acc:0.6024 acc1:0.3230 mse:500478752\n",
      "\n",
      "2020-10-30 08:11:07\n",
      "[10, 7, 18, 10, 17, 15, 14, 2, 9, 2]\n",
      "[9, 9, 15, 14, 16, 30, 19, 13, 12, 9]\n",
      "###### 112 batch Train loss:2.1142 acc:0.5462 acc1:0.3739 mse:96939232 Test loss:1.8599 acc:0.6202 acc1:0.3205 mse:499774016\n",
      "\n",
      "2020-10-30 08:11:09\n",
      "[13, 25, 8, 11, 15, 49, 30, 30, 21, 15]\n",
      "[11, 10, 17, 16, 20, 46, 30, 21, 17, 13]\n",
      "###### 113 batch Train loss:1.7323 acc:0.4780 acc1:0.3704 mse:80542792 Test loss:1.8590 acc:0.6492 acc1:0.3181 mse:499244864\n",
      "\n",
      "2020-10-30 08:11:12\n",
      "[8, 8, 17, 18, 17, 45, 21, 6, 5, 6]\n",
      "[10, 9, 16, 15, 17, 38, 21, 13, 12, 10]\n",
      "###### 114 batch Train loss:0.8333 acc:0.5055 acc1:0.3782 mse:5501530 Test loss:1.8586 acc:0.6560 acc1:0.3161 mse:499171264\n",
      "\n",
      "2020-10-30 08:11:14\n",
      "[10, 7, 11, 20, 11, 93, 28, 13, 6, 14]\n",
      "[11, 10, 17, 16, 19, 45, 27, 18, 15, 12]\n",
      "###### 115 batch Train loss:2.6309 acc:0.4087 acc1:0.2989 mse:155375184 Test loss:1.8580 acc:0.6696 acc1:0.3142 mse:498924640\n",
      "\n",
      "2020-10-30 08:11:17\n",
      "[10, 8, 13, 20, 17, 38, 23, 14, 17, 16]\n",
      "[9, 8, 15, 14, 16, 40, 24, 16, 13, 10]\n",
      "###### 116 batch Train loss:1.5785 acc:0.6440 acc1:0.2317 mse:42218440 Test loss:1.8576 acc:0.6753 acc1:0.3126 mse:498857408\n",
      "\n",
      "2020-10-30 08:11:19\n",
      "[7, 8, 10, 9, 13, 35, 27, 13, 5, 6]\n",
      "[8, 8, 13, 12, 15, 38, 23, 15, 12, 10]\n",
      "###### 117 batch Train loss:1.7618 acc:0.5542 acc1:0.2577 mse:78475840 Test loss:1.8576 acc:0.6840 acc1:0.3113 mse:498963872\n",
      "\n",
      "2020-10-30 08:11:22\n",
      "[10, 13, 45, 45, 56, 75, 51, 12, 25, 17]\n",
      "[11, 10, 19, 17, 20, 42, 25, 15, 15, 12]\n",
      "###### 118 batch Train loss:1.5908 acc:0.5525 acc1:0.3691 mse:39074812 Test loss:1.8568 acc:0.6890 acc1:0.3102 mse:498773568\n",
      "\n",
      "2020-10-30 08:11:24\n",
      "[8, 5, 26, 16, 11, 96, 29, 14, 3, 10]\n",
      "[8, 7, 14, 12, 14, 38, 22, 14, 11, 9]\n",
      "###### 119 batch Train loss:2.1007 acc:0.6744 acc1:0.3654 mse:83833376 Test loss:1.8555 acc:0.6966 acc1:0.3092 mse:498398656\n",
      "\n",
      "2020-10-30 08:11:27\n",
      "[10, 5, 11, 10, 29, 62, 39, 19, 11, 5]\n",
      "[10, 9, 16, 14, 17, 45, 26, 16, 13, 11]\n",
      "###### 120 batch Train loss:1.2120 acc:0.6020 acc1:0.3846 mse:15773049 Test loss:1.8541 acc:0.7009 acc1:0.3083 mse:497978144\n",
      "\n",
      "2020-10-30 08:11:29\n",
      "[12, 5, 12, 13, 21, 53, 25, 25, 15, 9]\n",
      "[9, 8, 14, 12, 16, 41, 27, 18, 14, 11]\n",
      "###### 121 batch Train loss:2.2882 acc:0.5988 acc1:0.3444 mse:75602992 Test loss:1.8526 acc:0.7020 acc1:0.3074 mse:497465280\n",
      "\n",
      "2020-10-30 08:11:32\n",
      "[8, 7, 3, 9, 12, 16, 6, 3, 4, 6]\n",
      "[9, 9, 15, 13, 16, 32, 21, 15, 13, 10]\n",
      "###### 122 batch Train loss:1.4710 acc:0.5918 acc1:0.4178 mse:32254874 Test loss:1.8504 acc:0.7029 acc1:0.3065 mse:496739328\n",
      "\n",
      "2020-10-30 08:11:34\n",
      "[16, 10, 29, 16, 18, 86, 53, 41, 35, 30]\n",
      "[12, 10, 18, 17, 21, 50, 32, 23, 18, 14]\n",
      "###### 123 batch Train loss:1.4400 acc:0.5867 acc1:0.2385 mse:20363532 Test loss:1.8487 acc:0.7037 acc1:0.3057 mse:496064544\n",
      "\n",
      "2020-10-30 08:11:38\n",
      "[11, 20, 47, 40, 35, 45, 29, 16, 7, 10]\n",
      "[8, 8, 16, 14, 17, 36, 21, 11, 11, 9]\n",
      "###### 124 batch Train loss:2.3664 acc:0.6091 acc1:0.2908 mse:84794760 Test loss:1.8465 acc:0.7043 acc1:0.3051 mse:495265984\n",
      "\n",
      "2020-10-30 08:11:41\n",
      "[4, 1, 3, 7, 5, 16, 7, 20, 16, 10]\n",
      "[11, 9, 17, 15, 18, 42, 27, 20, 16, 13]\n",
      "###### 125 batch Train loss:1.0658 acc:0.4998 acc1:0.2439 mse:18099246 Test loss:1.8447 acc:0.7051 acc1:0.3047 mse:494741664\n",
      "\n",
      "2020-10-30 08:11:43\n",
      "[1, 8, 2, 0, 1, 4, 1, 6, 2, 1]\n",
      "[7, 7, 12, 10, 12, 27, 19, 14, 11, 9]\n",
      "###### 126 batch Train loss:1.6485 acc:0.5646 acc1:0.3621 mse:82339912 Test loss:1.8431 acc:0.7058 acc1:0.3044 mse:494366144\n",
      "\n",
      "2020-10-30 08:11:46\n",
      "[8, 8, 17, 18, 17, 45, 21, 6, 5, 6]\n",
      "[9, 8, 16, 14, 16, 41, 23, 12, 11, 10]\n",
      "###### 127 batch Train loss:1.0064 acc:0.6780 acc1:0.3922 mse:11378554 Test loss:1.8414 acc:0.7065 acc1:0.3043 mse:494009216\n",
      "\n",
      "2020-10-30 08:11:48\n",
      "[13, 7, 13, 14, 24, 48, 39, 23, 11, 14]\n",
      "[10, 9, 16, 14, 18, 47, 31, 19, 15, 12]\n",
      "###### 128 batch Train loss:2.9669 acc:0.5896 acc1:0.2900 mse:119175016 Test loss:1.8396 acc:0.7070 acc1:0.3040 mse:493436736\n",
      "\n",
      "2020-10-30 08:11:51\n",
      "[5, 7, 7, 13, 13, 13, 8, 2, 8, 2]\n",
      "[10, 9, 15, 14, 16, 35, 22, 15, 13, 11]\n",
      "###### 129 batch Train loss:1.8020 acc:0.5828 acc1:0.3491 mse:36188296 Test loss:1.8374 acc:0.7074 acc1:0.3037 mse:492586400\n",
      "\n",
      "2020-10-30 08:11:53\n",
      "[6, 10, 21, 13, 17, 47, 18, 19, 11, 9]\n",
      "[11, 9, 17, 14, 17, 48, 28, 16, 13, 12]\n",
      "###### 130 batch Train loss:0.8575 acc:0.6590 acc1:0.2346 mse:7983418 Test loss:1.8357 acc:0.7079 acc1:0.3038 mse:492141440\n",
      "\n",
      "2020-10-30 08:11:56\n",
      "[14, 6, 14, 4, 13, 32, 20, 13, 20, 9]\n",
      "[11, 9, 17, 15, 18, 44, 25, 13, 13, 12]\n",
      "###### 131 batch Train loss:1.6667 acc:0.5570 acc1:0.3841 mse:59936256 Test loss:1.8339 acc:0.7084 acc1:0.3038 mse:491562304\n",
      "\n",
      "2020-10-30 08:11:58\n",
      "[3, 0, 4, 7, 3, 6, 4, 13, 13, 12]\n",
      "[10, 8, 15, 13, 16, 39, 26, 18, 14, 12]\n",
      "###### 132 batch Train loss:1.6207 acc:0.4473 acc1:0.1187 mse:37956808 Test loss:1.8324 acc:0.7089 acc1:0.3039 mse:491225920\n",
      "\n",
      "2020-10-30 08:12:01\n",
      "[1, 2, 0, 0, 0, 0, 0, 1, 0, 0]\n",
      "[10, 9, 15, 14, 16, 39, 25, 18, 15, 12]\n",
      "###### 133 batch Train loss:1.3291 acc:0.6551 acc1:0.3445 mse:18475316 Test loss:1.8311 acc:0.7094 acc1:0.3042 mse:491005888\n",
      "\n",
      "2020-10-30 08:12:03\n",
      "[8, 4, 9, 10, 4, 29, 24, 18, 13, 7]\n",
      "[8, 7, 12, 11, 14, 40, 26, 15, 11, 10]\n",
      "###### 134 batch Train loss:1.1004 acc:0.6830 acc1:0.3373 mse:16116719 Test loss:1.8295 acc:0.7099 acc1:0.3045 mse:490663488\n",
      "\n",
      "2020-10-30 08:12:06\n",
      "[10, 8, 21, 19, 9, 103, 25, 15, 16, 11]\n",
      "[10, 8, 15, 13, 15, 45, 26, 15, 12, 11]\n",
      "###### 135 batch Train loss:2.2841 acc:0.5374 acc1:0.2653 mse:75692904 Test loss:1.8281 acc:0.7104 acc1:0.3048 mse:490367360\n",
      "\n",
      "2020-10-30 08:12:08\n",
      "[32, 5, 30, 37, 52, 103, 54, 61, 74, 79]\n",
      "[10, 8, 16, 14, 17, 42, 27, 19, 15, 12]\n",
      "###### 136 batch Train loss:1.2883 acc:0.5683 acc1:0.3098 mse:28759336 Test loss:1.8269 acc:0.7108 acc1:0.3052 mse:490145728\n",
      "\n",
      "2020-10-30 08:12:11\n",
      "[11, 9, 22, 9, 11, 109, 22, 25, 11, 6]\n",
      "[8, 7, 13, 11, 13, 40, 23, 13, 10, 9]\n",
      "###### 137 batch Train loss:1.4094 acc:0.6527 acc1:0.4193 mse:62142916 Test loss:1.8258 acc:0.7112 acc1:0.3053 mse:489817248\n",
      "\n",
      "2020-10-30 08:12:13\n",
      "[21, 11, 19, 17, 17, 33, 11, 9, 10, 9]\n",
      "[10, 9, 16, 14, 18, 44, 24, 13, 12, 11]\n",
      "###### 138 batch Train loss:1.4737 acc:0.4929 acc1:0.2672 mse:28581574 Test loss:1.8246 acc:0.7115 acc1:0.3054 mse:489478112\n",
      "\n",
      "2020-10-30 08:12:16\n",
      "[5, 2, 5, 11, 10, 28, 39, 14, 9, 8]\n",
      "[10, 8, 14, 12, 16, 45, 28, 17, 13, 11]\n",
      "###### 139 batch Train loss:2.9577 acc:0.6503 acc1:0.3571 mse:139187680 Test loss:1.8230 acc:0.7117 acc1:0.3055 mse:488884000\n",
      "\n",
      "2020-10-30 08:12:18\n",
      "[3, 4, 17, 10, 14, 94, 25, 21, 13, 8]\n",
      "[9, 7, 14, 12, 15, 43, 24, 15, 11, 9]\n",
      "###### 140 batch Train loss:1.2313 acc:0.7205 acc1:0.2708 mse:16429662 Test loss:1.8216 acc:0.7121 acc1:0.3058 mse:488583072\n",
      "\n",
      "2020-10-30 08:12:21\n",
      "[24, 7, 16, 31, 47, 132, 57, 89, 73, 83]\n",
      "[11, 9, 16, 14, 18, 44, 27, 20, 16, 12]\n",
      "###### 141 batch Train loss:2.6307 acc:0.6049 acc1:0.3215 mse:122555248 Test loss:1.8198 acc:0.7123 acc1:0.3061 mse:488016096\n",
      "\n",
      "2020-10-30 08:12:23\n",
      "[13, 7, 9, 9, 14, 33, 31, 10, 15, 10]\n",
      "[9, 7, 13, 12, 15, 42, 26, 16, 13, 10]\n",
      "###### 142 batch Train loss:2.7448 acc:0.6546 acc1:0.2776 mse:127889704 Test loss:1.8178 acc:0.7125 acc1:0.3064 mse:487277504\n",
      "\n",
      "2020-10-30 08:12:26\n",
      "[13, 10, 13, 22, 18, 26, 14, 4, 4, 4]\n",
      "[10, 9, 17, 14, 17, 35, 20, 14, 13, 10]\n",
      "###### 143 batch Train loss:3.1687 acc:0.6223 acc1:0.3127 mse:162072496 Test loss:1.8153 acc:0.7125 acc1:0.3066 mse:486227776\n",
      "\n",
      "2020-10-30 08:12:28\n",
      "[10, 3, 7, 4, 8, 14, 10, 3, 5, 2]\n",
      "[7, 7, 11, 10, 12, 25, 15, 12, 10, 7]\n",
      "###### 144 batch Train loss:1.8602 acc:0.6888 acc1:0.3940 mse:98257400 Test loss:1.8129 acc:0.7125 acc1:0.3067 mse:485160896\n",
      "\n",
      "2020-10-30 08:12:31\n",
      "[10, 9, 14, 27, 27, 46, 40, 19, 11, 12]\n",
      "[11, 8, 15, 13, 18, 47, 29, 21, 16, 11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### 145 batch Train loss:2.3797 acc:0.6941 acc1:0.3219 mse:118363760 Test loss:1.8105 acc:0.7124 acc1:0.3068 mse:484072768\n",
      "\n",
      "2020-10-30 08:12:33\n",
      "[7, 9, 5, 6, 7, 13, 8, 3, 1, 1]\n",
      "[7, 7, 12, 10, 12, 26, 16, 12, 10, 8]\n",
      "###### 146 batch Train loss:0.8710 acc:0.6982 acc1:0.3195 mse:12300095 Test loss:1.8084 acc:0.7125 acc1:0.3073 mse:483197952\n",
      "\n",
      "2020-10-30 08:12:36\n",
      "[12, 8, 45, 41, 54, 77, 50, 17, 12, 18]\n",
      "[8, 8, 16, 13, 17, 37, 20, 10, 11, 9]\n",
      "###### 147 batch Train loss:2.2771 acc:0.6046 acc1:0.3559 mse:78180152 Test loss:1.8061 acc:0.7125 acc1:0.3075 mse:482145536\n",
      "\n",
      "2020-10-30 08:12:38\n",
      "[7, 26, 33, 43, 32, 52, 25, 18, 11, 11]\n",
      "[10, 9, 18, 15, 19, 40, 22, 13, 13, 10]\n",
      "###### 148 batch Train loss:1.5708 acc:0.6446 acc1:0.1693 mse:39044456 Test loss:1.8040 acc:0.7127 acc1:0.3081 mse:481312320\n",
      "\n",
      "2020-10-30 08:12:41\n",
      "[2, 3, 1, 1, 3, 3, 11, 2, 4, 4]\n",
      "[8, 7, 12, 11, 14, 30, 19, 15, 13, 9]\n",
      "###### 149 batch Train loss:1.7978 acc:0.6437 acc1:0.1864 mse:52803572 Test loss:1.8020 acc:0.7130 acc1:0.3088 mse:480667776\n",
      "\n",
      "2020-10-30 08:12:43\n",
      "[16, 3, 15, 7, 13, 45, 23, 15, 16, 8]\n",
      "[10, 9, 15, 14, 17, 47, 27, 16, 14, 11]\n",
      "###### 150 batch Train loss:0.8400 acc:0.6992 acc1:0.3853 mse:6546854 Test loss:1.8006 acc:0.7134 acc1:0.3098 mse:480404896\n",
      "\n",
      "2020-10-30 08:12:46\n",
      "[7, 10, 21, 9, 8, 20, 6, 7, 5, 5]\n",
      "[7, 7, 14, 12, 15, 28, 16, 11, 10, 8]\n",
      "###### 151 batch Train loss:1.4267 acc:0.6801 acc1:0.4168 mse:41360584 Test loss:1.7992 acc:0.7137 acc1:0.3108 mse:480189056\n",
      "\n",
      "2020-10-30 08:12:48\n",
      "[35, 36, 111, 76, 138, 228, 172, 111, 103, 105]\n",
      "[12, 9, 18, 16, 20, 47, 29, 22, 18, 13]\n",
      "###### 152 batch Train loss:2.2336 acc:0.5979 acc1:0.3361 mse:137451072 Test loss:1.7981 acc:0.7140 acc1:0.3117 mse:480049664\n",
      "\n",
      "2020-10-30 08:12:51\n",
      "[28, 6, 24, 34, 51, 122, 44, 68, 76, 86]\n",
      "[11, 9, 17, 16, 19, 43, 27, 21, 18, 13]\n",
      "###### 153 batch Train loss:2.5069 acc:0.6571 acc1:0.3447 mse:127189648 Test loss:1.7967 acc:0.7142 acc1:0.3124 mse:479681120\n",
      "\n",
      "2020-10-30 08:12:53\n",
      "[7, 6, 17, 14, 15, 46, 23, 19, 18, 17]\n",
      "[9, 8, 15, 13, 16, 43, 24, 15, 12, 10]\n",
      "###### 154 batch Train loss:3.1373 acc:0.6790 acc1:0.3247 mse:42665616 Test loss:1.7955 acc:0.7143 acc1:0.3129 mse:479254592\n",
      "\n",
      "2020-10-30 08:12:57\n",
      "[6, 9, 5, 17, 26, 38, 29, 13, 13, 10]\n",
      "[8, 7, 13, 12, 15, 40, 24, 14, 12, 9]\n",
      "###### 155 batch Train loss:1.7754 acc:0.6588 acc1:0.3620 mse:61153144 Test loss:1.7942 acc:0.7144 acc1:0.3135 mse:478807808\n",
      "\n",
      "2020-10-30 08:13:00\n",
      "[46, 21, 92, 61, 137, 282, 140, 115, 134, 178]\n",
      "[12, 9, 19, 17, 21, 47, 29, 23, 19, 14]\n",
      "###### 156 batch Train loss:1.7114 acc:0.6534 acc1:0.3627 mse:51672288 Test loss:1.7931 acc:0.7145 acc1:0.3140 mse:478404800\n",
      "\n",
      "2020-10-30 08:13:02\n",
      "[19, 7, 13, 11, 19, 61, 32, 20, 14, 10]\n",
      "[9, 7, 14, 13, 17, 43, 27, 19, 15, 11]\n",
      "###### 157 batch Train loss:2.0513 acc:0.6058 acc1:0.3798 mse:83510832 Test loss:1.7922 acc:0.7144 acc1:0.3143 mse:477902656\n",
      "\n",
      "2020-10-30 08:13:04\n",
      "[12, 8, 17, 19, 23, 35, 39, 20, 14, 15]\n",
      "[9, 8, 16, 14, 17, 41, 24, 14, 12, 10]\n",
      "###### 158 batch Train loss:0.9943 acc:0.6823 acc1:0.2482 mse:13481811 Test loss:1.7914 acc:0.7146 acc1:0.3150 mse:477671552\n",
      "\n",
      "2020-10-30 08:13:07\n",
      "[15, 8, 19, 12, 12, 61, 30, 26, 16, 12]\n",
      "[10, 8, 15, 14, 18, 45, 28, 21, 16, 12]\n",
      "###### 159 batch Train loss:1.7450 acc:0.6351 acc1:0.4065 mse:72757960 Test loss:1.7907 acc:0.7146 acc1:0.3152 mse:477320320\n",
      "\n",
      "2020-10-30 08:13:09\n",
      "[2, 3, 12, 9, 11, 23, 11, 6, 2, 5]\n",
      "[8, 7, 13, 12, 14, 28, 17, 14, 12, 9]\n",
      "###### 160 batch Train loss:0.9936 acc:0.6538 acc1:0.2296 mse:14242355 Test loss:1.7900 acc:0.7148 acc1:0.3159 mse:477182400\n",
      "\n",
      "2020-10-30 08:13:12\n",
      "[13, 7, 9, 9, 14, 33, 31, 10, 15, 10]\n",
      "[9, 8, 15, 14, 17, 44, 27, 17, 14, 11]\n",
      "###### 161 batch Train loss:1.3246 acc:0.6860 acc1:0.3300 mse:36308536 Test loss:1.7891 acc:0.7151 acc1:0.3167 mse:477080192\n",
      "\n",
      "2020-10-30 08:13:14\n",
      "[3, 7, 3, 5, 5, 6, 9, 5, 3, 3]\n",
      "[9, 8, 14, 13, 15, 31, 19, 16, 13, 10]\n",
      "###### 162 batch Train loss:1.7725 acc:0.6097 acc1:0.2133 mse:47958716 Test loss:1.7883 acc:0.7156 acc1:0.3178 mse:477104224\n",
      "\n",
      "2020-10-30 08:13:17\n",
      "[5, 9, 14, 14, 15, 40, 24, 19, 14, 7]\n",
      "[10, 9, 16, 15, 18, 48, 27, 17, 14, 12]\n",
      "###### 163 batch Train loss:2.6184 acc:0.6710 acc1:0.3708 mse:119346096 Test loss:1.7873 acc:0.7158 acc1:0.3186 mse:476888256\n",
      "\n",
      "2020-10-30 08:13:19\n",
      "[10, 7, 18, 10, 17, 15, 14, 2, 9, 2]\n",
      "[8, 8, 16, 13, 16, 31, 17, 13, 11, 9]\n",
      "###### 164 batch Train loss:2.8733 acc:0.5995 acc1:0.3521 mse:135858384 Test loss:1.7859 acc:0.7159 acc1:0.3191 mse:476401888\n",
      "\n",
      "2020-10-30 08:13:22\n",
      "[49, 5, 33, 34, 50, 109, 45, 60, 91, 81]\n",
      "[9, 6, 14, 13, 16, 36, 23, 19, 15, 11]\n",
      "###### 165 batch Train loss:0.8618 acc:0.7274 acc1:0.3646 mse:8466259 Test loss:1.7848 acc:0.7161 acc1:0.3199 mse:476157952\n",
      "\n",
      "2020-10-30 08:13:24\n",
      "[5, 8, 24, 10, 16, 38, 24, 8, 9, 9]\n",
      "[9, 7, 16, 13, 16, 39, 23, 14, 11, 10]\n",
      "###### 166 batch Train loss:1.9164 acc:0.7203 acc1:0.3106 mse:66549552 Test loss:1.7832 acc:0.7164 acc1:0.3208 mse:475801824\n",
      "\n",
      "2020-10-30 08:13:27\n",
      "[9, 8, 18, 17, 27, 87, 15, 7, 23, 7]\n",
      "[9, 8, 18, 16, 19, 40, 21, 12, 13, 10]\n",
      "###### 167 batch Train loss:0.9145 acc:0.6966 acc1:0.3927 mse:8843685 Test loss:1.7819 acc:0.7167 acc1:0.3218 mse:475553888\n",
      "\n",
      "2020-10-30 08:13:30\n",
      "[8, 8, 30, 8, 19, 49, 40, 30, 8, 13]\n",
      "[10, 8, 18, 15, 18, 44, 25, 15, 12, 11]\n",
      "###### 168 batch Train loss:2.0530 acc:0.6618 acc1:0.3568 mse:80997136 Test loss:1.7801 acc:0.7169 acc1:0.3225 mse:475135168\n",
      "\n",
      "2020-10-30 08:13:32\n",
      "[15, 10, 17, 14, 9, 25, 17, 8, 8, 8]\n",
      "[11, 8, 18, 16, 19, 42, 22, 13, 13, 11]\n",
      "###### 169 batch Train loss:2.6793 acc:0.6261 acc1:0.3471 mse:92357408 Test loss:1.7777 acc:0.7171 acc1:0.3231 mse:474373760\n",
      "\n",
      "2020-10-30 08:13:35\n",
      "[8, 4, 9, 10, 4, 29, 24, 18, 13, 7]\n",
      "[9, 7, 14, 13, 16, 40, 25, 17, 13, 10]\n",
      "###### 170 batch Train loss:1.0846 acc:0.6953 acc1:0.2853 mse:15523956 Test loss:1.7755 acc:0.7173 acc1:0.3239 mse:473865728\n",
      "\n",
      "2020-10-30 08:13:37\n",
      "[32, 5, 30, 37, 52, 103, 54, 61, 74, 79]\n",
      "[11, 8, 18, 16, 19, 42, 26, 22, 18, 13]\n",
      "###### 171 batch Train loss:2.5198 acc:0.6913 acc1:0.3837 mse:117360344 Test loss:1.7730 acc:0.7173 acc1:0.3243 mse:472963904\n",
      "\n",
      "2020-10-30 08:13:39\n",
      "[6, 5, 15, 13, 14, 56, 24, 14, 8, 10]\n",
      "[10, 8, 18, 15, 18, 46, 25, 17, 13, 11]\n",
      "###### 172 batch Train loss:1.7718 acc:0.6499 acc1:0.3935 mse:65260648 Test loss:1.7709 acc:0.7173 acc1:0.3245 mse:472165120\n",
      "\n",
      "2020-10-30 08:13:42\n",
      "[3, 4, 17, 10, 14, 94, 25, 21, 13, 8]\n",
      "[10, 8, 17, 14, 17, 44, 23, 16, 12, 10]\n",
      "###### 173 batch Train loss:1.6201 acc:0.6813 acc1:0.3435 mse:54869136 Test loss:1.7690 acc:0.7173 acc1:0.3247 mse:471434944\n",
      "\n",
      "2020-10-30 08:13:44\n",
      "[10, 5, 11, 10, 29, 62, 39, 19, 11, 5]\n",
      "[10, 8, 18, 15, 18, 48, 25, 17, 13, 11]\n",
      "###### 174 batch Train loss:1.3171 acc:0.6919 acc1:0.3224 mse:32574286 Test loss:1.7672 acc:0.7174 acc1:0.3251 mse:470937856\n",
      "\n",
      "2020-10-30 08:13:47\n",
      "[35, 36, 111, 76, 138, 228, 172, 111, 103, 105]\n",
      "[13, 9, 21, 18, 22, 49, 29, 25, 20, 14]\n",
      "###### 175 batch Train loss:2.6164 acc:0.5805 acc1:0.3134 mse:129681504 Test loss:1.7656 acc:0.7174 acc1:0.3254 mse:470454592\n",
      "\n",
      "2020-10-30 08:13:50\n",
      "[14, 6, 14, 4, 13, 32, 20, 13, 20, 9]\n",
      "[11, 9, 20, 17, 21, 45, 23, 14, 14, 12]\n",
      "###### 176 batch Train loss:1.9894 acc:0.6094 acc1:0.3837 mse:85675608 Test loss:1.7640 acc:0.7173 acc1:0.3253 mse:469809024\n",
      "\n",
      "2020-10-30 08:13:52\n",
      "[1, 2, 0, 0, 0, 0, 0, 1, 0, 0]\n",
      "[11, 9, 17, 15, 18, 39, 23, 20, 17, 12]\n",
      "###### 177 batch Train loss:1.4283 acc:0.5426 acc1:0.3689 mse:33523888 Test loss:1.7625 acc:0.7174 acc1:0.3255 mse:469451456\n",
      "\n",
      "2020-10-30 08:13:54\n",
      "[27, 34, 101, 76, 117, 209, 179, 104, 116, 110]\n",
      "[10, 8, 18, 15, 19, 43, 26, 23, 17, 12]\n",
      "###### 178 batch Train loss:2.7498 acc:0.6839 acc1:0.2295 mse:175517728 Test loss:1.7611 acc:0.7174 acc1:0.3256 mse:468975872\n",
      "\n",
      "2020-10-30 08:13:57\n",
      "[54, 21, 87, 59, 142, 245, 167, 123, 135, 156]\n",
      "[11, 9, 19, 16, 20, 44, 27, 23, 18, 13]\n",
      "###### 179 batch Train loss:2.5415 acc:0.6654 acc1:0.2728 mse:89365192 Test loss:1.7597 acc:0.7173 acc1:0.3256 mse:468431392\n",
      "\n",
      "2020-10-30 08:13:59\n",
      "[11, 6, 14, 18, 11, 31, 13, 6, 10, 9]\n",
      "[9, 8, 17, 15, 18, 39, 20, 11, 11, 10]\n",
      "###### 180 batch Train loss:1.0416 acc:0.6527 acc1:0.4419 mse:24983704 Test loss:1.7585 acc:0.7173 acc1:0.3257 mse:467988192\n",
      "\n",
      "2020-10-30 08:14:02\n",
      "[8, 5, 26, 16, 11, 96, 29, 14, 3, 10]\n",
      "[9, 7, 16, 13, 16, 43, 23, 15, 12, 9]\n",
      "###### 181 batch Train loss:1.9985 acc:0.6980 acc1:0.2550 mse:83747984 Test loss:1.7573 acc:0.7174 acc1:0.3260 mse:467707552\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-30 08:14:04\n",
      "[15, 16, 45, 22, 20, 96, 43, 38, 33, 32]\n",
      "[13, 10, 21, 18, 23, 54, 32, 27, 21, 15]\n",
      "###### 182 batch Train loss:1.9593 acc:0.6028 acc1:0.2357 mse:101504816 Test loss:1.7563 acc:0.7175 acc1:0.3264 mse:467495360\n",
      "\n",
      "2020-10-30 08:14:07\n",
      "[22, 6, 13, 10, 15, 35, 28, 18, 8, 13]\n",
      "[9, 8, 16, 14, 17, 40, 23, 14, 11, 10]\n",
      "###### 183 batch Train loss:1.2339 acc:0.6906 acc1:0.2032 mse:21017660 Test loss:1.7555 acc:0.7179 acc1:0.3272 mse:467619072\n",
      "\n",
      "2020-10-30 08:14:09\n",
      "[8, 10, 40, 41, 39, 61, 40, 19, 17, 17]\n",
      "[9, 8, 18, 17, 20, 40, 21, 11, 12, 10]\n",
      "###### 184 batch Train loss:1.7378 acc:0.5852 acc1:0.2343 mse:26835318 Test loss:1.7543 acc:0.7182 acc1:0.3280 mse:467656832\n",
      "\n",
      "2020-10-30 08:14:12\n",
      "[4, 4, 9, 9, 8, 13, 8, 2, 4, 5]\n",
      "[9, 9, 14, 14, 16, 33, 20, 17, 14, 11]\n",
      "###### 185 batch Train loss:0.9075 acc:0.6092 acc1:0.3605 mse:3030846 Test loss:1.7532 acc:0.7187 acc1:0.3289 mse:467806624\n",
      "\n",
      "2020-10-30 08:14:16\n",
      "[2, 7, 8, 8, 8, 7, 7, 5, 1, 3]\n",
      "[8, 8, 14, 13, 15, 30, 18, 15, 12, 9]\n",
      "###### 186 batch Train loss:0.8688 acc:0.7041 acc1:0.3821 mse:13942793 Test loss:1.7522 acc:0.7192 acc1:0.3299 mse:467982624\n",
      "\n",
      "2020-10-30 08:14:18\n",
      "[2, 6, 4, 1, 2, 2, 4, 2, 1, 4]\n",
      "[8, 7, 12, 12, 14, 31, 19, 17, 13, 9]\n",
      "###### 187 batch Train loss:2.1916 acc:0.6315 acc1:0.3226 mse:78572992 Test loss:1.7512 acc:0.7197 acc1:0.3307 mse:468068480\n",
      "\n",
      "2020-10-30 08:14:21\n",
      "[1, 8, 2, 0, 1, 4, 1, 6, 2, 1]\n",
      "[7, 6, 11, 10, 12, 26, 17, 15, 11, 8]\n",
      "###### 188 batch Train loss:1.1734 acc:0.6680 acc1:0.3394 mse:42023272 Test loss:1.7506 acc:0.7201 acc1:0.3314 mse:468249152\n",
      "\n",
      "2020-10-30 08:14:23\n",
      "[16, 10, 29, 16, 18, 86, 53, 41, 35, 30]\n",
      "[12, 10, 19, 18, 22, 53, 32, 25, 19, 15]\n",
      "###### 189 batch Train loss:2.8451 acc:0.6288 acc1:0.3508 mse:123238848 Test loss:1.7494 acc:0.7203 acc1:0.3318 mse:467962816\n",
      "\n",
      "2020-10-30 08:14:26\n",
      "[34, 11, 23, 32, 41, 124, 55, 73, 86, 86]\n",
      "[10, 8, 15, 15, 18, 40, 25, 21, 16, 12]\n",
      "###### 190 batch Train loss:2.2592 acc:0.7038 acc1:0.3256 mse:67356184 Test loss:1.7479 acc:0.7204 acc1:0.3321 mse:467445984\n",
      "\n",
      "2020-10-30 08:14:28\n",
      "[16, 9, 54, 51, 54, 59, 43, 5, 16, 16]\n",
      "[9, 10, 18, 18, 21, 44, 23, 12, 12, 11]\n",
      "###### 191 batch Train loss:2.6351 acc:0.6322 acc1:0.3818 mse:118792216 Test loss:1.7460 acc:0.7204 acc1:0.3321 mse:466697792\n",
      "\n",
      "2020-10-30 08:14:31\n",
      "[8, 1, 3, 10, 6, 10, 6, 24, 21, 8]\n",
      "[9, 8, 14, 14, 16, 37, 23, 19, 15, 11]\n",
      "###### 192 batch Train loss:0.8874 acc:0.6562 acc1:0.2484 mse:6523957 Test loss:1.7446 acc:0.7205 acc1:0.3324 mse:466270784\n",
      "\n",
      "2020-10-30 08:14:33\n",
      "[1, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "[7, 6, 11, 11, 13, 29, 19, 16, 12, 9]\n",
      "###### 193 batch Train loss:2.0367 acc:0.6764 acc1:0.3711 mse:100076224 Test loss:1.7430 acc:0.7207 acc1:0.3328 mse:465840736\n",
      "\n",
      "2020-10-30 08:14:36\n",
      "[14, 11, 13, 11, 15, 46, 27, 7, 13, 18]\n",
      "[9, 9, 16, 16, 18, 44, 25, 14, 11, 11]\n",
      "###### 194 batch Train loss:2.0183 acc:0.6458 acc1:0.3556 mse:79329048 Test loss:1.7413 acc:0.7207 acc1:0.3330 mse:465308512\n",
      "\n",
      "2020-10-30 08:14:38\n",
      "[38, 22, 91, 51, 139, 283, 164, 102, 133, 185]\n",
      "[9, 7, 14, 14, 17, 39, 25, 21, 15, 11]\n",
      "###### 195 batch Train loss:1.8203 acc:0.6224 acc1:0.3163 mse:53375212 Test loss:1.7396 acc:0.7209 acc1:0.3333 mse:464765856\n",
      "\n",
      "2020-10-30 08:14:41\n",
      "[10, 9, 22, 11, 11, 105, 22, 23, 12, 9]\n",
      "[9, 8, 15, 15, 16, 48, 25, 15, 11, 10]\n",
      "###### 196 batch Train loss:1.7712 acc:0.6538 acc1:0.3973 mse:63359868 Test loss:1.7381 acc:0.7209 acc1:0.3334 mse:464236160\n",
      "\n",
      "2020-10-30 08:14:43\n",
      "[12, 8, 17, 19, 23, 35, 39, 20, 14, 15]\n",
      "[9, 8, 15, 15, 16, 42, 24, 13, 11, 10]\n",
      "###### 197 batch Train loss:3.2586 acc:0.6483 acc1:0.3173 mse:151289296 Test loss:1.7361 acc:0.7208 acc1:0.3333 mse:463359904\n",
      "\n",
      "2020-10-30 08:14:46\n",
      "[8, 8, 17, 18, 17, 45, 21, 6, 5, 6]\n",
      "[9, 9, 15, 16, 18, 43, 20, 10, 11, 10]\n",
      "###### 198 batch Train loss:1.0526 acc:0.7023 acc1:0.4078 mse:18637030 Test loss:1.7345 acc:0.7207 acc1:0.3333 mse:462636928\n",
      "\n",
      "2020-10-30 08:14:48\n",
      "[15, 15, 28, 19, 27, 73, 44, 30, 29, 30]\n",
      "[11, 9, 16, 16, 19, 48, 29, 24, 18, 13]\n",
      "###### 199 batch Train loss:2.3750 acc:0.5154 acc1:0.1270 mse:105274184 Test loss:1.7330 acc:0.7206 acc1:0.3332 mse:462039936\n",
      "\n",
      "2020-10-30 08:14:51\n",
      "[6, 2, 1, 9, 8, 6, 8, 0, 2, 4]\n",
      "[7, 6, 10, 10, 11, 26, 16, 14, 11, 8]\n",
      "###### 200 batch Train loss:1.6884 acc:0.6975 acc1:0.3700 mse:85535648 Test loss:1.7316 acc:0.7206 acc1:0.3333 mse:461509632\n",
      "\n",
      "2020-10-30 08:14:53\n",
      "[5, 11, 2, 14, 12, 47, 25, 13, 15, 12]\n",
      "[9, 8, 13, 14, 16, 45, 27, 17, 13, 10]\n",
      "###### 201 batch Train loss:0.7410 acc:0.7146 acc1:0.4119 mse:6874436 Test loss:1.7305 acc:0.7207 acc1:0.3337 mse:461317216\n",
      "\n",
      "2020-10-30 08:14:56\n",
      "[10, 8, 21, 19, 9, 103, 25, 15, 16, 11]\n",
      "[9, 9, 15, 15, 16, 48, 25, 16, 12, 10]\n",
      "###### 202 batch Train loss:0.9427 acc:0.6734 acc1:0.2685 mse:15435960 Test loss:1.7297 acc:0.7211 acc1:0.3344 mse:461402560\n",
      "\n",
      "2020-10-30 08:14:58\n",
      "[46, 21, 92, 61, 137, 282, 140, 115, 134, 178]\n",
      "[12, 10, 17, 17, 20, 49, 29, 24, 19, 14]\n",
      "###### 203 batch Train loss:1.6489 acc:0.6234 acc1:0.3703 mse:46044292 Test loss:1.7292 acc:0.7215 acc1:0.3352 mse:461729088\n",
      "\n",
      "2020-10-30 08:15:01\n",
      "[6, 1, 3, 7, 8, 13, 3, 22, 12, 8]\n",
      "[8, 6, 12, 11, 14, 33, 21, 19, 14, 9]\n",
      "###### 204 batch Train loss:1.5192 acc:0.6784 acc1:0.3108 mse:35288216 Test loss:1.7287 acc:0.7219 acc1:0.3360 mse:462023616\n",
      "\n",
      "2020-10-30 08:15:03\n",
      "[14, 8, 16, 26, 34, 23, 15, 10, 11, 8]\n",
      "[8, 8, 15, 15, 17, 40, 19, 9, 11, 9]\n",
      "###### 205 batch Train loss:1.0283 acc:0.7307 acc1:0.4093 mse:18133094 Test loss:1.7281 acc:0.7223 acc1:0.3369 mse:462262784\n",
      "\n",
      "2020-10-30 08:15:06\n",
      "[12, 16, 45, 40, 52, 44, 39, 14, 15, 16]\n",
      "[8, 9, 17, 17, 19, 44, 21, 10, 11, 10]\n",
      "###### 206 batch Train loss:2.0095 acc:0.6669 acc1:0.2860 mse:84367128 Test loss:1.7276 acc:0.7226 acc1:0.3376 mse:462485760\n",
      "\n",
      "2020-10-30 08:15:09\n",
      "[8, 5, 26, 16, 11, 96, 29, 14, 3, 10]\n",
      "[8, 7, 13, 13, 14, 43, 23, 14, 11, 9]\n",
      "###### 207 batch Train loss:2.5240 acc:0.6633 acc1:0.3152 mse:162394000 Test loss:1.7272 acc:0.7229 acc1:0.3382 mse:462675136\n",
      "\n",
      "2020-10-30 08:15:11\n",
      "[17, 12, 32, 16, 28, 79, 36, 43, 32, 27]\n",
      "[10, 8, 16, 14, 18, 45, 28, 24, 17, 12]\n",
      "###### 208 batch Train loss:1.2483 acc:0.7349 acc1:0.3993 mse:37671360 Test loss:1.7267 acc:0.7231 acc1:0.3387 mse:462767616\n",
      "\n",
      "2020-10-30 08:15:14\n",
      "[0, 2, 0, 0, 0, 1, 0, 0, 1, 0]\n",
      "[9, 8, 13, 13, 15, 35, 21, 19, 15, 11]\n",
      "###### 209 batch Train loss:1.5437 acc:0.6594 acc1:0.3460 mse:29399918 Test loss:1.7259 acc:0.7233 acc1:0.3391 mse:462739680\n",
      "\n",
      "2020-10-30 08:15:16\n",
      "[12, 5, 16, 16, 12, 33, 25, 6, 11, 12]\n",
      "[9, 9, 14, 14, 16, 45, 26, 16, 13, 11]\n",
      "###### 210 batch Train loss:1.2948 acc:0.6993 acc1:0.3642 mse:36524224 Test loss:1.7250 acc:0.7236 acc1:0.3397 mse:462705856\n",
      "\n",
      "2020-10-30 08:15:19\n",
      "[35, 36, 111, 76, 138, 228, 172, 111, 103, 105]\n",
      "[12, 10, 18, 17, 20, 48, 29, 25, 19, 14]\n",
      "###### 211 batch Train loss:2.7632 acc:0.6823 acc1:0.3212 mse:136817264 Test loss:1.7239 acc:0.7237 acc1:0.3401 mse:462519872\n",
      "\n",
      "2020-10-30 08:15:21\n",
      "[24, 8, 23, 40, 40, 128, 60, 60, 95, 81]\n",
      "[10, 8, 15, 14, 17, 39, 24, 22, 17, 12]\n",
      "###### 212 batch Train loss:1.2402 acc:0.7128 acc1:0.3457 mse:16882532 Test loss:1.7230 acc:0.7239 acc1:0.3408 mse:462411008\n",
      "\n",
      "2020-10-30 08:15:23\n",
      "[3, 2, 1, 2, 2, 1, 0, 0, 0, 0]\n",
      "[9, 8, 14, 14, 16, 36, 22, 20, 15, 11]\n",
      "###### 213 batch Train loss:1.9401 acc:0.5690 acc1:0.3290 mse:97973504 Test loss:1.7222 acc:0.7241 acc1:0.3412 mse:462403104\n",
      "\n",
      "2020-10-30 08:15:26\n",
      "[17, 12, 34, 15, 37, 79, 38, 27, 28, 37]\n",
      "[10, 8, 17, 15, 18, 44, 28, 25, 17, 13]\n",
      "###### 214 batch Train loss:1.3746 acc:0.7037 acc1:0.3917 mse:35067224 Test loss:1.7212 acc:0.7243 acc1:0.3416 mse:462313312\n",
      "\n",
      "2020-10-30 08:15:28\n",
      "[42, 12, 30, 34, 50, 114, 49, 76, 75, 83]\n",
      "[9, 7, 15, 14, 16, 37, 24, 22, 16, 12]\n",
      "###### 215 batch Train loss:1.6725 acc:0.6027 acc1:0.3464 mse:48429508 Test loss:1.7196 acc:0.7243 acc1:0.3418 mse:461860800\n",
      "\n",
      "2020-10-30 08:15:31\n",
      "[12, 8, 45, 41, 54, 77, 50, 17, 12, 18]\n",
      "[8, 8, 17, 17, 19, 39, 21, 10, 11, 10]\n",
      "###### 216 batch Train loss:2.0047 acc:0.6906 acc1:0.3625 mse:12220442 Test loss:1.7175 acc:0.7243 acc1:0.3419 mse:461173184\n",
      "\n",
      "2020-10-30 08:15:35\n",
      "[7, 8, 17, 12, 13, 42, 26, 20, 10, 8]\n",
      "[10, 9, 15, 15, 18, 45, 28, 19, 15, 12]\n",
      "###### 217 batch Train loss:1.9303 acc:0.6711 acc1:0.2815 mse:83140936 Test loss:1.7154 acc:0.7244 acc1:0.3421 mse:460537280\n",
      "\n",
      "2020-10-30 08:15:37\n",
      "[7, 26, 33, 43, 32, 52, 25, 18, 11, 11]\n",
      "[9, 9, 19, 18, 21, 41, 22, 13, 12, 10]\n",
      "###### 218 batch Train loss:2.6632 acc:0.6700 acc1:0.4123 mse:114312792 Test loss:1.7131 acc:0.7242 acc1:0.3419 mse:459568768\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-30 08:15:40\n",
      "[18, 10, 13, 18, 18, 33, 16, 9, 15, 4]\n",
      "[9, 7, 16, 15, 17, 37, 20, 10, 10, 10]\n",
      "###### 219 batch Train loss:1.6456 acc:0.6971 acc1:0.3499 mse:47902444 Test loss:1.7113 acc:0.7241 acc1:0.3418 mse:458798016\n",
      "\n",
      "2020-10-30 08:15:42\n",
      "[14, 11, 13, 11, 15, 46, 27, 7, 13, 18]\n",
      "[10, 8, 17, 16, 18, 42, 26, 15, 12, 11]\n",
      "###### 220 batch Train loss:1.0802 acc:0.7066 acc1:0.4399 mse:33137678 Test loss:1.7100 acc:0.7240 acc1:0.3417 mse:458305472\n",
      "\n",
      "2020-10-30 08:15:45\n",
      "[4, 4, 8, 13, 13, 7, 7, 3, 7, 3]\n",
      "[8, 6, 11, 10, 13, 26, 17, 16, 12, 9]\n",
      "###### 221 batch Train loss:1.2175 acc:0.6675 acc1:0.3045 mse:17459312 Test loss:1.7086 acc:0.7240 acc1:0.3417 mse:457866528\n",
      "\n",
      "2020-10-30 08:15:47\n",
      "[2, 7, 8, 8, 8, 7, 7, 5, 1, 3]\n",
      "[8, 7, 12, 11, 14, 27, 16, 15, 12, 9]\n",
      "###### 222 batch Train loss:1.2402 acc:0.7368 acc1:0.3723 mse:18980998 Test loss:1.7073 acc:0.7241 acc1:0.3418 mse:457522336\n",
      "\n",
      "2020-10-30 08:15:50\n",
      "[5, 3, 18, 14, 10, 34, 10, 6, 6, 3]\n",
      "[9, 8, 17, 14, 17, 30, 17, 14, 11, 9]\n",
      "###### 223 batch Train loss:1.0593 acc:0.7045 acc1:0.4261 mse:31752242 Test loss:1.7064 acc:0.7242 acc1:0.3419 mse:457398048\n",
      "\n",
      "2020-10-30 08:15:52\n",
      "[7, 11, 12, 8, 21, 27, 17, 11, 13, 7]\n",
      "[11, 9, 15, 15, 18, 46, 29, 19, 14, 12]\n",
      "###### 224 batch Train loss:1.7176 acc:0.6392 acc1:0.4390 mse:83806688 Test loss:1.7053 acc:0.7243 acc1:0.3417 mse:457043360\n",
      "\n",
      "2020-10-30 08:15:55\n",
      "[4, 1, 6, 10, 6, 21, 5, 22, 16, 13]\n",
      "[11, 8, 16, 15, 18, 39, 25, 23, 17, 13]\n",
      "###### 225 batch Train loss:0.9527 acc:0.6841 acc1:0.2109 mse:9452209 Test loss:1.7046 acc:0.7246 acc1:0.3421 mse:457121504\n",
      "\n",
      "2020-10-30 08:15:57\n",
      "[1, 8, 2, 0, 1, 4, 1, 6, 2, 1]\n",
      "[7, 5, 10, 10, 12, 25, 17, 17, 11, 8]\n",
      "###### 226 batch Train loss:1.5886 acc:0.6701 acc1:0.3750 mse:78559488 Test loss:1.7039 acc:0.7248 acc1:0.3424 mse:457103040\n",
      "\n",
      "2020-10-30 08:16:00\n",
      "[10, 17, 39, 38, 46, 53, 24, 3, 16, 9]\n",
      "[8, 8, 18, 17, 20, 38, 21, 12, 10, 9]\n",
      "###### 227 batch Train loss:2.2983 acc:0.6948 acc1:0.4294 mse:116801824 Test loss:1.7027 acc:0.7249 acc1:0.3423 mse:456690080\n",
      "\n",
      "2020-10-30 08:16:02\n",
      "[1, 2, 0, 0, 0, 0, 0, 1, 0, 0]\n",
      "[10, 8, 14, 14, 16, 35, 22, 21, 15, 12]\n",
      "###### 228 batch Train loss:0.9732 acc:0.6398 acc1:0.2955 mse:9827831 Test loss:1.7020 acc:0.7251 acc1:0.3424 mse:456673664\n",
      "\n",
      "2020-10-30 08:16:05\n",
      "[4, 8, 7, 5, 7, 22, 12, 3, 6, 1]\n",
      "[6, 5, 9, 9, 11, 22, 15, 15, 10, 7]\n",
      "###### 229 batch Train loss:2.0722 acc:0.6687 acc1:0.4198 mse:75500048 Test loss:1.7003 acc:0.7251 acc1:0.3421 mse:456102496\n",
      "\n",
      "2020-10-30 08:16:08\n",
      "[11, 7, 16, 11, 22, 57, 32, 25, 11, 12]\n",
      "[11, 9, 15, 15, 20, 49, 32, 25, 16, 13]\n",
      "###### 230 batch Train loss:2.1163 acc:0.7064 acc1:0.3533 mse:79132088 Test loss:1.6982 acc:0.7250 acc1:0.3419 mse:455265536\n",
      "\n",
      "2020-10-30 08:16:10\n",
      "[37, 12, 91, 52, 124, 265, 142, 115, 139, 151]\n",
      "[12, 9, 17, 17, 20, 44, 28, 25, 18, 14]\n",
      "###### 231 batch Train loss:2.4144 acc:0.6600 acc1:0.3577 mse:120318784 Test loss:1.6962 acc:0.7249 acc1:0.3415 mse:454361792\n",
      "\n",
      "2020-10-30 08:16:13\n",
      "[12, 14, 10, 20, 19, 42, 16, 10, 14, 12]\n",
      "[10, 9, 18, 18, 21, 43, 22, 11, 12, 11]\n",
      "###### 232 batch Train loss:2.0117 acc:0.6734 acc1:0.3425 mse:84535760 Test loss:1.6940 acc:0.7248 acc1:0.3411 mse:453385600\n",
      "\n",
      "2020-10-30 08:16:15\n",
      "[10, 3, 7, 4, 8, 14, 10, 3, 5, 2]\n",
      "[6, 6, 10, 9, 11, 22, 13, 13, 9, 6]\n",
      "###### 233 batch Train loss:0.7915 acc:0.7095 acc1:0.3082 mse:10839192 Test loss:1.6921 acc:0.7248 acc1:0.3411 mse:452664320\n",
      "\n",
      "2020-10-30 08:16:18\n",
      "[6, 9, 18, 13, 9, 45, 31, 12, 15, 10]\n",
      "[9, 8, 14, 14, 16, 42, 26, 15, 11, 10]\n",
      "###### 234 batch Train loss:1.6971 acc:0.6861 acc1:0.3740 mse:51139648 Test loss:1.6903 acc:0.7249 acc1:0.3413 mse:451979040\n",
      "\n",
      "2020-10-30 08:16:20\n",
      "[7, 10, 21, 9, 8, 20, 6, 7, 5, 5]\n",
      "[7, 7, 15, 13, 15, 26, 14, 11, 9, 7]\n",
      "###### 235 batch Train loss:2.0781 acc:0.7095 acc1:0.3850 mse:78150352 Test loss:1.6883 acc:0.7248 acc1:0.3414 mse:451105312\n",
      "\n",
      "2020-10-30 08:16:23\n",
      "[22, 6, 13, 10, 15, 35, 28, 18, 8, 13]\n",
      "[9, 7, 15, 15, 17, 39, 25, 12, 10, 9]\n",
      "###### 236 batch Train loss:1.8978 acc:0.7160 acc1:0.2690 mse:93826032 Test loss:1.6864 acc:0.7248 acc1:0.3417 mse:450325760\n",
      "\n",
      "2020-10-30 08:16:25\n",
      "[42, 29, 108, 77, 133, 234, 205, 111, 96, 96]\n",
      "[11, 8, 17, 16, 20, 43, 28, 24, 17, 12]\n",
      "###### 237 batch Train loss:1.9730 acc:0.6460 acc1:0.3072 mse:82316120 Test loss:1.6846 acc:0.7249 acc1:0.3419 mse:449646592\n",
      "\n",
      "2020-10-30 08:16:28\n",
      "[8, 8, 30, 8, 19, 49, 40, 30, 8, 13]\n",
      "[10, 8, 16, 16, 18, 43, 26, 13, 10, 10]\n",
      "###### 238 batch Train loss:1.4403 acc:0.7170 acc1:0.3512 mse:50618916 Test loss:1.6829 acc:0.7249 acc1:0.3422 mse:449115552\n",
      "\n",
      "2020-10-30 08:16:30\n",
      "[10, 8, 21, 19, 9, 103, 25, 15, 16, 11]\n",
      "[10, 8, 15, 15, 18, 45, 26, 15, 11, 10]\n",
      "###### 239 batch Train loss:0.9415 acc:0.6633 acc1:0.2842 mse:10228257 Test loss:1.6817 acc:0.7252 acc1:0.3429 mse:448908992\n",
      "\n",
      "2020-10-30 08:16:33\n",
      "[3, 7, 3, 5, 5, 6, 9, 5, 3, 3]\n",
      "[8, 7, 11, 11, 13, 26, 16, 15, 11, 8]\n",
      "###### 240 batch Train loss:1.6938 acc:0.6127 acc1:0.2454 mse:42599064 Test loss:1.6803 acc:0.7255 acc1:0.3435 mse:448597984\n",
      "\n",
      "2020-10-30 08:16:35\n",
      "[17, 4, 14, 14, 23, 55, 20, 19, 19, 8]\n",
      "[10, 9, 16, 16, 18, 47, 27, 15, 12, 10]\n",
      "###### 241 batch Train loss:1.8959 acc:0.7181 acc1:0.4008 mse:72201112 Test loss:1.6787 acc:0.7256 acc1:0.3440 mse:448158656\n",
      "\n",
      "2020-10-30 08:16:38\n",
      "[24, 8, 23, 40, 40, 128, 60, 60, 95, 81]\n",
      "[10, 8, 15, 14, 18, 38, 24, 21, 16, 11]\n",
      "###### 242 batch Train loss:0.9656 acc:0.7076 acc1:0.3226 mse:8981982 Test loss:1.6777 acc:0.7260 acc1:0.3449 mse:448096512\n",
      "\n",
      "2020-10-30 08:16:41\n",
      "[16, 3, 15, 7, 13, 45, 23, 15, 16, 8]\n",
      "[10, 8, 15, 15, 17, 46, 26, 15, 12, 10]\n",
      "###### 243 batch Train loss:2.4891 acc:0.6599 acc1:0.3126 mse:89054600 Test loss:1.6769 acc:0.7263 acc1:0.3460 mse:448092992\n",
      "\n",
      "2020-10-30 08:16:43\n",
      "[30, 41, 99, 82, 134, 202, 228, 92, 115, 102]\n",
      "[12, 9, 18, 16, 21, 45, 28, 25, 19, 13]\n",
      "###### 244 batch Train loss:2.0558 acc:0.6718 acc1:0.3796 mse:96255832 Test loss:1.6760 acc:0.7266 acc1:0.3468 mse:447984128\n",
      "\n",
      "2020-10-30 08:16:46\n",
      "[12, 16, 45, 40, 52, 44, 39, 14, 15, 16]\n",
      "[9, 9, 19, 18, 22, 43, 22, 10, 12, 10]\n",
      "###### 245 batch Train loss:2.2014 acc:0.6848 acc1:0.3649 mse:75975976 Test loss:1.6750 acc:0.7266 acc1:0.3474 mse:447716160\n",
      "\n",
      "2020-10-30 08:16:48\n",
      "[4, 9, 11, 9, 12, 35, 28, 14, 11, 7]\n",
      "[10, 9, 14, 14, 18, 44, 27, 17, 14, 11]\n",
      "###### 246 batch Train loss:2.1419 acc:0.7162 acc1:0.3455 mse:103161808 Test loss:1.6741 acc:0.7266 acc1:0.3478 mse:447443904\n",
      "\n",
      "2020-10-30 08:16:50\n",
      "[4, 22, 47, 30, 35, 70, 36, 15, 11, 13]\n",
      "[10, 11, 21, 20, 24, 44, 23, 12, 13, 10]\n",
      "###### 247 batch Train loss:2.2385 acc:0.5683 acc1:0.2439 mse:25122916 Test loss:1.6726 acc:0.7266 acc1:0.3481 mse:446999616\n",
      "\n",
      "2020-10-30 08:16:54\n",
      "[15, 8, 19, 12, 12, 61, 30, 26, 16, 12]\n",
      "[11, 9, 15, 14, 20, 45, 29, 23, 16, 11]\n",
      "###### 248 batch Train loss:0.8216 acc:0.7370 acc1:0.4170 mse:6523492 Test loss:1.6717 acc:0.7266 acc1:0.3486 mse:446802976\n",
      "\n",
      "2020-10-30 08:16:57\n",
      "[1, 2, 0, 1, 0, 0, 0, 1, 1, 0]\n",
      "[9, 7, 13, 12, 15, 32, 20, 19, 14, 10]\n",
      "###### 249 batch Train loss:1.5076 acc:0.6906 acc1:0.4211 mse:48748512 Test loss:1.6706 acc:0.7266 acc1:0.3489 mse:446555168\n",
      "\n",
      "2020-10-30 08:16:59\n",
      "[3, 0, 6, 9, 8, 7, 6, 19, 14, 10]\n",
      "[9, 7, 14, 12, 16, 34, 21, 21, 15, 11]\n",
      "###### 250 batch Train loss:1.7520 acc:0.6392 acc1:0.1416 mse:62589388 Test loss:1.6700 acc:0.7269 acc1:0.3495 mse:446633024\n",
      "\n",
      "2020-10-30 08:17:02\n",
      "[25, 36, 106, 85, 123, 195, 209, 111, 84, 103]\n",
      "[13, 10, 20, 17, 23, 49, 30, 27, 21, 15]\n",
      "###### 251 batch Train loss:2.9843 acc:0.6883 acc1:0.3958 mse:146852816 Test loss:1.6689 acc:0.7267 acc1:0.3495 mse:446159936\n",
      "\n",
      "2020-10-30 08:17:04\n",
      "[13, 10, 13, 22, 18, 26, 14, 4, 4, 4]\n",
      "[9, 10, 19, 14, 18, 32, 16, 14, 12, 9]\n",
      "###### 252 batch Train loss:1.3254 acc:0.6979 acc1:0.3846 mse:25166756 Test loss:1.6679 acc:0.7267 acc1:0.3496 mse:445950112\n",
      "\n",
      "2020-10-30 08:17:07\n",
      "[15, 15, 28, 19, 27, 73, 44, 30, 29, 30]\n",
      "[12, 9, 20, 16, 21, 48, 30, 28, 20, 15]\n",
      "###### 253 batch Train loss:1.3637 acc:0.6656 acc1:0.2278 mse:34019792 Test loss:1.6669 acc:0.7268 acc1:0.3498 mse:445848384\n",
      "\n",
      "2020-10-30 08:17:10\n",
      "[30, 41, 99, 82, 134, 202, 228, 92, 115, 102]\n",
      "[13, 10, 20, 17, 22, 47, 29, 27, 20, 15]\n",
      "###### 254 batch Train loss:1.7369 acc:0.7173 acc1:0.3994 mse:81548640 Test loss:1.6659 acc:0.7269 acc1:0.3500 mse:445697984\n",
      "\n",
      "2020-10-30 08:17:12\n",
      "[7, 8, 10, 9, 13, 35, 27, 13, 5, 6]\n",
      "[9, 8, 15, 14, 16, 43, 25, 15, 13, 11]\n",
      "###### 255 batch Train loss:0.9494 acc:0.7408 acc1:0.4203 mse:21256140 Test loss:1.6648 acc:0.7271 acc1:0.3504 mse:445628928\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-30 08:17:15\n",
      "[35, 36, 111, 76, 138, 228, 172, 111, 103, 105]\n",
      "[13, 10, 21, 18, 22, 49, 30, 28, 21, 16]\n",
      "###### 256 batch Train loss:1.6896 acc:0.7032 acc1:0.4133 mse:71403664 Test loss:1.6641 acc:0.7272 acc1:0.3508 mse:445518784\n",
      "\n",
      "2020-10-30 08:17:17\n",
      "[37, 12, 91, 52, 124, 265, 142, 115, 139, 151]\n",
      "[12, 10, 19, 17, 21, 46, 28, 27, 20, 15]\n",
      "###### 257 batch Train loss:2.4733 acc:0.7297 acc1:0.3908 mse:99620816 Test loss:1.6624 acc:0.7271 acc1:0.3509 mse:444923712\n",
      "\n",
      "2020-10-30 08:17:20\n",
      "[12, 5, 16, 16, 12, 33, 25, 6, 11, 12]\n",
      "[10, 9, 16, 15, 17, 46, 27, 17, 14, 12]\n",
      "###### 258 batch Train loss:1.2816 acc:0.6789 acc1:0.2255 mse:31881466 Test loss:1.6611 acc:0.7273 acc1:0.3513 mse:444767520\n",
      "\n",
      "2020-10-30 08:17:22\n",
      "[4, 11, 16, 14, 20, 38, 29, 17, 20, 9]\n",
      "[12, 10, 17, 15, 21, 51, 31, 26, 17, 14]\n",
      "###### 259 batch Train loss:1.0389 acc:0.6865 acc1:0.4045 mse:17908944 Test loss:1.6602 acc:0.7276 acc1:0.3518 mse:444765536\n",
      "\n",
      "2020-10-30 08:17:25\n",
      "[5, 7, 7, 13, 13, 13, 8, 2, 8, 2]\n",
      "[9, 8, 13, 11, 14, 28, 15, 16, 12, 9]\n",
      "###### 260 batch Train loss:1.7508 acc:0.6972 acc1:0.3602 mse:94740112 Test loss:1.6595 acc:0.7278 acc1:0.3522 mse:444763072\n",
      "\n",
      "2020-10-30 08:17:27\n",
      "[59, 19, 75, 47, 161, 251, 162, 122, 129, 173]\n",
      "[11, 8, 18, 15, 19, 41, 26, 26, 18, 13]\n",
      "###### 261 batch Train loss:3.0628 acc:0.6852 acc1:0.3424 mse:123624456 Test loss:1.6584 acc:0.7279 acc1:0.3527 mse:444465408\n",
      "\n",
      "2020-10-30 08:17:30\n",
      "[54, 21, 87, 59, 142, 245, 167, 123, 135, 156]\n",
      "[12, 9, 19, 16, 20, 43, 27, 26, 19, 14]\n",
      "###### 262 batch Train loss:1.4974 acc:0.6949 acc1:0.3798 mse:45212796 Test loss:1.6576 acc:0.7280 acc1:0.3532 mse:444312416\n",
      "\n",
      "2020-10-30 08:17:32\n",
      "[17, 13, 45, 41, 50, 83, 34, 18, 22, 14]\n",
      "[12, 11, 22, 21, 23, 47, 24, 13, 14, 13]\n",
      "###### 263 batch Train loss:1.1702 acc:0.6900 acc1:0.3868 mse:17684472 Test loss:1.6566 acc:0.7282 acc1:0.3538 mse:444207776\n",
      "\n",
      "2020-10-30 08:17:35\n",
      "[19, 7, 13, 11, 19, 61, 32, 20, 14, 10]\n",
      "[10, 8, 15, 14, 18, 44, 28, 25, 16, 12]\n",
      "###### 264 batch Train loss:1.7015 acc:0.7182 acc1:0.3985 mse:91705528 Test loss:1.6560 acc:0.7283 acc1:0.3543 mse:444192320\n",
      "\n",
      "2020-10-30 08:17:37\n",
      "[7, 20, 11, 13, 14, 82, 12, 10, 11, 11]\n",
      "[10, 9, 19, 19, 20, 42, 21, 10, 13, 11]\n",
      "###### 265 batch Train loss:1.0657 acc:0.7288 acc1:0.3999 mse:24525806 Test loss:1.6559 acc:0.7286 acc1:0.3548 mse:444434240\n",
      "\n",
      "2020-10-30 08:17:40\n",
      "[10, 13, 45, 45, 56, 75, 51, 12, 25, 17]\n",
      "[12, 11, 22, 21, 23, 48, 24, 12, 14, 13]\n",
      "###### 266 batch Train loss:2.7103 acc:0.6461 acc1:0.2826 mse:149345664 Test loss:1.6553 acc:0.7287 acc1:0.3551 mse:444380832\n",
      "\n",
      "2020-10-30 08:17:42\n",
      "[8, 8, 17, 18, 17, 45, 21, 6, 5, 6]\n",
      "[11, 9, 18, 18, 19, 42, 20, 10, 12, 11]\n",
      "###### 267 batch Train loss:1.4165 acc:0.6781 acc1:0.3409 mse:21760998 Test loss:1.6544 acc:0.7288 acc1:0.3554 mse:444182912\n",
      "\n",
      "2020-10-30 08:17:45\n",
      "[9, 15, 30, 15, 29, 72, 52, 39, 41, 29]\n",
      "[12, 9, 20, 17, 21, 48, 30, 28, 20, 14]\n",
      "###### 268 batch Train loss:2.1514 acc:0.7252 acc1:0.4241 mse:116979416 Test loss:1.6534 acc:0.7286 acc1:0.3554 mse:443691040\n",
      "\n",
      "2020-10-30 08:17:47\n",
      "[21, 12, 38, 23, 35, 106, 60, 26, 31, 23]\n",
      "[13, 10, 20, 17, 22, 50, 31, 29, 21, 15]\n",
      "###### 269 batch Train loss:2.7047 acc:0.6894 acc1:0.3891 mse:115780160 Test loss:1.6519 acc:0.7281 acc1:0.3550 mse:442841792\n",
      "\n",
      "2020-10-30 08:17:50\n",
      "[4, 22, 47, 30, 35, 70, 36, 15, 11, 13]\n",
      "[10, 11, 22, 21, 23, 46, 24, 13, 13, 11]\n",
      "###### 270 batch Train loss:1.8711 acc:0.6536 acc1:0.4254 mse:59377304 Test loss:1.6504 acc:0.7274 acc1:0.3542 mse:441840960\n",
      "\n",
      "2020-10-30 08:17:52\n",
      "[46, 17, 86, 53, 140, 282, 181, 113, 153, 177]\n",
      "[10, 7, 17, 15, 19, 41, 26, 25, 18, 13]\n",
      "###### 271 batch Train loss:1.5964 acc:0.6700 acc1:0.3254 mse:49732620 Test loss:1.6491 acc:0.7269 acc1:0.3535 mse:440979520\n",
      "\n",
      "2020-10-30 08:17:55\n",
      "[35, 40, 127, 76, 149, 239, 187, 140, 93, 114]\n",
      "[13, 10, 21, 19, 23, 52, 32, 28, 22, 16]\n",
      "###### 272 batch Train loss:2.6039 acc:0.6090 acc1:0.3587 mse:120802600 Test loss:1.6478 acc:0.7259 acc1:0.3523 mse:439769312\n",
      "\n",
      "2020-10-30 08:17:57\n",
      "[16, 10, 29, 16, 18, 86, 53, 41, 35, 30]\n",
      "[13, 10, 22, 19, 24, 55, 34, 29, 23, 16]\n",
      "###### 273 batch Train loss:1.7037 acc:0.6856 acc1:0.3387 mse:93699192 Test loss:1.6466 acc:0.7252 acc1:0.3511 mse:438627456\n",
      "\n",
      "2020-10-30 08:18:00\n",
      "[12, 16, 45, 40, 52, 44, 39, 14, 15, 16]\n",
      "[10, 10, 21, 21, 22, 47, 25, 11, 13, 11]\n",
      "###### 274 batch Train loss:1.4070 acc:0.6078 acc1:0.3596 mse:26525724 Test loss:1.6449 acc:0.7251 acc1:0.3503 mse:437767872\n",
      "\n",
      "2020-10-30 08:18:02\n",
      "[4, 9, 11, 9, 12, 35, 28, 14, 11, 7]\n",
      "[10, 9, 15, 15, 18, 46, 30, 17, 15, 11]\n",
      "###### 275 batch Train loss:0.7304 acc:0.7271 acc1:0.3745 mse:7583487 Test loss:1.6431 acc:0.7257 acc1:0.3506 mse:437541696\n",
      "\n",
      "2020-10-30 08:18:05\n",
      "[6, 9, 5, 17, 26, 38, 29, 13, 13, 10]\n",
      "[8, 7, 14, 14, 15, 44, 27, 14, 13, 10]\n",
      "###### 276 batch Train loss:0.8945 acc:0.7174 acc1:0.2940 mse:7423947 Test loss:1.6419 acc:0.7268 acc1:0.3513 mse:437927456\n",
      "\n",
      "2020-10-30 08:18:07\n",
      "[15, 6, 11, 7, 20, 30, 17, 6, 10, 13]\n",
      "[10, 9, 18, 18, 19, 42, 22, 10, 12, 10]\n",
      "###### 277 batch Train loss:1.3467 acc:0.6836 acc1:0.2152 mse:32553486 Test loss:1.6415 acc:0.7278 acc1:0.3520 mse:438543040\n",
      "\n",
      "2020-10-30 08:18:10\n",
      "[16, 11, 54, 45, 44, 59, 47, 14, 13, 22]\n",
      "[10, 10, 21, 21, 23, 47, 26, 11, 14, 12]\n",
      "###### 278 batch Train loss:2.1372 acc:0.7022 acc1:0.4043 mse:12382246 Test loss:1.6404 acc:0.7281 acc1:0.3521 mse:438381824\n",
      "\n",
      "2020-10-30 08:18:13\n",
      "[8, 5, 26, 16, 11, 96, 29, 14, 3, 10]\n",
      "[8, 7, 15, 15, 16, 45, 26, 15, 12, 9]\n",
      "###### 279 batch Train loss:0.7477 acc:0.7189 acc1:0.3154 mse:7337296 Test loss:1.6402 acc:0.7285 acc1:0.3525 mse:438706176\n",
      "\n",
      "2020-10-30 08:18:16\n",
      "[35, 20, 102, 55, 156, 265, 164, 142, 144, 179]\n",
      "[10, 8, 18, 16, 20, 43, 28, 25, 19, 13]\n",
      "###### 280 batch Train loss:2.7774 acc:0.6975 acc1:0.3595 mse:97180832 Test loss:1.6391 acc:0.7286 acc1:0.3528 mse:438405280\n",
      "\n",
      "2020-10-30 08:18:18\n",
      "[0, 2, 0, 0, 0, 1, 0, 0, 1, 0]\n",
      "[9, 7, 14, 13, 16, 34, 21, 19, 15, 11]\n",
      "###### 281 batch Train loss:1.9500 acc:0.6623 acc1:0.3874 mse:91924336 Test loss:1.6382 acc:0.7287 acc1:0.3529 mse:438044064\n",
      "\n",
      "2020-10-30 08:18:21\n",
      "[11, 20, 47, 40, 35, 45, 29, 16, 7, 10]\n",
      "[8, 10, 21, 20, 23, 43, 25, 11, 11, 9]\n",
      "###### 282 batch Train loss:2.2906 acc:0.6969 acc1:0.4385 mse:75808688 Test loss:1.6362 acc:0.7284 acc1:0.3525 mse:437073216\n",
      "\n",
      "2020-10-30 08:18:24\n",
      "[17, 9, 15, 8, 16, 39, 24, 15, 11, 13]\n",
      "[10, 8, 15, 16, 17, 46, 29, 15, 13, 11]\n",
      "###### 283 batch Train loss:1.6332 acc:0.6567 acc1:0.3305 mse:48577540 Test loss:1.6345 acc:0.7282 acc1:0.3524 mse:436334080\n",
      "\n",
      "2020-10-30 08:18:26\n",
      "[3, 0, 4, 7, 3, 6, 4, 13, 13, 12]\n",
      "[10, 8, 16, 15, 19, 39, 25, 22, 17, 13]\n",
      "###### 284 batch Train loss:0.7841 acc:0.6751 acc1:0.2540 mse:6447440 Test loss:1.6335 acc:0.7283 acc1:0.3525 mse:436000896\n",
      "\n",
      "2020-10-30 08:18:29\n",
      "[10, 5, 11, 10, 29, 62, 39, 19, 11, 5]\n",
      "[10, 8, 17, 16, 18, 50, 28, 15, 12, 11]\n",
      "###### 285 batch Train loss:1.6964 acc:0.6848 acc1:0.3883 mse:85911680 Test loss:1.6326 acc:0.7284 acc1:0.3524 mse:435684064\n",
      "\n",
      "2020-10-30 08:18:31\n",
      "[5, 2, 5, 11, 10, 28, 39, 14, 9, 8]\n",
      "[10, 8, 14, 15, 19, 46, 30, 17, 13, 11]\n",
      "###### 286 batch Train loss:1.8907 acc:0.7102 acc1:0.4313 mse:73007520 Test loss:1.6309 acc:0.7282 acc1:0.3521 mse:434966592\n",
      "\n",
      "2020-10-30 08:18:34\n",
      "[10, 13, 45, 45, 56, 75, 51, 12, 25, 17]\n",
      "[11, 10, 22, 22, 26, 50, 27, 12, 14, 13]\n",
      "###### 287 batch Train loss:1.7127 acc:0.7112 acc1:0.4039 mse:43805752 Test loss:1.6290 acc:0.7278 acc1:0.3517 mse:434038304\n",
      "\n",
      "2020-10-30 08:18:36\n",
      "[20, 7, 12, 33, 23, 27, 22, 11, 16, 11]\n",
      "[11, 10, 21, 21, 24, 48, 25, 10, 13, 12]\n",
      "###### 288 batch Train loss:1.4915 acc:0.7229 acc1:0.3865 mse:48552080 Test loss:1.6273 acc:0.7275 acc1:0.3512 mse:433251936\n",
      "\n",
      "2020-10-30 08:18:39\n",
      "[8, 10, 40, 41, 39, 61, 40, 19, 17, 17]\n",
      "[10, 9, 21, 20, 24, 46, 25, 11, 12, 11]\n",
      "###### 289 batch Train loss:2.6675 acc:0.6754 acc1:0.2817 mse:151323952 Test loss:1.6255 acc:0.7271 acc1:0.3507 mse:432401280\n",
      "\n",
      "2020-10-30 08:18:41\n",
      "[49, 5, 33, 34, 50, 109, 45, 60, 91, 81]\n",
      "[10, 7, 16, 14, 20, 39, 26, 23, 16, 12]\n",
      "###### 290 batch Train loss:1.7074 acc:0.7066 acc1:0.3200 mse:48461076 Test loss:1.6242 acc:0.7267 acc1:0.3506 mse:431686368\n",
      "\n",
      "2020-10-30 08:18:44\n",
      "[8, 7, 13, 17, 27, 25, 23, 9, 5, 14]\n",
      "[10, 9, 14, 15, 20, 49, 30, 17, 13, 11]\n",
      "###### 291 batch Train loss:1.6746 acc:0.7211 acc1:0.3730 mse:58640512 Test loss:1.6234 acc:0.7264 acc1:0.3507 mse:431237440\n",
      "\n",
      "2020-10-30 08:18:46\n",
      "[16, 3, 15, 7, 13, 45, 23, 15, 16, 8]\n",
      "[10, 8, 15, 16, 19, 50, 29, 15, 13, 11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### 292 batch Train loss:1.0995 acc:0.6655 acc1:0.2967 mse:32117678 Test loss:1.6227 acc:0.7267 acc1:0.3512 mse:431235232\n",
      "\n",
      "2020-10-30 08:18:49\n",
      "[6, 9, 18, 13, 9, 45, 31, 12, 15, 10]\n",
      "[10, 8, 15, 15, 18, 47, 28, 14, 12, 11]\n",
      "###### 293 batch Train loss:1.5110 acc:0.6193 acc1:0.2557 mse:43730908 Test loss:1.6223 acc:0.7273 acc1:0.3522 mse:431671872\n",
      "\n",
      "2020-10-30 08:18:51\n",
      "[9, 15, 13, 23, 32, 35, 25, 13, 24, 16]\n",
      "[12, 10, 21, 21, 25, 49, 26, 11, 14, 12]\n",
      "###### 294 batch Train loss:1.7410 acc:0.6655 acc1:0.3870 mse:56189484 Test loss:1.6218 acc:0.7280 acc1:0.3532 mse:432081664\n",
      "\n",
      "2020-10-30 08:18:54\n",
      "[14, 10, 7, 25, 19, 34, 14, 14, 7, 13]\n",
      "[11, 9, 19, 19, 23, 46, 24, 10, 12, 11]\n",
      "###### 295 batch Train loss:0.8231 acc:0.7166 acc1:0.3693 mse:6484430 Test loss:1.6222 acc:0.7289 acc1:0.3546 mse:432990720\n",
      "\n",
      "2020-10-30 08:18:57\n",
      "[2, 7, 8, 8, 8, 7, 7, 5, 1, 3]\n",
      "[8, 6, 12, 10, 14, 27, 15, 14, 11, 8]\n",
      "###### 296 batch Train loss:2.4815 acc:0.6653 acc1:0.3573 mse:159864624 Test loss:1.6225 acc:0.7296 acc1:0.3552 mse:433512512\n",
      "\n",
      "2020-10-30 08:18:59\n",
      "[21, 11, 19, 17, 17, 33, 11, 9, 10, 9]\n",
      "[12, 9, 19, 20, 23, 47, 24, 10, 13, 12]\n",
      "###### 297 batch Train loss:0.9009 acc:0.7230 acc1:0.4300 mse:13549211 Test loss:1.6233 acc:0.7302 acc1:0.3559 mse:434313600\n",
      "\n",
      "2020-10-30 08:19:02\n",
      "[7, 26, 33, 43, 32, 52, 25, 18, 11, 11]\n",
      "[10, 10, 22, 22, 26, 47, 26, 12, 12, 11]\n",
      "###### 298 batch Train loss:1.5341 acc:0.7178 acc1:0.4091 mse:38842400 Test loss:1.6237 acc:0.7307 acc1:0.3563 mse:434859456\n",
      "\n",
      "2020-10-30 08:19:04\n",
      "[13, 25, 8, 11, 15, 49, 30, 30, 21, 15]\n",
      "[12, 9, 16, 15, 23, 52, 33, 25, 17, 13]\n",
      "###### 299 batch Train loss:2.3885 acc:0.7198 acc1:0.3986 mse:154419488 Test loss:1.6238 acc:0.7310 acc1:0.3565 mse:434990336\n",
      "\n",
      "2020-10-30 08:19:07\n",
      "[1, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "[8, 5, 13, 11, 15, 30, 19, 19, 13, 9]\n",
      "###### 300 batch Train loss:1.2442 acc:0.7075 acc1:0.3668 mse:31700894 Test loss:1.6239 acc:0.7313 acc1:0.3569 mse:435292864\n",
      "\n",
      "2020-10-30 08:19:09\n",
      "[9, 7, 16, 13, 10, 24, 5, 4, 2, 10]\n",
      "[7, 8, 17, 13, 17, 27, 14, 12, 9, 7]\n",
      "###### 301 batch Train loss:1.8286 acc:0.7277 acc1:0.3656 mse:100752256 Test loss:1.6236 acc:0.7316 acc1:0.3573 mse:435393120\n",
      "\n",
      "2020-10-30 08:19:12\n",
      "[12, 16, 45, 40, 52, 44, 39, 14, 15, 16]\n",
      "[10, 10, 21, 20, 24, 47, 25, 11, 13, 12]\n",
      "###### 302 batch Train loss:2.0933 acc:0.6923 acc1:0.3954 mse:68997800 Test loss:1.6222 acc:0.7316 acc1:0.3575 mse:434927680\n",
      "\n",
      "2020-10-30 08:19:14\n",
      "[14, 17, 38, 41, 32, 45, 37, 12, 15, 14]\n",
      "[10, 11, 22, 21, 25, 45, 25, 12, 12, 10]\n",
      "###### 303 batch Train loss:1.7115 acc:0.6876 acc1:0.3077 mse:40632096 Test loss:1.6204 acc:0.7317 acc1:0.3577 mse:434352992\n",
      "\n",
      "2020-10-30 08:19:17\n",
      "[8, 4, 9, 10, 4, 29, 24, 18, 13, 7]\n",
      "[9, 8, 13, 13, 17, 41, 27, 15, 12, 10]\n",
      "###### 304 batch Train loss:1.4650 acc:0.7322 acc1:0.4067 mse:45465660 Test loss:1.6185 acc:0.7317 acc1:0.3582 mse:433798880\n",
      "\n",
      "2020-10-30 08:19:19\n",
      "[8, 7, 3, 9, 12, 16, 6, 3, 4, 6]\n",
      "[7, 7, 11, 9, 12, 25, 13, 14, 11, 8]\n",
      "###### 305 batch Train loss:1.6205 acc:0.7073 acc1:0.4325 mse:49032820 Test loss:1.6160 acc:0.7315 acc1:0.3584 mse:432854656\n",
      "\n",
      "2020-10-30 08:19:22\n",
      "[12, 8, 45, 41, 54, 77, 50, 17, 12, 18]\n",
      "[10, 10, 20, 19, 22, 43, 24, 11, 13, 11]\n",
      "###### 306 batch Train loss:1.9408 acc:0.6626 acc1:0.2745 mse:82578112 Test loss:1.6133 acc:0.7313 acc1:0.3586 mse:431859456\n",
      "\n",
      "2020-10-30 08:19:24\n",
      "[7, 8, 17, 12, 13, 42, 26, 20, 10, 8]\n",
      "[10, 10, 14, 14, 18, 44, 28, 16, 14, 11]\n",
      "###### 307 batch Train loss:0.8457 acc:0.7078 acc1:0.3139 mse:13177113 Test loss:1.6117 acc:0.7314 acc1:0.3590 mse:431591712\n",
      "\n",
      "2020-10-30 08:19:27\n",
      "[7, 10, 21, 9, 8, 20, 6, 7, 5, 5]\n",
      "[7, 9, 17, 12, 16, 25, 12, 12, 9, 7]\n",
      "###### 308 batch Train loss:1.6497 acc:0.7378 acc1:0.3835 mse:52682880 Test loss:1.6102 acc:0.7316 acc1:0.3595 mse:431343936\n",
      "\n",
      "2020-10-30 08:19:29\n",
      "[10, 8, 13, 20, 17, 38, 23, 14, 17, 16]\n",
      "[9, 9, 14, 14, 15, 42, 25, 14, 13, 10]\n",
      "###### 309 batch Train loss:0.6717 acc:0.7304 acc1:0.4011 mse:1133910 Test loss:1.6097 acc:0.7321 acc1:0.3605 mse:431700992\n",
      "\n",
      "2020-10-30 08:19:33\n",
      "[21, 11, 19, 17, 17, 33, 11, 9, 10, 9]\n",
      "[11, 10, 18, 18, 20, 41, 21, 10, 13, 12]\n",
      "###### 310 batch Train loss:1.2365 acc:0.7223 acc1:0.3770 mse:25144708 Test loss:1.6092 acc:0.7324 acc1:0.3612 mse:432045120\n",
      "\n",
      "2020-10-30 08:19:36\n",
      "[5, 16, 38, 30, 40, 41, 25, 12, 15, 12]\n",
      "[9, 11, 21, 20, 22, 40, 22, 12, 12, 10]\n",
      "###### 311 batch Train loss:1.6732 acc:0.6692 acc1:0.4032 mse:40058120 Test loss:1.6084 acc:0.7326 acc1:0.3615 mse:432117120\n",
      "\n",
      "2020-10-30 08:19:38\n",
      "[3, 12, 5, 4, 5, 8, 10, 5, 7, 5]\n",
      "[7, 6, 10, 8, 11, 23, 13, 15, 11, 8]\n",
      "###### 312 batch Train loss:2.4389 acc:0.7049 acc1:0.3986 mse:94878728 Test loss:1.6063 acc:0.7324 acc1:0.3617 mse:431459264\n",
      "\n",
      "2020-10-30 08:19:41\n",
      "[32, 5, 30, 37, 52, 103, 54, 61, 74, 79]\n",
      "[11, 9, 17, 15, 18, 38, 24, 24, 18, 13]\n",
      "###### 313 batch Train loss:0.9855 acc:0.7150 acc1:0.4325 mse:19930824 Test loss:1.6048 acc:0.7322 acc1:0.3617 mse:430922880\n",
      "\n",
      "2020-10-30 08:19:43\n",
      "[7, 7, 15, 22, 19, 26, 16, 6, 15, 7]\n",
      "[10, 9, 19, 18, 19, 38, 20, 9, 12, 10]\n",
      "###### 314 batch Train loss:1.1693 acc:0.6722 acc1:0.3126 mse:13435041 Test loss:1.6038 acc:0.7322 acc1:0.3613 mse:430706752\n",
      "\n",
      "2020-10-30 08:19:46\n",
      "[2, 3, 1, 1, 3, 3, 11, 2, 4, 4]\n",
      "[7, 6, 11, 10, 12, 25, 16, 17, 12, 8]\n",
      "###### 315 batch Train loss:0.8053 acc:0.7197 acc1:0.3435 mse:6042764 Test loss:1.6038 acc:0.7325 acc1:0.3615 mse:431071296\n",
      "\n",
      "2020-10-30 08:19:48\n",
      "[14, 11, 13, 11, 15, 46, 27, 7, 13, 18]\n",
      "[11, 9, 17, 16, 17, 38, 25, 13, 11, 11]\n",
      "###### 316 batch Train loss:1.7196 acc:0.6927 acc1:0.3791 mse:62335940 Test loss:1.6041 acc:0.7329 acc1:0.3618 mse:431515904\n",
      "\n",
      "2020-10-30 08:19:51\n",
      "[4, 4, 9, 9, 8, 13, 8, 2, 4, 5]\n",
      "[7, 6, 11, 9, 11, 24, 14, 15, 11, 8]\n",
      "###### 317 batch Train loss:1.1863 acc:0.7123 acc1:0.4080 mse:30095082 Test loss:1.6044 acc:0.7334 acc1:0.3623 mse:432088416\n",
      "\n",
      "2020-10-30 08:19:53\n",
      "[6, 4, 6, 9, 14, 13, 4, 4, 3, 1]\n",
      "[7, 6, 10, 9, 10, 20, 12, 13, 9, 6]\n",
      "###### 318 batch Train loss:2.0315 acc:0.7292 acc1:0.4008 mse:101493872 Test loss:1.6036 acc:0.7336 acc1:0.3629 mse:432104384\n",
      "\n",
      "2020-10-30 08:19:56\n",
      "[13, 15, 22, 15, 16, 19, 5, 8, 7, 4]\n",
      "[9, 9, 18, 14, 16, 26, 13, 12, 9, 7]\n",
      "###### 319 batch Train loss:2.9255 acc:0.6692 acc1:0.4785 mse:177492304 Test loss:1.6005 acc:0.7331 acc1:0.3631 mse:430974944\n",
      "\n",
      "2020-10-30 08:19:58\n",
      "[2, 6, 4, 1, 2, 2, 4, 2, 1, 4]\n",
      "[7, 5, 11, 10, 12, 24, 16, 16, 12, 8]\n",
      "###### 320 batch Train loss:1.1199 acc:0.7282 acc1:0.3828 mse:26850678 Test loss:1.5979 acc:0.7325 acc1:0.3632 mse:430014304\n",
      "\n",
      "2020-10-30 08:20:01\n",
      "[12, 16, 45, 40, 52, 44, 39, 14, 15, 16]\n",
      "[10, 9, 21, 21, 22, 41, 23, 10, 12, 11]\n",
      "###### 321 batch Train loss:1.8523 acc:0.7020 acc1:0.4630 mse:56956944 Test loss:1.5949 acc:0.7308 acc1:0.3622 mse:428170368\n",
      "\n",
      "2020-10-30 08:20:03\n",
      "[37, 12, 91, 52, 124, 265, 142, 115, 139, 151]\n",
      "[12, 9, 19, 18, 21, 41, 27, 25, 19, 14]\n",
      "###### 322 batch Train loss:1.5873 acc:0.6769 acc1:0.3976 mse:49828256 Test loss:1.5935 acc:0.7285 acc1:0.3603 mse:426445632\n",
      "\n",
      "2020-10-30 08:20:06\n",
      "[3, 0, 4, 7, 3, 6, 4, 13, 13, 12]\n",
      "[11, 8, 16, 15, 17, 34, 22, 21, 16, 12]\n",
      "###### 323 batch Train loss:1.5504 acc:0.6188 acc1:0.2117 mse:45228404 Test loss:1.5927 acc:0.7283 acc1:0.3598 mse:426025472\n",
      "\n",
      "2020-10-30 08:20:08\n",
      "[5, 8, 24, 10, 16, 38, 24, 8, 9, 9]\n",
      "[10, 8, 16, 17, 17, 36, 26, 13, 10, 10]\n",
      "###### 324 batch Train loss:0.9097 acc:0.7223 acc1:0.3188 mse:24376214 Test loss:1.5917 acc:0.7300 acc1:0.3605 mse:426603008\n",
      "\n",
      "2020-10-30 08:20:11\n",
      "[9, 1, 3, 7, 8, 15, 4, 24, 16, 9]\n",
      "[9, 6, 15, 13, 16, 31, 21, 21, 15, 11]\n",
      "###### 325 batch Train loss:1.8783 acc:0.7318 acc1:0.3775 mse:109707744 Test loss:1.5915 acc:0.7310 acc1:0.3605 mse:426810752\n",
      "\n",
      "2020-10-30 08:20:13\n",
      "[5, 7, 7, 13, 13, 13, 8, 2, 8, 2]\n",
      "[8, 7, 11, 11, 12, 23, 13, 14, 10, 7]\n",
      "###### 326 batch Train loss:1.6521 acc:0.6384 acc1:0.3421 mse:49136864 Test loss:1.5922 acc:0.7319 acc1:0.3604 mse:427205600\n",
      "\n",
      "2020-10-30 08:20:16\n",
      "[5, 7, 7, 12, 10, 19, 14, 7, 4, 3]\n",
      "[7, 7, 11, 11, 12, 23, 13, 14, 10, 7]\n",
      "###### 327 batch Train loss:2.2031 acc:0.7044 acc1:0.4013 mse:90894936 Test loss:1.5918 acc:0.7319 acc1:0.3600 mse:426846976\n",
      "\n",
      "2020-10-30 08:20:18\n",
      "[34, 10, 19, 34, 40, 113, 54, 63, 86, 94]\n",
      "[11, 8, 18, 17, 19, 38, 25, 24, 18, 13]\n",
      "###### 328 batch Train loss:1.1715 acc:0.7036 acc1:0.3848 mse:14746223 Test loss:1.5915 acc:0.7320 acc1:0.3600 mse:426669184\n",
      "\n",
      "2020-10-30 08:20:21\n",
      "[37, 46, 119, 70, 157, 235, 203, 151, 101, 126]\n",
      "[13, 10, 21, 20, 24, 46, 30, 27, 21, 16]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### 329 batch Train loss:3.1273 acc:0.6038 acc1:0.3461 mse:158050512 Test loss:1.5903 acc:0.7315 acc1:0.3599 mse:425729408\n",
      "\n",
      "2020-10-30 08:20:24\n",
      "[9, 8, 18, 17, 27, 87, 15, 7, 23, 7]\n",
      "[10, 9, 20, 21, 22, 40, 23, 10, 13, 11]\n",
      "###### 330 batch Train loss:1.1345 acc:0.7115 acc1:0.3024 mse:30618706 Test loss:1.5895 acc:0.7314 acc1:0.3601 mse:425202112\n",
      "\n",
      "2020-10-30 08:20:26\n",
      "[1, 2, 0, 0, 0, 0, 0, 1, 0, 0]\n",
      "[9, 7, 14, 14, 16, 31, 20, 19, 14, 10]\n",
      "###### 331 batch Train loss:2.1433 acc:0.7012 acc1:0.3798 mse:106746832 Test loss:1.5882 acc:0.7311 acc1:0.3602 mse:424514624\n",
      "\n",
      "2020-10-30 08:20:29\n",
      "[27, 34, 101, 76, 117, 209, 179, 104, 116, 110]\n",
      "[12, 9, 21, 19, 24, 44, 30, 27, 20, 15]\n",
      "###### 332 batch Train loss:2.0458 acc:0.7340 acc1:0.3700 mse:109798936 Test loss:1.5862 acc:0.7305 acc1:0.3606 mse:423422944\n",
      "\n",
      "2020-10-30 08:20:31\n",
      "[0, 8, 12, 4, 7, 5, 9, 1, 2, 3]\n",
      "[7, 7, 11, 11, 13, 25, 15, 16, 12, 9]\n",
      "###### 333 batch Train loss:0.8288 acc:0.6811 acc1:0.3338 mse:8341264 Test loss:1.5850 acc:0.7311 acc1:0.3609 mse:423360064\n",
      "\n",
      "2020-10-30 08:20:34\n",
      "[2, 3, 12, 9, 11, 23, 11, 6, 2, 5]\n",
      "[7, 6, 11, 10, 12, 22, 12, 14, 10, 7]\n",
      "###### 334 batch Train loss:2.2491 acc:0.7255 acc1:0.4034 mse:112390528 Test loss:1.5832 acc:0.7311 acc1:0.3617 mse:422721888\n",
      "\n",
      "2020-10-30 08:20:36\n",
      "[38, 22, 91, 51, 139, 283, 164, 102, 133, 185]\n",
      "[11, 8, 20, 18, 22, 41, 27, 26, 19, 14]\n",
      "###### 335 batch Train loss:2.2739 acc:0.6969 acc1:0.3595 mse:82790024 Test loss:1.5812 acc:0.7306 acc1:0.3632 mse:421759200\n",
      "\n",
      "2020-10-30 08:20:39\n",
      "[2, 3, 3, 2, 1, 2, 4, 0, 0, 0]\n",
      "[7, 6, 12, 11, 14, 27, 17, 18, 12, 9]\n",
      "###### 336 batch Train loss:1.4997 acc:0.7082 acc1:0.3289 mse:67945520 Test loss:1.5799 acc:0.7309 acc1:0.3642 mse:421578112\n",
      "\n",
      "2020-10-30 08:20:41\n",
      "[16, 10, 29, 16, 18, 86, 53, 41, 35, 30]\n",
      "[14, 11, 24, 20, 26, 52, 32, 30, 22, 17]\n",
      "###### 337 batch Train loss:1.0452 acc:0.7136 acc1:0.3762 mse:24188444 Test loss:1.5796 acc:0.7319 acc1:0.3647 mse:422000064\n",
      "\n",
      "2020-10-30 08:20:44\n",
      "[10, 7, 11, 20, 11, 93, 28, 13, 6, 14]\n",
      "[9, 9, 15, 16, 17, 43, 26, 14, 13, 10]\n",
      "###### 338 batch Train loss:1.3307 acc:0.7345 acc1:0.3850 mse:24274484 Test loss:1.5793 acc:0.7326 acc1:0.3653 mse:422361280\n",
      "\n",
      "2020-10-30 08:20:46\n",
      "[36, 10, 28, 31, 44, 118, 51, 72, 61, 79]\n",
      "[11, 8, 18, 16, 20, 39, 24, 25, 18, 13]\n",
      "###### 339 batch Train loss:1.0290 acc:0.7100 acc1:0.2813 mse:24578896 Test loss:1.5803 acc:0.7335 acc1:0.3655 mse:423234080\n",
      "\n",
      "2020-10-30 08:20:49\n",
      "[17, 12, 32, 16, 28, 79, 36, 43, 32, 27]\n",
      "[12, 10, 22, 18, 24, 49, 31, 30, 21, 16]\n",
      "###### 340 batch Train loss:1.3366 acc:0.7359 acc1:0.4205 mse:20418494 Test loss:1.5806 acc:0.7338 acc1:0.3659 mse:423496608\n",
      "\n",
      "2020-10-30 08:20:52\n",
      "[10, 7, 11, 20, 11, 93, 28, 13, 6, 14]\n",
      "[10, 9, 15, 15, 17, 44, 25, 14, 13, 11]\n",
      "###### 341 batch Train loss:0.7462 acc:0.7135 acc1:0.2289 mse:4892387 Test loss:1.5832 acc:0.7347 acc1:0.3653 mse:424790784\n",
      "\n",
      "2020-10-30 08:20:55\n",
      "[36, 10, 28, 31, 44, 118, 51, 72, 61, 79]\n",
      "[11, 8, 18, 14, 20, 40, 24, 25, 18, 13]\n",
      "###### 342 batch Train loss:1.5737 acc:0.7256 acc1:0.4072 mse:50691064 Test loss:1.5840 acc:0.7350 acc1:0.3657 mse:425236608\n",
      "\n",
      "2020-10-30 08:20:58\n",
      "[47, 20, 98, 40, 149, 249, 162, 113, 133, 173]\n",
      "[13, 10, 21, 17, 23, 47, 27, 28, 21, 15]\n",
      "###### 343 batch Train loss:1.9357 acc:0.6736 acc1:0.3724 mse:64426940 Test loss:1.5838 acc:0.7350 acc1:0.3661 mse:425247456\n",
      "\n",
      "2020-10-30 08:21:00\n",
      "[2, 7, 8, 8, 8, 7, 7, 5, 1, 3]\n",
      "[7, 7, 12, 9, 12, 25, 12, 15, 11, 8]\n",
      "###### 344 batch Train loss:2.2569 acc:0.6843 acc1:0.3371 mse:115196664 Test loss:1.5828 acc:0.7348 acc1:0.3668 mse:424878688\n",
      "\n",
      "2020-10-30 08:21:03\n",
      "[1, 4, 2, 1, 2, 4, 3, 0, 2, 2]\n",
      "[7, 5, 11, 8, 13, 27, 16, 18, 13, 8]\n",
      "###### 345 batch Train loss:0.6790 acc:0.7104 acc1:0.2171 mse:4080275 Test loss:1.5841 acc:0.7355 acc1:0.3673 mse:425764032\n",
      "\n",
      "2020-10-30 08:21:05\n",
      "[42, 29, 108, 77, 133, 234, 205, 111, 96, 96]\n",
      "[14, 10, 22, 17, 24, 50, 30, 30, 23, 17]\n",
      "###### 346 batch Train loss:1.7303 acc:0.7637 acc1:0.4066 mse:91093672 Test loss:1.5842 acc:0.7360 acc1:0.3680 mse:426247360\n",
      "\n",
      "2020-10-30 08:21:08\n",
      "[9, 15, 30, 15, 29, 72, 52, 39, 41, 29]\n",
      "[14, 11, 23, 16, 24, 54, 32, 31, 23, 17]\n",
      "###### 347 batch Train loss:1.0193 acc:0.6974 acc1:0.4124 mse:25498674 Test loss:1.5853 acc:0.7366 acc1:0.3677 mse:426946560\n",
      "\n",
      "2020-10-30 08:21:10\n",
      "[10, 8, 21, 19, 9, 103, 25, 15, 16, 11]\n",
      "[10, 8, 15, 13, 16, 47, 25, 16, 12, 10]\n",
      "###### 348 batch Train loss:1.0954 acc:0.7202 acc1:0.4388 mse:39410436 Test loss:1.5860 acc:0.7370 acc1:0.3671 mse:427262304\n",
      "\n",
      "2020-10-30 08:21:13\n",
      "[4, 4, 11, 5, 7, 13, 11, 2, 1, 2]\n",
      "[6, 6, 10, 7, 11, 23, 12, 14, 10, 7]\n",
      "###### 349 batch Train loss:1.1375 acc:0.7429 acc1:0.4472 mse:36561928 Test loss:1.5862 acc:0.7372 acc1:0.3665 mse:427235328\n",
      "\n",
      "2020-10-30 08:21:15\n",
      "[7, 11, 13, 23, 23, 61, 34, 11, 22, 18]\n",
      "[10, 8, 14, 13, 15, 46, 26, 14, 13, 11]\n",
      "###### 350 batch Train loss:2.2071 acc:0.7266 acc1:0.3956 mse:88448680 Test loss:1.5833 acc:0.7369 acc1:0.3668 mse:426267552\n",
      "\n",
      "2020-10-30 08:21:18\n",
      "[6, 6, 17, 17, 20, 32, 32, 13, 11, 11]\n",
      "[10, 8, 17, 14, 17, 43, 26, 14, 12, 11]\n",
      "###### 351 batch Train loss:2.5410 acc:0.7024 acc1:0.3088 mse:141649840 Test loss:1.5789 acc:0.7359 acc1:0.3676 mse:424579776\n",
      "\n",
      "2020-10-30 08:21:20\n",
      "[4, 11, 16, 14, 20, 38, 29, 17, 20, 9]\n",
      "[12, 10, 16, 13, 20, 53, 31, 25, 17, 13]\n",
      "###### 352 batch Train loss:1.5941 acc:0.7049 acc1:0.4391 mse:49147472 Test loss:1.5750 acc:0.7343 acc1:0.3680 mse:422618144\n",
      "\n",
      "2020-10-30 08:21:23\n",
      "[35, 40, 127, 76, 149, 239, 187, 140, 93, 114]\n",
      "[14, 11, 23, 16, 24, 54, 31, 29, 23, 18]\n",
      "###### 353 batch Train loss:1.9866 acc:0.6886 acc1:0.3223 mse:98061200 Test loss:1.5728 acc:0.7314 acc1:0.3676 mse:420458816\n",
      "\n",
      "2020-10-30 08:21:25\n",
      "[7, 8, 10, 9, 13, 35, 27, 13, 5, 6]\n",
      "[9, 7, 14, 13, 15, 43, 26, 14, 12, 10]\n",
      "###### 354 batch Train loss:0.8044 acc:0.6864 acc1:0.3682 mse:8394473 Test loss:1.5710 acc:0.7317 acc1:0.3681 mse:420123488\n",
      "\n",
      "2020-10-30 08:21:28\n",
      "[5, 2, 5, 11, 10, 28, 39, 14, 9, 8]\n",
      "[10, 9, 14, 13, 17, 45, 28, 16, 14, 12]\n",
      "###### 355 batch Train loss:1.6577 acc:0.6614 acc1:0.4260 mse:27773856 Test loss:1.5685 acc:0.7311 acc1:0.3687 mse:419251648\n",
      "\n",
      "2020-10-30 08:21:31\n",
      "[35, 36, 111, 76, 138, 228, 172, 111, 103, 105]\n",
      "[14, 12, 25, 18, 27, 54, 32, 29, 23, 18]\n",
      "###### 356 batch Train loss:2.0990 acc:0.7052 acc1:0.3648 mse:102022504 Test loss:1.5671 acc:0.7297 acc1:0.3692 mse:418255104\n",
      "\n",
      "2020-10-30 08:21:33\n",
      "[10, 8, 16, 16, 15, 39, 13, 5, 9, 17]\n",
      "[12, 10, 21, 18, 23, 46, 23, 11, 13, 13]\n",
      "###### 357 batch Train loss:1.2954 acc:0.6923 acc1:0.4090 mse:30030122 Test loss:1.5652 acc:0.7298 acc1:0.3696 mse:417888032\n",
      "\n",
      "2020-10-30 08:21:36\n",
      "[8, 8, 17, 18, 17, 45, 21, 6, 5, 6]\n",
      "[12, 10, 21, 18, 23, 46, 24, 11, 13, 14]\n",
      "###### 358 batch Train loss:1.4726 acc:0.7151 acc1:0.3877 mse:74961816 Test loss:1.5628 acc:0.7317 acc1:0.3713 mse:418278816\n",
      "\n",
      "2020-10-30 08:21:38\n",
      "[5, 6, 8, 1, 2, 2, 5, 5, 3, 3]\n",
      "[7, 7, 11, 8, 13, 30, 17, 17, 13, 9]\n",
      "###### 359 batch Train loss:2.6736 acc:0.5933 acc1:0.4284 mse:102376968 Test loss:1.5617 acc:0.7303 acc1:0.3703 mse:417101376\n",
      "\n",
      "2020-10-30 08:21:41\n",
      "[9, 8, 18, 17, 27, 87, 15, 7, 23, 7]\n",
      "[12, 11, 23, 21, 26, 48, 26, 11, 15, 15]\n",
      "###### 360 batch Train loss:1.5184 acc:0.6772 acc1:0.2705 mse:71273696 Test loss:1.5596 acc:0.7320 acc1:0.3702 mse:417225984\n",
      "\n",
      "2020-10-30 08:21:43\n",
      "[1, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "[7, 6, 13, 9, 15, 31, 20, 19, 14, 10]\n",
      "###### 361 batch Train loss:1.6326 acc:0.7174 acc1:0.3805 mse:57268836 Test loss:1.5584 acc:0.7341 acc1:0.3702 mse:417809728\n",
      "\n",
      "2020-10-30 08:21:46\n",
      "[16, 3, 15, 7, 13, 45, 23, 15, 16, 8]\n",
      "[9, 8, 14, 14, 16, 45, 27, 14, 13, 11]\n",
      "###### 362 batch Train loss:2.1913 acc:0.7079 acc1:0.3638 mse:82176816 Test loss:1.5572 acc:0.7343 acc1:0.3706 mse:417420352\n",
      "\n",
      "2020-10-30 08:21:48\n",
      "[12, 8, 45, 41, 54, 77, 50, 17, 12, 18]\n",
      "[11, 10, 24, 22, 27, 49, 28, 11, 15, 15]\n",
      "###### 363 batch Train loss:2.3219 acc:0.6991 acc1:0.4348 mse:103792064 Test loss:1.5549 acc:0.7318 acc1:0.3698 mse:415435296\n",
      "\n",
      "2020-10-30 08:21:51\n",
      "[12, 5, 12, 13, 21, 53, 25, 25, 15, 9]\n",
      "[11, 9, 18, 15, 23, 50, 35, 24, 18, 14]\n",
      "###### 364 batch Train loss:1.0875 acc:0.7231 acc1:0.3854 mse:14916365 Test loss:1.5533 acc:0.7310 acc1:0.3691 mse:414535040\n",
      "\n",
      "2020-10-30 08:21:53\n",
      "[7, 11, 12, 8, 21, 27, 17, 11, 13, 7]\n",
      "[9, 9, 15, 14, 18, 45, 30, 15, 14, 12]\n",
      "###### 365 batch Train loss:1.2943 acc:0.6932 acc1:0.4206 mse:23398238 Test loss:1.5516 acc:0.7314 acc1:0.3696 mse:414318080\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-30 08:21:56\n",
      "[3, 4, 17, 10, 14, 94, 25, 21, 13, 8]\n",
      "[9, 7, 15, 14, 16, 46, 27, 15, 12, 10]\n",
      "###### 366 batch Train loss:1.9508 acc:0.6569 acc1:0.3425 mse:66409576 Test loss:1.5499 acc:0.7318 acc1:0.3700 mse:414147040\n",
      "\n",
      "2020-10-30 08:21:58\n",
      "[8, 4, 9, 10, 4, 29, 24, 18, 13, 7]\n",
      "[8, 7, 14, 13, 17, 41, 29, 14, 13, 10]\n",
      "###### 367 batch Train loss:0.8288 acc:0.7219 acc1:0.3254 mse:12430149 Test loss:1.5496 acc:0.7344 acc1:0.3711 mse:415531648\n",
      "\n",
      "2020-10-30 08:22:01\n",
      "[6, 5, 15, 13, 14, 56, 24, 14, 8, 10]\n",
      "[9, 7, 15, 14, 15, 46, 26, 15, 12, 10]\n",
      "###### 368 batch Train loss:0.6999 acc:0.7230 acc1:0.3648 mse:3990359 Test loss:1.5545 acc:0.7372 acc1:0.3701 mse:418183744\n",
      "\n",
      "2020-10-30 08:22:03\n",
      "[24, 43, 105, 77, 126, 203, 199, 121, 111, 115]\n",
      "[13, 9, 24, 17, 24, 49, 32, 28, 22, 16]\n",
      "###### 369 batch Train loss:2.4849 acc:0.7064 acc1:0.4645 mse:132295120 Test loss:1.5559 acc:0.7376 acc1:0.3690 mse:418649856\n",
      "\n",
      "2020-10-30 08:22:06\n",
      "[7, 8, 17, 12, 13, 42, 26, 20, 10, 8]\n",
      "[9, 8, 13, 13, 16, 42, 27, 14, 13, 10]\n",
      "###### 370 batch Train loss:1.1658 acc:0.7285 acc1:0.4480 mse:30371416 Test loss:1.5575 acc:0.7380 acc1:0.3677 mse:419200928\n",
      "\n",
      "2020-10-30 08:22:08\n",
      "[10, 15, 42, 37, 40, 45, 39, 16, 25, 9]\n",
      "[10, 10, 25, 21, 25, 44, 26, 11, 12, 9]\n",
      "###### 371 batch Train loss:2.0796 acc:0.7205 acc1:0.4140 mse:25982054 Test loss:1.5539 acc:0.7375 acc1:0.3691 mse:418457792\n",
      "\n",
      "2020-10-30 08:22:12\n",
      "[15, 12, 15, 12, 15, 40, 27, 16, 12, 11]\n",
      "[10, 8, 17, 15, 16, 41, 27, 13, 11, 10]\n",
      "###### 372 batch Train loss:0.8847 acc:0.7130 acc1:0.4276 mse:14533971 Test loss:1.5528 acc:0.7374 acc1:0.3693 mse:418417824\n",
      "\n",
      "2020-10-30 08:22:15\n",
      "[5, 2, 5, 11, 10, 28, 39, 14, 9, 8]\n",
      "[9, 8, 13, 13, 15, 41, 26, 14, 12, 9]\n",
      "###### 373 batch Train loss:0.7206 acc:0.7008 acc1:0.2502 mse:4483460 Test loss:1.5570 acc:0.7382 acc1:0.3673 mse:420005184\n",
      "\n",
      "2020-10-30 08:22:17\n",
      "[12, 5, 12, 13, 21, 53, 25, 25, 15, 9]\n",
      "[10, 8, 15, 13, 19, 46, 30, 23, 15, 9]\n",
      "###### 374 batch Train loss:0.8121 acc:0.7145 acc1:0.3485 mse:7448388 Test loss:1.5628 acc:0.7388 acc1:0.3649 mse:421830208\n",
      "\n",
      "2020-10-30 08:22:20\n",
      "[48, 23, 85, 46, 135, 292, 170, 112, 145, 173]\n",
      "[12, 8, 20, 16, 20, 43, 27, 26, 19, 13]\n",
      "###### 375 batch Train loss:2.8925 acc:0.6783 acc1:0.3723 mse:117848104 Test loss:1.5613 acc:0.7387 acc1:0.3660 mse:421708480\n",
      "\n",
      "2020-10-30 08:22:22\n",
      "[35, 36, 111, 76, 138, 228, 172, 111, 103, 105]\n",
      "[14, 10, 22, 18, 23, 49, 29, 28, 21, 14]\n",
      "###### 376 batch Train loss:1.7706 acc:0.7210 acc1:0.4437 mse:74343504 Test loss:1.5574 acc:0.7383 acc1:0.3681 mse:420915904\n",
      "\n",
      "2020-10-30 08:22:25\n",
      "[0, 0, 1, 0, 0, 0, 1, 0, 2, 0]\n",
      "[7, 5, 13, 9, 13, 29, 18, 19, 13, 8]\n",
      "###### 377 batch Train loss:1.9996 acc:0.7268 acc1:0.3854 mse:70825160 Test loss:1.5507 acc:0.7368 acc1:0.3711 mse:419138368\n",
      "\n",
      "2020-10-30 08:22:27\n",
      "[4, 6, 5, 4, 9, 4, 14, 1, 0, 0]\n",
      "[6, 5, 10, 8, 10, 23, 13, 15, 10, 6]\n",
      "###### 378 batch Train loss:1.7721 acc:0.7481 acc1:0.4612 mse:75127912 Test loss:1.5449 acc:0.7330 acc1:0.3717 mse:416232928\n",
      "\n",
      "2020-10-30 08:22:30\n",
      "[4, 2, 6, 8, 2, 10, 7, 22, 18, 10]\n",
      "[11, 8, 18, 15, 19, 37, 23, 23, 17, 11]\n",
      "###### 379 batch Train loss:1.8115 acc:0.6786 acc1:0.3248 mse:53558200 Test loss:1.5447 acc:0.7268 acc1:0.3680 mse:413394976\n",
      "\n",
      "2020-10-30 08:22:33\n",
      "[35, 40, 127, 76, 149, 239, 187, 140, 93, 114]\n",
      "[16, 11, 26, 22, 27, 52, 31, 30, 22, 14]\n",
      "###### 380 batch Train loss:1.3838 acc:0.6531 acc1:0.3564 mse:69818352 Test loss:1.5476 acc:0.7216 acc1:0.3623 mse:411592832\n",
      "\n",
      "2020-10-30 08:22:35\n",
      "[1, 4, 2, 1, 2, 4, 3, 0, 2, 2]\n",
      "[6, 5, 11, 8, 11, 25, 15, 17, 12, 7]\n",
      "###### 381 batch Train loss:1.1090 acc:0.6901 acc1:0.3563 mse:14514879 Test loss:1.5479 acc:0.7204 acc1:0.3593 mse:410839744\n",
      "\n",
      "2020-10-30 08:22:38\n",
      "[9, 15, 15, 13, 27, 76, 16, 6, 26, 11]\n",
      "[13, 11, 25, 25, 26, 46, 24, 12, 13, 10]\n",
      "###### 382 batch Train loss:1.5060 acc:0.6997 acc1:0.3912 mse:69082416 Test loss:1.5458 acc:0.7222 acc1:0.3595 mse:410794304\n",
      "\n",
      "2020-10-30 08:22:40\n",
      "[15, 8, 19, 12, 12, 61, 30, 26, 16, 12]\n",
      "[13, 10, 19, 19, 25, 52, 33, 26, 17, 10]\n",
      "###### 383 batch Train loss:1.6664 acc:0.6372 acc1:0.3706 mse:49055268 Test loss:1.5423 acc:0.7259 acc1:0.3601 mse:411104256\n",
      "\n",
      "2020-10-30 08:22:43\n",
      "[12, 8, 17, 19, 23, 35, 39, 20, 14, 15]\n",
      "[11, 8, 19, 19, 19, 42, 27, 16, 12, 9]\n",
      "###### 384 batch Train loss:0.9796 acc:0.6845 acc1:0.3164 mse:22631106 Test loss:1.5399 acc:0.7331 acc1:0.3629 mse:413294784\n",
      "\n",
      "2020-10-30 08:22:45\n",
      "[4, 1, 2, 6, 7, 21, 4, 28, 10, 14]\n",
      "[11, 8, 18, 16, 19, 38, 23, 24, 17, 11]\n",
      "###### 385 batch Train loss:1.7724 acc:0.6952 acc1:0.3097 mse:91289936 Test loss:1.5445 acc:0.7367 acc1:0.3612 mse:415490048\n",
      "\n",
      "2020-10-30 08:22:48\n",
      "[4, 4, 9, 9, 8, 13, 8, 2, 4, 5]\n",
      "[6, 6, 10, 8, 10, 24, 12, 15, 11, 6]\n",
      "###### 386 batch Train loss:0.7575 acc:0.7708 acc1:0.3738 mse:10612307 Test loss:1.5546 acc:0.7386 acc1:0.3575 mse:418337408\n",
      "\n",
      "2020-10-30 08:22:50\n",
      "[12, 8, 45, 41, 54, 77, 50, 17, 12, 18]\n",
      "[10, 9, 22, 22, 23, 44, 24, 11, 14, 10]\n",
      "###### 387 batch Train loss:1.6572 acc:0.6875 acc1:0.3547 mse:40695532 Test loss:1.5618 acc:0.7390 acc1:0.3547 mse:419917504\n",
      "\n",
      "2020-10-30 08:22:53\n",
      "[46, 21, 92, 61, 137, 282, 140, 115, 134, 178]\n",
      "[12, 9, 19, 16, 20, 46, 26, 27, 21, 13]\n",
      "###### 388 batch Train loss:1.7231 acc:0.7080 acc1:0.4180 mse:65298040 Test loss:1.5652 acc:0.7390 acc1:0.3535 mse:420554752\n",
      "\n",
      "2020-10-30 08:22:55\n",
      "[14, 10, 7, 25, 19, 34, 14, 14, 7, 13]\n",
      "[10, 8, 17, 17, 17, 39, 19, 9, 12, 9]\n",
      "###### 389 batch Train loss:1.4472 acc:0.7389 acc1:0.4545 mse:47294576 Test loss:1.5662 acc:0.7390 acc1:0.3527 mse:420602112\n",
      "\n",
      "2020-10-30 08:22:58\n",
      "[5, 3, 18, 14, 10, 34, 10, 6, 6, 3]\n",
      "[7, 9, 17, 13, 14, 25, 11, 11, 9, 5]\n",
      "###### 390 batch Train loss:1.6095 acc:0.7331 acc1:0.4021 mse:47418120 Test loss:1.5641 acc:0.7390 acc1:0.3525 mse:419840000\n",
      "\n",
      "2020-10-30 08:23:01\n",
      "[37, 46, 119, 70, 157, 235, 203, 151, 101, 126]\n",
      "[12, 10, 21, 17, 21, 51, 29, 29, 22, 15]\n",
      "###### 391 batch Train loss:2.3998 acc:0.6670 acc1:0.4017 mse:117356288 Test loss:1.5591 acc:0.7387 acc1:0.3531 mse:418181600\n",
      "\n",
      "2020-10-30 08:23:03\n",
      "[11, 7, 16, 11, 22, 57, 32, 25, 11, 12]\n",
      "[10, 9, 14, 13, 18, 51, 29, 25, 17, 11]\n",
      "###### 392 batch Train loss:2.0472 acc:0.7142 acc1:0.3796 mse:100266760 Test loss:1.5527 acc:0.7379 acc1:0.3537 mse:415894112\n",
      "\n",
      "2020-10-30 08:23:06\n",
      "[36, 10, 28, 31, 44, 118, 51, 72, 61, 79]\n",
      "[10, 8, 18, 14, 18, 42, 24, 25, 19, 13]\n",
      "###### 393 batch Train loss:2.2955 acc:0.7080 acc1:0.3195 mse:80311728 Test loss:1.5462 acc:0.7360 acc1:0.3536 mse:412941056\n",
      "\n",
      "2020-10-30 08:23:08\n",
      "[6, 5, 15, 13, 14, 56, 24, 14, 8, 10]\n",
      "[8, 8, 14, 14, 14, 46, 24, 15, 12, 9]\n",
      "###### 394 batch Train loss:1.4259 acc:0.7188 acc1:0.3308 mse:71085520 Test loss:1.5437 acc:0.7331 acc1:0.3516 mse:410398784\n",
      "\n",
      "2020-10-30 08:23:11\n",
      "[24, 43, 105, 77, 126, 203, 199, 121, 111, 115]\n",
      "[14, 11, 25, 19, 24, 57, 32, 30, 24, 18]\n",
      "###### 395 batch Train loss:2.3089 acc:0.7063 acc1:0.4148 mse:148470096 Test loss:1.5466 acc:0.7278 acc1:0.3451 mse:407632704\n",
      "\n",
      "2020-10-30 08:23:13\n",
      "[17, 12, 34, 15, 37, 79, 38, 27, 28, 37]\n",
      "[15, 11, 28, 19, 26, 62, 35, 32, 26, 20]\n",
      "###### 396 batch Train loss:1.5602 acc:0.7421 acc1:0.3697 mse:85647536 Test loss:1.5541 acc:0.7213 acc1:0.3360 mse:405325568\n",
      "\n",
      "2020-10-30 08:23:16\n",
      "[0, 0, 0, 0, 2, 0, 0, 0, 0, 0]\n",
      "[8, 7, 15, 11, 14, 36, 19, 20, 15, 11]\n",
      "###### 397 batch Train loss:1.1233 acc:0.7122 acc1:0.3862 mse:30694684 Test loss:1.5562 acc:0.7194 acc1:0.3337 mse:404566912\n",
      "\n",
      "2020-10-30 08:23:18\n",
      "[5, 12, 23, 16, 23, 29, 13, 7, 6, 3]\n",
      "[11, 11, 24, 18, 20, 37, 16, 14, 12, 11]\n",
      "###### 398 batch Train loss:1.7372 acc:0.6760 acc1:0.3510 mse:51695528 Test loss:1.5541 acc:0.7203 acc1:0.3365 mse:404550400\n",
      "\n",
      "2020-10-30 08:23:21\n",
      "[49, 5, 33, 34, 50, 109, 45, 60, 91, 81]\n",
      "[14, 9, 24, 18, 22, 51, 29, 27, 22, 18]\n",
      "###### 399 batch Train loss:1.6574 acc:0.7170 acc1:0.3438 mse:50020356 Test loss:1.5502 acc:0.7225 acc1:0.3417 mse:404887616\n",
      "\n",
      "2020-10-30 08:23:23\n",
      "[5, 7, 7, 13, 13, 13, 8, 2, 8, 2]\n",
      "[9, 8, 14, 11, 13, 31, 14, 15, 12, 10]\n",
      "###### 400 batch Train loss:1.0773 acc:0.6397 acc1:0.2860 mse:32638340 Test loss:1.5423 acc:0.7285 acc1:0.3517 mse:406427008\n",
      "\n",
      "2020-10-30 08:23:26\n",
      "[12, 16, 45, 40, 52, 44, 39, 14, 15, 16]\n",
      "[13, 12, 27, 24, 26, 56, 28, 13, 16, 16]\n",
      "###### 401 batch Train loss:1.8417 acc:0.7157 acc1:0.4171 mse:46962004 Test loss:1.5366 acc:0.7328 acc1:0.3589 mse:407674432\n",
      "\n",
      "2020-10-30 08:23:28\n",
      "[8, 8, 17, 18, 17, 45, 21, 6, 5, 6]\n",
      "[13, 10, 22, 19, 21, 48, 23, 11, 13, 14]\n",
      "###### 402 batch Train loss:0.6698 acc:0.7224 acc1:0.2918 mse:1283028 Test loss:1.5355 acc:0.7373 acc1:0.3645 mse:410259648\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-30 08:23:32\n",
      "[2, 7, 8, 8, 8, 7, 7, 5, 1, 3]\n",
      "[7, 7, 12, 10, 12, 26, 12, 13, 10, 8]\n",
      "###### 403 batch Train loss:1.9472 acc:0.7354 acc1:0.4096 mse:76485760 Test loss:1.5383 acc:0.7394 acc1:0.3661 mse:412262752\n",
      "\n",
      "2020-10-30 08:23:34\n",
      "[0, 8, 12, 4, 7, 5, 9, 1, 2, 3]\n",
      "[6, 6, 11, 8, 11, 26, 13, 14, 10, 8]\n",
      "###### 404 batch Train loss:1.3782 acc:0.7474 acc1:0.4693 mse:52430164 Test loss:1.5418 acc:0.7401 acc1:0.3651 mse:413424672\n",
      "\n",
      "2020-10-30 08:23:37\n",
      "[10, 10, 40, 53, 50, 55, 41, 12, 17, 21]\n",
      "[11, 10, 23, 23, 25, 47, 26, 10, 13, 13]\n",
      "###### 405 batch Train loss:2.5085 acc:0.7275 acc1:0.4297 mse:95447768 Test loss:1.5402 acc:0.7395 acc1:0.3641 mse:412641536\n",
      "\n",
      "2020-10-30 08:23:39\n",
      "[3, 0, 6, 9, 8, 7, 6, 19, 14, 10]\n",
      "[9, 7, 16, 13, 17, 36, 22, 20, 16, 12]\n",
      "###### 406 batch Train loss:1.6182 acc:0.7005 acc1:0.2898 mse:57975336 Test loss:1.5388 acc:0.7390 acc1:0.3629 mse:411872800\n",
      "\n",
      "2020-10-30 08:23:42\n",
      "[10, 9, 14, 27, 27, 46, 40, 19, 11, 12]\n",
      "[10, 9, 15, 14, 20, 49, 31, 21, 14, 11]\n",
      "###### 407 batch Train loss:0.9833 acc:0.7478 acc1:0.4416 mse:29965882 Test loss:1.5377 acc:0.7384 acc1:0.3618 mse:411119488\n",
      "\n",
      "2020-10-30 08:23:45\n",
      "[5, 3, 18, 14, 10, 34, 10, 6, 6, 3]\n",
      "[7, 9, 19, 16, 18, 26, 12, 9, 7, 6]\n",
      "###### 408 batch Train loss:1.7601 acc:0.7261 acc1:0.3551 mse:70478408 Test loss:1.5355 acc:0.7378 acc1:0.3610 mse:409999680\n",
      "\n",
      "2020-10-30 08:23:47\n",
      "[42, 12, 30, 34, 50, 114, 49, 76, 75, 83]\n",
      "[10, 8, 19, 16, 20, 39, 26, 22, 17, 13]\n",
      "###### 409 batch Train loss:1.7984 acc:0.7368 acc1:0.4317 mse:95016576 Test loss:1.5319 acc:0.7368 acc1:0.3607 mse:408326560\n",
      "\n",
      "2020-10-30 08:23:50\n",
      "[10, 9, 22, 11, 11, 105, 22, 23, 12, 9]\n",
      "[7, 7, 15, 13, 14, 46, 25, 13, 10, 9]\n",
      "###### 410 batch Train loss:1.5777 acc:0.7355 acc1:0.3851 mse:81689352 Test loss:1.5286 acc:0.7357 acc1:0.3603 mse:406638112\n",
      "\n",
      "2020-10-30 08:23:52\n",
      "[15, 14, 36, 17, 33, 95, 58, 29, 79, 23]\n",
      "[13, 11, 26, 19, 26, 54, 35, 26, 21, 16]\n",
      "###### 411 batch Train loss:1.0496 acc:0.7125 acc1:0.4046 mse:23744652 Test loss:1.5262 acc:0.7351 acc1:0.3607 mse:405506304\n",
      "\n",
      "2020-10-30 08:23:55\n",
      "[8, 1, 3, 10, 6, 10, 6, 24, 21, 8]\n",
      "[9, 7, 17, 14, 18, 36, 24, 20, 15, 12]\n",
      "###### 412 batch Train loss:0.9017 acc:0.7165 acc1:0.2268 mse:23083476 Test loss:1.5256 acc:0.7354 acc1:0.3614 mse:405389472\n",
      "\n",
      "2020-10-30 08:23:57\n",
      "[6, 9, 5, 17, 26, 38, 29, 13, 13, 10]\n",
      "[7, 7, 13, 13, 14, 40, 26, 12, 10, 9]\n",
      "###### 413 batch Train loss:1.0727 acc:0.7116 acc1:0.3730 mse:11916707 Test loss:1.5256 acc:0.7361 acc1:0.3628 mse:405701376\n",
      "\n",
      "2020-10-30 08:24:00\n",
      "[24, 7, 16, 31, 47, 132, 57, 89, 73, 83]\n",
      "[10, 9, 19, 15, 19, 41, 26, 22, 17, 13]\n",
      "###### 414 batch Train loss:1.8383 acc:0.6808 acc1:0.3904 mse:49231736 Test loss:1.5241 acc:0.7361 acc1:0.3641 mse:405251136\n",
      "\n",
      "2020-10-30 08:24:02\n",
      "[8, 4, 9, 10, 4, 29, 24, 18, 13, 7]\n",
      "[7, 7, 12, 12, 15, 38, 27, 13, 10, 9]\n",
      "###### 415 batch Train loss:1.5616 acc:0.7189 acc1:0.4363 mse:47275700 Test loss:1.5223 acc:0.7356 acc1:0.3647 mse:404533888\n",
      "\n",
      "2020-10-30 08:24:05\n",
      "[32, 30, 100, 63, 117, 209, 186, 117, 112, 121]\n",
      "[13, 10, 25, 18, 25, 50, 33, 27, 21, 16]\n",
      "###### 416 batch Train loss:3.1294 acc:0.7212 acc1:0.3753 mse:174837040 Test loss:1.5197 acc:0.7326 acc1:0.3627 mse:402168768\n",
      "\n",
      "2020-10-30 08:24:07\n",
      "[12, 8, 45, 41, 54, 77, 50, 17, 12, 18]\n",
      "[11, 11, 26, 23, 27, 47, 28, 11, 13, 13]\n",
      "###### 417 batch Train loss:1.3730 acc:0.7069 acc1:0.4056 mse:19673070 Test loss:1.5209 acc:0.7281 acc1:0.3572 mse:399855936\n",
      "\n",
      "2020-10-30 08:24:10\n",
      "[10, 13, 45, 45, 56, 75, 51, 12, 25, 17]\n",
      "[12, 13, 26, 24, 28, 50, 28, 11, 14, 15]\n",
      "###### 418 batch Train loss:1.7224 acc:0.6963 acc1:0.3547 mse:75772504 Test loss:1.5254 acc:0.7230 acc1:0.3502 mse:398116672\n",
      "\n",
      "2020-10-30 08:24:12\n",
      "[5, 11, 2, 14, 12, 47, 25, 13, 15, 12]\n",
      "[8, 8, 14, 14, 17, 40, 29, 14, 11, 10]\n",
      "###### 419 batch Train loss:1.2252 acc:0.7243 acc1:0.3996 mse:28691910 Test loss:1.5285 acc:0.7198 acc1:0.3456 mse:397256928\n",
      "\n",
      "2020-10-30 08:24:15\n",
      "[9, 15, 15, 13, 27, 76, 16, 6, 26, 11]\n",
      "[12, 11, 26, 22, 27, 49, 27, 12, 13, 14]\n",
      "###### 420 batch Train loss:0.8351 acc:0.7261 acc1:0.3501 mse:14707321 Test loss:1.5241 acc:0.7221 acc1:0.3488 mse:397635264\n",
      "\n",
      "2020-10-30 08:24:17\n",
      "[0, 0, 0, 0, 2, 0, 0, 0, 0, 0]\n",
      "[8, 7, 16, 10, 15, 35, 21, 19, 14, 11]\n",
      "###### 421 batch Train loss:1.4693 acc:0.6850 acc1:0.3894 mse:70520560 Test loss:1.5182 acc:0.7264 acc1:0.3543 mse:398753120\n",
      "\n",
      "2020-10-30 08:24:20\n",
      "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[7, 6, 15, 9, 15, 33, 21, 19, 14, 10]\n",
      "###### 422 batch Train loss:1.5565 acc:0.7459 acc1:0.3918 mse:44623640 Test loss:1.5132 acc:0.7304 acc1:0.3590 mse:400034432\n",
      "\n",
      "2020-10-30 08:24:22\n",
      "[33, 44, 109, 68, 119, 235, 204, 110, 113, 108]\n",
      "[16, 12, 28, 20, 29, 56, 35, 30, 23, 18]\n",
      "###### 423 batch Train loss:2.3507 acc:0.6773 acc1:0.3595 mse:143944704 Test loss:1.5106 acc:0.7332 acc1:0.3619 mse:401046592\n",
      "\n",
      "2020-10-30 08:24:25\n",
      "[4, 6, 6, 3, 8, 10, 6, 1, 0, 2]\n",
      "[6, 6, 11, 7, 10, 27, 15, 16, 11, 8]\n",
      "###### 424 batch Train loss:1.6624 acc:0.6842 acc1:0.3941 mse:61538256 Test loss:1.5100 acc:0.7354 acc1:0.3641 mse:402087648\n",
      "\n",
      "2020-10-30 08:24:27\n",
      "[38, 22, 91, 51, 139, 283, 164, 102, 133, 185]\n",
      "[14, 10, 25, 18, 25, 48, 30, 28, 21, 15]\n",
      "###### 425 batch Train loss:2.2370 acc:0.6488 acc1:0.3019 mse:105324696 Test loss:1.5094 acc:0.7362 acc1:0.3653 mse:402419136\n",
      "\n",
      "2020-10-30 08:24:30\n",
      "[15, 8, 19, 12, 12, 61, 30, 26, 16, 12]\n",
      "[12, 9, 17, 14, 22, 51, 33, 25, 16, 12]\n",
      "###### 426 batch Train loss:1.6054 acc:0.6727 acc1:0.4064 mse:45629964 Test loss:1.5096 acc:0.7371 acc1:0.3669 mse:402848960\n",
      "\n",
      "2020-10-30 08:24:32\n",
      "[14, 11, 13, 11, 15, 46, 27, 7, 13, 18]\n",
      "[12, 8, 18, 15, 17, 41, 26, 15, 11, 11]\n",
      "###### 427 batch Train loss:0.6952 acc:0.7413 acc1:0.3384 mse:4199504 Test loss:1.5115 acc:0.7387 acc1:0.3687 mse:404199680\n",
      "\n",
      "2020-10-30 08:24:35\n",
      "[7, 11, 12, 8, 21, 27, 17, 11, 13, 7]\n",
      "[9, 8, 12, 13, 14, 42, 25, 15, 12, 10]\n",
      "###### 428 batch Train loss:1.8542 acc:0.6870 acc1:0.4480 mse:66153048 Test loss:1.5118 acc:0.7393 acc1:0.3697 mse:404641600\n",
      "\n",
      "2020-10-30 08:24:38\n",
      "[3, 4, 17, 10, 14, 94, 25, 21, 13, 8]\n",
      "[10, 6, 15, 13, 14, 46, 24, 16, 12, 10]\n",
      "###### 429 batch Train loss:1.5724 acc:0.7424 acc1:0.4042 mse:51361148 Test loss:1.5101 acc:0.7393 acc1:0.3704 mse:404389120\n",
      "\n",
      "2020-10-30 08:24:40\n",
      "[9, 8, 18, 17, 27, 87, 15, 7, 23, 7]\n",
      "[13, 10, 23, 21, 24, 45, 23, 10, 14, 13]\n",
      "###### 430 batch Train loss:0.8653 acc:0.7280 acc1:0.3825 mse:8640792 Test loss:1.5093 acc:0.7397 acc1:0.3719 mse:404627904\n",
      "\n",
      "2020-10-30 08:24:43\n",
      "[27, 34, 101, 76, 117, 209, 179, 104, 116, 110]\n",
      "[17, 11, 28, 20, 27, 57, 32, 30, 24, 18]\n",
      "###### 431 batch Train loss:1.5685 acc:0.7276 acc1:0.3842 mse:73273624 Test loss:1.5080 acc:0.7397 acc1:0.3732 mse:404555872\n",
      "\n",
      "2020-10-30 08:24:45\n",
      "[4, 1, 3, 7, 5, 16, 7, 20, 16, 10]\n",
      "[12, 8, 18, 14, 18, 41, 22, 23, 18, 13]\n",
      "###### 432 batch Train loss:1.0670 acc:0.6970 acc1:0.3645 mse:26648274 Test loss:1.5084 acc:0.7400 acc1:0.3741 mse:404825216\n",
      "\n",
      "2020-10-30 08:24:48\n",
      "[3, 0, 4, 7, 3, 6, 4, 13, 13, 12]\n",
      "[12, 8, 18, 15, 19, 41, 23, 23, 18, 13]\n",
      "###### 433 batch Train loss:0.7781 acc:0.6718 acc1:0.0692 mse:1664774 Test loss:1.5125 acc:0.7419 acc1:0.3747 mse:406837312\n",
      "\n",
      "2020-10-30 08:24:51\n",
      "[24, 7, 16, 31, 47, 132, 57, 89, 73, 83]\n",
      "[14, 10, 21, 17, 22, 47, 25, 25, 20, 15]\n",
      "###### 434 batch Train loss:1.8757 acc:0.6700 acc1:0.3707 mse:64419660 Test loss:1.5149 acc:0.7423 acc1:0.3750 mse:407641472\n",
      "\n",
      "2020-10-30 08:24:54\n",
      "[1, 8, 2, 0, 1, 4, 1, 6, 2, 1]\n",
      "[5, 4, 11, 6, 10, 25, 15, 16, 12, 7]\n",
      "###### 435 batch Train loss:1.3186 acc:0.7338 acc1:0.3742 mse:69633352 Test loss:1.5166 acc:0.7426 acc1:0.3752 mse:408220416\n",
      "\n",
      "2020-10-30 08:24:56\n",
      "[21, 12, 38, 23, 35, 106, 60, 26, 31, 23]\n",
      "[17, 12, 29, 20, 29, 66, 35, 32, 26, 20]\n",
      "###### 436 batch Train loss:1.1754 acc:0.7414 acc1:0.4660 mse:46655620 Test loss:1.5177 acc:0.7428 acc1:0.3747 mse:408447360\n",
      "\n",
      "2020-10-30 08:24:59\n",
      "[10, 8, 10, 8, 20, 35, 25, 9, 7, 16]\n",
      "[8, 8, 12, 13, 16, 44, 26, 14, 12, 10]\n",
      "###### 437 batch Train loss:1.1870 acc:0.7486 acc1:0.4391 mse:36043476 Test loss:1.5175 acc:0.7430 acc1:0.3745 mse:408569856\n",
      "\n",
      "2020-10-30 08:25:01\n",
      "[14, 7, 23, 17, 9, 40, 38, 22, 14, 12]\n",
      "[12, 8, 17, 15, 17, 46, 26, 15, 13, 12]\n",
      "###### 438 batch Train loss:1.0505 acc:0.7332 acc1:0.4309 mse:37714020 Test loss:1.5176 acc:0.7431 acc1:0.3740 mse:408608160\n",
      "\n",
      "2020-10-30 08:25:04\n",
      "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[6, 5, 12, 8, 12, 32, 17, 18, 14, 9]\n",
      "###### 439 batch Train loss:1.1055 acc:0.7685 acc1:0.3775 mse:18266352 Test loss:1.5158 acc:0.7429 acc1:0.3740 mse:408182528\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-30 08:25:06\n",
      "[19, 7, 13, 11, 19, 61, 32, 20, 14, 10]\n",
      "[12, 10, 17, 15, 23, 57, 33, 25, 17, 13]\n",
      "###### 440 batch Train loss:2.0706 acc:0.7214 acc1:0.3738 mse:67254792 Test loss:1.5103 acc:0.7416 acc1:0.3740 mse:406593152\n",
      "\n",
      "2020-10-30 08:25:09\n",
      "[49, 5, 33, 34, 50, 109, 45, 60, 91, 81]\n",
      "[13, 9, 22, 18, 25, 50, 28, 25, 21, 16]\n",
      "###### 441 batch Train loss:0.7933 acc:0.7450 acc1:0.1965 mse:6847377 Test loss:1.5085 acc:0.7419 acc1:0.3752 mse:406781568\n",
      "\n",
      "2020-10-30 08:25:12\n",
      "[0, 0, 0, 0, 2, 0, 0, 0, 0, 0]\n",
      "[6, 6, 12, 9, 12, 31, 17, 18, 14, 9]\n",
      "###### 442 batch Train loss:1.8188 acc:0.7343 acc1:0.2646 mse:66631884 Test loss:1.5055 acc:0.7416 acc1:0.3761 mse:406528768\n",
      "\n",
      "2020-10-30 08:25:14\n",
      "[35, 20, 102, 55, 156, 265, 164, 142, 144, 179]\n",
      "[14, 10, 25, 21, 27, 54, 31, 27, 23, 17]\n",
      "###### 443 batch Train loss:1.5881 acc:0.7151 acc1:0.4235 mse:50583816 Test loss:1.5033 acc:0.7415 acc1:0.3774 mse:406547520\n",
      "\n",
      "2020-10-30 08:25:17\n",
      "[10, 8, 13, 20, 17, 38, 23, 14, 17, 16]\n",
      "[8, 8, 13, 15, 14, 42, 24, 13, 11, 9]\n",
      "###### 444 batch Train loss:1.4140 acc:0.7323 acc1:0.4146 mse:70168264 Test loss:1.5020 acc:0.7420 acc1:0.3794 mse:406936864\n",
      "\n",
      "2020-10-30 08:25:19\n",
      "[1, 2, 0, 1, 0, 0, 0, 1, 1, 0]\n",
      "[6, 5, 12, 8, 12, 29, 17, 17, 13, 9]\n",
      "###### 445 batch Train loss:1.3990 acc:0.7211 acc1:0.3559 mse:43557028 Test loss:1.5008 acc:0.7424 acc1:0.3816 mse:407369568\n",
      "\n",
      "2020-10-30 08:25:22\n",
      "[4, 4, 9, 9, 8, 13, 8, 2, 4, 5]\n",
      "[4, 5, 8, 7, 9, 22, 11, 13, 9, 6]\n",
      "###### 446 batch Train loss:1.0213 acc:0.6768 acc1:0.2615 mse:13109153 Test loss:1.5018 acc:0.7443 acc1:0.3835 mse:408914624\n",
      "\n",
      "2020-10-30 08:25:24\n",
      "[7, 6, 17, 14, 15, 46, 23, 19, 18, 17]\n",
      "[7, 6, 13, 12, 12, 43, 23, 14, 10, 9]\n",
      "###### 447 batch Train loss:1.5307 acc:0.7437 acc1:0.3751 mse:52163124 Test loss:1.5020 acc:0.7453 acc1:0.3849 mse:409890752\n",
      "\n",
      "2020-10-30 08:25:27\n",
      "[42, 12, 30, 34, 50, 114, 49, 76, 75, 83]\n",
      "[11, 8, 20, 17, 21, 40, 25, 24, 18, 13]\n",
      "###### 448 batch Train loss:1.0048 acc:0.7287 acc1:0.4711 mse:18876390 Test loss:1.5035 acc:0.7465 acc1:0.3858 mse:411016064\n",
      "\n",
      "2020-10-30 08:25:29\n",
      "[11, 11, 19, 12, 17, 45, 27, 28, 15, 11]\n",
      "[11, 9, 14, 15, 20, 48, 30, 22, 14, 11]\n",
      "###### 449 batch Train loss:1.4484 acc:0.7173 acc1:0.4532 mse:40339888 Test loss:1.5040 acc:0.7474 acc1:0.3868 mse:411652992\n",
      "\n",
      "2020-10-30 08:25:32\n",
      "[17, 13, 45, 41, 50, 83, 34, 18, 22, 14]\n",
      "[10, 10, 21, 23, 24, 42, 24, 9, 13, 11]\n",
      "###### 450 batch Train loss:1.1642 acc:0.7383 acc1:0.4441 mse:28571778 Test loss:1.5025 acc:0.7477 acc1:0.3880 mse:411600960\n",
      "\n",
      "2020-10-30 08:25:34\n",
      "[34, 10, 19, 34, 40, 113, 54, 63, 86, 94]\n",
      "[12, 8, 18, 16, 20, 37, 24, 24, 17, 13]\n",
      "###### 451 batch Train loss:1.2981 acc:0.7470 acc1:0.4518 mse:38671288 Test loss:1.4990 acc:0.7475 acc1:0.3893 mse:410860896\n",
      "\n",
      "2020-10-30 08:25:37\n",
      "[4, 4, 8, 13, 13, 7, 7, 3, 7, 3]\n",
      "[4, 4, 8, 6, 8, 20, 11, 13, 9, 6]\n",
      "###### 452 batch Train loss:1.5574 acc:0.7334 acc1:0.3836 mse:81487224 Test loss:1.4956 acc:0.7471 acc1:0.3901 mse:409966880\n",
      "\n",
      "2020-10-30 08:25:39\n",
      "[6, 5, 15, 13, 14, 56, 24, 14, 8, 10]\n",
      "[8, 6, 13, 12, 12, 42, 23, 15, 10, 9]\n",
      "###### 453 batch Train loss:1.6676 acc:0.7307 acc1:0.4307 mse:47450200 Test loss:1.4900 acc:0.7452 acc1:0.3904 mse:407881824\n",
      "\n",
      "2020-10-30 08:25:42\n",
      "[3, 7, 3, 5, 5, 6, 9, 5, 3, 3]\n",
      "[4, 4, 7, 6, 8, 20, 11, 13, 9, 6]\n",
      "###### 454 batch Train loss:0.7244 acc:0.7377 acc1:0.4573 mse:10058676 Test loss:1.4883 acc:0.7449 acc1:0.3905 mse:407289024\n",
      "\n",
      "2020-10-30 08:25:44\n",
      "[16, 10, 29, 16, 18, 86, 53, 41, 35, 30]\n",
      "[16, 12, 26, 19, 27, 57, 34, 31, 23, 18]\n",
      "###### 455 batch Train loss:2.0105 acc:0.7113 acc1:0.4701 mse:117532808 Test loss:1.4859 acc:0.7430 acc1:0.3887 mse:405349760\n",
      "\n",
      "2020-10-30 08:25:47\n",
      "[2, 3, 12, 9, 11, 23, 11, 6, 2, 5]\n",
      "[6, 6, 10, 9, 12, 18, 11, 12, 8, 5]\n",
      "###### 456 batch Train loss:2.4279 acc:0.7117 acc1:0.4732 mse:161081552 Test loss:1.4854 acc:0.7381 acc1:0.3820 mse:401951712\n",
      "\n",
      "2020-10-30 08:25:49\n",
      "[8, 10, 40, 41, 39, 61, 40, 19, 17, 17]\n",
      "[14, 12, 26, 26, 29, 49, 29, 13, 16, 14]\n",
      "###### 457 batch Train loss:1.0199 acc:0.7184 acc1:0.4257 mse:12100480 Test loss:1.4856 acc:0.7352 acc1:0.3768 mse:399880352\n",
      "\n",
      "2020-10-30 08:25:52\n",
      "[25, 36, 106, 85, 123, 195, 209, 111, 84, 103]\n",
      "[19, 12, 28, 22, 28, 61, 34, 32, 25, 19]\n",
      "###### 458 batch Train loss:2.2232 acc:0.6976 acc1:0.4658 mse:116067032 Test loss:1.4870 acc:0.7296 acc1:0.3680 mse:396907712\n",
      "\n",
      "2020-10-30 08:25:54\n",
      "[10, 13, 45, 45, 56, 75, 51, 12, 25, 17]\n",
      "[14, 13, 26, 26, 28, 52, 28, 13, 16, 15]\n",
      "###### 459 batch Train loss:2.3281 acc:0.6799 acc1:0.4356 mse:134920080 Test loss:1.4970 acc:0.7175 acc1:0.3500 mse:393097184\n",
      "\n",
      "2020-10-30 08:25:57\n",
      "[46, 17, 86, 53, 140, 282, 181, 113, 153, 177]\n",
      "[17, 11, 28, 22, 28, 58, 33, 31, 24, 18]\n",
      "###### 460 batch Train loss:1.4016 acc:0.7076 acc1:0.3705 mse:40738064 Test loss:1.5090 acc:0.7066 acc1:0.3337 mse:390543840\n",
      "\n",
      "2020-10-30 08:25:59\n",
      "[25, 8, 21, 36, 44, 128, 52, 75, 85, 84]\n",
      "[15, 11, 26, 21, 26, 53, 31, 28, 22, 17]\n",
      "###### 461 batch Train loss:2.4525 acc:0.6789 acc1:0.4358 mse:102555544 Test loss:1.5367 acc:0.6843 acc1:0.3043 mse:387507136\n",
      "\n",
      "2020-10-30 08:26:02\n",
      "[36, 10, 28, 31, 44, 118, 51, 72, 61, 79]\n",
      "[16, 12, 29, 23, 29, 57, 33, 28, 23, 18]\n",
      "###### 462 batch Train loss:1.2939 acc:0.6330 acc1:0.2925 mse:29182606 Test loss:1.5378 acc:0.6828 acc1:0.2998 mse:386380032\n",
      "\n",
      "2020-10-30 08:26:04\n",
      "[6, 9, 18, 13, 9, 45, 31, 12, 15, 10]\n",
      "[8, 8, 14, 15, 15, 40, 26, 14, 11, 10]\n",
      "###### 463 batch Train loss:1.4556 acc:0.6385 acc1:0.2439 mse:41459316 Test loss:1.5156 acc:0.6994 acc1:0.3158 mse:386582848\n",
      "\n",
      "2020-10-30 08:26:07\n",
      "[48, 23, 85, 46, 135, 292, 170, 112, 145, 173]\n",
      "[18, 13, 33, 26, 33, 67, 37, 31, 25, 21]\n",
      "###### 464 batch Train loss:3.1923 acc:0.6760 acc1:0.4165 mse:52203024 Test loss:1.5200 acc:0.6971 acc1:0.3095 mse:385022208\n",
      "\n",
      "2020-10-30 08:26:10\n",
      "[6, 6, 17, 17, 20, 32, 32, 13, 11, 11]\n",
      "[13, 9, 23, 18, 21, 52, 33, 18, 15, 15]\n",
      "###### 465 batch Train loss:0.8810 acc:0.6098 acc1:0.0881 mse:5413851 Test loss:1.4964 acc:0.7168 acc1:0.3301 mse:386390464\n",
      "\n",
      "2020-10-30 08:26:13\n",
      "[1, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "[5, 5, 14, 9, 13, 35, 20, 19, 14, 10]\n",
      "###### 466 batch Train loss:0.7782 acc:0.7486 acc1:0.3114 mse:13660430 Test loss:1.4807 acc:0.7349 acc1:0.3501 mse:390429920\n",
      "\n",
      "2020-10-30 08:26:15\n",
      "[3, 7, 3, 5, 5, 6, 9, 5, 3, 3]\n",
      "[4, 5, 9, 6, 9, 23, 13, 13, 9, 7]\n",
      "###### 467 batch Train loss:1.4925 acc:0.7206 acc1:0.4228 mse:55439564 Test loss:1.4859 acc:0.7417 acc1:0.3539 mse:394095936\n",
      "\n",
      "2020-10-30 08:26:18\n",
      "[13, 7, 13, 14, 24, 48, 39, 23, 11, 14]\n",
      "[10, 10, 19, 15, 22, 56, 34, 24, 16, 14]\n",
      "###### 468 batch Train loss:0.6266 acc:0.7705 acc1:0.1623 mse:4670252 Test loss:1.5030 acc:0.7454 acc1:0.3521 mse:399343616\n",
      "\n",
      "2020-10-30 08:26:20\n",
      "[46, 21, 92, 61, 137, 282, 140, 115, 134, 178]\n",
      "[11, 9, 22, 16, 22, 55, 28, 26, 20, 17]\n",
      "###### 469 batch Train loss:1.4320 acc:0.7092 acc1:0.2679 mse:42863232 Test loss:1.5211 acc:0.7463 acc1:0.3482 mse:403782560\n",
      "\n",
      "2020-10-30 08:26:23\n",
      "[7, 7, 15, 22, 19, 26, 16, 6, 15, 7]\n",
      "[8, 8, 21, 18, 21, 42, 24, 9, 12, 12]\n",
      "###### 470 batch Train loss:1.3640 acc:0.7393 acc1:0.4249 mse:38006192 Test loss:1.5320 acc:0.7465 acc1:0.3457 mse:406358656\n",
      "\n",
      "2020-10-30 08:26:25\n",
      "[10, 11, 14, 12, 18, 37, 33, 21, 15, 12]\n",
      "[7, 7, 15, 12, 13, 37, 26, 13, 9, 10]\n",
      "###### 471 batch Train loss:1.9458 acc:0.7224 acc1:0.4029 mse:92141528 Test loss:1.5327 acc:0.7466 acc1:0.3454 mse:406338464\n",
      "\n",
      "2020-10-30 08:26:28\n",
      "[2, 3, 1, 1, 3, 3, 11, 2, 4, 4]\n",
      "[3, 4, 9, 5, 9, 26, 14, 14, 10, 7]\n",
      "###### 472 batch Train loss:1.7314 acc:0.7207 acc1:0.3639 mse:74978624 Test loss:1.5273 acc:0.7465 acc1:0.3466 mse:404620416\n",
      "\n",
      "2020-10-30 08:26:30\n",
      "[25, 8, 21, 36, 44, 128, 52, 75, 85, 84]\n",
      "[9, 6, 18, 13, 19, 45, 26, 24, 17, 14]\n",
      "###### 473 batch Train loss:1.4176 acc:0.7473 acc1:0.3828 mse:47626052 Test loss:1.5193 acc:0.7460 acc1:0.3476 mse:402028096\n",
      "\n",
      "2020-10-30 08:26:33\n",
      "[8, 7, 3, 9, 12, 16, 6, 3, 4, 6]\n",
      "[4, 5, 9, 8, 11, 21, 10, 10, 7, 6]\n",
      "###### 474 batch Train loss:1.8058 acc:0.7356 acc1:0.3913 mse:84129176 Test loss:1.5103 acc:0.7446 acc1:0.3473 mse:398664224\n",
      "\n",
      "2020-10-30 08:26:35\n",
      "[7, 8, 10, 9, 13, 35, 27, 13, 5, 6]\n",
      "[6, 6, 13, 11, 13, 43, 26, 14, 11, 9]\n",
      "###### 475 batch Train loss:0.6181 acc:0.7585 acc1:0.3668 mse:3766353 Test loss:1.5054 acc:0.7428 acc1:0.3458 mse:396346688\n",
      "\n",
      "2020-10-30 08:26:38\n",
      "[8, 10, 40, 41, 39, 61, 40, 19, 17, 17]\n",
      "[11, 10, 29, 25, 31, 56, 30, 12, 15, 16]\n",
      "###### 476 batch Train loss:1.7616 acc:0.6761 acc1:0.3467 mse:45708592 Test loss:1.5010 acc:0.7405 acc1:0.3436 mse:394077824\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-30 08:26:40\n",
      "[34, 11, 23, 32, 41, 124, 55, 73, 86, 86]\n",
      "[13, 9, 23, 18, 25, 60, 28, 26, 20, 17]\n",
      "###### 477 batch Train loss:1.5344 acc:0.7061 acc1:0.4197 mse:40852144 Test loss:1.4967 acc:0.7382 acc1:0.3423 mse:392120640\n",
      "\n",
      "2020-10-30 08:26:43\n",
      "[12, 8, 45, 41, 54, 77, 50, 17, 12, 18]\n",
      "[14, 11, 32, 28, 36, 64, 32, 14, 17, 18]\n",
      "###### 478 batch Train loss:1.5141 acc:0.7207 acc1:0.3920 mse:29782742 Test loss:1.4905 acc:0.7373 acc1:0.3441 mse:391004704\n",
      "\n",
      "2020-10-30 08:26:45\n",
      "[9, 1, 3, 7, 8, 15, 4, 24, 16, 9]\n",
      "[11, 7, 20, 17, 24, 56, 26, 24, 18, 16]\n",
      "###### 479 batch Train loss:1.7070 acc:0.7043 acc1:0.3585 mse:71124320 Test loss:1.4848 acc:0.7368 acc1:0.3463 mse:390377920\n",
      "\n",
      "2020-10-30 08:26:48\n",
      "[21, 11, 19, 17, 17, 33, 11, 9, 10, 9]\n",
      "[15, 10, 26, 23, 29, 55, 25, 11, 14, 16]\n",
      "###### 480 batch Train loss:1.5283 acc:0.7231 acc1:0.3821 mse:46190244 Test loss:1.4806 acc:0.7366 acc1:0.3495 mse:390149952\n",
      "\n",
      "2020-10-30 08:26:50\n",
      "[12, 5, 16, 16, 12, 33, 25, 6, 11, 12]\n",
      "[8, 7, 13, 14, 16, 43, 25, 14, 11, 9]\n",
      "###### 481 batch Train loss:1.5198 acc:0.7644 acc1:0.3954 mse:83652536 Test loss:1.4775 acc:0.7359 acc1:0.3516 mse:389701600\n",
      "\n",
      "2020-10-30 08:26:53\n",
      "[6, 15, 30, 32, 33, 44, 34, 13, 12, 6]\n",
      "[13, 14, 39, 35, 45, 68, 36, 15, 15, 16]\n",
      "###### 482 batch Train loss:2.4206 acc:0.7398 acc1:0.3627 mse:126501040 Test loss:1.4790 acc:0.7305 acc1:0.3456 mse:387559008\n",
      "\n",
      "2020-10-30 08:26:55\n",
      "[7, 11, 13, 23, 23, 61, 34, 11, 22, 18]\n",
      "[8, 8, 13, 15, 16, 42, 24, 13, 11, 9]\n",
      "###### 483 batch Train loss:1.7118 acc:0.6911 acc1:0.3759 mse:94133200 Test loss:1.4797 acc:0.7268 acc1:0.3416 mse:385920288\n",
      "\n",
      "2020-10-30 08:26:58\n",
      "[10, 17, 39, 38, 46, 53, 24, 3, 16, 9]\n",
      "[13, 15, 40, 36, 46, 65, 37, 15, 15, 17]\n",
      "###### 484 batch Train loss:2.3343 acc:0.6897 acc1:0.3942 mse:86921720 Test loss:1.4820 acc:0.7220 acc1:0.3357 mse:384125504\n",
      "\n",
      "2020-10-30 08:27:00\n",
      "[7, 20, 11, 13, 14, 82, 12, 10, 11, 11]\n",
      "[14, 14, 33, 29, 38, 58, 31, 13, 16, 18]\n",
      "###### 485 batch Train loss:1.4479 acc:0.6778 acc1:0.3739 mse:62061616 Test loss:1.4752 acc:0.7246 acc1:0.3425 mse:384208064\n",
      "\n",
      "2020-10-30 08:27:03\n",
      "[30, 41, 99, 82, 134, 202, 228, 92, 115, 102]\n",
      "[19, 15, 36, 28, 39, 83, 39, 34, 26, 25]\n",
      "###### 486 batch Train loss:2.6565 acc:0.6904 acc1:0.4067 mse:131594808 Test loss:1.4795 acc:0.7200 acc1:0.3361 mse:382416640\n",
      "\n",
      "2020-10-30 08:27:05\n",
      "[15, 8, 19, 12, 12, 61, 30, 26, 16, 12]\n",
      "[12, 13, 22, 18, 27, 58, 37, 26, 17, 16]\n",
      "###### 487 batch Train loss:1.6768 acc:0.6825 acc1:0.4150 mse:45551116 Test loss:1.4746 acc:0.7215 acc1:0.3405 mse:382048096\n",
      "\n",
      "2020-10-30 08:27:08\n",
      "[16, 11, 54, 45, 44, 59, 47, 14, 13, 22]\n",
      "[13, 16, 32, 30, 36, 57, 32, 14, 16, 17]\n",
      "###### 488 batch Train loss:2.4954 acc:0.6745 acc1:0.4111 mse:90749968 Test loss:1.4769 acc:0.7183 acc1:0.3365 mse:380661728\n",
      "\n",
      "2020-10-30 08:27:10\n",
      "[20, 7, 12, 33, 23, 27, 22, 11, 16, 11]\n",
      "[12, 14, 27, 26, 30, 48, 27, 11, 14, 15]\n",
      "###### 489 batch Train loss:0.9474 acc:0.6888 acc1:0.3522 mse:15541596 Test loss:1.4623 acc:0.7281 acc1:0.3553 mse:382567808\n",
      "\n",
      "2020-10-30 08:27:13\n",
      "[24, 8, 23, 40, 40, 128, 60, 60, 95, 81]\n",
      "[13, 12, 22, 19, 24, 55, 28, 27, 19, 16]\n",
      "###### 490 batch Train loss:1.1022 acc:0.6855 acc1:0.3828 mse:30136434 Test loss:1.4564 acc:0.7371 acc1:0.3704 mse:385893856\n",
      "\n",
      "2020-10-30 08:27:15\n",
      "[8, 8, 30, 8, 19, 49, 40, 30, 8, 13]\n",
      "[8, 8, 15, 13, 14, 40, 26, 16, 11, 10]\n",
      "###### 491 batch Train loss:0.7924 acc:0.7099 acc1:0.3442 mse:8648950 Test loss:1.4660 acc:0.7436 acc1:0.3761 mse:391245952\n",
      "\n",
      "2020-10-30 08:27:18\n",
      "[1, 2, 0, 1, 0, 0, 0, 1, 1, 0]\n",
      "[5, 5, 10, 7, 10, 29, 16, 16, 12, 8]\n",
      "###### 492 batch Train loss:0.7751 acc:0.7762 acc1:0.2691 mse:22707578 Test loss:1.4872 acc:0.7457 acc1:0.3707 mse:396847936\n",
      "\n",
      "2020-10-30 08:27:20\n",
      "[8, 8, 17, 18, 17, 45, 21, 6, 5, 6]\n",
      "[8, 7, 14, 13, 15, 35, 18, 8, 10, 8]\n",
      "###### 493 batch Train loss:1.7247 acc:0.7407 acc1:0.4348 mse:69414792 Test loss:1.5008 acc:0.7458 acc1:0.3648 mse:399626016\n",
      "\n",
      "2020-10-30 08:27:23\n",
      "[1, 4, 2, 1, 2, 4, 3, 0, 2, 2]\n",
      "[4, 4, 8, 6, 8, 25, 14, 14, 10, 7]\n",
      "###### 494 batch Train loss:1.9659 acc:0.7538 acc1:0.4275 mse:109350080 Test loss:1.5027 acc:0.7457 acc1:0.3622 mse:399440256\n",
      "\n",
      "2020-10-30 08:27:25\n",
      "[10, 9, 22, 11, 11, 105, 22, 23, 12, 9]\n",
      "[7, 6, 12, 10, 11, 44, 23, 14, 10, 7]\n",
      "###### 495 batch Train loss:0.6287 acc:0.7437 acc1:0.4274 mse:1030415 Test loss:1.5040 acc:0.7458 acc1:0.3605 mse:399453504\n",
      "\n",
      "2020-10-30 08:27:29\n",
      "[5, 11, 13, 10, 17, 17, 9, 3, 7, 7]\n",
      "[5, 8, 14, 12, 13, 21, 9, 9, 6, 4]\n",
      "###### 496 batch Train loss:0.8174 acc:0.7528 acc1:0.2516 mse:13112543 Test loss:1.5050 acc:0.7460 acc1:0.3591 mse:399590752\n",
      "\n",
      "2020-10-30 08:27:32\n",
      "[19, 7, 13, 11, 19, 61, 32, 20, 14, 10]\n",
      "[8, 7, 11, 11, 15, 48, 28, 22, 14, 9]\n",
      "###### 497 batch Train loss:1.9173 acc:0.7416 acc1:0.4330 mse:92164064 Test loss:1.4980 acc:0.7461 acc1:0.3595 mse:397565664\n",
      "\n",
      "2020-10-30 08:27:34\n",
      "[9, 7, 16, 13, 10, 24, 5, 4, 2, 10]\n",
      "[5, 8, 14, 12, 13, 21, 9, 9, 6, 4]\n",
      "###### 498 batch Train loss:1.5184 acc:0.7462 acc1:0.4430 mse:32093936 Test loss:1.4863 acc:0.7456 acc1:0.3601 mse:394097152\n",
      "\n",
      "2020-10-30 08:27:37\n",
      "[6, 5, 15, 13, 14, 56, 24, 14, 8, 10]\n",
      "[8, 6, 12, 11, 11, 43, 23, 13, 10, 8]\n",
      "###### 499 batch Train loss:1.5361 acc:0.7213 acc1:0.4419 mse:37350880 Test loss:1.4738 acc:0.7438 acc1:0.3589 mse:389501248\n",
      "\n",
      "2020-10-30 08:27:39\n",
      "[11, 6, 14, 18, 11, 31, 13, 6, 10, 9]\n",
      "[10, 7, 16, 16, 17, 35, 18, 7, 11, 9]\n",
      "###### 500 batch Train loss:1.2065 acc:0.7255 acc1:0.4042 mse:27692020 Test loss:1.4660 acc:0.7405 acc1:0.3546 mse:385105536\n",
      "\n",
      "2020-10-30 08:27:42\n",
      "[7, 9, 24, 11, 21, 32, 14, 12, 14, 10]\n",
      "[10, 9, 20, 23, 22, 44, 21, 7, 12, 10]\n",
      "###### 501 batch Train loss:1.5924 acc:0.7194 acc1:0.3871 mse:56441044 Test loss:1.4639 acc:0.7354 acc1:0.3469 mse:380889600\n",
      "\n",
      "2020-10-30 08:27:44\n",
      "[7, 7, 15, 22, 19, 26, 16, 6, 15, 7]\n",
      "[11, 9, 22, 25, 25, 51, 23, 8, 13, 10]\n",
      "###### 502 batch Train loss:2.1404 acc:0.6913 acc1:0.3343 mse:104515848 Test loss:1.4684 acc:0.7285 acc1:0.3355 mse:377097440\n",
      "\n",
      "2020-10-30 08:27:47\n",
      "[2, 7, 8, 8, 8, 7, 7, 5, 1, 3]\n",
      "[5, 6, 9, 11, 10, 19, 9, 10, 8, 5]\n",
      "###### 503 batch Train loss:0.8507 acc:0.7551 acc1:0.3816 mse:22740090 Test loss:1.4741 acc:0.7231 acc1:0.3265 mse:374760032\n",
      "\n",
      "2020-10-30 08:27:49\n",
      "[13, 12, 42, 56, 50, 79, 38, 13, 15, 19]\n",
      "[14, 11, 29, 34, 33, 66, 29, 11, 15, 13]\n",
      "###### 504 batch Train loss:1.1739 acc:0.6899 acc1:0.3331 mse:25895052 Test loss:1.4738 acc:0.7217 acc1:0.3247 mse:373642592\n",
      "\n",
      "2020-10-30 08:27:52\n",
      "[25, 8, 21, 36, 44, 128, 52, 75, 85, 84]\n",
      "[15, 9, 24, 25, 27, 69, 29, 26, 21, 15]\n",
      "###### 505 batch Train loss:1.3519 acc:0.7152 acc1:0.3760 mse:43185928 Test loss:1.4655 acc:0.7249 acc1:0.3325 mse:373708800\n",
      "\n",
      "2020-10-30 08:27:54\n",
      "[17, 4, 14, 14, 23, 55, 20, 19, 19, 8]\n",
      "[9, 7, 14, 13, 13, 45, 23, 15, 11, 9]\n",
      "###### 506 batch Train loss:2.0101 acc:0.7040 acc1:0.4090 mse:98668304 Test loss:1.4635 acc:0.7249 acc1:0.3343 mse:373112768\n",
      "\n",
      "2020-10-30 08:27:57\n",
      "[4, 6, 5, 4, 9, 4, 14, 1, 0, 0]\n",
      "[4, 5, 8, 7, 8, 21, 11, 12, 9, 6]\n",
      "###### 507 batch Train loss:0.7030 acc:0.7381 acc1:0.3570 mse:5456160 Test loss:1.4575 acc:0.7287 acc1:0.3430 mse:374150752\n",
      "\n",
      "2020-10-30 08:28:00\n",
      "[7, 8, 17, 12, 13, 42, 26, 20, 10, 8]\n",
      "[8, 8, 13, 14, 14, 39, 25, 13, 12, 9]\n",
      "###### 508 batch Train loss:1.7620 acc:0.7124 acc1:0.3907 mse:87466896 Test loss:1.4531 acc:0.7322 acc1:0.3510 mse:375556288\n",
      "\n",
      "2020-10-30 08:28:02\n",
      "[10, 7, 18, 10, 17, 15, 14, 2, 9, 2]\n",
      "[9, 11, 24, 24, 23, 29, 15, 11, 9, 6]\n",
      "###### 509 batch Train loss:1.1417 acc:0.7125 acc1:0.4051 mse:19042754 Test loss:1.4481 acc:0.7378 acc1:0.3624 mse:378295424\n",
      "\n",
      "2020-10-30 08:28:05\n",
      "[4, 11, 16, 14, 20, 38, 29, 17, 20, 9]\n",
      "[11, 10, 18, 15, 20, 55, 32, 22, 15, 12]\n",
      "###### 510 batch Train loss:1.0935 acc:0.7118 acc1:0.3384 mse:30099110 Test loss:1.4500 acc:0.7440 acc1:0.3733 mse:383038272\n",
      "\n",
      "2020-10-30 08:28:07\n",
      "[10, 3, 7, 4, 8, 14, 10, 3, 5, 2]\n",
      "[4, 6, 10, 10, 11, 19, 11, 11, 8, 6]\n",
      "###### 511 batch Train loss:0.7494 acc:0.7696 acc1:0.3723 mse:8341266 Test loss:1.4621 acc:0.7477 acc1:0.3778 mse:388724960\n",
      "\n",
      "2020-10-30 08:28:10\n",
      "[7, 11, 13, 23, 23, 61, 34, 11, 22, 18]\n",
      "[8, 7, 13, 12, 12, 39, 24, 13, 12, 10]\n",
      "###### 512 batch Train loss:2.4939 acc:0.7157 acc1:0.4259 mse:112244136 Test loss:1.4647 acc:0.7482 acc1:0.3796 mse:389800640\n",
      "\n",
      "2020-10-30 08:28:12\n",
      "[5, 7, 7, 12, 10, 19, 14, 7, 4, 3]\n",
      "[4, 6, 9, 9, 9, 17, 9, 10, 8, 6]\n",
      "###### 513 batch Train loss:0.6623 acc:0.7630 acc1:0.3733 mse:6000451 Test loss:1.4680 acc:0.7488 acc1:0.3807 mse:391173504\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-30 08:28:15\n",
      "[6, 10, 21, 13, 17, 47, 18, 19, 11, 9]\n",
      "[8, 7, 15, 12, 13, 42, 23, 15, 12, 10]\n",
      "###### 514 batch Train loss:0.8198 acc:0.7498 acc1:0.3392 mse:12374143 Test loss:1.4723 acc:0.7496 acc1:0.3811 mse:392993440\n",
      "\n",
      "2020-10-30 08:28:17\n",
      "[0, 0, 0, 0, 2, 0, 0, 0, 0, 0]\n",
      "[6, 5, 11, 8, 11, 28, 16, 16, 13, 10]\n",
      "###### 515 batch Train loss:1.5122 acc:0.7791 acc1:0.4427 mse:81098240 Test loss:1.4714 acc:0.7502 acc1:0.3814 mse:393108288\n",
      "\n",
      "2020-10-30 08:28:20\n",
      "[1, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "[6, 5, 12, 8, 13, 29, 18, 17, 14, 10]\n",
      "###### 516 batch Train loss:1.3730 acc:0.7788 acc1:0.3357 mse:44251472 Test loss:1.4667 acc:0.7507 acc1:0.3828 mse:392212352\n",
      "\n",
      "2020-10-30 08:28:22\n",
      "[10, 17, 39, 38, 46, 53, 24, 3, 16, 9]\n",
      "[11, 12, 32, 30, 34, 54, 30, 13, 14, 12]\n",
      "###### 517 batch Train loss:1.3239 acc:0.7421 acc1:0.4210 mse:40029648 Test loss:1.4573 acc:0.7507 acc1:0.3840 mse:389903680\n",
      "\n",
      "2020-10-30 08:28:25\n",
      "[4, 6, 6, 3, 8, 10, 6, 1, 0, 2]\n",
      "[5, 5, 9, 6, 8, 23, 12, 13, 11, 8]\n",
      "###### 518 batch Train loss:1.8013 acc:0.7455 acc1:0.4364 mse:89397784 Test loss:1.4443 acc:0.7489 acc1:0.3834 mse:385563360\n",
      "\n",
      "2020-10-30 08:28:27\n",
      "[4, 4, 11, 5, 7, 13, 11, 2, 1, 2]\n",
      "[5, 6, 10, 10, 12, 22, 10, 12, 8, 6]\n",
      "###### 519 batch Train loss:0.9615 acc:0.7381 acc1:0.3825 mse:24464754 Test loss:1.4378 acc:0.7466 acc1:0.3805 mse:382374016\n",
      "\n",
      "2020-10-30 08:28:30\n",
      "[35, 20, 102, 55, 156, 265, 164, 142, 144, 179]\n",
      "[25, 12, 33, 25, 35, 110, 35, 34, 28, 22]\n",
      "###### 520 batch Train loss:1.5623 acc:0.7229 acc1:0.4058 mse:56189936 Test loss:1.4345 acc:0.7435 acc1:0.3762 mse:379422464\n",
      "\n",
      "2020-10-30 08:28:32\n",
      "[10, 15, 42, 37, 40, 45, 39, 16, 25, 9]\n",
      "[17, 14, 38, 35, 41, 73, 33, 16, 16, 14]\n",
      "###### 521 batch Train loss:1.8503 acc:0.6961 acc1:0.3930 mse:68385464 Test loss:1.4337 acc:0.7386 acc1:0.3681 mse:376001152\n",
      "\n",
      "2020-10-30 08:28:35\n",
      "[0, 8, 12, 4, 7, 5, 9, 1, 2, 3]\n",
      "[4, 5, 7, 5, 7, 19, 10, 11, 8, 6]\n",
      "###### 522 batch Train loss:1.9044 acc:0.7228 acc1:0.4396 mse:93504864 Test loss:1.4440 acc:0.7284 acc1:0.3497 mse:371802304\n",
      "\n",
      "2020-10-30 08:28:37\n",
      "[10, 8, 10, 8, 20, 35, 25, 9, 7, 16]\n",
      "[8, 8, 13, 13, 15, 37, 26, 13, 11, 10]\n",
      "###### 523 batch Train loss:1.4431 acc:0.7272 acc1:0.3992 mse:55665888 Test loss:1.4685 acc:0.7144 acc1:0.3231 mse:368546816\n",
      "\n",
      "2020-10-30 08:28:40\n",
      "[13, 7, 13, 14, 24, 48, 39, 23, 11, 14]\n",
      "[13, 12, 23, 19, 26, 75, 36, 26, 19, 16]\n",
      "###### 524 batch Train loss:2.4194 acc:0.6542 acc1:0.3393 mse:143866800 Test loss:1.4911 acc:0.7026 acc1:0.3002 mse:366250432\n",
      "\n",
      "2020-10-30 08:28:43\n",
      "[14, 7, 23, 17, 9, 40, 38, 22, 14, 12]\n",
      "[18, 9, 22, 16, 21, 63, 30, 21, 15, 15]\n",
      "###### 525 batch Train loss:2.0661 acc:0.5750 acc1:0.3068 mse:77818992 Test loss:1.4928 acc:0.7000 acc1:0.2948 mse:364319136\n",
      "\n",
      "2020-10-30 08:28:45\n",
      "[17, 13, 45, 41, 50, 83, 34, 18, 22, 14]\n",
      "[14, 15, 33, 33, 36, 69, 32, 13, 17, 16]\n",
      "###### 526 batch Train loss:2.4238 acc:0.6453 acc1:0.4639 mse:14240117 Test loss:1.4881 acc:0.6970 acc1:0.2917 mse:362092576\n",
      "\n",
      "2020-10-30 08:28:49\n",
      "[25, 8, 21, 36, 44, 128, 52, 75, 85, 84]\n",
      "[22, 12, 34, 28, 36, 84, 37, 32, 25, 20]\n",
      "###### 527 batch Train loss:1.6614 acc:0.7112 acc1:0.3921 mse:45351196 Test loss:1.4905 acc:0.6919 acc1:0.2859 mse:360805824\n",
      "\n",
      "2020-10-30 08:28:51\n",
      "[19, 7, 13, 11, 19, 61, 32, 20, 14, 10]\n",
      "[12, 13, 24, 20, 28, 59, 40, 24, 17, 15]\n",
      "###### 528 batch Train loss:0.9157 acc:0.6349 acc1:0.3326 mse:8153650 Test loss:1.4648 acc:0.7044 acc1:0.3087 mse:362248256\n",
      "\n",
      "2020-10-30 08:28:54\n",
      "[17, 9, 15, 8, 16, 39, 24, 15, 11, 13]\n",
      "[7, 8, 14, 14, 14, 38, 26, 12, 10, 9]\n",
      "###### 529 batch Train loss:1.4061 acc:0.7155 acc1:0.4373 mse:46122188 Test loss:1.4524 acc:0.7135 acc1:0.3235 mse:364972704\n",
      "\n",
      "2020-10-30 08:28:56\n",
      "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[5, 5, 13, 8, 13, 26, 20, 16, 11, 8]\n",
      "###### 530 batch Train loss:1.6166 acc:0.7241 acc1:0.3596 mse:71716816 Test loss:1.4458 acc:0.7218 acc1:0.3351 mse:368394400\n",
      "\n",
      "2020-10-30 08:28:59\n",
      "[10, 8, 13, 20, 17, 38, 23, 14, 17, 16]\n",
      "[7, 8, 14, 13, 14, 38, 26, 12, 10, 9]\n",
      "###### 531 batch Train loss:2.6550 acc:0.6891 acc1:0.4304 mse:132904952 Test loss:1.4430 acc:0.7235 acc1:0.3372 mse:368179968\n",
      "\n",
      "2020-10-30 08:29:01\n",
      "[1, 2, 0, 0, 0, 0, 0, 1, 0, 0]\n",
      "[4, 5, 11, 7, 11, 24, 18, 14, 10, 7]\n",
      "###### 532 batch Train loss:1.0492 acc:0.6905 acc1:0.3627 mse:17363942 Test loss:1.4322 acc:0.7307 acc1:0.3486 mse:369000832\n",
      "\n",
      "2020-10-30 08:29:04\n",
      "[7, 11, 12, 8, 21, 27, 17, 11, 13, 7]\n",
      "[6, 8, 12, 13, 14, 36, 26, 13, 9, 8]\n",
      "###### 533 batch Train loss:0.8052 acc:0.7084 acc1:0.3567 mse:5687184 Test loss:1.4248 acc:0.7389 acc1:0.3613 mse:371225760\n",
      "\n",
      "2020-10-30 08:29:06\n",
      "[5, 12, 23, 16, 23, 29, 13, 7, 6, 3]\n",
      "[6, 10, 22, 21, 22, 22, 17, 8, 5, 4]\n",
      "###### 534 batch Train loss:1.6324 acc:0.7133 acc1:0.4115 mse:56907724 Test loss:1.4245 acc:0.7443 acc1:0.3687 mse:373082912\n",
      "\n",
      "2020-10-30 08:29:09\n",
      "[4, 1, 3, 7, 5, 16, 7, 20, 16, 10]\n",
      "[8, 7, 14, 11, 14, 51, 24, 21, 15, 11]\n",
      "###### 535 batch Train loss:1.4841 acc:0.7255 acc1:0.3333 mse:49548832 Test loss:1.4285 acc:0.7471 acc1:0.3706 mse:374627840\n",
      "\n",
      "2020-10-30 08:29:12\n",
      "[4, 6, 6, 3, 8, 10, 6, 1, 0, 2]\n",
      "[4, 5, 7, 5, 8, 20, 14, 12, 8, 5]\n",
      "###### 536 batch Train loss:1.5351 acc:0.7087 acc1:0.3598 mse:50586848 Test loss:1.4319 acc:0.7484 acc1:0.3706 mse:375087104\n",
      "\n",
      "2020-10-30 08:29:14\n",
      "[7, 11, 13, 23, 23, 61, 34, 11, 22, 18]\n",
      "[6, 6, 11, 10, 11, 37, 25, 12, 10, 8]\n",
      "###### 537 batch Train loss:2.1086 acc:0.7522 acc1:0.3806 mse:107051656 Test loss:1.4274 acc:0.7482 acc1:0.3699 mse:372861888\n",
      "\n",
      "2020-10-30 08:29:17\n",
      "[59, 19, 75, 47, 161, 251, 162, 122, 129, 173]\n",
      "[21, 10, 33, 25, 35, 120, 41, 35, 27, 21]\n",
      "###### 538 batch Train loss:1.6477 acc:0.7122 acc1:0.3915 mse:57755204 Test loss:1.4207 acc:0.7461 acc1:0.3676 mse:368696576\n",
      "\n",
      "2020-10-30 08:29:19\n",
      "[10, 5, 11, 10, 29, 62, 39, 19, 11, 5]\n",
      "[6, 6, 15, 11, 13, 44, 26, 17, 11, 9]\n",
      "###### 539 batch Train loss:1.3327 acc:0.7360 acc1:0.3856 mse:61602448 Test loss:1.4175 acc:0.7434 acc1:0.3631 mse:365217056\n",
      "\n",
      "2020-10-30 08:29:22\n",
      "[35, 20, 102, 55, 156, 265, 164, 142, 144, 179]\n",
      "[24, 11, 38, 28, 41, 134, 47, 39, 31, 23]\n",
      "###### 540 batch Train loss:2.1016 acc:0.7201 acc1:0.4042 mse:72701240 Test loss:1.4222 acc:0.7359 acc1:0.3506 mse:360688352\n",
      "\n",
      "2020-10-30 08:29:24\n",
      "[15, 15, 28, 19, 27, 73, 44, 30, 29, 30]\n",
      "[25, 14, 46, 26, 45, 149, 58, 42, 37, 28]\n",
      "###### 541 batch Train loss:1.5316 acc:0.7469 acc1:0.4113 mse:79389256 Test loss:1.4404 acc:0.7240 acc1:0.3283 mse:356521088\n",
      "\n",
      "2020-10-30 08:29:27\n",
      "[4, 1, 6, 10, 6, 21, 5, 22, 16, 13]\n",
      "[16, 8, 23, 18, 28, 70, 32, 28, 24, 16]\n",
      "###### 542 batch Train loss:1.5688 acc:0.6794 acc1:0.2907 mse:67970040 Test loss:1.4568 acc:0.7142 acc1:0.3086 mse:353585728\n",
      "\n",
      "2020-10-30 08:29:29\n",
      "[13, 7, 13, 14, 24, 48, 39, 23, 11, 14]\n",
      "[12, 11, 23, 14, 26, 70, 44, 26, 22, 17]\n",
      "###### 543 batch Train loss:0.8291 acc:0.6825 acc1:0.3215 mse:5400561 Test loss:1.4444 acc:0.7194 acc1:0.3191 mse:353459488\n",
      "\n",
      "2020-10-30 08:29:32\n",
      "[10, 9, 22, 11, 11, 105, 22, 23, 12, 9]\n",
      "[11, 6, 20, 14, 18, 39, 32, 22, 16, 11]\n",
      "###### 544 batch Train loss:0.8459 acc:0.7471 acc1:0.3462 mse:12827240 Test loss:1.4233 acc:0.7303 acc1:0.3403 mse:355314304\n",
      "\n",
      "2020-10-30 08:29:34\n",
      "[3, 5, 4, 14, 13, 9, 6, 5, 3, 0]\n",
      "[4, 4, 6, 5, 9, 17, 14, 11, 9, 5]\n",
      "###### 545 batch Train loss:0.7868 acc:0.6954 acc1:0.2506 mse:5189314 Test loss:1.4084 acc:0.7446 acc1:0.3661 mse:361475328\n",
      "\n",
      "2020-10-30 08:29:37\n",
      "[9, 7, 16, 13, 10, 24, 5, 4, 2, 10]\n",
      "[9, 10, 22, 18, 25, 22, 21, 11, 9, 7]\n",
      "###### 546 batch Train loss:0.9492 acc:0.7385 acc1:0.2263 mse:29983860 Test loss:1.4221 acc:0.7524 acc1:0.3751 mse:370737024\n",
      "\n",
      "2020-10-30 08:29:39\n",
      "[15, 19, 42, 36, 26, 62, 31, 10, 10, 10]\n",
      "[6, 11, 25, 28, 30, 35, 29, 6, 9, 7]\n",
      "###### 547 batch Train loss:1.7928 acc:0.7340 acc1:0.4323 mse:60260160 Test loss:1.4415 acc:0.7533 acc1:0.3723 mse:377142304\n",
      "\n",
      "2020-10-30 08:29:42\n",
      "[4, 22, 47, 30, 35, 70, 36, 15, 11, 13]\n",
      "[6, 11, 24, 27, 30, 34, 28, 5, 9, 7]\n",
      "###### 548 batch Train loss:1.2191 acc:0.7759 acc1:0.4410 mse:41524312 Test loss:1.4535 acc:0.7530 acc1:0.3689 mse:380889600\n",
      "\n",
      "2020-10-30 08:29:44\n",
      "[10, 7, 18, 10, 17, 15, 14, 2, 9, 2]\n",
      "[5, 9, 15, 16, 18, 16, 12, 6, 5, 3]\n",
      "###### 549 batch Train loss:1.5073 acc:0.7424 acc1:0.4354 mse:75346184 Test loss:1.4565 acc:0.7527 acc1:0.3677 mse:382160096\n",
      "\n",
      "2020-10-30 08:29:47\n",
      "[5, 3, 18, 14, 10, 34, 10, 6, 6, 3]\n",
      "[5, 9, 14, 16, 18, 16, 11, 5, 5, 3]\n",
      "###### 550 batch Train loss:2.3857 acc:0.7348 acc1:0.4675 mse:118538536 Test loss:1.4445 acc:0.7518 acc1:0.3684 mse:378585376\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-30 08:29:49\n",
      "[2, 3, 1, 1, 3, 3, 11, 2, 4, 4]\n",
      "[3, 4, 6, 5, 8, 19, 13, 11, 9, 6]\n",
      "###### 551 batch Train loss:1.0970 acc:0.7549 acc1:0.4424 mse:30572190 Test loss:1.4315 acc:0.7500 acc1:0.3682 mse:373857952\n",
      "\n",
      "2020-10-30 08:29:52\n",
      "[21, 11, 19, 17, 17, 33, 11, 9, 10, 9]\n",
      "[8, 8, 13, 15, 16, 27, 18, 4, 8, 7]\n",
      "###### 552 batch Train loss:2.2175 acc:0.7370 acc1:0.4187 mse:117695944 Test loss:1.4154 acc:0.7462 acc1:0.3658 mse:366236896\n",
      "\n",
      "2020-10-30 08:29:55\n",
      "[12, 5, 16, 16, 12, 33, 25, 6, 11, 12]\n",
      "[6, 7, 10, 11, 12, 36, 23, 11, 10, 7]\n",
      "###### 553 batch Train loss:0.7887 acc:0.7545 acc1:0.2545 mse:20117510 Test loss:1.4076 acc:0.7423 acc1:0.3607 mse:360394144\n",
      "\n",
      "2020-10-30 08:29:57\n",
      "[8, 10, 13, 17, 12, 44, 33, 17, 13, 11]\n",
      "[10, 11, 16, 14, 21, 55, 35, 21, 15, 13]\n",
      "###### 554 batch Train loss:1.7316 acc:0.7177 acc1:0.4067 mse:85298880 Test loss:1.4059 acc:0.7362 acc1:0.3513 mse:354757568\n",
      "\n",
      "2020-10-30 08:30:00\n",
      "[14, 6, 14, 4, 13, 32, 20, 13, 20, 9]\n",
      "[10, 10, 17, 19, 20, 34, 22, 4, 10, 10]\n",
      "###### 555 batch Train loss:1.3838 acc:0.7114 acc1:0.4334 mse:30032114 Test loss:1.4107 acc:0.7290 acc1:0.3392 mse:350536448\n",
      "\n",
      "2020-10-30 08:30:02\n",
      "[8, 7, 13, 17, 27, 25, 23, 9, 5, 14]\n",
      "[6, 8, 10, 12, 13, 35, 22, 12, 10, 8]\n",
      "###### 556 batch Train loss:0.9135 acc:0.7220 acc1:0.3151 mse:9727080 Test loss:1.4147 acc:0.7246 acc1:0.3316 mse:348378592\n",
      "\n",
      "2020-10-30 08:30:04\n",
      "[1, 2, 0, 1, 0, 0, 0, 1, 1, 0]\n",
      "[4, 5, 8, 6, 9, 24, 15, 14, 11, 8]\n",
      "###### 557 batch Train loss:1.4791 acc:0.7910 acc1:0.4018 mse:9113102 Test loss:1.4243 acc:0.7170 acc1:0.3188 mse:346771904\n",
      "\n",
      "2020-10-30 08:30:08\n",
      "[4, 6, 6, 3, 8, 10, 6, 1, 0, 2]\n",
      "[3, 5, 5, 5, 6, 19, 11, 11, 9, 6]\n",
      "###### 558 batch Train loss:2.1720 acc:0.6764 acc1:0.3717 mse:84170120 Test loss:1.4334 acc:0.7097 acc1:0.3071 mse:345054528\n",
      "\n",
      "2020-10-30 08:30:11\n",
      "[1, 2, 0, 1, 0, 0, 0, 1, 1, 0]\n",
      "[4, 5, 9, 7, 10, 24, 16, 14, 11, 8]\n",
      "###### 559 batch Train loss:1.4270 acc:0.7127 acc1:0.2677 mse:48899944 Test loss:1.4339 acc:0.7077 acc1:0.3040 mse:343872768\n",
      "\n",
      "2020-10-30 08:30:13\n",
      "[21, 11, 19, 17, 17, 33, 11, 9, 10, 9]\n",
      "[13, 11, 25, 26, 24, 42, 29, 7, 13, 14]\n",
      "###### 560 batch Train loss:1.5233 acc:0.6807 acc1:0.3243 mse:63827804 Test loss:1.4101 acc:0.7181 acc1:0.3244 mse:343928960\n",
      "\n",
      "2020-10-30 08:30:16\n",
      "[11, 6, 14, 18, 11, 31, 13, 6, 10, 9]\n",
      "[14, 10, 27, 26, 25, 47, 32, 10, 14, 15]\n",
      "###### 561 batch Train loss:1.7114 acc:0.6945 acc1:0.3448 mse:77606400 Test loss:1.3877 acc:0.7307 acc1:0.3490 mse:346218496\n",
      "\n",
      "2020-10-30 08:30:19\n",
      "[3, 0, 4, 7, 3, 6, 4, 13, 13, 12]\n",
      "[10, 8, 16, 16, 17, 56, 26, 20, 18, 15]\n",
      "###### 562 batch Train loss:1.6971 acc:0.6619 acc1:0.2880 mse:55398284 Test loss:1.3758 acc:0.7419 acc1:0.3691 mse:350277824\n",
      "\n",
      "2020-10-30 08:30:21\n",
      "[15, 12, 15, 12, 15, 40, 27, 16, 12, 11]\n",
      "[9, 7, 16, 12, 12, 33, 29, 17, 10, 11]\n",
      "###### 563 batch Train loss:1.1217 acc:0.7406 acc1:0.4492 mse:39135580 Test loss:1.3764 acc:0.7490 acc1:0.3804 mse:355058592\n",
      "\n",
      "2020-10-30 08:30:24\n",
      "[8, 5, 26, 16, 11, 96, 29, 14, 3, 10]\n",
      "[6, 5, 13, 10, 11, 41, 22, 16, 10, 9]\n",
      "###### 564 batch Train loss:0.8573 acc:0.7305 acc1:0.3114 mse:7632140 Test loss:1.3887 acc:0.7535 acc1:0.3859 mse:361296768\n",
      "\n",
      "2020-10-30 08:30:26\n",
      "[34, 11, 23, 32, 41, 124, 55, 73, 86, 86]\n",
      "[16, 9, 21, 20, 26, 89, 31, 32, 23, 19]\n",
      "###### 565 batch Train loss:1.5892 acc:0.7376 acc1:0.4574 mse:81467896 Test loss:1.3999 acc:0.7548 acc1:0.3864 mse:364790496\n",
      "\n",
      "2020-10-30 08:30:29\n",
      "[5, 11, 13, 10, 17, 17, 9, 3, 7, 7]\n",
      "[7, 9, 19, 18, 17, 20, 14, 11, 8, 9]\n",
      "###### 566 batch Train loss:1.8462 acc:0.7467 acc1:0.4557 mse:94802784 Test loss:1.4026 acc:0.7549 acc1:0.3867 mse:365406464\n",
      "\n",
      "2020-10-30 08:30:32\n",
      "[17, 9, 15, 8, 16, 39, 24, 15, 11, 13]\n",
      "[7, 6, 10, 9, 9, 37, 20, 14, 10, 9]\n",
      "###### 567 batch Train loss:2.0692 acc:0.7431 acc1:0.4450 mse:134539216 Test loss:1.3941 acc:0.7535 acc1:0.3867 mse:361412448\n",
      "\n",
      "2020-10-30 08:30:34\n",
      "[7, 20, 11, 13, 14, 82, 12, 10, 11, 11]\n",
      "[13, 10, 25, 22, 26, 36, 26, 18, 16, 15]\n",
      "###### 568 batch Train loss:1.7398 acc:0.7231 acc1:0.4361 mse:72895176 Test loss:1.3853 acc:0.7481 acc1:0.3802 mse:354537696\n",
      "\n",
      "2020-10-30 08:30:37\n",
      "[5, 7, 7, 12, 10, 19, 14, 7, 4, 3]\n",
      "[4, 6, 5, 8, 8, 13, 6, 8, 6, 5]\n",
      "###### 569 batch Train loss:1.2762 acc:0.7192 acc1:0.4076 mse:41409584 Test loss:1.3857 acc:0.7404 acc1:0.3669 mse:348328768\n",
      "\n",
      "2020-10-30 08:30:39\n",
      "[11, 22, 42, 28, 33, 90, 53, 35, 23, 26]\n",
      "[24, 15, 43, 28, 45, 148, 54, 52, 39, 34]\n",
      "###### 570 batch Train loss:0.9130 acc:0.7522 acc1:0.4185 mse:26034990 Test loss:1.3853 acc:0.7362 acc1:0.3587 mse:344556960\n",
      "\n",
      "2020-10-30 08:30:42\n",
      "[25, 8, 21, 36, 44, 128, 52, 75, 85, 84]\n",
      "[22, 10, 30, 31, 41, 97, 39, 44, 31, 25]\n",
      "###### 571 batch Train loss:0.7837 acc:0.7447 acc1:0.3814 mse:5833100 Test loss:1.3783 acc:0.7370 acc1:0.3604 mse:342993664\n",
      "\n",
      "2020-10-30 08:30:44\n",
      "[10, 9, 22, 11, 11, 105, 22, 23, 12, 9]\n",
      "[8, 6, 12, 12, 12, 42, 20, 20, 10, 8]\n",
      "###### 572 batch Train loss:0.7381 acc:0.7427 acc1:0.4019 mse:11967122 Test loss:1.3677 acc:0.7416 acc1:0.3686 mse:343280288\n",
      "\n",
      "2020-10-30 08:30:47\n",
      "[13, 25, 8, 11, 15, 49, 30, 30, 21, 15]\n",
      "[12, 11, 16, 14, 18, 49, 30, 24, 15, 15]\n",
      "###### 573 batch Train loss:1.4989 acc:0.7391 acc1:0.4277 mse:63773176 Test loss:1.3584 acc:0.7454 acc1:0.3754 mse:343546432\n",
      "\n",
      "2020-10-30 08:30:49\n",
      "[24, 8, 23, 40, 40, 128, 60, 60, 95, 81]\n",
      "[20, 10, 25, 28, 34, 80, 34, 37, 26, 21]\n",
      "###### 574 batch Train loss:1.5264 acc:0.7419 acc1:0.4446 mse:50215084 Test loss:1.3511 acc:0.7475 acc1:0.3798 mse:343816032\n",
      "\n",
      "2020-10-30 08:30:52\n",
      "[12, 8, 45, 41, 54, 77, 50, 17, 12, 18]\n",
      "[14, 12, 33, 36, 36, 41, 32, 17, 16, 17]\n",
      "###### 575 batch Train loss:1.2298 acc:0.7352 acc1:0.3623 mse:16906506 Test loss:1.3506 acc:0.7481 acc1:0.3809 mse:345375456\n",
      "\n",
      "2020-10-30 08:30:55\n",
      "[8, 10, 13, 17, 12, 44, 33, 17, 13, 11]\n",
      "[12, 10, 17, 14, 19, 48, 31, 24, 15, 14]\n",
      "###### 576 batch Train loss:0.9630 acc:0.7726 acc1:0.3912 mse:27044340 Test loss:1.3572 acc:0.7470 acc1:0.3778 mse:347831168\n",
      "\n",
      "2020-10-30 08:30:57\n",
      "[11, 11, 19, 12, 17, 45, 27, 28, 15, 11]\n",
      "[12, 11, 16, 14, 19, 47, 29, 22, 13, 12]\n",
      "###### 577 batch Train loss:0.7247 acc:0.7367 acc1:0.4356 mse:6734739 Test loss:1.3669 acc:0.7477 acc1:0.3761 mse:351861056\n",
      "\n",
      "2020-10-30 08:31:00\n",
      "[7, 10, 21, 9, 8, 20, 6, 7, 5, 5]\n",
      "[7, 11, 23, 26, 23, 22, 12, 7, 5, 4]\n",
      "###### 578 batch Train loss:1.9810 acc:0.7627 acc1:0.4347 mse:104337272 Test loss:1.3658 acc:0.7468 acc1:0.3740 mse:351056224\n",
      "\n",
      "2020-10-30 08:31:02\n",
      "[7, 8, 17, 12, 13, 42, 26, 20, 10, 8]\n",
      "[7, 8, 11, 12, 12, 37, 22, 12, 9, 8]\n",
      "###### 579 batch Train loss:0.7893 acc:0.7390 acc1:0.4285 mse:7755004 Test loss:1.3616 acc:0.7483 acc1:0.3765 mse:350799328\n",
      "\n",
      "2020-10-30 08:31:05\n",
      "[13, 12, 42, 56, 50, 79, 38, 13, 15, 19]\n",
      "[11, 13, 33, 36, 34, 45, 30, 10, 13, 13]\n",
      "###### 580 batch Train loss:3.0064 acc:0.7024 acc1:0.4465 mse:116433368 Test loss:1.3454 acc:0.7446 acc1:0.3746 mse:343417952\n",
      "\n",
      "2020-10-30 08:31:07\n",
      "[5, 7, 7, 13, 13, 13, 8, 2, 8, 2]\n",
      "[4, 7, 6, 10, 9, 13, 7, 6, 5, 3]\n",
      "###### 581 batch Train loss:1.8633 acc:0.7327 acc1:0.4355 mse:67517976 Test loss:1.3511 acc:0.7312 acc1:0.3542 mse:335364992\n",
      "\n",
      "2020-10-30 08:31:10\n",
      "[13, 7, 9, 9, 14, 33, 31, 10, 15, 10]\n",
      "[7, 8, 12, 12, 13, 38, 24, 12, 9, 8]\n",
      "###### 582 batch Train loss:0.9833 acc:0.7283 acc1:0.3616 mse:12780778 Test loss:1.3788 acc:0.7160 acc1:0.3267 mse:332454368\n",
      "\n",
      "2020-10-30 08:31:13\n",
      "[4, 1, 3, 7, 5, 16, 7, 20, 16, 10]\n",
      "[14, 9, 24, 25, 31, 127, 33, 27, 24, 16]\n",
      "###### 583 batch Train loss:0.9483 acc:0.6913 acc1:0.2540 mse:9696896 Test loss:1.3928 acc:0.7103 acc1:0.3144 mse:331918720\n",
      "\n",
      "2020-10-30 08:31:15\n",
      "[17, 4, 14, 14, 23, 55, 20, 19, 19, 8]\n",
      "[7, 8, 15, 12, 11, 45, 29, 17, 13, 10]\n",
      "###### 584 batch Train loss:1.4249 acc:0.6818 acc1:0.4027 mse:34084592 Test loss:1.3785 acc:0.7163 acc1:0.3239 mse:331484800\n",
      "\n",
      "2020-10-30 08:31:18\n",
      "[17, 12, 34, 15, 37, 79, 38, 27, 28, 37]\n",
      "[28, 17, 57, 39, 62, 239, 76, 50, 46, 35]\n",
      "###### 585 batch Train loss:1.4073 acc:0.6534 acc1:0.1776 mse:40763256 Test loss:1.3388 acc:0.7349 acc1:0.3566 mse:331846944\n",
      "\n",
      "2020-10-30 08:31:20\n",
      "[1, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "[4, 4, 9, 7, 11, 27, 16, 14, 10, 7]\n",
      "###### 586 batch Train loss:0.8417 acc:0.7535 acc1:0.4072 mse:14707303 Test loss:1.3256 acc:0.7470 acc1:0.3750 mse:335198336\n",
      "\n",
      "2020-10-30 08:31:23\n",
      "[13, 10, 13, 22, 18, 26, 14, 4, 4, 4]\n",
      "[6, 11, 20, 19, 19, 18, 11, 3, 4, 2]\n",
      "###### 587 batch Train loss:1.5633 acc:0.7248 acc1:0.4348 mse:81430920 Test loss:1.3297 acc:0.7530 acc1:0.3813 mse:338840384\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-30 08:31:25\n",
      "[8, 7, 13, 17, 27, 25, 23, 9, 5, 14]\n",
      "[5, 7, 9, 8, 10, 36, 22, 10, 9, 6]\n",
      "###### 588 batch Train loss:0.6359 acc:0.7416 acc1:0.4447 mse:1047300 Test loss:1.3437 acc:0.7559 acc1:0.3816 mse:343467072\n",
      "\n",
      "2020-10-30 08:31:29\n",
      "[17, 12, 34, 15, 37, 79, 38, 27, 28, 37]\n",
      "[18, 13, 35, 21, 36, 119, 52, 34, 31, 25]\n",
      "###### 589 batch Train loss:0.7053 acc:0.7774 acc1:0.2851 mse:18146180 Test loss:1.3633 acc:0.7573 acc1:0.3789 mse:348772640\n",
      "\n",
      "2020-10-30 08:31:31\n",
      "[4, 4, 9, 9, 8, 13, 8, 2, 4, 5]\n",
      "[2, 4, 3, 3, 5, 13, 7, 6, 5, 3]\n",
      "###### 590 batch Train loss:1.0668 acc:0.7439 acc1:0.4344 mse:23105756 Test loss:1.3782 acc:0.7575 acc1:0.3758 mse:352489376\n",
      "\n",
      "2020-10-30 08:31:34\n",
      "[16, 3, 15, 7, 13, 45, 23, 15, 16, 8]\n",
      "[5, 6, 10, 7, 10, 38, 22, 10, 9, 7]\n",
      "###### 591 batch Train loss:2.0255 acc:0.7271 acc1:0.4303 mse:96447240 Test loss:1.3769 acc:0.7571 acc1:0.3751 mse:350861312\n",
      "\n",
      "2020-10-30 08:31:36\n",
      "[1, 2, 0, 1, 0, 0, 0, 1, 1, 0]\n",
      "[4, 4, 7, 5, 9, 21, 14, 10, 9, 6]\n",
      "###### 592 batch Train loss:1.1706 acc:0.7792 acc1:0.4254 mse:58543816 Test loss:1.3711 acc:0.7559 acc1:0.3735 mse:347094656\n",
      "\n",
      "2020-10-30 08:31:39\n",
      "[47, 20, 98, 40, 149, 249, 162, 113, 133, 173]\n",
      "[18, 9, 21, 21, 31, 49, 35, 25, 22, 17]\n",
      "###### 593 batch Train loss:2.4008 acc:0.7388 acc1:0.4167 mse:116685568 Test loss:1.3593 acc:0.7510 acc1:0.3670 mse:338744512\n",
      "\n",
      "2020-10-30 08:31:41\n",
      "[32, 5, 30, 37, 52, 103, 54, 61, 74, 79]\n",
      "[12, 8, 15, 15, 20, 42, 26, 18, 16, 14]\n",
      "###### 594 batch Train loss:1.8052 acc:0.7222 acc1:0.3487 mse:57747512 Test loss:1.3556 acc:0.7430 acc1:0.3545 mse:331051360\n",
      "\n",
      "2020-10-30 08:31:44\n",
      "[20, 7, 12, 33, 23, 27, 22, 11, 16, 11]\n",
      "[8, 9, 19, 17, 20, 34, 21, 4, 10, 10]\n",
      "###### 595 batch Train loss:2.2710 acc:0.7194 acc1:0.4499 mse:65448004 Test loss:1.3662 acc:0.7269 acc1:0.3272 mse:322845728\n",
      "\n",
      "2020-10-30 08:31:46\n",
      "[17, 12, 32, 16, 28, 79, 36, 43, 32, 27]\n",
      "[22, 13, 41, 24, 44, 90, 58, 36, 35, 31]\n",
      "###### 596 batch Train loss:1.4514 acc:0.7018 acc1:0.3931 mse:52427080 Test loss:1.3767 acc:0.7140 acc1:0.3076 mse:317776864\n",
      "\n",
      "2020-10-30 08:31:49\n",
      "[10, 9, 14, 27, 27, 46, 40, 19, 11, 12]\n",
      "[13, 11, 22, 15, 24, 60, 40, 22, 19, 18]\n",
      "###### 597 batch Train loss:1.6976 acc:0.6664 acc1:0.3320 mse:65945352 Test loss:1.3731 acc:0.7097 acc1:0.3045 mse:315238336\n",
      "\n",
      "2020-10-30 08:31:51\n",
      "[14, 8, 16, 26, 34, 23, 15, 10, 11, 8]\n",
      "[14, 11, 29, 27, 35, 44, 33, 11, 17, 16]\n",
      "###### 598 batch Train loss:1.7097 acc:0.6546 acc1:0.3028 mse:40861768 Test loss:1.3592 acc:0.7134 acc1:0.3156 mse:315700000\n",
      "\n",
      "2020-10-30 08:31:54\n",
      "[6, 9, 5, 17, 26, 38, 29, 13, 13, 10]\n",
      "[7, 6, 14, 12, 15, 41, 28, 12, 12, 9]\n",
      "###### 599 batch Train loss:1.2349 acc:0.7338 acc1:0.3278 mse:32696580 Test loss:1.3427 acc:0.7210 acc1:0.3324 mse:317492096\n",
      "\n",
      "2020-10-30 08:31:56\n",
      "[15, 10, 17, 14, 9, 25, 17, 8, 8, 8]\n",
      "[15, 10, 25, 23, 33, 38, 29, 12, 16, 16]\n",
      "###### 600 batch Train loss:0.8694 acc:0.6787 acc1:0.3123 mse:5113954 Test loss:1.3220 acc:0.7366 acc1:0.3625 mse:323657152\n",
      "\n",
      "2020-10-30 08:31:59\n",
      "[21, 11, 19, 17, 17, 33, 11, 9, 10, 9]\n",
      "[11, 9, 20, 18, 23, 34, 23, 7, 11, 12]\n",
      "###### 601 batch Train loss:1.4530 acc:0.7040 acc1:0.4287 mse:69446576 Test loss:1.3185 acc:0.7483 acc1:0.3820 mse:330744960\n",
      "\n",
      "2020-10-30 08:32:02\n",
      "[8, 7, 3, 9, 12, 16, 6, 3, 4, 6]\n",
      "[6, 6, 9, 12, 15, 13, 12, 7, 7, 6]\n",
      "###### 602 batch Train loss:0.7076 acc:0.7739 acc1:0.4211 mse:20479276 Test loss:1.3316 acc:0.7547 acc1:0.3892 mse:338224320\n",
      "\n",
      "2020-10-30 08:32:04\n",
      "[3, 5, 4, 14, 13, 9, 6, 5, 3, 0]\n",
      "[3, 3, 4, 4, 8, 15, 10, 9, 7, 5]\n",
      "###### 603 batch Train loss:1.2920 acc:0.7410 acc1:0.4038 mse:18132086 Test loss:1.3435 acc:0.7568 acc1:0.3895 mse:342592448\n",
      "\n",
      "2020-10-30 08:32:07\n",
      "[10, 17, 39, 38, 46, 53, 24, 3, 16, 9]\n",
      "[8, 10, 32, 32, 37, 42, 31, 9, 13, 11]\n",
      "###### 604 batch Train loss:1.4481 acc:0.7461 acc1:0.4103 mse:45601924 Test loss:1.3454 acc:0.7574 acc1:0.3887 mse:343034560\n",
      "\n",
      "2020-10-30 08:32:09\n",
      "[0, 2, 0, 0, 0, 1, 0, 0, 1, 0]\n",
      "[5, 4, 7, 8, 12, 31, 14, 11, 10, 7]\n",
      "###### 605 batch Train loss:0.6798 acc:0.7750 acc1:0.3881 mse:10884084 Test loss:1.3484 acc:0.7579 acc1:0.3870 mse:343520768\n",
      "\n",
      "2020-10-30 08:32:12\n",
      "[4, 9, 11, 9, 12, 35, 28, 14, 11, 7]\n",
      "[7, 6, 11, 11, 14, 37, 25, 12, 11, 8]\n",
      "###### 606 batch Train loss:1.8084 acc:0.7487 acc1:0.4346 mse:114559952 Test loss:1.3365 acc:0.7581 acc1:0.3872 mse:338655808\n",
      "\n",
      "2020-10-30 08:32:14\n",
      "[10, 8, 16, 16, 15, 39, 13, 5, 9, 17]\n",
      "[8, 6, 15, 16, 19, 32, 18, 7, 11, 9]\n",
      "###### 607 batch Train loss:0.6486 acc:0.7592 acc1:0.3874 mse:5213251 Test loss:1.3264 acc:0.7584 acc1:0.3874 mse:334461600\n",
      "\n",
      "2020-10-30 08:32:17\n",
      "[0, 5, 3, 4, 3, 7, 2, 1, 1, 1]\n",
      "[4, 3, 6, 5, 9, 18, 13, 10, 8, 6]\n",
      "###### 608 batch Train loss:1.0295 acc:0.7771 acc1:0.3809 mse:36379988 Test loss:1.3148 acc:0.7580 acc1:0.3864 mse:329512704\n",
      "\n",
      "2020-10-30 08:32:19\n",
      "[2, 7, 8, 8, 8, 7, 7, 5, 1, 3]\n",
      "[3, 4, 5, 8, 9, 12, 7, 5, 5, 3]\n",
      "###### 609 batch Train loss:1.4139 acc:0.7464 acc1:0.4350 mse:43373672 Test loss:1.3020 acc:0.7559 acc1:0.3833 mse:322823712\n",
      "\n",
      "2020-10-30 08:32:22\n",
      "[13, 15, 22, 15, 16, 19, 5, 8, 7, 4]\n",
      "[5, 8, 16, 17, 17, 17, 8, 3, 4, 3]\n",
      "###### 610 batch Train loss:1.3555 acc:0.7500 acc1:0.4303 mse:41797712 Test loss:1.2982 acc:0.7498 acc1:0.3725 mse:315664640\n",
      "\n",
      "2020-10-30 08:32:24\n",
      "[32, 30, 100, 63, 117, 209, 186, 117, 112, 121]\n",
      "[31, 13, 48, 49, 74, 204, 68, 56, 47, 37]\n",
      "###### 611 batch Train loss:1.7804 acc:0.7273 acc1:0.3976 mse:110578888 Test loss:1.3101 acc:0.7408 acc1:0.3543 mse:310358400\n",
      "\n",
      "2020-10-30 08:32:27\n",
      "[10, 9, 22, 11, 11, 105, 22, 23, 12, 9]\n",
      "[7, 6, 13, 13, 15, 42, 24, 15, 11, 9]\n",
      "###### 612 batch Train loss:0.6998 acc:0.7305 acc1:0.3018 mse:5299480 Test loss:1.3130 acc:0.7381 acc1:0.3490 mse:308231712\n",
      "\n",
      "2020-10-30 08:32:29\n",
      "[15, 8, 19, 12, 12, 61, 30, 26, 16, 12]\n",
      "[11, 9, 16, 13, 19, 50, 33, 21, 15, 13]\n",
      "###### 613 batch Train loss:0.9687 acc:0.7047 acc1:0.4030 mse:16001212 Test loss:1.2976 acc:0.7436 acc1:0.3612 mse:307496896\n",
      "\n",
      "2020-10-30 08:32:32\n",
      "[6, 10, 21, 13, 17, 47, 18, 19, 11, 9]\n",
      "[7, 6, 12, 13, 13, 42, 24, 14, 11, 9]\n",
      "###### 614 batch Train loss:0.7971 acc:0.7304 acc1:0.3997 mse:7898730 Test loss:1.2838 acc:0.7517 acc1:0.3783 mse:309830080\n",
      "\n",
      "2020-10-30 08:32:34\n",
      "[7, 6, 17, 14, 15, 46, 23, 19, 18, 17]\n",
      "[7, 6, 13, 13, 14, 43, 25, 16, 11, 9]\n",
      "###### 615 batch Train loss:2.1709 acc:0.7059 acc1:0.4382 mse:99917976 Test loss:1.2819 acc:0.7512 acc1:0.3796 mse:309090336\n",
      "\n",
      "2020-10-30 08:32:37\n",
      "[10, 7, 11, 20, 11, 93, 28, 13, 6, 14]\n",
      "[8, 7, 11, 10, 10, 40, 23, 14, 11, 9]\n",
      "###### 616 batch Train loss:1.3653 acc:0.7334 acc1:0.4440 mse:44393496 Test loss:1.2867 acc:0.7475 acc1:0.3747 mse:307548224\n",
      "\n",
      "2020-10-30 08:32:40\n",
      "[5, 16, 38, 30, 40, 41, 25, 12, 15, 12]\n",
      "[12, 14, 41, 41, 48, 44, 41, 22, 19, 18]\n",
      "###### 617 batch Train loss:1.8445 acc:0.7455 acc1:0.4345 mse:64850648 Test loss:1.2824 acc:0.7441 acc1:0.3722 mse:305044512\n",
      "\n",
      "2020-10-30 08:32:42\n",
      "[8, 7, 13, 17, 27, 25, 23, 9, 5, 14]\n",
      "[7, 7, 11, 9, 11, 38, 23, 14, 11, 8]\n",
      "###### 618 batch Train loss:0.8069 acc:0.7666 acc1:0.4161 mse:18509612 Test loss:1.2771 acc:0.7438 acc1:0.3744 mse:304638144\n",
      "\n",
      "2020-10-30 08:32:44\n",
      "[0, 1, 0, 0, 0, 0, 0, 2, 0, 0]\n",
      "[7, 5, 7, 9, 13, 46, 14, 17, 12, 8]\n",
      "###### 619 batch Train loss:0.5445 acc:0.8149 acc1:0.3580 mse:1552044 Test loss:1.2729 acc:0.7468 acc1:0.3800 mse:306265984\n",
      "\n",
      "2020-10-30 08:32:48\n",
      "[10, 3, 7, 4, 8, 14, 10, 3, 5, 2]\n",
      "[5, 6, 7, 9, 11, 14, 9, 9, 6, 5]\n",
      "###### 620 batch Train loss:0.7888 acc:0.7321 acc1:0.3497 mse:18961498 Test loss:1.2721 acc:0.7518 acc1:0.3871 mse:309943168\n",
      "\n",
      "2020-10-30 08:32:51\n",
      "[5, 7, 7, 12, 10, 19, 14, 7, 4, 3]\n",
      "[5, 7, 5, 8, 8, 12, 6, 6, 4, 3]\n",
      "###### 621 batch Train loss:1.5596 acc:0.6962 acc1:0.4198 mse:42733508 Test loss:1.2720 acc:0.7531 acc1:0.3875 mse:310915552\n",
      "\n",
      "2020-10-30 08:32:53\n",
      "[17, 12, 34, 15, 37, 79, 38, 27, 28, 37]\n",
      "[25, 17, 48, 29, 54, 175, 66, 54, 47, 41]\n",
      "###### 622 batch Train loss:1.1887 acc:0.7349 acc1:0.4108 mse:37030904 Test loss:1.2722 acc:0.7538 acc1:0.3862 mse:311032064\n",
      "\n",
      "2020-10-30 08:32:56\n",
      "[16, 11, 54, 45, 44, 59, 47, 14, 13, 22]\n",
      "[13, 14, 32, 31, 33, 49, 30, 13, 16, 15]\n",
      "###### 623 batch Train loss:1.5980 acc:0.7319 acc1:0.4646 mse:53273896 Test loss:1.2671 acc:0.7521 acc1:0.3819 mse:307242112\n",
      "\n",
      "2020-10-30 08:32:58\n",
      "[0, 0, 0, 0, 2, 0, 0, 0, 0, 0]\n",
      "[5, 5, 6, 5, 7, 21, 11, 12, 8, 6]\n",
      "###### 624 batch Train loss:0.8439 acc:0.7919 acc1:0.4394 mse:22042164 Test loss:1.2667 acc:0.7493 acc1:0.3755 mse:304123648\n",
      "\n",
      "2020-10-30 08:33:01\n",
      "[0, 5, 3, 4, 3, 7, 2, 1, 1, 1]\n",
      "[4, 4, 5, 4, 7, 18, 10, 12, 7, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### 625 batch Train loss:0.9002 acc:0.7237 acc1:0.4390 mse:9012422 Test loss:1.2605 acc:0.7492 acc1:0.3758 mse:301110976\n",
      "\n",
      "2020-10-30 08:33:03\n",
      "[0, 8, 12, 4, 7, 5, 9, 1, 2, 3]\n",
      "[3, 5, 3, 2, 3, 13, 6, 7, 4, 3]\n",
      "###### 626 batch Train loss:0.8186 acc:0.7234 acc1:0.4363 mse:12655828 Test loss:1.2550 acc:0.7508 acc1:0.3783 mse:299702464\n",
      "\n",
      "2020-10-30 08:33:06\n",
      "[5, 12, 23, 16, 23, 29, 13, 7, 6, 3]\n",
      "[8, 11, 21, 19, 19, 25, 12, 6, 4, 5]\n",
      "###### 627 batch Train loss:1.8627 acc:0.7423 acc1:0.4433 mse:109923232 Test loss:1.2515 acc:0.7517 acc1:0.3798 mse:297711264\n",
      "\n",
      "2020-10-30 08:33:09\n",
      "[13, 7, 9, 9, 14, 33, 31, 10, 15, 10]\n",
      "[7, 8, 11, 10, 12, 41, 23, 14, 10, 8]\n",
      "###### 628 batch Train loss:1.1086 acc:0.7497 acc1:0.4410 mse:47967324 Test loss:1.2594 acc:0.7503 acc1:0.3756 mse:297188352\n",
      "\n",
      "2020-10-30 08:33:11\n",
      "[10, 9, 14, 27, 27, 46, 40, 19, 11, 12]\n",
      "[11, 11, 16, 11, 18, 54, 31, 24, 15, 14]\n",
      "###### 629 batch Train loss:1.7416 acc:0.7499 acc1:0.4627 mse:73274176 Test loss:1.2677 acc:0.7454 acc1:0.3663 mse:295058016\n",
      "\n",
      "2020-10-30 08:33:14\n",
      "[37, 46, 119, 70, 157, 235, 203, 151, 101, 126]\n",
      "[38, 17, 53, 46, 80, 240, 79, 70, 60, 44]\n",
      "###### 630 batch Train loss:1.9669 acc:0.7185 acc1:0.4405 mse:80845384 Test loss:1.2823 acc:0.7354 acc1:0.3487 mse:291604800\n",
      "\n",
      "2020-10-30 08:33:16\n",
      "[12, 5, 12, 13, 21, 53, 25, 25, 15, 9]\n",
      "[10, 10, 18, 12, 19, 54, 34, 26, 16, 16]\n",
      "###### 631 batch Train loss:0.8468 acc:0.6827 acc1:0.2580 mse:5940715 Test loss:1.2621 acc:0.7418 acc1:0.3627 mse:289989728\n",
      "\n",
      "2020-10-30 08:33:19\n",
      "[0, 1, 0, 0, 0, 0, 0, 2, 0, 0]\n",
      "[4, 4, 6, 5, 8, 20, 13, 15, 10, 7]\n",
      "###### 632 batch Train loss:0.6304 acc:0.7541 acc1:0.1749 mse:4594433 Test loss:1.2426 acc:0.7523 acc1:0.3818 mse:291601088\n",
      "\n",
      "2020-10-30 08:33:21\n",
      "[15, 10, 17, 14, 9, 25, 17, 8, 8, 8]\n",
      "[10, 10, 22, 15, 20, 32, 27, 12, 14, 14]\n",
      "###### 633 batch Train loss:1.4520 acc:0.7400 acc1:0.4349 mse:66413560 Test loss:1.2367 acc:0.7583 acc1:0.3916 mse:294299776\n",
      "\n",
      "2020-10-30 08:33:24\n",
      "[33, 44, 109, 68, 119, 235, 204, 110, 113, 108]\n",
      "[33, 16, 58, 48, 82, 206, 87, 73, 65, 50]\n",
      "###### 634 batch Train loss:1.8432 acc:0.7590 acc1:0.4534 mse:78214824 Test loss:1.2307 acc:0.7571 acc1:0.3904 mse:291887872\n",
      "\n",
      "2020-10-30 08:33:26\n",
      "[17, 9, 15, 8, 16, 39, 24, 15, 11, 13]\n",
      "[7, 7, 12, 9, 10, 43, 23, 13, 10, 9]\n",
      "###### 635 batch Train loss:0.8447 acc:0.7315 acc1:0.4355 mse:18254188 Test loss:1.2272 acc:0.7574 acc1:0.3914 mse:291281664\n",
      "\n",
      "2020-10-30 08:33:29\n",
      "[3, 5, 4, 14, 13, 9, 6, 5, 3, 0]\n",
      "[2, 3, 4, 3, 5, 12, 9, 9, 5, 4]\n",
      "###### 636 batch Train loss:0.8706 acc:0.7533 acc1:0.4327 mse:23537624 Test loss:1.2270 acc:0.7597 acc1:0.3956 mse:292965856\n",
      "\n",
      "2020-10-30 08:33:31\n",
      "[49, 5, 33, 34, 50, 109, 45, 60, 91, 81]\n",
      "[17, 9, 28, 27, 43, 80, 46, 42, 38, 28]\n",
      "###### 637 batch Train loss:0.6222 acc:0.8023 acc1:0.2795 mse:5107326 Test loss:1.2311 acc:0.7623 acc1:0.3993 mse:295995808\n",
      "\n",
      "2020-10-30 08:33:34\n",
      "[6, 5, 15, 13, 14, 56, 24, 14, 8, 10]\n",
      "[7, 6, 13, 9, 10, 48, 23, 14, 9, 8]\n",
      "###### 638 batch Train loss:1.1889 acc:0.7503 acc1:0.4539 mse:40002624 Test loss:1.2347 acc:0.7633 acc1:0.4009 mse:297858240\n",
      "\n",
      "2020-10-30 08:33:36\n",
      "[6, 9, 5, 17, 26, 38, 29, 13, 13, 10]\n",
      "[6, 6, 12, 9, 11, 44, 25, 14, 11, 9]\n",
      "###### 639 batch Train loss:0.7376 acc:0.7364 acc1:0.4000 mse:16579046 Test loss:1.2417 acc:0.7644 acc1:0.4016 mse:300442560\n",
      "\n",
      "2020-10-30 08:33:39\n",
      "[11, 9, 22, 9, 11, 109, 22, 25, 11, 6]\n",
      "[7, 6, 14, 9, 11, 49, 24, 15, 10, 9]\n",
      "###### 640 batch Train loss:1.0176 acc:0.7674 acc1:0.4311 mse:25862676 Test loss:1.2448 acc:0.7643 acc1:0.4010 mse:301641728\n",
      "\n",
      "2020-10-30 08:33:41\n",
      "[2, 3, 3, 2, 1, 2, 4, 0, 0, 0]\n",
      "[2, 4, 4, 4, 6, 13, 10, 8, 6, 4]\n",
      "###### 641 batch Train loss:1.6978 acc:0.7743 acc1:0.4687 mse:88482584 Test loss:1.2365 acc:0.7605 acc1:0.3954 mse:296718400\n",
      "\n",
      "2020-10-30 08:33:44\n",
      "[1, 8, 2, 0, 1, 4, 1, 6, 2, 1]\n",
      "[2, 3, 6, 5, 8, 15, 12, 11, 7, 5]\n",
      "###### 642 batch Train loss:1.2414 acc:0.7813 acc1:0.3775 mse:32544906 Test loss:1.2281 acc:0.7547 acc1:0.3866 mse:289580352\n",
      "\n",
      "2020-10-30 08:33:46\n",
      "[7, 9, 24, 11, 21, 32, 14, 12, 14, 10]\n",
      "[8, 11, 24, 24, 26, 36, 21, 4, 10, 10]\n",
      "###### 643 batch Train loss:1.5578 acc:0.7363 acc1:0.4534 mse:74599848 Test loss:1.2203 acc:0.7490 acc1:0.3785 mse:282322080\n",
      "\n",
      "2020-10-30 08:33:49\n",
      "[13, 15, 22, 15, 16, 19, 5, 8, 7, 4]\n",
      "[5, 11, 22, 23, 21, 19, 11, 3, 3, 2]\n",
      "###### 644 batch Train loss:1.9649 acc:0.6995 acc1:0.4374 mse:81103912 Test loss:1.2281 acc:0.7364 acc1:0.3560 mse:274014720\n",
      "\n",
      "2020-10-30 08:33:51\n",
      "[5, 6, 8, 1, 2, 2, 5, 5, 3, 3]\n",
      "[2, 4, 3, 4, 5, 12, 9, 8, 6, 3]\n",
      "###### 645 batch Train loss:1.5038 acc:0.7285 acc1:0.4256 mse:39801100 Test loss:1.2605 acc:0.7191 acc1:0.3243 mse:270845664\n",
      "\n",
      "2020-10-30 08:33:54\n",
      "[7, 7, 15, 22, 19, 26, 16, 6, 15, 7]\n",
      "[11, 13, 32, 31, 35, 38, 35, 19, 25, 21]\n",
      "###### 646 batch Train loss:1.2741 acc:0.6762 acc1:0.3425 mse:28545960 Test loss:1.2451 acc:0.7247 acc1:0.3382 mse:270773152\n",
      "\n",
      "2020-10-30 08:33:57\n",
      "[25, 8, 21, 36, 44, 128, 52, 75, 85, 84]\n",
      "[28, 11, 38, 46, 72, 167, 67, 69, 69, 45]\n",
      "###### 647 batch Train loss:1.3750 acc:0.7248 acc1:0.3737 mse:46220076 Test loss:1.2216 acc:0.7374 acc1:0.3656 mse:272910816\n",
      "\n",
      "2020-10-30 08:33:59\n",
      "[46, 17, 86, 53, 140, 282, 181, 113, 153, 177]\n",
      "[41, 16, 57, 66, 109, 288, 100, 102, 103, 65]\n",
      "###### 648 batch Train loss:1.7773 acc:0.7159 acc1:0.4486 mse:50924388 Test loss:1.2233 acc:0.7397 acc1:0.3729 mse:275293792\n",
      "\n",
      "2020-10-30 08:34:02\n",
      "[3, 0, 4, 7, 3, 6, 4, 13, 13, 12]\n",
      "[13, 6, 10, 17, 27, 32, 28, 42, 47, 26]\n",
      "###### 649 batch Train loss:0.6445 acc:0.7265 acc1:0.3199 mse:3831634 Test loss:1.2192 acc:0.7487 acc1:0.3889 mse:280291840\n",
      "\n",
      "2020-10-30 08:34:04\n",
      "[7, 9, 5, 6, 7, 13, 8, 3, 1, 1]\n",
      "[4, 6, 7, 9, 12, 10, 10, 8, 6, 5]\n",
      "###### 650 batch Train loss:0.7192 acc:0.7745 acc1:0.4651 mse:5810489 Test loss:1.2268 acc:0.7565 acc1:0.3998 mse:287329952\n",
      "\n",
      "2020-10-30 08:34:08\n",
      "[0, 0, 0, 0, 2, 0, 0, 0, 0, 0]\n",
      "[4, 5, 5, 4, 8, 29, 14, 19, 18, 9]\n",
      "###### 651 batch Train loss:0.7225 acc:0.7664 acc1:0.3267 mse:11828558 Test loss:1.2413 acc:0.7623 acc1:0.4038 mse:294540704\n",
      "\n",
      "2020-10-30 08:34:10\n",
      "[36, 10, 28, 31, 44, 118, 51, 72, 61, 79]\n",
      "[30, 11, 35, 35, 67, 181, 68, 79, 85, 53]\n",
      "###### 652 batch Train loss:2.3561 acc:0.7425 acc1:0.4859 mse:107822808 Test loss:1.2309 acc:0.7624 acc1:0.4034 mse:290283264\n",
      "\n",
      "2020-10-30 08:34:13\n",
      "[11, 7, 16, 11, 22, 57, 32, 25, 11, 12]\n",
      "[10, 10, 14, 10, 17, 39, 31, 21, 16, 14]\n",
      "###### 653 batch Train loss:1.4868 acc:0.7591 acc1:0.4704 mse:86722536 Test loss:1.2132 acc:0.7614 acc1:0.4019 mse:282364192\n",
      "\n",
      "2020-10-30 08:34:15\n",
      "[32, 30, 100, 63, 117, 209, 186, 117, 112, 121]\n",
      "[42, 20, 76, 55, 123, 253, 123, 112, 117, 87]\n",
      "###### 654 batch Train loss:1.0975 acc:0.7596 acc1:0.4615 mse:44903268 Test loss:1.2023 acc:0.7576 acc1:0.3950 mse:274556992\n",
      "\n",
      "2020-10-30 08:34:18\n",
      "[0, 8, 12, 4, 7, 5, 9, 1, 2, 3]\n",
      "[3, 4, 2, 2, 3, 7, 5, 5, 5, 3]\n",
      "###### 655 batch Train loss:0.9890 acc:0.7283 acc1:0.3652 mse:10538726 Test loss:1.1958 acc:0.7535 acc1:0.3865 mse:268717536\n",
      "\n",
      "2020-10-30 08:34:20\n",
      "[5, 11, 2, 14, 12, 47, 25, 13, 15, 12]\n",
      "[8, 7, 11, 9, 12, 33, 23, 13, 11, 8]\n",
      "###### 656 batch Train loss:0.9586 acc:0.7714 acc1:0.3993 mse:24886726 Test loss:1.1869 acc:0.7519 acc1:0.3828 mse:265040304\n",
      "\n",
      "2020-10-30 08:34:23\n",
      "[37, 46, 119, 70, 157, 235, 203, 151, 101, 126]\n",
      "[36, 21, 76, 47, 112, 161, 112, 87, 90, 79]\n",
      "###### 657 batch Train loss:1.1950 acc:0.7954 acc1:0.4421 mse:49858280 Test loss:1.1901 acc:0.7457 acc1:0.3694 mse:261611200\n",
      "\n",
      "2020-10-30 08:34:25\n",
      "[7, 10, 21, 9, 8, 20, 6, 7, 5, 5]\n",
      "[9, 10, 18, 17, 19, 20, 13, 5, 6, 6]\n",
      "###### 658 batch Train loss:1.3814 acc:0.7333 acc1:0.4281 mse:34777752 Test loss:1.1952 acc:0.7400 acc1:0.3587 mse:259472960\n",
      "\n",
      "2020-10-30 08:34:28\n",
      "[6, 9, 5, 17, 26, 38, 29, 13, 13, 10]\n",
      "[9, 6, 12, 10, 12, 37, 24, 12, 11, 9]\n",
      "###### 659 batch Train loss:1.1670 acc:0.6784 acc1:0.2830 mse:31688852 Test loss:1.1697 acc:0.7506 acc1:0.3798 mse:259620384\n",
      "\n",
      "2020-10-30 08:34:30\n",
      "[13, 15, 22, 15, 16, 19, 5, 8, 7, 4]\n",
      "[9, 10, 17, 18, 17, 21, 9, 2, 3, 3]\n",
      "###### 660 batch Train loss:1.0844 acc:0.7270 acc1:0.4431 mse:47190644 Test loss:1.1614 acc:0.7598 acc1:0.3950 mse:262753312\n",
      "\n",
      "2020-10-30 08:34:33\n",
      "[5, 16, 38, 30, 40, 41, 25, 12, 15, 12]\n",
      "[10, 14, 36, 37, 37, 51, 29, 6, 11, 10]\n",
      "###### 661 batch Train loss:1.2111 acc:0.7674 acc1:0.4637 mse:37905052 Test loss:1.1669 acc:0.7635 acc1:0.3994 mse:266430672\n",
      "\n",
      "2020-10-30 08:34:35\n",
      "[54, 21, 87, 59, 142, 245, 167, 123, 135, 156]\n",
      "[40, 15, 50, 41, 88, 106, 82, 67, 66, 60]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### 662 batch Train loss:1.9841 acc:0.7504 acc1:0.4520 mse:68740864 Test loss:1.1543 acc:0.7618 acc1:0.3992 mse:260934848\n",
      "\n",
      "2020-10-30 08:34:38\n",
      "[3, 7, 3, 5, 5, 6, 9, 5, 3, 3]\n",
      "[2, 4, 2, 2, 3, 8, 6, 5, 4, 4]\n",
      "###### 663 batch Train loss:1.0239 acc:0.7773 acc1:0.4594 mse:29565616 Test loss:1.1495 acc:0.7572 acc1:0.3934 mse:255999952\n",
      "\n",
      "2020-10-30 08:34:40\n",
      "[5, 6, 8, 1, 2, 2, 5, 5, 3, 3]\n",
      "[3, 4, 3, 2, 4, 11, 7, 6, 5, 5]\n",
      "###### 664 batch Train loss:1.0100 acc:0.7566 acc1:0.4635 mse:11542260 Test loss:1.1585 acc:0.7467 acc1:0.3768 mse:251874112\n",
      "\n",
      "2020-10-30 08:34:43\n",
      "[14, 10, 7, 25, 19, 34, 14, 14, 7, 13]\n",
      "[11, 9, 15, 14, 18, 34, 16, 8, 8, 10]\n",
      "###### 665 batch Train loss:1.1620 acc:0.7429 acc1:0.4239 mse:35866352 Test loss:1.1716 acc:0.7373 acc1:0.3608 mse:248981616\n",
      "\n",
      "2020-10-30 08:34:46\n",
      "[1, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "[4, 4, 7, 5, 9, 17, 13, 14, 8, 8]\n",
      "###### 666 batch Train loss:0.7626 acc:0.7496 acc1:0.3659 mse:14853911 Test loss:1.1612 acc:0.7412 acc1:0.3680 mse:248341200\n",
      "\n",
      "2020-10-30 08:34:48\n",
      "[37, 12, 91, 52, 124, 265, 142, 115, 139, 151]\n",
      "[56, 17, 59, 55, 117, 164, 117, 92, 94, 89]\n",
      "###### 667 batch Train loss:1.3268 acc:0.7235 acc1:0.4565 mse:37369132 Test loss:1.1528 acc:0.7439 acc1:0.3727 mse:247290944\n",
      "\n",
      "2020-10-30 08:34:51\n",
      "[7, 11, 12, 8, 21, 27, 17, 11, 13, 7]\n",
      "[8, 8, 11, 10, 12, 39, 23, 11, 10, 8]\n",
      "###### 668 batch Train loss:1.0491 acc:0.7151 acc1:0.3967 mse:38880024 Test loss:1.1406 acc:0.7509 acc1:0.3843 mse:247334496\n",
      "\n",
      "2020-10-30 08:34:53\n",
      "[6, 6, 17, 17, 20, 32, 32, 13, 11, 11]\n",
      "[13, 7, 15, 15, 23, 41, 37, 25, 21, 19]\n",
      "###### 669 batch Train loss:0.9436 acc:0.7169 acc1:0.4013 mse:18869252 Test loss:1.1322 acc:0.7580 acc1:0.3944 mse:248928880\n",
      "\n",
      "2020-10-30 08:34:56\n",
      "[6, 10, 21, 13, 17, 47, 18, 19, 11, 9]\n",
      "[8, 7, 13, 11, 11, 49, 29, 19, 17, 13]\n",
      "###### 670 batch Train loss:0.6630 acc:0.7442 acc1:0.3604 mse:4156946 Test loss:1.1344 acc:0.7639 acc1:0.4002 mse:252921120\n",
      "\n",
      "2020-10-30 08:34:58\n",
      "[7, 9, 24, 11, 21, 32, 14, 12, 14, 10]\n",
      "[11, 11, 24, 23, 22, 45, 25, 12, 18, 17]\n",
      "###### 671 batch Train loss:1.2152 acc:0.7316 acc1:0.4344 mse:30101386 Test loss:1.1405 acc:0.7658 acc1:0.4001 mse:254629920\n",
      "\n",
      "2020-10-30 08:35:01\n",
      "[17, 12, 32, 16, 28, 79, 36, 43, 32, 27]\n",
      "[17, 18, 56, 28, 55, 108, 87, 54, 50, 57]\n",
      "###### 672 batch Train loss:1.7285 acc:0.7375 acc1:0.4532 mse:77877784 Test loss:1.1420 acc:0.7643 acc1:0.3972 mse:251472384\n",
      "\n",
      "2020-10-30 08:35:03\n",
      "[12, 8, 45, 41, 54, 77, 50, 17, 12, 18]\n",
      "[11, 12, 33, 32, 31, 56, 29, 9, 15, 16]\n",
      "###### 673 batch Train loss:1.4876 acc:0.7672 acc1:0.4246 mse:45584432 Test loss:1.1333 acc:0.7613 acc1:0.3930 mse:246177344\n",
      "\n",
      "2020-10-30 08:35:06\n",
      "[3, 2, 1, 2, 2, 1, 0, 0, 0, 0]\n",
      "[4, 5, 5, 4, 5, 15, 9, 7, 6, 4]\n",
      "###### 674 batch Train loss:0.6055 acc:0.7663 acc1:0.3588 mse:4481192 Test loss:1.1295 acc:0.7595 acc1:0.3892 mse:243142192\n",
      "\n",
      "2020-10-30 08:35:08\n",
      "[5, 7, 7, 13, 13, 13, 8, 2, 8, 2]\n",
      "[5, 6, 4, 7, 6, 11, 4, 2, 2, 2]\n",
      "###### 675 batch Train loss:0.8428 acc:0.7574 acc1:0.4361 mse:14912470 Test loss:1.1208 acc:0.7613 acc1:0.3929 mse:242214656\n",
      "\n",
      "2020-10-30 08:35:11\n",
      "[9, 15, 13, 23, 32, 35, 25, 13, 24, 16]\n",
      "[10, 11, 20, 20, 18, 40, 17, 4, 10, 8]\n",
      "###### 676 batch Train loss:1.4878 acc:0.7513 acc1:0.4723 mse:64825936 Test loss:1.1166 acc:0.7604 acc1:0.3928 mse:239915600\n",
      "\n",
      "2020-10-30 08:35:14\n",
      "[24, 8, 23, 40, 40, 128, 60, 60, 95, 81]\n",
      "[30, 12, 39, 35, 64, 104, 76, 64, 71, 71]\n",
      "###### 677 batch Train loss:0.8087 acc:0.7618 acc1:0.3049 mse:16226798 Test loss:1.1088 acc:0.7641 acc1:0.4004 mse:240230704\n",
      "\n",
      "2020-10-30 08:35:16\n",
      "[6, 1, 3, 7, 8, 13, 3, 22, 12, 8]\n",
      "[7, 5, 11, 8, 14, 23, 17, 21, 26, 23]\n",
      "###### 678 batch Train loss:0.7437 acc:0.7478 acc1:0.3585 mse:10742281 Test loss:1.1156 acc:0.7687 acc1:0.4074 mse:245450640\n",
      "\n",
      "2020-10-30 08:35:19\n",
      "[28, 6, 24, 34, 51, 122, 44, 68, 76, 86]\n",
      "[17, 8, 17, 19, 28, 53, 30, 39, 45, 41]\n",
      "###### 679 batch Train loss:1.4887 acc:0.7388 acc1:0.4722 mse:40575816 Test loss:1.1159 acc:0.7690 acc1:0.4097 mse:245696080\n",
      "\n",
      "2020-10-30 08:35:21\n",
      "[10, 7, 11, 20, 11, 93, 28, 13, 6, 14]\n",
      "[8, 7, 11, 10, 11, 40, 23, 11, 10, 7]\n",
      "###### 680 batch Train loss:0.8191 acc:0.7555 acc1:0.4669 mse:21121100 Test loss:1.1222 acc:0.7690 acc1:0.4109 mse:247398320\n",
      "\n",
      "2020-10-30 08:35:23\n",
      "[14, 8, 16, 26, 34, 23, 15, 10, 11, 8]\n",
      "[9, 9, 19, 19, 19, 39, 18, 6, 11, 9]\n",
      "###### 681 batch Train loss:2.0156 acc:0.7200 acc1:0.4633 mse:41271320 Test loss:1.1175 acc:0.7666 acc1:0.4089 mse:242556960\n",
      "\n",
      "2020-10-30 08:35:27\n",
      "[24, 43, 105, 77, 126, 203, 199, 121, 111, 115]\n",
      "[36, 24, 97, 62, 119, 198, 160, 117, 110, 120]\n",
      "###### 682 batch Train loss:1.1406 acc:0.7903 acc1:0.4605 mse:41896724 Test loss:1.1149 acc:0.7612 acc1:0.4007 mse:236505216\n",
      "\n",
      "2020-10-30 08:35:30\n",
      "[46, 21, 92, 61, 137, 282, 140, 115, 134, 178]\n",
      "[40, 17, 63, 55, 100, 161, 122, 102, 100, 103]\n",
      "###### 683 batch Train loss:1.0930 acc:0.7631 acc1:0.4615 mse:26236448 Test loss:1.1505 acc:0.7455 acc1:0.3700 mse:233263888\n",
      "\n",
      "2020-10-30 08:35:33\n",
      "[16, 10, 29, 16, 18, 86, 53, 41, 35, 30]\n",
      "[14, 17, 59, 28, 51, 98, 87, 51, 49, 56]\n",
      "###### 684 batch Train loss:0.9437 acc:0.6987 acc1:0.3799 mse:21246450 Test loss:1.1627 acc:0.7418 acc1:0.3626 mse:233380768\n",
      "\n",
      "2020-10-30 08:35:35\n",
      "[6, 15, 30, 32, 33, 44, 34, 13, 12, 6]\n",
      "[9, 13, 39, 41, 35, 51, 36, 19, 17, 16]\n",
      "###### 685 batch Train loss:1.0931 acc:0.7343 acc1:0.4150 mse:24001040 Test loss:1.1293 acc:0.7510 acc1:0.3830 mse:230412576\n",
      "\n",
      "2020-10-30 08:35:38\n",
      "[6, 2, 1, 9, 8, 6, 8, 0, 2, 4]\n",
      "[2, 3, 2, 3, 3, 10, 7, 7, 3, 3]\n",
      "###### 686 batch Train loss:1.1804 acc:0.7644 acc1:0.4372 mse:32562740 Test loss:1.0986 acc:0.7576 acc1:0.3969 mse:227924400\n",
      "\n",
      "2020-10-30 08:35:40\n",
      "[14, 10, 7, 25, 19, 34, 14, 14, 7, 13]\n",
      "[10, 8, 15, 18, 22, 33, 22, 15, 14, 15]\n",
      "###### 687 batch Train loss:1.1000 acc:0.7324 acc1:0.4387 mse:26052534 Test loss:1.1013 acc:0.7573 acc1:0.3943 mse:229520640\n",
      "\n",
      "2020-10-30 08:35:43\n",
      "[6, 5, 15, 13, 14, 56, 24, 14, 8, 10]\n",
      "[7, 6, 14, 12, 11, 52, 26, 18, 12, 11]\n",
      "###### 688 batch Train loss:1.1291 acc:0.7713 acc1:0.4509 mse:48636716 Test loss:1.0996 acc:0.7606 acc1:0.3991 mse:231821952\n",
      "\n",
      "2020-10-30 08:35:45\n",
      "[15, 14, 36, 17, 33, 95, 58, 29, 79, 23]\n",
      "[16, 18, 56, 29, 49, 111, 80, 45, 41, 55]\n",
      "###### 689 batch Train loss:1.1935 acc:0.7313 acc1:0.4450 mse:33764248 Test loss:1.0933 acc:0.7640 acc1:0.4057 mse:231936544\n",
      "\n",
      "2020-10-30 08:35:48\n",
      "[4, 1, 3, 7, 5, 16, 7, 20, 16, 10]\n",
      "[6, 5, 8, 8, 10, 31, 14, 21, 21, 17]\n",
      "###### 690 batch Train loss:1.1379 acc:0.7631 acc1:0.4542 mse:44642844 Test loss:1.0865 acc:0.7646 acc1:0.4073 mse:229176832\n",
      "\n",
      "2020-10-30 08:35:50\n",
      "[8, 1, 3, 10, 6, 10, 6, 24, 21, 8]\n",
      "[9, 5, 9, 12, 20, 45, 24, 26, 27, 24]\n",
      "###### 691 batch Train loss:0.7998 acc:0.7818 acc1:0.3857 mse:17185426 Test loss:1.0825 acc:0.7641 acc1:0.4058 mse:226612112\n",
      "\n",
      "2020-10-30 08:35:53\n",
      "[28, 6, 24, 34, 51, 122, 44, 68, 76, 86]\n",
      "[20, 8, 16, 26, 40, 83, 43, 41, 49, 52]\n",
      "###### 692 batch Train loss:0.7233 acc:0.7439 acc1:0.4638 mse:6664648 Test loss:1.0813 acc:0.7633 acc1:0.4040 mse:224520336\n",
      "\n",
      "2020-10-30 08:35:55\n",
      "[48, 23, 85, 46, 135, 292, 170, 112, 145, 173]\n",
      "[45, 20, 74, 65, 119, 227, 142, 108, 113, 124]\n",
      "###### 693 batch Train loss:1.5838 acc:0.7700 acc1:0.3843 mse:83951976 Test loss:1.0810 acc:0.7614 acc1:0.3999 mse:220187136\n",
      "\n",
      "2020-10-30 08:35:58\n",
      "[7, 8, 17, 12, 13, 42, 26, 20, 10, 8]\n",
      "[8, 7, 11, 12, 13, 36, 24, 11, 9, 7]\n",
      "###### 694 batch Train loss:0.6684 acc:0.7771 acc1:0.4340 mse:13647425 Test loss:1.0845 acc:0.7611 acc1:0.3969 mse:218417760\n",
      "\n",
      "2020-10-30 08:36:00\n",
      "[21, 12, 38, 23, 35, 106, 60, 26, 31, 23]\n",
      "[16, 20, 57, 29, 51, 108, 83, 43, 46, 54]\n",
      "###### 695 batch Train loss:0.9615 acc:0.7418 acc1:0.3541 mse:29888180 Test loss:1.0806 acc:0.7668 acc1:0.4049 mse:219449952\n",
      "\n",
      "2020-10-30 08:36:03\n",
      "[30, 41, 99, 82, 134, 202, 228, 92, 115, 102]\n",
      "[31, 30, 100, 60, 112, 202, 169, 106, 103, 111]\n",
      "###### 696 batch Train loss:1.0500 acc:0.7541 acc1:0.4774 mse:39209304 Test loss:1.0904 acc:0.7698 acc1:0.4079 mse:222333280\n",
      "\n",
      "2020-10-30 08:36:06\n",
      "[12, 5, 12, 13, 21, 53, 25, 25, 15, 9]\n",
      "[9, 8, 14, 12, 17, 45, 31, 20, 13, 12]\n",
      "###### 697 batch Train loss:1.3055 acc:0.7335 acc1:0.4537 mse:25099132 Test loss:1.0905 acc:0.7716 acc1:0.4107 mse:223425312\n",
      "\n",
      "2020-10-30 08:36:08\n",
      "[36, 10, 28, 31, 44, 118, 51, 72, 61, 79]\n",
      "[17, 8, 22, 21, 32, 71, 48, 43, 52, 40]\n",
      "###### 698 batch Train loss:1.3985 acc:0.7502 acc1:0.4731 mse:37512396 Test loss:1.0785 acc:0.7704 acc1:0.4106 mse:219111008\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-30 08:36:10\n",
      "[10, 9, 14, 27, 27, 46, 40, 19, 11, 12]\n",
      "[10, 9, 14, 12, 17, 44, 30, 19, 14, 12]\n",
      "###### 699 batch Train loss:1.1676 acc:0.7541 acc1:0.4673 mse:44607376 Test loss:1.0679 acc:0.7673 acc1:0.4077 mse:213445168\n",
      "\n",
      "2020-10-30 08:36:13\n",
      "[5, 7, 7, 13, 13, 13, 8, 2, 8, 2]\n",
      "[3, 6, 4, 7, 5, 11, 4, 2, 3, 2]\n",
      "###### 700 batch Train loss:0.9569 acc:0.7687 acc1:0.4844 mse:24523834 Test loss:1.0644 acc:0.7624 acc1:0.4013 mse:209005184\n",
      "\n",
      "2020-10-30 08:36:16\n",
      "[13, 7, 9, 9, 14, 33, 31, 10, 15, 10]\n",
      "[8, 7, 12, 12, 15, 41, 25, 13, 10, 8]\n",
      "###### 701 batch Train loss:0.8185 acc:0.8011 acc1:0.4329 mse:23803062 Test loss:1.0710 acc:0.7559 acc1:0.3911 mse:206702032\n",
      "\n",
      "2020-10-30 08:36:18\n",
      "[25, 8, 21, 36, 44, 128, 52, 75, 85, 84]\n",
      "[28, 11, 39, 33, 72, 112, 98, 79, 112, 82]\n",
      "###### 702 batch Train loss:1.0680 acc:0.7560 acc1:0.4566 mse:13510620 Test loss:1.0787 acc:0.7502 acc1:0.3829 mse:206630192\n",
      "\n",
      "2020-10-30 08:36:21\n",
      "[37, 12, 91, 52, 124, 265, 142, 115, 139, 151]\n",
      "[48, 26, 83, 59, 136, 230, 190, 131, 175, 139]\n",
      "###### 703 batch Train loss:0.8788 acc:0.7778 acc1:0.4240 mse:18940436 Test loss:1.0831 acc:0.7458 acc1:0.3761 mse:205446976\n",
      "\n",
      "2020-10-30 08:36:23\n",
      "[4, 3, 5, 4, 7, 17, 10, 23, 18, 9]\n",
      "[13, 6, 15, 14, 28, 63, 41, 42, 70, 47]\n",
      "###### 704 batch Train loss:1.2117 acc:0.6940 acc1:0.2902 mse:22711824 Test loss:1.0691 acc:0.7512 acc1:0.3854 mse:205957568\n",
      "\n",
      "2020-10-30 08:36:26\n",
      "[5, 12, 23, 16, 23, 29, 13, 7, 6, 3]\n",
      "[8, 11, 23, 18, 21, 24, 13, 4, 7, 5]\n",
      "###### 705 batch Train loss:0.6952 acc:0.7581 acc1:0.3987 mse:9710346 Test loss:1.0557 acc:0.7602 acc1:0.3994 mse:208297136\n",
      "\n",
      "2020-10-30 08:36:28\n",
      "[35, 36, 111, 76, 138, 228, 172, 111, 103, 105]\n",
      "[39, 38, 118, 65, 146, 256, 214, 134, 155, 150]\n",
      "###### 706 batch Train loss:1.5754 acc:0.7329 acc1:0.4586 mse:74249456 Test loss:1.0434 acc:0.7662 acc1:0.4091 mse:206922576\n",
      "\n",
      "2020-10-30 08:36:31\n",
      "[4, 9, 11, 9, 12, 35, 28, 14, 11, 7]\n",
      "[9, 7, 13, 12, 15, 37, 24, 12, 10, 8]\n",
      "###### 707 batch Train loss:1.2685 acc:0.7386 acc1:0.4615 mse:40403796 Test loss:1.0396 acc:0.7680 acc1:0.4108 mse:204362496\n",
      "\n",
      "2020-10-30 08:36:33\n",
      "[8, 4, 9, 10, 4, 29, 24, 18, 13, 7]\n",
      "[9, 7, 13, 12, 16, 36, 25, 12, 10, 8]\n",
      "###### 708 batch Train loss:0.6285 acc:0.7587 acc1:0.3186 mse:4156789 Test loss:1.0503 acc:0.7693 acc1:0.4094 mse:205604672\n",
      "\n",
      "2020-10-30 08:36:36\n",
      "[7, 11, 13, 23, 23, 61, 34, 11, 22, 18]\n",
      "[9, 7, 13, 10, 13, 40, 24, 12, 10, 8]\n",
      "###### 709 batch Train loss:0.8077 acc:0.7422 acc1:0.4184 mse:12009465 Test loss:1.0667 acc:0.7710 acc1:0.4086 mse:209556128\n",
      "\n",
      "2020-10-30 08:36:38\n",
      "[10, 11, 14, 12, 18, 37, 33, 21, 15, 12]\n",
      "[9, 7, 14, 10, 12, 35, 20, 11, 7, 7]\n",
      "###### 710 batch Train loss:1.3274 acc:0.7493 acc1:0.4721 mse:30197814 Test loss:1.0700 acc:0.7699 acc1:0.4057 mse:208488000\n",
      "\n",
      "2020-10-30 08:36:41\n",
      "[9, 8, 18, 17, 27, 87, 15, 7, 23, 7]\n",
      "[11, 10, 21, 21, 24, 38, 17, 6, 11, 9]\n",
      "###### 711 batch Train loss:1.6623 acc:0.7486 acc1:0.4729 mse:61309552 Test loss:1.0762 acc:0.7640 acc1:0.3960 mse:204756512\n",
      "\n",
      "2020-10-30 08:36:43\n",
      "[12, 5, 16, 16, 12, 33, 25, 6, 11, 12]\n",
      "[9, 7, 13, 11, 14, 42, 25, 12, 10, 8]\n",
      "###### 712 batch Train loss:0.4401 acc:0.8576 acc1:0.3939 mse:931412 Test loss:1.0977 acc:0.7551 acc1:0.3790 mse:203776544\n",
      "\n",
      "2020-10-30 08:36:47\n",
      "[1, 4, 2, 1, 2, 4, 3, 0, 2, 2]\n",
      "[2, 3, 4, 3, 5, 11, 8, 6, 4, 3]\n",
      "###### 713 batch Train loss:1.2819 acc:0.7522 acc1:0.3237 mse:48024756 Test loss:1.0908 acc:0.7540 acc1:0.3790 mse:200185664\n",
      "\n",
      "2020-10-30 08:36:49\n",
      "[3, 12, 5, 4, 5, 8, 10, 5, 7, 5]\n",
      "[2, 3, 2, 2, 3, 7, 5, 4, 2, 2]\n",
      "###### 714 batch Train loss:1.1250 acc:0.7720 acc1:0.4435 mse:19398346 Test loss:1.0610 acc:0.7561 acc1:0.3879 mse:193703072\n",
      "\n",
      "2020-10-30 08:36:52\n",
      "[6, 4, 6, 9, 14, 13, 4, 4, 3, 1]\n",
      "[5, 5, 6, 7, 8, 11, 7, 4, 3, 4]\n",
      "###### 715 batch Train loss:0.7768 acc:0.7384 acc1:0.3759 mse:12143491 Test loss:1.0340 acc:0.7642 acc1:0.4063 mse:192654192\n",
      "\n",
      "2020-10-30 08:36:54\n",
      "[0, 1, 0, 0, 0, 0, 0, 2, 0, 0]\n",
      "[3, 3, 5, 4, 5, 13, 9, 7, 5, 5]\n",
      "###### 716 batch Train loss:0.8854 acc:0.7675 acc1:0.4482 mse:26870044 Test loss:1.0294 acc:0.7697 acc1:0.4163 mse:196041840\n",
      "\n",
      "2020-10-30 08:36:57\n",
      "[13, 10, 13, 22, 18, 26, 14, 4, 4, 4]\n",
      "[8, 9, 17, 12, 16, 20, 7, 1, 4, 3]\n",
      "###### 717 batch Train loss:0.6945 acc:0.7645 acc1:0.4713 mse:10421646 Test loss:1.0412 acc:0.7720 acc1:0.4185 mse:201889696\n",
      "\n",
      "2020-10-30 08:37:00\n",
      "[24, 7, 16, 31, 47, 132, 57, 89, 73, 83]\n",
      "[13, 6, 17, 18, 35, 44, 34, 33, 29, 41]\n",
      "###### 718 batch Train loss:1.1217 acc:0.7549 acc1:0.4016 mse:27073304 Test loss:1.0442 acc:0.7725 acc1:0.4181 mse:203223248\n",
      "\n",
      "2020-10-30 08:37:02\n",
      "[2, 3, 1, 1, 3, 3, 11, 2, 4, 4]\n",
      "[2, 3, 3, 3, 3, 10, 7, 6, 4, 4]\n",
      "###### 719 batch Train loss:1.4254 acc:0.7562 acc1:0.4836 mse:45769352 Test loss:1.0349 acc:0.7699 acc1:0.4144 mse:197545344\n",
      "\n",
      "2020-10-30 08:37:05\n",
      "[5, 16, 38, 30, 40, 41, 25, 12, 15, 12]\n",
      "[10, 13, 40, 36, 41, 50, 30, 10, 13, 11]\n",
      "###### 720 batch Train loss:1.4522 acc:0.7898 acc1:0.4855 mse:45234016 Test loss:1.0454 acc:0.7575 acc1:0.3915 mse:191685696\n",
      "\n",
      "2020-10-30 08:37:07\n",
      "[13, 25, 8, 11, 15, 49, 30, 30, 21, 15]\n",
      "[11, 8, 15, 11, 17, 44, 30, 19, 14, 13]\n",
      "###### 721 batch Train loss:1.0107 acc:0.7512 acc1:0.4332 mse:35259832 Test loss:1.0667 acc:0.7468 acc1:0.3713 mse:188672672\n",
      "\n",
      "2020-10-30 08:37:10\n",
      "[1, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "[3, 2, 6, 5, 6, 15, 10, 10, 6, 6]\n",
      "###### 722 batch Train loss:0.6229 acc:0.7703 acc1:0.3635 mse:4875869 Test loss:1.0802 acc:0.7424 acc1:0.3620 mse:187986432\n",
      "\n",
      "2020-10-30 08:37:12\n",
      "[9, 15, 13, 23, 32, 35, 25, 13, 24, 16]\n",
      "[11, 10, 21, 22, 25, 41, 18, 8, 12, 12]\n",
      "###### 723 batch Train loss:1.3848 acc:0.7255 acc1:0.4346 mse:50344772 Test loss:1.0498 acc:0.7494 acc1:0.3772 mse:181956704\n",
      "\n",
      "2020-10-30 08:37:15\n",
      "[5, 9, 14, 14, 15, 40, 24, 19, 14, 7]\n",
      "[8, 6, 13, 9, 11, 41, 24, 12, 11, 9]\n",
      "###### 724 batch Train loss:0.8217 acc:0.7676 acc1:0.4387 mse:13336932 Test loss:1.0211 acc:0.7590 acc1:0.3960 mse:179643600\n",
      "\n",
      "2020-10-30 08:37:17\n",
      "[24, 43, 105, 77, 126, 203, 199, 121, 111, 115]\n",
      "[35, 32, 124, 68, 144, 258, 194, 126, 132, 157]\n",
      "###### 725 batch Train loss:1.3621 acc:0.7370 acc1:0.4533 mse:46714100 Test loss:1.0105 acc:0.7661 acc1:0.4095 mse:180393632\n",
      "\n",
      "2020-10-30 08:37:20\n",
      "[6, 9, 5, 17, 26, 38, 29, 13, 13, 10]\n",
      "[8, 6, 13, 12, 13, 44, 26, 13, 12, 11]\n",
      "###### 726 batch Train loss:0.7618 acc:0.7768 acc1:0.4511 mse:8455059 Test loss:1.0180 acc:0.7686 acc1:0.4137 mse:183811840\n",
      "\n",
      "2020-10-30 08:37:22\n",
      "[42, 29, 108, 77, 133, 234, 205, 111, 96, 96]\n",
      "[30, 30, 105, 60, 119, 225, 168, 108, 110, 132]\n",
      "###### 727 batch Train loss:1.1295 acc:0.7747 acc1:0.4746 mse:36832204 Test loss:1.0229 acc:0.7701 acc1:0.4163 mse:186106848\n",
      "\n",
      "2020-10-30 08:37:25\n",
      "[24, 8, 23, 40, 40, 128, 60, 60, 95, 81]\n",
      "[20, 7, 19, 23, 47, 110, 40, 48, 58, 65]\n",
      "###### 728 batch Train loss:1.2686 acc:0.7324 acc1:0.4742 mse:33962244 Test loss:1.0208 acc:0.7704 acc1:0.4179 mse:185995232\n",
      "\n",
      "2020-10-30 08:37:28\n",
      "[7, 11, 13, 23, 23, 61, 34, 11, 22, 18]\n",
      "[8, 7, 12, 11, 11, 45, 25, 13, 12, 11]\n",
      "###### 729 batch Train loss:1.4856 acc:0.7516 acc1:0.4975 mse:42502748 Test loss:1.0057 acc:0.7674 acc1:0.4161 mse:180341984\n",
      "\n",
      "2020-10-30 08:37:30\n",
      "[15, 14, 36, 17, 33, 95, 58, 29, 79, 23]\n",
      "[15, 17, 42, 23, 39, 102, 67, 31, 34, 42]\n",
      "###### 730 batch Train loss:0.6862 acc:0.7662 acc1:0.4153 mse:10658708 Test loss:0.9989 acc:0.7654 acc1:0.4152 mse:177341040\n",
      "\n",
      "2020-10-30 08:37:33\n",
      "[11, 11, 19, 12, 17, 45, 27, 28, 15, 11]\n",
      "[11, 8, 13, 12, 15, 45, 29, 19, 14, 13]\n",
      "###### 731 batch Train loss:1.0773 acc:0.7343 acc1:0.4861 mse:24933856 Test loss:0.9995 acc:0.7622 acc1:0.4107 mse:174548992\n",
      "\n",
      "2020-10-30 08:37:35\n",
      "[7, 26, 33, 43, 32, 52, 25, 18, 11, 11]\n",
      "[10, 15, 43, 44, 41, 53, 35, 13, 14, 12]\n",
      "###### 732 batch Train loss:1.1233 acc:0.7228 acc1:0.4227 mse:29953424 Test loss:0.9960 acc:0.7630 acc1:0.4114 mse:173544000\n",
      "\n",
      "2020-10-30 08:37:38\n",
      "[3, 0, 4, 7, 3, 6, 4, 13, 13, 12]\n",
      "[5, 4, 7, 8, 6, 19, 14, 23, 27, 24]\n",
      "###### 733 batch Train loss:0.9960 acc:0.7562 acc1:0.4477 mse:21900398 Test loss:1.0006 acc:0.7613 acc1:0.4052 mse:171892032\n",
      "\n",
      "2020-10-30 08:37:40\n",
      "[8, 10, 40, 41, 39, 61, 40, 19, 17, 17]\n",
      "[12, 13, 33, 39, 39, 55, 34, 18, 19, 18]\n",
      "###### 734 batch Train loss:1.1416 acc:0.7460 acc1:0.4846 mse:24881278 Test loss:1.0148 acc:0.7562 acc1:0.3932 mse:170243056\n",
      "\n",
      "2020-10-30 08:37:43\n",
      "[15, 15, 28, 19, 27, 73, 44, 30, 29, 30]\n",
      "[17, 20, 52, 28, 44, 107, 92, 48, 45, 55]\n",
      "###### 735 batch Train loss:0.6792 acc:0.7604 acc1:0.3316 mse:9500269 Test loss:1.0123 acc:0.7589 acc1:0.3947 mse:169668144\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-30 08:37:45\n",
      "[27, 34, 101, 76, 117, 209, 179, 104, 116, 110]\n",
      "[38, 34, 116, 72, 136, 291, 218, 135, 135, 169]\n",
      "###### 736 batch Train loss:1.2130 acc:0.7463 acc1:0.4511 mse:49104864 Test loss:0.9913 acc:0.7656 acc1:0.4061 mse:166966080\n",
      "\n",
      "2020-10-30 08:37:48\n",
      "[15, 10, 17, 14, 9, 25, 17, 8, 8, 8]\n",
      "[12, 9, 13, 16, 16, 31, 15, 8, 9, 9]\n",
      "###### 737 batch Train loss:0.6863 acc:0.7603 acc1:0.3404 mse:8052208 Test loss:0.9821 acc:0.7725 acc1:0.4157 mse:168020960\n",
      "\n",
      "2020-10-30 08:37:50\n",
      "[1, 8, 2, 0, 1, 4, 1, 6, 2, 1]\n",
      "[1, 2, 3, 4, 3, 11, 7, 8, 4, 3]\n",
      "###### 738 batch Train loss:0.5827 acc:0.7921 acc1:0.4461 mse:8154574 Test loss:0.9935 acc:0.7760 acc1:0.4185 mse:172588896\n",
      "\n",
      "2020-10-30 08:37:53\n",
      "[6, 5, 15, 13, 14, 56, 24, 14, 8, 10]\n",
      "[8, 6, 14, 11, 12, 48, 20, 16, 11, 7]\n",
      "###### 739 batch Train loss:1.0384 acc:0.7631 acc1:0.4396 mse:19344174 Test loss:1.0082 acc:0.7771 acc1:0.4192 mse:176455728\n",
      "\n",
      "2020-10-30 08:37:55\n",
      "[17, 12, 34, 15, 37, 79, 38, 27, 28, 37]\n",
      "[14, 16, 43, 24, 35, 86, 69, 38, 34, 38]\n",
      "###### 740 batch Train loss:1.0485 acc:0.7511 acc1:0.4617 mse:17991212 Test loss:1.0147 acc:0.7779 acc1:0.4211 mse:178690048\n",
      "\n",
      "2020-10-30 08:37:58\n",
      "[8, 7, 3, 9, 12, 16, 6, 3, 4, 6]\n",
      "[4, 6, 4, 7, 5, 10, 5, 3, 2, 1]\n",
      "###### 741 batch Train loss:0.9646 acc:0.7641 acc1:0.4535 mse:31947988 Test loss:1.0175 acc:0.7778 acc1:0.4217 mse:178736928\n",
      "\n",
      "2020-10-30 08:38:01\n",
      "[12, 14, 10, 20, 19, 42, 16, 10, 14, 12]\n",
      "[10, 10, 17, 20, 22, 35, 18, 9, 12, 10]\n",
      "###### 742 batch Train loss:0.6229 acc:0.7919 acc1:0.4266 mse:4850316 Test loss:1.0195 acc:0.7774 acc1:0.4224 mse:179062480\n",
      "\n",
      "2020-10-30 08:38:03\n",
      "[10, 13, 45, 45, 56, 75, 51, 12, 25, 17]\n",
      "[11, 12, 25, 29, 32, 45, 25, 12, 14, 12]\n",
      "###### 743 batch Train loss:1.3676 acc:0.7441 acc1:0.4896 mse:5489068 Test loss:0.9948 acc:0.7741 acc1:0.4206 mse:171598816\n",
      "\n",
      "2020-10-30 08:38:07\n",
      "[21, 12, 38, 23, 35, 106, 60, 26, 31, 23]\n",
      "[15, 15, 42, 22, 33, 75, 69, 36, 36, 38]\n",
      "###### 744 batch Train loss:1.3126 acc:0.7930 acc1:0.5138 mse:55065444 Test loss:0.9944 acc:0.7623 acc1:0.4022 mse:163840224\n",
      "\n",
      "2020-10-30 08:38:09\n",
      "[10, 8, 16, 16, 15, 39, 13, 5, 9, 17]\n",
      "[13, 8, 14, 16, 17, 31, 15, 8, 9, 7]\n",
      "###### 745 batch Train loss:1.2396 acc:0.7353 acc1:0.4519 mse:42031524 Test loss:1.0261 acc:0.7473 acc1:0.3749 mse:161592720\n",
      "\n",
      "2020-10-30 08:38:12\n",
      "[8, 7, 13, 17, 27, 25, 23, 9, 5, 14]\n",
      "[8, 7, 11, 11, 13, 34, 20, 12, 9, 5]\n",
      "###### 746 batch Train loss:0.6756 acc:0.7700 acc1:0.2704 mse:8786686 Test loss:1.0387 acc:0.7435 acc1:0.3666 mse:161778960\n",
      "\n",
      "2020-10-30 08:38:14\n",
      "[5, 9, 14, 14, 15, 40, 24, 19, 14, 7]\n",
      "[8, 7, 13, 11, 12, 41, 20, 12, 10, 6]\n",
      "###### 747 batch Train loss:0.9916 acc:0.7117 acc1:0.4000 mse:15645169 Test loss:1.0176 acc:0.7510 acc1:0.3793 mse:160259648\n",
      "\n",
      "2020-10-30 08:38:17\n",
      "[8, 10, 40, 41, 39, 61, 40, 19, 17, 17]\n",
      "[12, 14, 37, 44, 51, 62, 38, 17, 20, 18]\n",
      "###### 748 batch Train loss:1.1830 acc:0.7429 acc1:0.4639 mse:25401330 Test loss:1.0010 acc:0.7571 acc1:0.3898 mse:159328560\n",
      "\n",
      "2020-10-30 08:38:20\n",
      "[15, 15, 28, 19, 27, 73, 44, 30, 29, 30]\n",
      "[17, 18, 57, 31, 46, 93, 99, 50, 48, 51]\n",
      "###### 749 batch Train loss:1.0532 acc:0.7755 acc1:0.4686 mse:22741838 Test loss:0.9950 acc:0.7595 acc1:0.3938 mse:159155568\n",
      "\n",
      "2020-10-30 08:38:22\n",
      "[1, 2, 0, 1, 0, 0, 0, 1, 1, 0]\n",
      "[3, 3, 4, 5, 4, 13, 8, 7, 5, 3]\n",
      "###### 750 batch Train loss:0.8810 acc:0.7556 acc1:0.3329 mse:8254938 Test loss:0.9781 acc:0.7680 acc1:0.4097 mse:160913504\n",
      "\n",
      "2020-10-30 08:38:25\n",
      "[0, 0, 1, 0, 0, 0, 1, 0, 2, 0]\n",
      "[3, 2, 5, 5, 5, 14, 9, 8, 5, 3]\n",
      "###### 751 batch Train loss:0.6824 acc:0.8359 acc1:0.4652 mse:23444824 Test loss:0.9805 acc:0.7729 acc1:0.4177 mse:164478016\n",
      "\n",
      "2020-10-30 08:38:27\n",
      "[11, 6, 14, 18, 11, 31, 13, 6, 10, 9]\n",
      "[13, 8, 15, 17, 20, 34, 15, 8, 11, 8]\n",
      "###### 752 batch Train loss:1.0707 acc:0.7663 acc1:0.3966 mse:26087974 Test loss:0.9857 acc:0.7748 acc1:0.4206 mse:166148272\n",
      "\n",
      "2020-10-30 08:38:30\n",
      "[12, 8, 17, 19, 23, 35, 39, 20, 14, 15]\n",
      "[10, 7, 17, 12, 15, 46, 25, 17, 10, 8]\n",
      "###### 753 batch Train loss:0.9265 acc:0.7554 acc1:0.4609 mse:28033232 Test loss:0.9901 acc:0.7760 acc1:0.4223 mse:166337968\n",
      "\n",
      "2020-10-30 08:38:32\n",
      "[15, 12, 15, 12, 15, 40, 27, 16, 12, 11]\n",
      "[10, 7, 17, 12, 15, 45, 24, 16, 9, 9]\n",
      "###### 754 batch Train loss:0.6037 acc:0.7977 acc1:0.4395 mse:5101838 Test loss:0.9981 acc:0.7763 acc1:0.4223 mse:167215888\n",
      "\n",
      "2020-10-30 08:38:35\n",
      "[10, 6, 24, 7, 15, 45, 38, 15, 10, 18]\n",
      "[9, 6, 16, 11, 15, 44, 24, 16, 9, 7]\n",
      "###### 755 batch Train loss:0.7006 acc:0.7592 acc1:0.4269 mse:9218634 Test loss:1.0090 acc:0.7770 acc1:0.4231 mse:169374832\n",
      "\n",
      "2020-10-30 08:38:38\n",
      "[7, 11, 12, 8, 21, 27, 17, 11, 13, 7]\n",
      "[8, 7, 12, 11, 14, 41, 22, 11, 11, 7]\n",
      "###### 756 batch Train loss:1.1400 acc:0.7534 acc1:0.4884 mse:32942438 Test loss:1.0099 acc:0.7754 acc1:0.4206 mse:168589360\n",
      "\n",
      "2020-10-30 08:38:40\n",
      "[2, 6, 4, 1, 2, 2, 4, 2, 1, 4]\n",
      "[2, 3, 3, 3, 3, 9, 6, 4, 3, 2]\n",
      "###### 757 batch Train loss:0.8449 acc:0.8049 acc1:0.4778 mse:29512492 Test loss:1.0152 acc:0.7731 acc1:0.4164 mse:167566528\n",
      "\n",
      "2020-10-30 08:38:43\n",
      "[6, 15, 30, 32, 33, 44, 34, 13, 12, 6]\n",
      "[8, 13, 39, 36, 39, 49, 37, 12, 14, 8]\n",
      "###### 758 batch Train loss:1.0455 acc:0.7630 acc1:0.4638 mse:26267156 Test loss:1.0074 acc:0.7721 acc1:0.4161 mse:162789824\n",
      "\n",
      "2020-10-30 08:38:45\n",
      "[19, 7, 13, 11, 19, 61, 32, 20, 14, 10]\n",
      "[10, 7, 14, 12, 18, 46, 29, 18, 14, 10]\n",
      "###### 759 batch Train loss:0.9608 acc:0.7425 acc1:0.4334 mse:15339336 Test loss:0.9968 acc:0.7719 acc1:0.4175 mse:158378688\n",
      "\n",
      "2020-10-30 08:38:48\n",
      "[7, 10, 14, 11, 18, 19, 13, 6, 9, 9]\n",
      "[9, 10, 16, 11, 15, 22, 12, 3, 6, 4]\n",
      "###### 760 batch Train loss:0.8312 acc:0.7823 acc1:0.4643 mse:11035840 Test loss:0.9860 acc:0.7712 acc1:0.4176 mse:155332720\n",
      "\n",
      "2020-10-30 08:38:51\n",
      "[34, 10, 19, 34, 40, 113, 54, 63, 86, 94]\n",
      "[32, 9, 40, 28, 79, 87, 74, 69, 73, 105]\n",
      "###### 761 batch Train loss:0.9571 acc:0.7704 acc1:0.4353 mse:17886212 Test loss:0.9882 acc:0.7684 acc1:0.4133 mse:154905648\n",
      "\n",
      "2020-10-30 08:38:53\n",
      "[36, 10, 28, 31, 44, 118, 51, 72, 61, 79]\n",
      "[37, 12, 59, 35, 97, 165, 97, 86, 96, 130]\n",
      "###### 762 batch Train loss:0.8066 acc:0.7452 acc1:0.4238 mse:9576832 Test loss:0.9847 acc:0.7707 acc1:0.4177 mse:157294160\n",
      "\n",
      "2020-10-30 08:38:56\n",
      "[10, 7, 18, 10, 17, 15, 14, 2, 9, 2]\n",
      "[9, 10, 17, 14, 18, 24, 15, 4, 7, 5]\n",
      "###### 763 batch Train loss:0.9445 acc:0.7611 acc1:0.4811 mse:18881464 Test loss:0.9838 acc:0.7720 acc1:0.4205 mse:159095744\n",
      "\n",
      "2020-10-30 08:38:58\n",
      "[25, 36, 106, 85, 123, 195, 209, 111, 84, 103]\n",
      "[41, 35, 130, 69, 155, 266, 221, 127, 139, 169]\n",
      "###### 764 batch Train loss:1.3722 acc:0.7536 acc1:0.5201 mse:47073928 Test loss:0.9739 acc:0.7706 acc1:0.4197 mse:155849776\n",
      "\n",
      "2020-10-30 08:39:01\n",
      "[1, 4, 2, 1, 2, 4, 3, 0, 2, 2]\n",
      "[2, 2, 3, 3, 3, 9, 7, 5, 4, 3]\n",
      "###### 765 batch Train loss:0.7464 acc:0.7751 acc1:0.4534 mse:13912574 Test loss:0.9636 acc:0.7713 acc1:0.4220 mse:153191536\n",
      "\n",
      "2020-10-30 08:39:03\n",
      "[54, 21, 87, 59, 142, 245, 167, 123, 135, 156]\n",
      "[54, 24, 99, 63, 154, 290, 174, 130, 166, 195]\n",
      "###### 766 batch Train loss:1.0440 acc:0.7745 acc1:0.5004 mse:24196496 Test loss:0.9579 acc:0.7687 acc1:0.4185 mse:149247120\n",
      "\n",
      "2020-10-30 08:39:06\n",
      "[6, 6, 17, 17, 20, 32, 32, 13, 11, 11]\n",
      "[11, 7, 16, 12, 14, 38, 28, 16, 11, 11]\n",
      "###### 767 batch Train loss:0.6397 acc:0.7451 acc1:0.3843 mse:3328997 Test loss:0.9538 acc:0.7688 acc1:0.4181 mse:147887328\n",
      "\n",
      "2020-10-30 08:39:08\n",
      "[11, 20, 47, 40, 35, 45, 29, 16, 7, 10]\n",
      "[8, 15, 36, 36, 36, 48, 35, 14, 14, 9]\n",
      "###### 768 batch Train loss:1.2583 acc:0.7607 acc1:0.5027 mse:42347392 Test loss:0.9557 acc:0.7647 acc1:0.4102 mse:145357744\n",
      "\n",
      "2020-10-30 08:39:11\n",
      "[13, 7, 10, 11, 8, 29, 13, 9, 9, 12]\n",
      "[14, 9, 14, 17, 17, 32, 18, 8, 10, 10]\n",
      "###### 769 batch Train loss:0.9293 acc:0.7396 acc1:0.4512 mse:9284595 Test loss:0.9628 acc:0.7615 acc1:0.4034 mse:144640048\n",
      "\n",
      "2020-10-30 08:39:14\n",
      "[6, 2, 1, 9, 8, 6, 8, 0, 2, 4]\n",
      "[2, 4, 2, 4, 3, 7, 5, 4, 2, 1]\n",
      "###### 770 batch Train loss:1.2699 acc:0.7500 acc1:0.4904 mse:20713178 Test loss:0.9653 acc:0.7583 acc1:0.3994 mse:142564352\n",
      "\n",
      "2020-10-30 08:39:16\n",
      "[17, 9, 15, 8, 16, 39, 24, 15, 11, 13]\n",
      "[8, 9, 13, 14, 13, 44, 25, 14, 13, 10]\n",
      "###### 771 batch Train loss:0.9956 acc:0.7158 acc1:0.3960 mse:26157400 Test loss:0.9453 acc:0.7658 acc1:0.4138 mse:140864608\n",
      "\n",
      "2020-10-30 08:39:19\n",
      "[12, 5, 16, 16, 12, 33, 25, 6, 11, 12]\n",
      "[8, 9, 14, 14, 13, 45, 25, 14, 13, 10]\n",
      "###### 772 batch Train loss:0.9949 acc:0.7698 acc1:0.4963 mse:20875588 Test loss:0.9408 acc:0.7676 acc1:0.4172 mse:140203152\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-30 08:39:21\n",
      "[4, 9, 11, 9, 12, 35, 28, 14, 11, 7]\n",
      "[7, 8, 12, 13, 13, 38, 22, 12, 11, 8]\n",
      "###### 773 batch Train loss:0.5371 acc:0.7952 acc1:0.3924 mse:3374912 Test loss:0.9440 acc:0.7702 acc1:0.4194 mse:142182976\n",
      "\n",
      "2020-10-30 08:39:24\n",
      "[12, 8, 45, 41, 54, 77, 50, 17, 12, 18]\n",
      "[10, 13, 35, 39, 38, 57, 38, 16, 16, 17]\n",
      "###### 774 batch Train loss:1.0569 acc:0.7595 acc1:0.5008 mse:3422802 Test loss:0.9477 acc:0.7699 acc1:0.4188 mse:143847776\n",
      "\n",
      "2020-10-30 08:39:28\n",
      "[25, 36, 106, 85, 123, 195, 209, 111, 84, 103]\n",
      "[25, 29, 90, 57, 93, 178, 159, 94, 99, 102]\n",
      "###### 775 batch Train loss:1.2489 acc:0.7920 acc1:0.5223 mse:40394160 Test loss:0.9628 acc:0.7598 acc1:0.4005 mse:141502032\n",
      "\n",
      "2020-10-30 08:39:30\n",
      "[12, 8, 45, 41, 54, 77, 50, 17, 12, 18]\n",
      "[10, 13, 36, 39, 39, 59, 40, 18, 15, 18]\n",
      "###### 776 batch Train loss:0.9579 acc:0.7869 acc1:0.4318 mse:25042304 Test loss:0.9808 acc:0.7527 acc1:0.3867 mse:142276288\n",
      "\n",
      "2020-10-30 08:39:33\n",
      "[34, 10, 19, 34, 40, 113, 54, 63, 86, 94]\n",
      "[23, 6, 24, 26, 46, 80, 60, 68, 77, 85]\n",
      "###### 777 batch Train loss:0.9822 acc:0.7189 acc1:0.4135 mse:18222128 Test loss:0.9649 acc:0.7582 acc1:0.3968 mse:141840592\n",
      "\n",
      "2020-10-30 08:39:35\n",
      "[7, 11, 12, 8, 21, 27, 17, 11, 13, 7]\n",
      "[7, 8, 11, 12, 13, 40, 24, 13, 9, 8]\n",
      "###### 778 batch Train loss:0.7131 acc:0.7543 acc1:0.4407 mse:9784635 Test loss:0.9466 acc:0.7676 acc1:0.4121 mse:142472928\n",
      "\n",
      "2020-10-30 08:39:38\n",
      "[7, 8, 17, 12, 13, 42, 26, 20, 10, 8]\n",
      "[7, 8, 11, 12, 13, 34, 24, 12, 9, 8]\n",
      "###### 779 batch Train loss:0.5548 acc:0.7990 acc1:0.3987 mse:3887529 Test loss:0.9461 acc:0.7744 acc1:0.4208 mse:145864960\n",
      "\n",
      "2020-10-30 08:39:40\n",
      "[7, 20, 11, 13, 14, 82, 12, 10, 11, 11]\n",
      "[10, 10, 18, 22, 24, 42, 23, 12, 11, 14]\n",
      "###### 780 batch Train loss:0.7973 acc:0.7558 acc1:0.4445 mse:5866878 Test loss:0.9563 acc:0.7769 acc1:0.4225 mse:149627216\n",
      "\n",
      "2020-10-30 08:39:43\n",
      "[32, 5, 30, 37, 52, 103, 54, 61, 74, 79]\n",
      "[24, 6, 21, 24, 46, 129, 47, 61, 73, 81]\n",
      "###### 781 batch Train loss:0.8123 acc:0.7977 acc1:0.4727 mse:21404232 Test loss:0.9641 acc:0.7785 acc1:0.4238 mse:151620144\n",
      "\n",
      "2020-10-30 08:39:45\n",
      "[11, 6, 14, 18, 11, 31, 13, 6, 10, 9]\n",
      "[13, 7, 14, 16, 16, 32, 18, 8, 7, 9]\n",
      "###### 782 batch Train loss:0.7101 acc:0.7573 acc1:0.4455 mse:5374888 Test loss:0.9761 acc:0.7795 acc1:0.4246 mse:154356192\n",
      "\n",
      "2020-10-30 08:39:48\n",
      "[59, 19, 75, 47, 161, 251, 162, 122, 129, 173]\n",
      "[45, 18, 79, 57, 121, 271, 146, 115, 135, 150]\n",
      "###### 783 batch Train loss:1.1083 acc:0.7638 acc1:0.4635 mse:24404094 Test loss:0.9749 acc:0.7797 acc1:0.4258 mse:152923408\n",
      "\n",
      "2020-10-30 08:39:51\n",
      "[38, 22, 91, 51, 139, 283, 164, 102, 133, 185]\n",
      "[46, 18, 83, 59, 125, 270, 144, 115, 134, 151]\n",
      "###### 784 batch Train loss:0.9441 acc:0.8252 acc1:0.4609 mse:23880532 Test loss:0.9579 acc:0.7784 acc1:0.4257 mse:146905984\n",
      "\n",
      "2020-10-30 08:39:53\n",
      "[0, 0, 0, 0, 2, 0, 0, 0, 0, 0]\n",
      "[2, 2, 3, 4, 3, 12, 8, 6, 3, 4]\n",
      "###### 785 batch Train loss:0.7263 acc:0.8073 acc1:0.4032 mse:15957194 Test loss:0.9473 acc:0.7749 acc1:0.4200 mse:141598592\n",
      "\n",
      "2020-10-30 08:39:56\n",
      "[7, 10, 14, 11, 18, 19, 13, 6, 9, 9]\n",
      "[7, 9, 13, 12, 14, 25, 8, 4, 3, 4]\n",
      "###### 786 batch Train loss:1.1552 acc:0.7577 acc1:0.4824 mse:31628496 Test loss:0.9376 acc:0.7715 acc1:0.4150 mse:136547488\n",
      "\n",
      "2020-10-30 08:39:58\n",
      "[15, 6, 11, 7, 20, 30, 17, 6, 10, 13]\n",
      "[14, 8, 14, 17, 18, 32, 16, 7, 8, 9]\n",
      "###### 787 batch Train loss:1.0754 acc:0.7542 acc1:0.4738 mse:21595928 Test loss:0.9453 acc:0.7645 acc1:0.4024 mse:133392720\n",
      "\n",
      "2020-10-30 08:40:01\n",
      "[13, 25, 8, 11, 15, 49, 30, 30, 21, 15]\n",
      "[10, 8, 13, 12, 17, 44, 28, 19, 11, 10]\n",
      "###### 788 batch Train loss:1.2496 acc:0.7504 acc1:0.5053 mse:30537118 Test loss:0.9973 acc:0.7499 acc1:0.3731 mse:136591936\n",
      "\n",
      "2020-10-30 08:40:03\n",
      "[17, 13, 45, 41, 50, 83, 34, 18, 22, 14]\n",
      "[10, 11, 34, 38, 42, 57, 33, 11, 14, 16]\n",
      "###### 789 batch Train loss:1.1422 acc:0.7439 acc1:0.4573 mse:21303112 Test loss:1.0468 acc:0.7369 acc1:0.3463 mse:142720480\n",
      "\n",
      "2020-10-30 08:40:06\n",
      "[13, 7, 13, 14, 24, 48, 39, 23, 11, 14]\n",
      "[11, 8, 14, 12, 18, 45, 29, 20, 13, 11]\n",
      "###### 790 batch Train loss:1.0047 acc:0.7157 acc1:0.3808 mse:18892506 Test loss:1.0275 acc:0.7425 acc1:0.3592 mse:141246464\n",
      "\n",
      "2020-10-30 08:40:08\n",
      "[10, 15, 42, 37, 40, 45, 39, 16, 25, 9]\n",
      "[9, 15, 47, 42, 43, 55, 40, 16, 12, 11]\n",
      "###### 791 batch Train loss:1.0718 acc:0.7106 acc1:0.3611 mse:20492630 Test loss:0.9521 acc:0.7645 acc1:0.4047 mse:134202328\n",
      "\n",
      "2020-10-30 08:40:11\n",
      "[24, 7, 16, 31, 47, 132, 57, 89, 73, 83]\n",
      "[23, 6, 22, 22, 50, 73, 43, 49, 62, 76]\n",
      "###### 792 batch Train loss:0.9650 acc:0.7469 acc1:0.4066 mse:24314294 Test loss:0.9348 acc:0.7765 acc1:0.4254 mse:136909440\n",
      "\n",
      "2020-10-30 08:40:13\n",
      "[8, 1, 3, 10, 6, 10, 6, 24, 21, 8]\n",
      "[4, 3, 7, 7, 7, 17, 13, 20, 16, 9]\n",
      "###### 793 batch Train loss:0.8896 acc:0.7555 acc1:0.4479 mse:9927924 Test loss:0.9684 acc:0.7799 acc1:0.4275 mse:148493664\n",
      "\n",
      "2020-10-30 08:40:16\n",
      "[6, 9, 18, 13, 9, 45, 31, 12, 15, 10]\n",
      "[8, 6, 13, 12, 15, 45, 24, 14, 11, 9]\n",
      "###### 794 batch Train loss:0.9288 acc:0.7869 acc1:0.4760 mse:26979186 Test loss:0.9961 acc:0.7801 acc1:0.4249 mse:155657840\n",
      "\n",
      "2020-10-30 08:40:18\n",
      "[10, 9, 14, 27, 27, 46, 40, 19, 11, 12]\n",
      "[10, 7, 12, 11, 17, 44, 28, 20, 13, 10]\n",
      "###### 795 batch Train loss:0.9744 acc:0.7535 acc1:0.4560 mse:16230313 Test loss:1.0049 acc:0.7797 acc1:0.4227 mse:157378352\n",
      "\n",
      "2020-10-30 08:40:21\n",
      "[10, 10, 40, 53, 50, 55, 41, 12, 17, 21]\n",
      "[10, 12, 35, 34, 41, 60, 38, 14, 16, 15]\n",
      "###### 796 batch Train loss:0.9604 acc:0.7813 acc1:0.4413 mse:9675419 Test loss:0.9942 acc:0.7785 acc1:0.4212 mse:154459104\n",
      "\n",
      "2020-10-30 08:40:23\n",
      "[1, 4, 2, 1, 2, 4, 3, 0, 2, 2]\n",
      "[1, 2, 3, 3, 5, 9, 7, 6, 4, 3]\n",
      "###### 797 batch Train loss:1.1906 acc:0.7700 acc1:0.4662 mse:30961684 Test loss:0.9712 acc:0.7756 acc1:0.4178 mse:147802912\n",
      "\n",
      "2020-10-30 08:40:26\n",
      "[3, 12, 5, 4, 5, 8, 10, 5, 7, 5]\n",
      "[3, 5, 4, 4, 9, 6, 5, 4, 3, 2]\n",
      "###### 798 batch Train loss:0.8015 acc:0.7798 acc1:0.4423 mse:15254757 Test loss:0.9624 acc:0.7716 acc1:0.4117 mse:143598960\n",
      "\n",
      "2020-10-30 08:40:28\n",
      "[1, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "[2, 1, 4, 4, 5, 12, 9, 8, 5, 4]\n",
      "###### 799 batch Train loss:0.9692 acc:0.8074 acc1:0.4805 mse:30018388 Test loss:0.9785 acc:0.7625 acc1:0.3942 mse:142697200\n",
      "\n",
      "2020-10-30 08:40:31\n",
      "[10, 7, 11, 20, 11, 93, 28, 13, 6, 14]\n",
      "[8, 8, 14, 12, 15, 43, 25, 13, 13, 11]\n",
      "###### 800 batch Train loss:1.1063 acc:0.7440 acc1:0.4510 mse:21254868 Test loss:0.9903 acc:0.7557 acc1:0.3819 mse:139650128\n",
      "\n",
      "2020-10-30 08:40:33\n",
      "[13, 7, 10, 11, 8, 29, 13, 9, 9, 12]\n",
      "[14, 9, 15, 17, 20, 31, 18, 9, 12, 11]\n",
      "###### 801 batch Train loss:1.0674 acc:0.7351 acc1:0.4406 mse:22267876 Test loss:0.9865 acc:0.7544 acc1:0.3802 mse:135110752\n",
      "\n",
      "2020-10-30 08:40:36\n",
      "[0, 1, 0, 0, 0, 0, 0, 2, 0, 0]\n",
      "[2, 2, 4, 4, 4, 11, 8, 7, 6, 5]\n",
      "###### 802 batch Train loss:0.7685 acc:0.7568 acc1:0.3610 mse:8770097 Test loss:0.9551 acc:0.7623 acc1:0.3965 mse:131361360\n",
      "\n",
      "2020-10-30 08:40:39\n",
      "[1, 8, 2, 0, 1, 4, 1, 6, 2, 1]\n",
      "[1, 2, 3, 3, 4, 9, 7, 6, 4, 4]\n",
      "###### 803 batch Train loss:0.8738 acc:0.7630 acc1:0.4155 mse:19290456 Test loss:0.9322 acc:0.7702 acc1:0.4123 mse:130611080\n",
      "\n",
      "2020-10-30 08:40:41\n",
      "[5, 8, 24, 10, 16, 38, 24, 8, 9, 9]\n",
      "[10, 6, 17, 12, 16, 41, 29, 18, 12, 12]\n",
      "###### 804 batch Train loss:0.8562 acc:0.7389 acc1:0.4084 mse:12742154 Test loss:0.9300 acc:0.7775 acc1:0.4266 mse:134583184\n",
      "\n",
      "2020-10-30 08:40:43\n",
      "[6, 4, 6, 9, 14, 13, 4, 4, 3, 1]\n",
      "[6, 7, 7, 7, 10, 12, 8, 4, 5, 4]\n",
      "###### 805 batch Train loss:0.6128 acc:0.7723 acc1:0.4382 mse:1722405 Test loss:0.9603 acc:0.7808 acc1:0.4312 mse:144760656\n",
      "\n",
      "2020-10-30 08:40:47\n",
      "[10, 8, 10, 8, 20, 35, 25, 9, 7, 16]\n",
      "[8, 7, 12, 12, 15, 39, 25, 12, 12, 9]\n",
      "###### 806 batch Train loss:0.6517 acc:0.7960 acc1:0.4563 mse:10383531 Test loss:0.9962 acc:0.7819 acc1:0.4315 mse:154325376\n",
      "\n",
      "2020-10-30 08:40:50\n",
      "[8, 7, 3, 9, 12, 16, 6, 3, 4, 6]\n",
      "[5, 7, 4, 6, 8, 11, 6, 2, 3, 3]\n",
      "###### 807 batch Train loss:0.8064 acc:0.8256 acc1:0.4700 mse:16736547 Test loss:1.0121 acc:0.7816 acc1:0.4303 mse:157029792\n",
      "\n",
      "2020-10-30 08:40:52\n",
      "[5, 2, 5, 11, 10, 28, 39, 14, 9, 8]\n",
      "[8, 8, 11, 12, 14, 36, 25, 11, 12, 9]\n",
      "###### 808 batch Train loss:1.1536 acc:0.7743 acc1:0.4626 mse:25620516 Test loss:1.0014 acc:0.7801 acc1:0.4288 mse:151810336\n",
      "\n",
      "2020-10-30 08:40:55\n",
      "[12, 16, 45, 40, 52, 44, 39, 14, 15, 16]\n",
      "[11, 11, 24, 30, 31, 45, 24, 9, 14, 14]\n",
      "###### 809 batch Train loss:1.4206 acc:0.7444 acc1:0.4835 mse:26208750 Test loss:1.0110 acc:0.7715 acc1:0.4133 mse:148369904\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-30 08:40:57\n",
      "[4, 9, 11, 9, 12, 35, 28, 14, 11, 7]\n",
      "[8, 8, 11, 12, 14, 36, 25, 11, 11, 9]\n",
      "###### 810 batch Train loss:0.9548 acc:0.7479 acc1:0.4594 mse:23704852 Test loss:1.0603 acc:0.7584 acc1:0.3868 mse:154876464\n",
      "\n",
      "2020-10-30 08:41:00\n",
      "[8, 10, 40, 41, 39, 61, 40, 19, 17, 17]\n",
      "[12, 11, 28, 36, 38, 51, 29, 10, 17, 17]\n",
      "###### 811 batch Train loss:0.7753 acc:0.7970 acc1:0.4610 mse:7971649 Test loss:1.1047 acc:0.7460 acc1:0.3627 mse:162754144\n",
      "\n",
      "2020-10-30 08:41:02\n",
      "[13, 10, 13, 22, 18, 26, 14, 4, 4, 4]\n",
      "[8, 10, 11, 11, 13, 19, 7, 2, 4, 4]\n",
      "###### 812 batch Train loss:0.7073 acc:0.7523 acc1:0.3846 mse:8253658 Test loss:1.1227 acc:0.7409 acc1:0.3533 mse:168915856\n",
      "\n",
      "2020-10-30 08:41:05\n",
      "[13, 7, 13, 14, 24, 48, 39, 23, 11, 14]\n",
      "[12, 9, 14, 13, 17, 44, 31, 19, 14, 12]\n",
      "###### 813 batch Train loss:1.5063 acc:0.6912 acc1:0.4452 mse:42734516 Test loss:1.0349 acc:0.7553 acc1:0.3874 mse:149777088\n",
      "\n",
      "2020-10-30 08:41:07\n",
      "[10, 9, 22, 11, 11, 105, 22, 23, 12, 9]\n",
      "[7, 7, 15, 12, 13, 51, 24, 16, 10, 8]\n",
      "###### 814 batch Train loss:0.9185 acc:0.7394 acc1:0.4074 mse:14094545 Test loss:0.9552 acc:0.7688 acc1:0.4166 mse:135102256\n",
      "\n",
      "2020-10-30 08:41:10\n",
      "[28, 6, 24, 34, 51, 122, 44, 68, 76, 86]\n",
      "[28, 7, 29, 25, 46, 100, 41, 63, 74, 79]\n",
      "###### 815 batch Train loss:1.3022 acc:0.7432 acc1:0.5090 mse:35509368 Test loss:0.9375 acc:0.7726 acc1:0.4247 mse:133778256\n",
      "\n",
      "2020-10-30 08:41:13\n",
      "[27, 34, 101, 76, 117, 209, 179, 104, 116, 110]\n",
      "[31, 38, 107, 64, 123, 212, 186, 111, 98, 104]\n",
      "###### 816 batch Train loss:1.0467 acc:0.7738 acc1:0.4663 mse:25355892 Test loss:0.9488 acc:0.7739 acc1:0.4274 mse:138439424\n",
      "\n",
      "2020-10-30 08:41:15\n",
      "[4, 1, 2, 6, 7, 21, 4, 28, 10, 14]\n",
      "[5, 3, 6, 7, 6, 17, 13, 12, 9, 7]\n",
      "###### 817 batch Train loss:1.1873 acc:0.7687 acc1:0.4693 mse:33168498 Test loss:0.9430 acc:0.7729 acc1:0.4257 mse:134851200\n",
      "\n",
      "2020-10-30 08:41:18\n",
      "[9, 15, 15, 13, 27, 76, 16, 6, 26, 11]\n",
      "[8, 9, 18, 22, 24, 36, 20, 8, 10, 9]\n",
      "###### 818 batch Train loss:0.9227 acc:0.7527 acc1:0.4798 mse:16227952 Test loss:0.9381 acc:0.7722 acc1:0.4245 mse:130917672\n",
      "\n",
      "2020-10-30 08:41:20\n",
      "[15, 10, 17, 14, 9, 25, 17, 8, 8, 8]\n",
      "[10, 8, 13, 16, 16, 30, 16, 6, 9, 9]\n",
      "###### 819 batch Train loss:1.3152 acc:0.7494 acc1:0.4797 mse:29754686 Test loss:0.9191 acc:0.7709 acc1:0.4228 mse:122956944\n",
      "\n",
      "2020-10-30 08:41:23\n",
      "[6, 14, 11, 18, 13, 44, 17, 10, 9, 7]\n",
      "[6, 6, 10, 10, 11, 35, 25, 11, 9, 6]\n",
      "###### 820 batch Train loss:0.6959 acc:0.7846 acc1:0.4795 mse:5356500 Test loss:0.9247 acc:0.7668 acc1:0.4140 mse:121697392\n",
      "\n",
      "2020-10-30 08:41:25\n",
      "[17, 13, 45, 41, 50, 83, 34, 18, 22, 14]\n",
      "[10, 12, 36, 35, 40, 53, 35, 10, 16, 15]\n",
      "###### 821 batch Train loss:1.0789 acc:0.7631 acc1:0.4839 mse:15122232 Test loss:0.9383 acc:0.7616 acc1:0.4034 mse:123412232\n",
      "\n",
      "2020-10-30 08:41:28\n",
      "[16, 3, 15, 7, 13, 45, 23, 15, 16, 8]\n",
      "[6, 7, 12, 11, 12, 43, 24, 12, 10, 8]\n",
      "###### 822 batch Train loss:1.0516 acc:0.7572 acc1:0.4833 mse:28913432 Test loss:0.9420 acc:0.7591 acc1:0.3984 mse:122995416\n",
      "\n",
      "2020-10-30 08:41:30\n",
      "[3, 0, 4, 7, 3, 6, 4, 13, 13, 12]\n",
      "[4, 3, 6, 7, 5, 18, 13, 22, 15, 9]\n",
      "###### 823 batch Train loss:0.8112 acc:0.7372 acc1:0.3932 mse:12002844 Test loss:0.9221 acc:0.7645 acc1:0.4089 mse:120735888\n",
      "\n",
      "2020-10-30 08:41:33\n",
      "[13, 12, 42, 56, 50, 79, 38, 13, 15, 19]\n",
      "[11, 13, 41, 42, 47, 57, 39, 13, 17, 17]\n",
      "###### 824 batch Train loss:0.9161 acc:0.8237 acc1:0.5211 mse:14421950 Test loss:0.9167 acc:0.7655 acc1:0.4109 mse:121073104\n",
      "\n",
      "2020-10-30 08:41:35\n",
      "[8, 7, 13, 17, 27, 25, 23, 9, 5, 14]\n",
      "[6, 7, 11, 10, 13, 33, 23, 11, 9, 7]\n",
      "###### 825 batch Train loss:0.7230 acc:0.7806 acc1:0.4740 mse:6262282 Test loss:0.9174 acc:0.7666 acc1:0.4130 mse:124000960\n",
      "\n",
      "2020-10-30 08:41:38\n",
      "[8, 4, 9, 10, 4, 29, 24, 18, 13, 7]\n",
      "[7, 7, 12, 12, 15, 36, 26, 12, 11, 8]\n",
      "###### 826 batch Train loss:0.9196 acc:0.7312 acc1:0.3909 mse:12894012 Test loss:0.9111 acc:0.7739 acc1:0.4275 mse:129090576\n",
      "\n",
      "2020-10-30 08:41:40\n",
      "[5, 11, 2, 14, 12, 47, 25, 13, 15, 12]\n",
      "[7, 7, 12, 12, 15, 38, 25, 12, 11, 8]\n",
      "###### 827 batch Train loss:0.5309 acc:0.7979 acc1:0.4132 mse:2835269 Test loss:0.9284 acc:0.7781 acc1:0.4343 mse:138606384\n",
      "\n",
      "2020-10-30 08:41:43\n",
      "[6, 1, 3, 7, 8, 13, 3, 22, 12, 8]\n",
      "[4, 2, 7, 8, 8, 18, 14, 16, 10, 9]\n",
      "###### 828 batch Train loss:0.6370 acc:0.7675 acc1:0.3870 mse:4627480 Test loss:0.9630 acc:0.7807 acc1:0.4368 mse:151817536\n",
      "\n",
      "2020-10-30 08:41:46\n",
      "[7, 6, 17, 14, 15, 46, 23, 19, 18, 17]\n",
      "[9, 6, 17, 12, 14, 54, 24, 18, 12, 10]\n",
      "###### 829 batch Train loss:0.5762 acc:0.8058 acc1:0.3625 mse:8361566 Test loss:1.0006 acc:0.7813 acc1:0.4345 mse:163074176\n",
      "\n",
      "2020-10-30 08:41:48\n",
      "[10, 3, 7, 4, 8, 14, 10, 3, 5, 2]\n",
      "[5, 5, 7, 8, 12, 11, 7, 4, 2, 1]\n",
      "###### 830 batch Train loss:1.5940 acc:0.7764 acc1:0.4784 mse:60793700 Test loss:0.9749 acc:0.7811 acc1:0.4337 mse:152092704\n",
      "\n",
      "2020-10-30 08:41:51\n",
      "[6, 15, 30, 32, 33, 44, 34, 13, 12, 6]\n",
      "[8, 15, 45, 38, 40, 49, 31, 14, 11, 9]\n",
      "###### 831 batch Train loss:0.7437 acc:0.7862 acc1:0.4096 mse:13490826 Test loss:0.9538 acc:0.7800 acc1:0.4310 mse:142809376\n",
      "\n",
      "2020-10-30 08:41:53\n",
      "[14, 18, 39, 21, 24, 76, 62, 38, 30, 72]\n",
      "[14, 11, 33, 20, 24, 76, 43, 25, 29, 25]\n",
      "###### 832 batch Train loss:0.8953 acc:0.7868 acc1:0.4764 mse:26156214 Test loss:0.9435 acc:0.7774 acc1:0.4254 mse:136185472\n",
      "\n",
      "2020-10-30 08:41:56\n",
      "[25, 36, 106, 85, 123, 195, 209, 111, 84, 103]\n",
      "[27, 37, 111, 68, 126, 196, 184, 108, 105, 114]\n",
      "###### 833 batch Train loss:0.8540 acc:0.7883 acc1:0.4660 mse:20761354 Test loss:0.9544 acc:0.7731 acc1:0.4157 mse:135801136\n",
      "\n",
      "2020-10-30 08:41:58\n",
      "[10, 17, 39, 38, 46, 53, 24, 3, 16, 9]\n",
      "[9, 15, 45, 37, 38, 49, 31, 15, 12, 10]\n",
      "###### 834 batch Train loss:0.9313 acc:0.7427 acc1:0.4311 mse:13466638 Test loss:0.9574 acc:0.7709 acc1:0.4111 mse:135626768\n",
      "\n",
      "2020-10-30 08:42:01\n",
      "[5, 8, 24, 10, 16, 38, 24, 8, 9, 9]\n",
      "[11, 6, 17, 13, 16, 43, 26, 21, 11, 11]\n",
      "###### 835 batch Train loss:0.8714 acc:0.7767 acc1:0.4628 mse:15897348 Test loss:0.9559 acc:0.7697 acc1:0.4093 mse:133909808\n",
      "\n",
      "2020-10-30 08:42:03\n",
      "[13, 15, 22, 15, 16, 19, 5, 8, 7, 4]\n",
      "[8, 9, 16, 12, 14, 22, 7, 3, 4, 2]\n",
      "###### 836 batch Train loss:0.5685 acc:0.8527 acc1:0.4892 mse:3670775 Test loss:0.9643 acc:0.7675 acc1:0.4043 mse:135017632\n",
      "\n",
      "2020-10-30 08:42:07\n",
      "[10, 15, 42, 37, 40, 45, 39, 16, 25, 9]\n",
      "[10, 15, 43, 36, 35, 49, 31, 16, 14, 10]\n",
      "###### 837 batch Train loss:1.4866 acc:0.7635 acc1:0.5239 mse:39493708 Test loss:0.9554 acc:0.7645 acc1:0.4001 mse:129004768\n",
      "\n",
      "2020-10-30 08:42:09\n",
      "[15, 16, 45, 22, 20, 96, 43, 38, 33, 32]\n",
      "[12, 14, 40, 23, 32, 82, 68, 33, 35, 27]\n",
      "###### 838 batch Train loss:1.1811 acc:0.7388 acc1:0.4725 mse:31807072 Test loss:0.9147 acc:0.7687 acc1:0.4114 mse:119939760\n",
      "\n",
      "2020-10-30 08:42:12\n",
      "[4, 2, 6, 8, 2, 10, 7, 22, 18, 10]\n",
      "[5, 3, 7, 7, 5, 17, 10, 14, 11, 8]\n",
      "###### 839 batch Train loss:0.8385 acc:0.7690 acc1:0.4418 mse:13187730 Test loss:0.9043 acc:0.7703 acc1:0.4155 mse:118621144\n",
      "\n",
      "2020-10-30 08:42:14\n",
      "[4, 6, 5, 4, 9, 4, 14, 1, 0, 0]\n",
      "[2, 5, 3, 3, 4, 5, 5, 4, 2, 1]\n",
      "###### 840 batch Train loss:0.8689 acc:0.7867 acc1:0.5091 mse:16710387 Test loss:0.9064 acc:0.7682 acc1:0.4119 mse:118821264\n",
      "\n",
      "2020-10-30 08:42:17\n",
      "[11, 6, 14, 18, 11, 31, 13, 6, 10, 9]\n",
      "[14, 8, 15, 16, 18, 31, 14, 9, 10, 9]\n",
      "###### 841 batch Train loss:0.9646 acc:0.7295 acc1:0.4486 mse:26254810 Test loss:0.9042 acc:0.7691 acc1:0.4134 mse:118262040\n",
      "\n",
      "2020-10-30 08:42:19\n",
      "[4, 11, 16, 14, 20, 38, 29, 17, 20, 9]\n",
      "[10, 8, 12, 10, 15, 37, 23, 20, 12, 8]\n",
      "###### 842 batch Train loss:0.6754 acc:0.7765 acc1:0.4404 mse:7843292 Test loss:0.9003 acc:0.7725 acc1:0.4195 mse:119070528\n",
      "\n",
      "2020-10-30 08:42:22\n",
      "[4, 4, 11, 5, 7, 13, 11, 2, 1, 2]\n",
      "[4, 6, 6, 7, 10, 12, 7, 5, 3, 1]\n",
      "###### 843 batch Train loss:0.6524 acc:0.7708 acc1:0.4444 mse:4660784 Test loss:0.9016 acc:0.7758 acc1:0.4252 mse:121736768\n",
      "\n",
      "2020-10-30 08:42:24\n",
      "[9, 15, 13, 23, 32, 35, 25, 13, 24, 16]\n",
      "[11, 11, 21, 24, 31, 41, 20, 9, 14, 11]\n",
      "###### 844 batch Train loss:0.6829 acc:0.7737 acc1:0.4821 mse:6008322 Test loss:0.9075 acc:0.7775 acc1:0.4275 mse:124588544\n",
      "\n",
      "2020-10-30 08:42:27\n",
      "[4, 4, 8, 13, 13, 7, 7, 3, 7, 3]\n",
      "[2, 5, 3, 3, 5, 6, 6, 4, 2, 1]\n",
      "###### 845 batch Train loss:0.6866 acc:0.7783 acc1:0.4315 mse:5053835 Test loss:0.9152 acc:0.7782 acc1:0.4280 mse:127937664\n",
      "\n",
      "2020-10-30 08:42:29\n",
      "[4, 9, 11, 9, 12, 35, 28, 14, 11, 7]\n",
      "[8, 8, 11, 12, 15, 39, 23, 13, 12, 9]\n",
      "###### 846 batch Train loss:0.8240 acc:0.7574 acc1:0.4415 mse:8390070 Test loss:0.9200 acc:0.7802 acc1:0.4313 mse:131548808\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-30 08:42:32\n",
      "[5, 3, 18, 14, 10, 34, 10, 6, 6, 3]\n",
      "[8, 11, 18, 12, 18, 22, 11, 7, 6, 4]\n",
      "###### 847 batch Train loss:0.6652 acc:0.7676 acc1:0.4372 mse:6259726 Test loss:0.9331 acc:0.7821 acc1:0.4345 mse:137205904\n",
      "\n",
      "2020-10-30 08:42:34\n",
      "[10, 9, 22, 11, 11, 105, 22, 23, 12, 9]\n",
      "[8, 7, 15, 10, 13, 51, 22, 17, 11, 8]\n",
      "###### 848 batch Train loss:0.9743 acc:0.7912 acc1:0.4883 mse:23028994 Test loss:0.9377 acc:0.7824 acc1:0.4356 mse:137038784\n",
      "\n",
      "2020-10-30 08:42:37\n",
      "[17, 4, 14, 14, 23, 55, 20, 19, 19, 8]\n",
      "[8, 7, 15, 11, 14, 52, 24, 17, 12, 10]\n",
      "###### 849 batch Train loss:1.3627 acc:0.7785 acc1:0.5075 mse:46413496 Test loss:0.9228 acc:0.7796 acc1:0.4315 mse:128762352\n",
      "\n",
      "2020-10-30 08:42:39\n",
      "[14, 7, 23, 17, 9, 40, 38, 22, 14, 12]\n",
      "[10, 8, 14, 11, 14, 39, 27, 16, 11, 11]\n",
      "###### 850 batch Train loss:0.8581 acc:0.7704 acc1:0.4435 mse:13197978 Test loss:0.9374 acc:0.7734 acc1:0.4196 mse:127505520\n",
      "\n",
      "2020-10-30 08:42:42\n",
      "[15, 19, 42, 36, 26, 62, 31, 10, 10, 10]\n",
      "[8, 16, 39, 33, 34, 46, 30, 12, 13, 10]\n",
      "###### 851 batch Train loss:0.9617 acc:0.7918 acc1:0.4295 mse:20007630 Test loss:0.9418 acc:0.7677 acc1:0.4087 mse:125321232\n",
      "\n",
      "2020-10-30 08:42:44\n",
      "[5, 11, 13, 10, 17, 17, 9, 3, 7, 7]\n",
      "[9, 10, 15, 11, 16, 23, 12, 8, 7, 5]\n",
      "###### 852 batch Train loss:1.0081 acc:0.7790 acc1:0.4752 mse:26443054 Test loss:0.9225 acc:0.7672 acc1:0.4093 mse:118432768\n",
      "\n",
      "2020-10-30 08:42:47\n",
      "[15, 14, 36, 17, 33, 95, 58, 29, 79, 23]\n",
      "[17, 21, 54, 28, 44, 103, 83, 45, 40, 36]\n",
      "###### 853 batch Train loss:1.0865 acc:0.7265 acc1:0.4173 mse:14213594 Test loss:0.8843 acc:0.7719 acc1:0.4208 mse:110027312\n",
      "\n",
      "2020-10-30 08:42:50\n",
      "[7, 11, 12, 8, 21, 27, 17, 11, 13, 7]\n",
      "[7, 9, 11, 11, 14, 37, 24, 12, 11, 9]\n",
      "###### 854 batch Train loss:0.8052 acc:0.7536 acc1:0.4620 mse:11666573 Test loss:0.8821 acc:0.7747 acc1:0.4268 mse:110393440\n",
      "\n",
      "2020-10-30 08:42:52\n",
      "[8, 10, 13, 17, 12, 44, 33, 17, 13, 11]\n",
      "[11, 8, 13, 11, 16, 45, 29, 21, 14, 11]\n",
      "###### 855 batch Train loss:0.5827 acc:0.7750 acc1:0.4439 mse:3794848 Test loss:0.9044 acc:0.7762 acc1:0.4288 mse:117615984\n",
      "\n",
      "2020-10-30 08:42:55\n",
      "[12, 8, 17, 19, 23, 35, 39, 20, 14, 15]\n",
      "[8, 6, 15, 11, 15, 39, 28, 15, 10, 11]\n",
      "###### 856 batch Train loss:0.7777 acc:0.7598 acc1:0.4533 mse:6270424 Test loss:0.9264 acc:0.7767 acc1:0.4286 mse:125634752\n",
      "\n",
      "2020-10-30 08:42:57\n",
      "[2, 6, 4, 1, 2, 2, 4, 2, 1, 4]\n",
      "[1, 3, 3, 2, 2, 8, 6, 4, 2, 2]\n",
      "###### 857 batch Train loss:0.6612 acc:0.7782 acc1:0.4514 mse:8108780 Test loss:0.9451 acc:0.7780 acc1:0.4298 mse:133113216\n",
      "\n",
      "2020-10-30 08:43:00\n",
      "[2, 3, 1, 1, 3, 3, 11, 2, 4, 4]\n",
      "[1, 3, 3, 2, 3, 8, 6, 4, 2, 2]\n",
      "###### 858 batch Train loss:0.7961 acc:0.8273 acc1:0.4687 mse:24456804 Test loss:0.9455 acc:0.7793 acc1:0.4317 mse:133507840\n",
      "\n",
      "2020-10-30 08:43:02\n",
      "[16, 10, 29, 16, 18, 86, 53, 41, 35, 30]\n",
      "[12, 9, 17, 11, 15, 45, 29, 24, 19, 16]\n",
      "###### 859 batch Train loss:0.9970 acc:0.7911 acc1:0.4728 mse:20072228 Test loss:0.9285 acc:0.7797 acc1:0.4332 mse:127574152\n",
      "\n",
      "2020-10-30 08:43:04\n",
      "[30, 41, 99, 82, 134, 202, 228, 92, 115, 102]\n",
      "[26, 31, 96, 55, 93, 144, 157, 93, 75, 83]\n",
      "###### 860 batch Train loss:0.8814 acc:0.7905 acc1:0.4343 mse:23460988 Test loss:0.9060 acc:0.7809 acc1:0.4358 mse:120864616\n",
      "\n",
      "2020-10-30 08:43:07\n",
      "[6, 4, 6, 9, 14, 13, 4, 4, 3, 1]\n",
      "[5, 6, 8, 9, 10, 11, 11, 4, 3, 3]\n",
      "###### 861 batch Train loss:0.9954 acc:0.7609 acc1:0.4761 mse:19114662 Test loss:0.8945 acc:0.7802 acc1:0.4348 mse:117538144\n",
      "\n",
      "2020-10-30 08:43:10\n",
      "[11, 20, 47, 40, 35, 45, 29, 16, 7, 10]\n",
      "[8, 16, 42, 35, 36, 47, 33, 13, 12, 10]\n",
      "###### 862 batch Train loss:0.7714 acc:0.7851 acc1:0.4650 mse:13144568 Test loss:0.9034 acc:0.7770 acc1:0.4285 mse:119741912\n",
      "\n",
      "2020-10-30 08:43:12\n",
      "[7, 8, 17, 12, 13, 42, 26, 20, 10, 8]\n",
      "[7, 8, 13, 12, 15, 34, 25, 11, 11, 9]\n",
      "###### 863 batch Train loss:0.8225 acc:0.7877 acc1:0.4512 mse:18450168 Test loss:0.9111 acc:0.7762 acc1:0.4268 mse:121461584\n",
      "\n",
      "2020-10-30 08:43:14\n",
      "[17, 12, 32, 16, 28, 79, 36, 43, 32, 27]\n",
      "[17, 17, 52, 31, 47, 107, 88, 49, 44, 41]\n",
      "###### 864 batch Train loss:1.3046 acc:0.7575 acc1:0.4669 mse:27251018 Test loss:0.8889 acc:0.7788 acc1:0.4339 mse:114817824\n",
      "\n",
      "2020-10-30 08:43:17\n",
      "[35, 36, 111, 76, 138, 228, 172, 111, 103, 105]\n",
      "[32, 35, 118, 73, 135, 238, 211, 119, 116, 129]\n",
      "###### 865 batch Train loss:0.9390 acc:0.7613 acc1:0.4746 mse:20703604 Test loss:0.8723 acc:0.7799 acc1:0.4378 mse:109908200\n",
      "\n",
      "2020-10-30 08:43:19\n",
      "[4, 3, 5, 4, 7, 17, 10, 23, 18, 9]\n",
      "[6, 2, 7, 8, 6, 20, 12, 17, 18, 11]\n",
      "###### 866 batch Train loss:0.7251 acc:0.8221 acc1:0.4048 mse:8335420 Test loss:0.8633 acc:0.7817 acc1:0.4416 mse:108824264\n",
      "\n",
      "2020-10-30 08:43:22\n",
      "[24, 7, 16, 31, 47, 132, 57, 89, 73, 83]\n",
      "[17, 5, 14, 17, 24, 43, 24, 31, 41, 44]\n",
      "###### 867 batch Train loss:1.2474 acc:0.7474 acc1:0.5378 mse:4343468 Test loss:0.8721 acc:0.7757 acc1:0.4309 mse:109382648\n",
      "\n",
      "2020-10-30 08:43:25\n",
      "[12, 8, 45, 41, 54, 77, 50, 17, 12, 18]\n",
      "[12, 12, 41, 42, 47, 60, 39, 13, 15, 16]\n",
      "###### 868 batch Train loss:1.2641 acc:0.7584 acc1:0.5042 mse:34376332 Test loss:0.8941 acc:0.7676 acc1:0.4158 mse:110902600\n",
      "\n",
      "2020-10-30 08:43:28\n",
      "[6, 1, 3, 7, 8, 13, 3, 22, 12, 8]\n",
      "[5, 2, 6, 8, 7, 20, 12, 16, 13, 8]\n",
      "###### 869 batch Train loss:0.9487 acc:0.7483 acc1:0.4658 mse:16153605 Test loss:0.9250 acc:0.7585 acc1:0.3976 mse:112857256\n",
      "\n",
      "2020-10-30 08:43:31\n",
      "[15, 6, 11, 7, 20, 30, 17, 6, 10, 13]\n",
      "[14, 8, 14, 19, 20, 32, 16, 7, 9, 10]\n",
      "###### 870 batch Train loss:0.6283 acc:0.7694 acc1:0.3338 mse:4470500 Test loss:0.9249 acc:0.7602 acc1:0.3998 mse:113545288\n",
      "\n",
      "2020-10-30 08:43:33\n",
      "[13, 7, 10, 11, 8, 29, 13, 9, 9, 12]\n",
      "[14, 8, 14, 19, 19, 32, 16, 8, 10, 10]\n",
      "###### 871 batch Train loss:0.9620 acc:0.7280 acc1:0.4079 mse:20238912 Test loss:0.9013 acc:0.7683 acc1:0.4143 mse:111356320\n",
      "\n",
      "2020-10-30 08:43:35\n",
      "[14, 11, 13, 11, 15, 46, 27, 7, 13, 18]\n",
      "[10, 7, 16, 13, 16, 39, 25, 15, 9, 11]\n",
      "###### 872 batch Train loss:0.9325 acc:0.7777 acc1:0.4943 mse:18847806 Test loss:0.8843 acc:0.7736 acc1:0.4233 mse:108982264\n",
      "\n",
      "2020-10-30 08:43:38\n",
      "[9, 15, 15, 13, 27, 76, 16, 6, 26, 11]\n",
      "[10, 9, 20, 24, 30, 38, 19, 10, 11, 11]\n",
      "###### 873 batch Train loss:0.5767 acc:0.7778 acc1:0.3859 mse:3374322 Test loss:0.8757 acc:0.7784 acc1:0.4303 mse:108731384\n",
      "\n",
      "2020-10-30 08:43:40\n",
      "[10, 10, 40, 53, 50, 55, 41, 12, 17, 21]\n",
      "[13, 12, 45, 45, 54, 64, 41, 14, 16, 18]\n",
      "###### 874 batch Train loss:0.9415 acc:0.7589 acc1:0.4784 mse:15852433 Test loss:0.8724 acc:0.7813 acc1:0.4347 mse:108805224\n",
      "\n",
      "2020-10-30 08:43:43\n",
      "[47, 20, 98, 40, 149, 249, 162, 113, 133, 173]\n",
      "[51, 18, 70, 62, 124, 255, 147, 114, 139, 175]\n",
      "###### 875 batch Train loss:0.7735 acc:0.7781 acc1:0.4526 mse:10608237 Test loss:0.8777 acc:0.7825 acc1:0.4356 mse:110071440\n",
      "\n",
      "2020-10-30 08:43:46\n",
      "[6, 14, 11, 18, 13, 44, 17, 10, 9, 7]\n",
      "[6, 6, 11, 10, 13, 36, 23, 11, 8, 7]\n",
      "###### 876 batch Train loss:0.8007 acc:0.7728 acc1:0.4829 mse:16385266 Test loss:0.8858 acc:0.7830 acc1:0.4355 mse:111402256\n",
      "\n",
      "2020-10-30 08:43:48\n",
      "[6, 9, 5, 17, 26, 38, 29, 13, 13, 10]\n",
      "[8, 7, 13, 14, 15, 47, 26, 12, 11, 10]\n",
      "###### 877 batch Train loss:0.8309 acc:0.7657 acc1:0.4676 mse:9458321 Test loss:0.8876 acc:0.7838 acc1:0.4369 mse:111590656\n",
      "\n",
      "2020-10-30 08:43:50\n",
      "[24, 7, 16, 31, 47, 132, 57, 89, 73, 83]\n",
      "[16, 5, 14, 17, 23, 28, 29, 34, 40, 39]\n",
      "###### 878 batch Train loss:0.8306 acc:0.7910 acc1:0.4911 mse:14731716 Test loss:0.8837 acc:0.7845 acc1:0.4387 mse:110571936\n",
      "\n",
      "2020-10-30 08:43:53\n",
      "[12, 16, 45, 40, 52, 44, 39, 14, 15, 16]\n",
      "[11, 11, 32, 34, 38, 55, 30, 12, 14, 13]\n",
      "###### 879 batch Train loss:1.1998 acc:0.7776 acc1:0.4822 mse:22387752 Test loss:0.8692 acc:0.7832 acc1:0.4377 mse:106672176\n",
      "\n",
      "2020-10-30 08:43:55\n",
      "[10, 15, 42, 37, 40, 45, 39, 16, 25, 9]\n",
      "[9, 16, 44, 40, 38, 52, 36, 14, 14, 11]\n",
      "###### 880 batch Train loss:0.7171 acc:0.7992 acc1:0.4796 mse:11902547 Test loss:0.8717 acc:0.7801 acc1:0.4323 mse:105945008\n",
      "\n",
      "2020-10-30 08:43:58\n",
      "[7, 8, 17, 12, 13, 42, 26, 20, 10, 8]\n",
      "[7, 8, 12, 12, 14, 33, 26, 12, 11, 9]\n",
      "###### 881 batch Train loss:0.7432 acc:0.7977 acc1:0.4854 mse:8386746 Test loss:0.8825 acc:0.7763 acc1:0.4250 mse:107065128\n",
      "\n",
      "2020-10-30 08:44:00\n",
      "[6, 2, 1, 9, 8, 6, 8, 0, 2, 4]\n",
      "[3, 5, 5, 5, 7, 7, 8, 3, 1, 1]\n",
      "###### 882 batch Train loss:0.9009 acc:0.7707 acc1:0.4907 mse:14269864 Test loss:0.8944 acc:0.7714 acc1:0.4156 mse:107051624\n",
      "\n",
      "2020-10-30 08:44:03\n",
      "[10, 3, 7, 4, 8, 14, 10, 3, 5, 2]\n",
      "[4, 6, 7, 8, 11, 13, 8, 5, 4, 2]\n",
      "###### 883 batch Train loss:0.7915 acc:0.8318 acc1:0.4926 mse:12317978 Test loss:0.8996 acc:0.7670 acc1:0.4080 mse:105397296\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-30 08:44:05\n",
      "[42, 29, 108, 77, 133, 234, 205, 111, 96, 96]\n",
      "[27, 35, 103, 70, 125, 176, 201, 105, 99, 106]\n",
      "###### 884 batch Train loss:0.9455 acc:0.7398 acc1:0.3827 mse:18255646 Test loss:0.8732 acc:0.7715 acc1:0.4189 mse:101167376\n",
      "\n",
      "2020-10-30 08:44:08\n",
      "[2, 3, 12, 9, 11, 23, 11, 6, 2, 5]\n",
      "[4, 7, 8, 9, 11, 14, 8, 4, 4, 2]\n",
      "###### 885 batch Train loss:0.6723 acc:0.8040 acc1:0.4654 mse:13801006 Test loss:0.8590 acc:0.7756 acc1:0.4275 mse:99748584\n",
      "\n",
      "2020-10-30 08:44:10\n",
      "[10, 11, 14, 12, 18, 37, 33, 21, 15, 12]\n",
      "[11, 8, 16, 11, 14, 39, 28, 17, 11, 12]\n",
      "###### 886 batch Train loss:0.5903 acc:0.7789 acc1:0.4593 mse:4496548 Test loss:0.8595 acc:0.7781 acc1:0.4320 mse:101153056\n",
      "\n",
      "2020-10-30 08:44:13\n",
      "[21, 11, 19, 17, 17, 33, 11, 9, 10, 9]\n",
      "[12, 9, 14, 15, 16, 31, 16, 6, 10, 10]\n",
      "###### 887 batch Train loss:0.6165 acc:0.7817 acc1:0.4512 mse:5505445 Test loss:0.8649 acc:0.7808 acc1:0.4363 mse:103814856\n",
      "\n",
      "2020-10-30 08:44:15\n",
      "[46, 17, 86, 53, 140, 282, 181, 113, 153, 177]\n",
      "[42, 18, 80, 63, 143, 262, 161, 115, 144, 170]\n",
      "###### 888 batch Train loss:0.9796 acc:0.7576 acc1:0.4645 mse:16852392 Test loss:0.8665 acc:0.7836 acc1:0.4414 mse:105036264\n",
      "\n",
      "2020-10-30 08:44:18\n",
      "[7, 9, 24, 11, 21, 32, 14, 12, 14, 10]\n",
      "[9, 10, 20, 25, 30, 46, 25, 10, 15, 13]\n",
      "###### 889 batch Train loss:0.7196 acc:0.7824 acc1:0.4313 mse:9272388 Test loss:0.8718 acc:0.7868 acc1:0.4468 mse:107069696\n",
      "\n",
      "2020-10-30 08:44:20\n",
      "[13, 10, 13, 22, 18, 26, 14, 4, 4, 4]\n",
      "[5, 9, 12, 10, 12, 23, 6, 3, 5, 3]\n",
      "###### 890 batch Train loss:0.8521 acc:0.7806 acc1:0.4949 mse:11582690 Test loss:0.8740 acc:0.7880 acc1:0.4488 mse:107226080\n",
      "\n",
      "2020-10-30 08:44:23\n",
      "[32, 5, 30, 37, 52, 103, 54, 61, 74, 79]\n",
      "[21, 6, 20, 22, 44, 102, 42, 52, 69, 74]\n",
      "###### 891 batch Train loss:1.1437 acc:0.7506 acc1:0.4944 mse:18751106 Test loss:0.8683 acc:0.7882 acc1:0.4498 mse:104692576\n",
      "\n",
      "2020-10-30 08:44:25\n",
      "[0, 2, 0, 0, 0, 1, 0, 0, 1, 0]\n",
      "[1, 2, 3, 3, 1, 10, 5, 5, 4, 3]\n",
      "###### 892 batch Train loss:0.8190 acc:0.8030 acc1:0.5112 mse:11193739 Test loss:0.8599 acc:0.7870 acc1:0.4487 mse:101076608\n",
      "\n",
      "2020-10-30 08:44:28\n",
      "[6, 4, 6, 9, 14, 13, 4, 4, 3, 1]\n",
      "[4, 6, 7, 8, 9, 13, 6, 5, 5, 3]\n",
      "###### 893 batch Train loss:0.8041 acc:0.7801 acc1:0.4833 mse:11946154 Test loss:0.8584 acc:0.7846 acc1:0.4453 mse:98844064\n",
      "\n",
      "2020-10-30 08:44:30\n",
      "[10, 5, 11, 10, 29, 62, 39, 19, 11, 5]\n",
      "[8, 6, 18, 12, 13, 48, 22, 18, 11, 8]\n",
      "###### 894 batch Train loss:1.2579 acc:0.7815 acc1:0.5033 mse:26742972 Test loss:0.8601 acc:0.7779 acc1:0.4342 mse:95664816\n",
      "\n",
      "2020-10-30 08:44:33\n",
      "[1, 2, 0, 0, 0, 0, 0, 1, 0, 0]\n",
      "[2, 2, 3, 3, 1, 9, 4, 5, 4, 3]\n",
      "###### 895 batch Train loss:0.9168 acc:0.8077 acc1:0.5022 mse:25952460 Test loss:0.8850 acc:0.7682 acc1:0.4154 mse:95168728\n",
      "\n",
      "2020-10-30 08:44:35\n",
      "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[2, 1, 3, 3, 2, 10, 6, 7, 4, 2]\n",
      "###### 896 batch Train loss:0.6738 acc:0.8077 acc1:0.4259 mse:10179356 Test loss:0.9046 acc:0.7631 acc1:0.4046 mse:95357968\n",
      "\n",
      "2020-10-30 08:44:38\n",
      "[54, 21, 87, 59, 142, 245, 167, 123, 135, 156]\n",
      "[49, 22, 95, 69, 155, 299, 182, 128, 170, 179]\n",
      "###### 897 batch Train loss:0.9414 acc:0.7824 acc1:0.5041 mse:15390694 Test loss:0.9148 acc:0.7596 acc1:0.3979 mse:94750824\n",
      "\n",
      "2020-10-30 08:44:40\n",
      "[34, 11, 23, 32, 41, 124, 55, 73, 86, 86]\n",
      "[30, 5, 34, 34, 61, 139, 61, 74, 101, 99]\n",
      "###### 898 batch Train loss:0.8246 acc:0.7236 acc1:0.4194 mse:2193890 Test loss:0.8838 acc:0.7671 acc1:0.4139 mse:92159632\n",
      "\n",
      "2020-10-30 08:44:44\n",
      "[9, 1, 3, 7, 8, 15, 4, 24, 16, 9]\n",
      "[5, 2, 6, 7, 6, 16, 11, 19, 19, 7]\n",
      "###### 899 batch Train loss:1.1131 acc:0.7726 acc1:0.4797 mse:24177124 Test loss:0.8519 acc:0.7767 acc1:0.4337 mse:90652848\n",
      "\n",
      "2020-10-30 08:44:46\n",
      "[30, 41, 99, 82, 134, 202, 228, 92, 115, 102]\n",
      "[30, 34, 108, 72, 132, 196, 201, 107, 108, 103]\n",
      "###### 900 batch Train loss:1.2136 acc:0.7511 acc1:0.5317 mse:24402836 Test loss:0.8466 acc:0.7800 acc1:0.4399 mse:90960264\n",
      "\n",
      "2020-10-30 08:44:49\n",
      "[5, 7, 7, 12, 10, 19, 14, 7, 4, 3]\n",
      "[5, 7, 7, 8, 10, 10, 6, 1, 3, 1]\n",
      "###### 901 batch Train loss:0.8259 acc:0.7654 acc1:0.4827 mse:9184785 Test loss:0.8481 acc:0.7812 acc1:0.4419 mse:91698304\n",
      "\n",
      "2020-10-30 08:44:52\n",
      "[4, 1, 6, 10, 6, 21, 5, 22, 16, 13]\n",
      "[5, 3, 6, 6, 4, 14, 9, 13, 11, 7]\n",
      "###### 902 batch Train loss:0.8061 acc:0.7846 acc1:0.4734 mse:13553936 Test loss:0.8495 acc:0.7821 acc1:0.4425 mse:91245864\n",
      "\n",
      "2020-10-30 08:44:54\n",
      "[14, 6, 14, 4, 13, 32, 20, 13, 20, 9]\n",
      "[14, 9, 13, 16, 14, 28, 13, 6, 9, 8]\n",
      "###### 903 batch Train loss:0.6336 acc:0.7707 acc1:0.4438 mse:5339312 Test loss:0.8553 acc:0.7838 acc1:0.4439 mse:92468120\n",
      "\n",
      "2020-10-30 08:44:56\n",
      "[4, 22, 47, 30, 35, 70, 36, 15, 11, 13]\n",
      "[9, 15, 38, 35, 31, 43, 30, 12, 12, 9]\n",
      "###### 904 batch Train loss:0.7282 acc:0.7893 acc1:0.4859 mse:9161283 Test loss:0.8597 acc:0.7841 acc1:0.4429 mse:92989936\n",
      "\n",
      "2020-10-30 08:44:59\n",
      "[6, 14, 11, 18, 13, 44, 17, 10, 9, 7]\n",
      "[6, 7, 9, 10, 11, 28, 22, 11, 9, 7]\n",
      "###### 905 batch Train loss:0.6075 acc:0.7744 acc1:0.4438 mse:5034049 Test loss:0.8653 acc:0.7847 acc1:0.4423 mse:94348704\n",
      "\n",
      "2020-10-30 08:45:01\n",
      "[4, 1, 3, 7, 5, 16, 7, 20, 16, 10]\n",
      "[5, 3, 6, 6, 4, 14, 9, 13, 10, 8]\n",
      "###### 906 batch Train loss:0.6455 acc:0.7900 acc1:0.4531 mse:6811609 Test loss:0.8685 acc:0.7856 acc1:0.4426 mse:95738552\n",
      "\n",
      "2020-10-30 08:45:04\n",
      "[8, 7, 3, 9, 12, 16, 6, 3, 4, 6]\n",
      "[5, 6, 6, 8, 11, 10, 8, 4, 3, 2]\n",
      "###### 907 batch Train loss:0.8190 acc:0.7801 acc1:0.4901 mse:14470889 Test loss:0.8690 acc:0.7864 acc1:0.4433 mse:96158120\n",
      "\n",
      "2020-10-30 08:45:06\n",
      "[2, 7, 8, 8, 8, 7, 7, 5, 1, 3]\n",
      "[5, 6, 6, 8, 11, 11, 9, 4, 4, 3]\n",
      "###### 908 batch Train loss:0.5156 acc:0.7970 acc1:0.4583 mse:3262820 Test loss:0.8729 acc:0.7865 acc1:0.4426 mse:97402320\n",
      "\n",
      "2020-10-30 08:45:09\n",
      "[42, 12, 30, 34, 50, 114, 49, 76, 75, 83]\n",
      "[24, 5, 20, 22, 39, 90, 44, 57, 59, 68]\n",
      "###### 909 batch Train loss:0.7846 acc:0.7761 acc1:0.4467 mse:10017851 Test loss:0.8696 acc:0.7862 acc1:0.4419 mse:96967624\n",
      "\n",
      "2020-10-30 08:45:11\n",
      "[10, 9, 14, 27, 27, 46, 40, 19, 11, 12]\n",
      "[12, 8, 12, 12, 17, 42, 30, 21, 15, 12]\n",
      "###### 910 batch Train loss:0.8228 acc:0.7869 acc1:0.4634 mse:8454813 Test loss:0.8607 acc:0.7854 acc1:0.4408 mse:95655392\n",
      "\n",
      "2020-10-30 08:45:14\n",
      "[4, 6, 6, 3, 8, 10, 6, 1, 0, 2]\n",
      "[1, 4, 2, 2, 2, 7, 4, 4, 3, 4]\n",
      "###### 911 batch Train loss:0.5640 acc:0.7934 acc1:0.4516 mse:3949546 Test loss:0.8553 acc:0.7844 acc1:0.4398 mse:94640344\n",
      "\n",
      "2020-10-30 08:45:16\n",
      "[28, 6, 24, 34, 51, 122, 44, 68, 76, 86]\n",
      "[18, 5, 15, 14, 21, 59, 24, 44, 41, 44]\n",
      "###### 912 batch Train loss:0.5825 acc:0.8146 acc1:0.4622 mse:4306866 Test loss:0.8574 acc:0.7818 acc1:0.4355 mse:94450536\n",
      "\n",
      "2020-10-30 08:45:19\n",
      "[13, 7, 9, 9, 14, 33, 31, 10, 15, 10]\n",
      "[7, 8, 10, 12, 15, 38, 26, 13, 12, 10]\n",
      "###### 913 batch Train loss:0.7866 acc:0.7859 acc1:0.4829 mse:9374429 Test loss:0.8564 acc:0.7799 acc1:0.4330 mse:93302208\n",
      "\n",
      "2020-10-30 08:45:21\n",
      "[10, 17, 39, 38, 46, 53, 24, 3, 16, 9]\n",
      "[8, 16, 41, 38, 41, 52, 40, 16, 14, 11]\n",
      "###### 914 batch Train loss:1.0286 acc:0.7559 acc1:0.4785 mse:14384304 Test loss:0.8515 acc:0.7797 acc1:0.4343 mse:93018408\n",
      "\n",
      "2020-10-30 08:45:24\n",
      "[20, 7, 12, 33, 23, 27, 22, 11, 16, 11]\n",
      "[9, 10, 22, 24, 31, 40, 23, 11, 15, 13]\n",
      "###### 915 batch Train loss:1.3418 acc:0.7572 acc1:0.5237 mse:24303024 Test loss:0.8585 acc:0.7760 acc1:0.4287 mse:93644824\n",
      "\n",
      "2020-10-30 08:45:26\n",
      "[15, 15, 28, 19, 27, 73, 44, 30, 29, 30]\n",
      "[17, 15, 37, 23, 34, 83, 66, 40, 39, 29]\n",
      "###### 916 batch Train loss:1.0276 acc:0.7587 acc1:0.5073 mse:18142720 Test loss:0.8761 acc:0.7709 acc1:0.4195 mse:96202448\n",
      "\n",
      "2020-10-30 08:45:29\n",
      "[8, 5, 26, 16, 11, 96, 29, 14, 3, 10]\n",
      "[9, 6, 15, 12, 15, 56, 24, 19, 13, 9]\n",
      "###### 917 batch Train loss:0.5077 acc:0.8032 acc1:0.4185 mse:3311162 Test loss:0.8986 acc:0.7668 acc1:0.4112 mse:101446296\n",
      "\n",
      "2020-10-30 08:45:31\n",
      "[6, 2, 1, 9, 8, 6, 8, 0, 2, 4]\n",
      "[3, 4, 6, 4, 7, 7, 8, 5, 2, 2]\n",
      "###### 918 batch Train loss:0.9130 acc:0.7430 acc1:0.4202 mse:13817852 Test loss:0.8857 acc:0.7712 acc1:0.4208 mse:102002704\n",
      "\n",
      "2020-10-30 08:45:33\n",
      "[12, 14, 10, 20, 19, 42, 16, 10, 14, 12]\n",
      "[9, 10, 21, 21, 26, 40, 20, 9, 14, 11]\n",
      "###### 919 batch Train loss:0.8109 acc:0.7569 acc1:0.4334 mse:11365397 Test loss:0.8680 acc:0.7775 acc1:0.4329 mse:101085664\n",
      "\n",
      "2020-10-30 08:45:36\n",
      "[5, 6, 8, 1, 2, 2, 5, 5, 3, 3]\n",
      "[1, 4, 3, 1, 1, 8, 4, 4, 3, 3]\n",
      "###### 920 batch Train loss:0.8420 acc:0.7848 acc1:0.5074 mse:8949006 Test loss:0.8571 acc:0.7797 acc1:0.4369 mse:99079744\n",
      "\n",
      "2020-10-30 08:45:38\n",
      "[2, 3, 3, 2, 1, 2, 4, 0, 0, 0]\n",
      "[1, 4, 3, 1, 2, 8, 4, 4, 2, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### 921 batch Train loss:0.8344 acc:0.7954 acc1:0.4576 mse:20072924 Test loss:0.8460 acc:0.7825 acc1:0.4419 mse:96365888\n",
      "\n",
      "2020-10-30 08:45:41\n",
      "[37, 46, 119, 70, 157, 235, 203, 151, 101, 126]\n",
      "[29, 35, 104, 62, 125, 175, 182, 100, 90, 83]\n",
      "###### 922 batch Train loss:0.6182 acc:0.8535 acc1:0.4709 mse:13372947 Test loss:0.8421 acc:0.7836 acc1:0.4433 mse:94225376\n",
      "\n",
      "2020-10-30 08:45:43\n",
      "[12, 5, 16, 16, 12, 33, 25, 6, 11, 12]\n",
      "[7, 7, 13, 12, 13, 47, 24, 13, 11, 9]\n",
      "###### 923 batch Train loss:0.6099 acc:0.8029 acc1:0.4799 mse:6319896 Test loss:0.8406 acc:0.7846 acc1:0.4445 mse:91829248\n",
      "\n",
      "2020-10-30 08:45:46\n",
      "[1, 6, 6, 1, 3, 5, 2, 0, 0, 7]\n",
      "[1, 3, 3, 2, 2, 8, 4, 3, 2, 2]\n",
      "###### 924 batch Train loss:0.7828 acc:0.7671 acc1:0.4660 mse:9043958 Test loss:0.8424 acc:0.7850 acc1:0.4446 mse:90217672\n",
      "\n",
      "2020-10-30 08:45:48\n",
      "[8, 10, 13, 17, 12, 44, 33, 17, 13, 11]\n",
      "[12, 7, 14, 11, 17, 46, 28, 20, 13, 10]\n",
      "###### 925 batch Train loss:0.9547 acc:0.7717 acc1:0.5014 mse:17309648 Test loss:0.8403 acc:0.7842 acc1:0.4430 mse:87272800\n",
      "\n",
      "2020-10-30 08:45:51\n",
      "[48, 23, 85, 46, 135, 292, 170, 112, 145, 173]\n",
      "[54, 24, 98, 60, 142, 268, 173, 123, 136, 160]\n",
      "###### 926 batch Train loss:0.8787 acc:0.8077 acc1:0.4802 mse:16380744 Test loss:0.8414 acc:0.7823 acc1:0.4392 mse:85464768\n",
      "\n",
      "2020-10-30 08:45:53\n",
      "[14, 8, 16, 26, 34, 23, 15, 10, 11, 8]\n",
      "[9, 9, 18, 20, 23, 38, 19, 8, 12, 10]\n",
      "###### 927 batch Train loss:1.2842 acc:0.7650 acc1:0.5319 mse:28842988 Test loss:0.8465 acc:0.7794 acc1:0.4337 mse:85248408\n",
      "\n",
      "2020-10-30 08:45:56\n",
      "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[2, 1, 3, 3, 2, 11, 6, 5, 3, 3]\n",
      "###### 928 batch Train loss:0.8703 acc:0.8268 acc1:0.5056 mse:10470757 Test loss:0.8585 acc:0.7748 acc1:0.4250 mse:86956848\n",
      "\n",
      "2020-10-30 08:45:58\n",
      "[4, 4, 11, 5, 7, 13, 11, 2, 1, 2]\n",
      "[4, 5, 7, 8, 10, 12, 9, 3, 1, 1]\n",
      "###### 929 batch Train loss:0.6171 acc:0.7774 acc1:0.4561 mse:1480417 Test loss:0.8688 acc:0.7728 acc1:0.4217 mse:88937168\n",
      "\n",
      "2020-10-30 08:46:02\n",
      "[4, 22, 47, 30, 35, 70, 36, 15, 11, 13]\n",
      "[8, 16, 40, 37, 33, 48, 33, 10, 10, 10]\n",
      "###### 930 batch Train loss:1.0156 acc:0.7601 acc1:0.5083 mse:15971163 Test loss:0.8719 acc:0.7734 acc1:0.4239 mse:89713392\n",
      "\n",
      "2020-10-30 08:46:04\n",
      "[10, 11, 14, 12, 18, 37, 33, 21, 15, 12]\n",
      "[11, 8, 18, 12, 14, 42, 30, 17, 9, 13]\n",
      "###### 931 batch Train loss:0.5435 acc:0.7912 acc1:0.4017 mse:3540455 Test loss:0.8760 acc:0.7754 acc1:0.4279 mse:92099520\n",
      "\n",
      "2020-10-30 08:46:07\n",
      "[5, 12, 23, 16, 23, 29, 13, 7, 6, 3]\n",
      "[7, 9, 17, 11, 14, 22, 11, 3, 3, 4]\n",
      "###### 932 batch Train loss:0.7322 acc:0.7771 acc1:0.4181 mse:9505778 Test loss:0.8692 acc:0.7807 acc1:0.4381 mse:92169592\n",
      "\n",
      "2020-10-30 08:46:09\n",
      "[12, 8, 45, 41, 54, 77, 50, 17, 12, 18]\n",
      "[11, 11, 37, 41, 39, 59, 37, 11, 14, 15]\n",
      "###### 933 batch Train loss:0.7846 acc:0.7850 acc1:0.4935 mse:9841326 Test loss:0.8616 acc:0.7838 acc1:0.4438 mse:91119704\n",
      "\n",
      "2020-10-30 08:46:12\n",
      "[1, 4, 2, 1, 2, 4, 3, 0, 2, 2]\n",
      "[1, 3, 2, 3, 2, 8, 6, 4, 2, 2]\n",
      "###### 934 batch Train loss:1.1486 acc:0.7830 acc1:0.5110 mse:28576056 Test loss:0.8469 acc:0.7856 acc1:0.4476 mse:86162896\n",
      "\n",
      "2020-10-30 08:46:14\n",
      "[14, 17, 38, 41, 32, 45, 37, 12, 15, 14]\n",
      "[8, 16, 39, 37, 33, 49, 35, 11, 12, 12]\n",
      "###### 935 batch Train loss:1.0360 acc:0.7715 acc1:0.5076 mse:17981480 Test loss:0.8362 acc:0.7843 acc1:0.4452 mse:81128672\n",
      "\n",
      "2020-10-30 08:46:17\n",
      "[10, 5, 11, 10, 29, 62, 39, 19, 11, 5]\n",
      "[8, 7, 20, 13, 14, 56, 26, 19, 10, 10]\n",
      "###### 936 batch Train loss:0.8520 acc:0.7685 acc1:0.4850 mse:11525148 Test loss:0.8339 acc:0.7819 acc1:0.4405 mse:78873336\n",
      "\n",
      "2020-10-30 08:46:19\n",
      "[9, 15, 30, 15, 29, 72, 52, 39, 41, 29]\n",
      "[15, 14, 35, 26, 29, 93, 55, 35, 35, 33]\n",
      "###### 937 batch Train loss:0.9173 acc:0.8009 acc1:0.5042 mse:17292722 Test loss:0.8280 acc:0.7810 acc1:0.4391 mse:77088864\n",
      "\n",
      "2020-10-30 08:46:22\n",
      "[4, 4, 11, 5, 7, 13, 11, 2, 1, 2]\n",
      "[3, 6, 8, 8, 10, 13, 8, 3, 2, 1]\n",
      "###### 938 batch Train loss:0.6503 acc:0.8395 acc1:0.5060 mse:9239243 Test loss:0.8218 acc:0.7805 acc1:0.4390 mse:75349496\n",
      "\n",
      "2020-10-30 08:46:24\n",
      "[9, 8, 18, 17, 27, 87, 15, 7, 23, 7]\n",
      "[10, 9, 23, 29, 28, 45, 23, 9, 14, 12]\n",
      "###### 939 batch Train loss:0.8309 acc:0.7484 acc1:0.4644 mse:5827086 Test loss:0.8142 acc:0.7820 acc1:0.4429 mse:75147240\n",
      "\n",
      "2020-10-30 08:46:26\n",
      "[7, 8, 10, 9, 13, 35, 27, 13, 5, 6]\n",
      "[7, 7, 13, 14, 14, 48, 28, 14, 11, 11]\n",
      "###### 940 batch Train loss:0.8733 acc:0.7809 acc1:0.4872 mse:12307017 Test loss:0.8101 acc:0.7830 acc1:0.4455 mse:75670240\n",
      "\n",
      "2020-10-30 08:46:29\n",
      "[8, 5, 26, 16, 11, 96, 29, 14, 3, 10]\n",
      "[8, 6, 17, 13, 14, 57, 25, 18, 11, 10]\n",
      "###### 941 batch Train loss:0.5454 acc:0.7857 acc1:0.4327 mse:3549156 Test loss:0.8119 acc:0.7844 acc1:0.4476 mse:77616120\n",
      "\n",
      "2020-10-30 08:46:31\n",
      "[5, 6, 8, 1, 2, 2, 5, 5, 3, 3]\n",
      "[1, 4, 3, 2, 1, 8, 3, 3, 2, 2]\n",
      "###### 942 batch Train loss:0.9441 acc:0.7799 acc1:0.5162 mse:13600978 Test loss:0.8124 acc:0.7843 acc1:0.4474 mse:77766784\n",
      "\n",
      "2020-10-30 08:46:34\n",
      "[6, 6, 17, 17, 20, 32, 32, 13, 11, 11]\n",
      "[10, 7, 16, 12, 16, 41, 27, 18, 10, 11]\n",
      "###### 943 batch Train loss:0.6646 acc:0.7650 acc1:0.4418 mse:4451480 Test loss:0.8153 acc:0.7841 acc1:0.4466 mse:79139536\n",
      "\n",
      "2020-10-30 08:46:36\n",
      "[16, 3, 15, 7, 13, 45, 23, 15, 16, 8]\n",
      "[6, 7, 13, 11, 13, 45, 23, 12, 10, 9]\n",
      "###### 944 batch Train loss:0.6929 acc:0.7895 acc1:0.4890 mse:6862725 Test loss:0.8222 acc:0.7819 acc1:0.4421 mse:80596248\n",
      "\n",
      "2020-10-30 08:46:39\n",
      "[15, 10, 17, 14, 9, 25, 17, 8, 8, 8]\n",
      "[14, 8, 13, 16, 18, 31, 16, 8, 11, 10]\n",
      "###### 945 batch Train loss:0.9248 acc:0.7618 acc1:0.4997 mse:15102562 Test loss:0.8261 acc:0.7803 acc1:0.4391 mse:80579288\n",
      "\n",
      "2020-10-30 08:46:41\n",
      "[13, 12, 42, 56, 50, 79, 38, 13, 15, 19]\n",
      "[13, 13, 46, 47, 51, 64, 45, 15, 18, 17]\n",
      "###### 946 batch Train loss:0.6675 acc:0.8008 acc1:0.4826 mse:5282069 Test loss:0.8313 acc:0.7785 acc1:0.4357 mse:80588032\n",
      "\n",
      "2020-10-30 08:46:44\n",
      "[7, 9, 5, 6, 7, 13, 8, 3, 1, 1]\n",
      "[5, 6, 9, 7, 12, 12, 10, 4, 3, 1]\n",
      "###### 947 batch Train loss:0.8853 acc:0.7664 acc1:0.4936 mse:14871290 Test loss:0.8372 acc:0.7775 acc1:0.4335 mse:80316064\n",
      "\n",
      "2020-10-30 08:46:46\n",
      "[15, 12, 15, 12, 15, 40, 27, 16, 12, 11]\n",
      "[11, 7, 15, 11, 15, 40, 25, 16, 10, 11]\n",
      "###### 948 batch Train loss:0.6437 acc:0.7587 acc1:0.4242 mse:3668485 Test loss:0.8438 acc:0.7787 acc1:0.4348 mse:81685352\n",
      "\n",
      "2020-10-30 08:46:49\n",
      "[14, 7, 23, 17, 9, 40, 38, 22, 14, 12]\n",
      "[11, 8, 15, 11, 15, 38, 25, 16, 10, 12]\n",
      "###### 949 batch Train loss:0.8359 acc:0.7650 acc1:0.5031 mse:12048977 Test loss:0.8444 acc:0.7806 acc1:0.4378 mse:80261240\n",
      "\n",
      "2020-10-30 08:46:51\n",
      "[7, 7, 15, 22, 19, 26, 16, 6, 15, 7]\n",
      "[11, 9, 16, 20, 23, 38, 21, 12, 14, 10]\n",
      "###### 950 batch Train loss:0.9142 acc:0.7772 acc1:0.4609 mse:14071750 Test loss:0.8287 acc:0.7851 acc1:0.4469 mse:76878504\n",
      "\n",
      "2020-10-30 08:46:54\n",
      "[3, 0, 4, 7, 3, 6, 4, 13, 13, 12]\n",
      "[9, 3, 5, 7, 5, 16, 10, 25, 24, 10]\n",
      "###### 951 batch Train loss:0.5757 acc:0.7849 acc1:0.4576 mse:3576236 Test loss:0.8285 acc:0.7879 acc1:0.4516 mse:77130096\n",
      "\n",
      "2020-10-30 08:46:56\n",
      "[10, 17, 39, 38, 46, 53, 24, 3, 16, 9]\n",
      "[9, 16, 37, 36, 35, 47, 36, 14, 12, 10]\n",
      "###### 952 batch Train loss:0.8266 acc:0.8127 acc1:0.4869 mse:10061830 Test loss:0.8206 acc:0.7894 acc1:0.4546 mse:75956760\n",
      "\n",
      "2020-10-30 08:46:59\n",
      "[1, 6, 6, 1, 3, 5, 2, 0, 0, 7]\n",
      "[1, 4, 1, 1, 1, 6, 4, 4, 2, 2]\n",
      "###### 953 batch Train loss:1.1444 acc:0.7860 acc1:0.5230 mse:24379000 Test loss:0.8111 acc:0.7877 acc1:0.4516 mse:73752736\n",
      "\n",
      "2020-10-30 08:47:01\n",
      "[6, 1, 3, 7, 8, 13, 3, 22, 12, 8]\n",
      "[5, 2, 5, 7, 6, 15, 11, 17, 12, 8]\n",
      "###### 954 batch Train loss:0.9434 acc:0.7795 acc1:0.4979 mse:10921752 Test loss:0.8066 acc:0.7842 acc1:0.4453 mse:71646536\n",
      "\n",
      "2020-10-30 08:47:04\n",
      "[16, 9, 54, 51, 54, 59, 43, 5, 16, 16]\n",
      "[12, 13, 37, 44, 44, 57, 36, 13, 15, 15]\n",
      "###### 955 batch Train loss:0.7063 acc:0.7952 acc1:0.4962 mse:6368006 Test loss:0.8179 acc:0.7792 acc1:0.4356 mse:71157104\n",
      "\n",
      "2020-10-30 08:47:06\n",
      "[11, 9, 22, 9, 11, 109, 22, 25, 11, 6]\n",
      "[8, 6, 16, 13, 14, 50, 23, 17, 11, 10]\n",
      "###### 956 batch Train loss:0.7145 acc:0.8362 acc1:0.5088 mse:11935878 Test loss:0.8383 acc:0.7734 acc1:0.4238 mse:72313120\n",
      "\n",
      "2020-10-30 08:47:09\n",
      "[9, 7, 16, 13, 10, 24, 5, 4, 2, 10]\n",
      "[6, 9, 13, 10, 13, 20, 8, 4, 3, 2]\n",
      "###### 957 batch Train loss:0.6263 acc:0.7756 acc1:0.4298 mse:4934510 Test loss:0.8500 acc:0.7717 acc1:0.4195 mse:73814920\n",
      "\n",
      "2020-10-30 08:47:11\n",
      "[8, 7, 3, 9, 12, 16, 6, 3, 4, 6]\n",
      "[5, 7, 6, 8, 11, 11, 8, 3, 3, 2]\n",
      "###### 958 batch Train loss:0.9806 acc:0.7425 acc1:0.4647 mse:9712844 Test loss:0.8237 acc:0.7779 acc1:0.4325 mse:71064104\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-30 08:47:14\n",
      "[2, 3, 12, 9, 11, 23, 11, 6, 2, 5]\n",
      "[4, 6, 6, 8, 11, 11, 7, 4, 3, 2]\n",
      "###### 959 batch Train loss:0.6163 acc:0.8051 acc1:0.4841 mse:6247283 Test loss:0.8048 acc:0.7834 acc1:0.4432 mse:69971344\n",
      "\n",
      "2020-10-30 08:47:16\n",
      "[10, 6, 24, 7, 15, 45, 38, 15, 10, 18]\n",
      "[9, 7, 16, 11, 15, 34, 22, 16, 9, 10]\n",
      "###### 960 batch Train loss:0.3436 acc:0.8675 acc1:0.4370 mse:686760 Test loss:0.8013 acc:0.7868 acc1:0.4490 mse:71416400\n",
      "\n",
      "2020-10-30 08:47:20\n",
      "[17, 12, 32, 16, 28, 79, 36, 43, 32, 27]\n",
      "[16, 15, 39, 29, 38, 83, 61, 39, 36, 31]\n",
      "###### 961 batch Train loss:1.0615 acc:0.7795 acc1:0.5356 mse:18438266 Test loss:0.7951 acc:0.7889 acc1:0.4529 mse:69970192\n",
      "\n",
      "2020-10-30 08:47:22\n",
      "[24, 8, 23, 40, 40, 128, 60, 60, 95, 81]\n",
      "[26, 5, 29, 33, 53, 111, 50, 72, 78, 85]\n",
      "###### 962 batch Train loss:0.6722 acc:0.7814 acc1:0.4867 mse:8986184 Test loss:0.7947 acc:0.7904 acc1:0.4555 mse:69860672\n",
      "\n",
      "2020-10-30 08:47:25\n",
      "[6, 5, 15, 13, 14, 56, 24, 14, 8, 10]\n",
      "[7, 6, 17, 14, 14, 51, 22, 16, 12, 9]\n",
      "###### 963 batch Train loss:0.6600 acc:0.8086 acc1:0.4982 mse:10422161 Test loss:0.8021 acc:0.7902 acc1:0.4546 mse:71028608\n",
      "\n",
      "2020-10-30 08:47:27\n",
      "[21, 12, 38, 23, 35, 106, 60, 26, 31, 23]\n",
      "[16, 15, 38, 28, 36, 96, 68, 39, 38, 32]\n",
      "###### 964 batch Train loss:0.6295 acc:0.7862 acc1:0.4630 mse:5659877 Test loss:0.8122 acc:0.7904 acc1:0.4543 mse:72898464\n",
      "\n",
      "2020-10-30 08:47:30\n",
      "[5, 9, 14, 14, 15, 40, 24, 19, 14, 7]\n",
      "[6, 8, 13, 12, 13, 39, 23, 12, 11, 9]\n",
      "###### 965 batch Train loss:0.9104 acc:0.7777 acc1:0.4882 mse:11225593 Test loss:0.8076 acc:0.7897 acc1:0.4527 mse:70891936\n",
      "\n",
      "2020-10-30 08:47:32\n",
      "[7, 8, 17, 12, 13, 42, 26, 20, 10, 8]\n",
      "[6, 8, 11, 13, 14, 32, 25, 11, 11, 9]\n",
      "###### 966 batch Train loss:0.7142 acc:0.7719 acc1:0.4943 mse:5853821 Test loss:0.8064 acc:0.7881 acc1:0.4497 mse:69633280\n",
      "\n",
      "2020-10-30 08:47:34\n",
      "[0, 8, 12, 4, 7, 5, 9, 1, 2, 3]\n",
      "[3, 6, 4, 5, 7, 6, 7, 1, 2, 2]\n",
      "###### 967 batch Train loss:0.7325 acc:0.7822 acc1:0.5070 mse:6839983 Test loss:0.8103 acc:0.7853 acc1:0.4446 mse:69485536\n",
      "\n",
      "2020-10-30 08:47:37\n",
      "[0, 5, 3, 4, 3, 7, 2, 1, 1, 1]\n",
      "[0, 3, 1, 2, 3, 7, 5, 4, 2, 1]\n",
      "###### 968 batch Train loss:0.8359 acc:0.7879 acc1:0.5046 mse:11433640 Test loss:0.8086 acc:0.7831 acc1:0.4410 mse:67971040\n",
      "\n",
      "2020-10-30 08:47:39\n",
      "[0, 1, 0, 0, 0, 0, 0, 2, 0, 0]\n",
      "[1, 1, 2, 3, 2, 10, 5, 5, 4, 3]\n",
      "###### 969 batch Train loss:0.5045 acc:0.8175 acc1:0.4228 mse:3151096 Test loss:0.8099 acc:0.7823 acc1:0.4397 mse:68229728\n",
      "\n",
      "2020-10-30 08:47:42\n",
      "[8, 7, 13, 17, 27, 25, 23, 9, 5, 14]\n",
      "[6, 8, 10, 11, 13, 33, 23, 11, 10, 8]\n",
      "###### 970 batch Train loss:0.7346 acc:0.8162 acc1:0.5189 mse:7565496 Test loss:0.8102 acc:0.7814 acc1:0.4386 mse:68301896\n",
      "\n",
      "2020-10-30 08:47:44\n",
      "[8, 10, 13, 17, 12, 44, 33, 17, 13, 11]\n",
      "[12, 9, 14, 14, 18, 49, 31, 21, 16, 11]\n",
      "###### 971 batch Train loss:0.7117 acc:0.8123 acc1:0.4803 mse:8798566 Test loss:0.8017 acc:0.7824 acc1:0.4415 mse:66592528\n",
      "\n",
      "2020-10-30 08:47:47\n",
      "[5, 7, 7, 12, 10, 19, 14, 7, 4, 3]\n",
      "[5, 7, 9, 9, 10, 15, 9, 1, 3, 2]\n",
      "###### 972 batch Train loss:0.7223 acc:0.8060 acc1:0.4971 mse:8399139 Test loss:0.7965 acc:0.7826 acc1:0.4428 mse:65787300\n",
      "\n",
      "2020-10-30 08:47:49\n",
      "[1, 6, 6, 1, 3, 5, 2, 0, 0, 7]\n",
      "[0, 4, 3, 2, 2, 7, 4, 3, 2, 2]\n",
      "###### 973 batch Train loss:0.4764 acc:0.8047 acc1:0.4394 mse:2673977 Test loss:0.7992 acc:0.7827 acc1:0.4430 mse:67803360\n",
      "\n",
      "2020-10-30 08:47:52\n",
      "[16, 9, 54, 51, 54, 59, 43, 5, 16, 16]\n",
      "[12, 12, 44, 46, 47, 62, 37, 12, 16, 16]\n",
      "###### 974 batch Train loss:0.8871 acc:0.7733 acc1:0.4967 mse:9986736 Test loss:0.8108 acc:0.7813 acc1:0.4397 mse:71336616\n",
      "\n",
      "2020-10-30 08:47:54\n",
      "[35, 40, 127, 76, 149, 239, 187, 140, 93, 114]\n",
      "[28, 38, 96, 64, 112, 205, 192, 106, 102, 93]\n",
      "###### 975 batch Train loss:0.7117 acc:0.7907 acc1:0.4844 mse:12607365 Test loss:0.8237 acc:0.7805 acc1:0.4368 mse:75354736\n",
      "\n",
      "2020-10-30 08:47:57\n",
      "[16, 3, 15, 7, 13, 45, 23, 15, 16, 8]\n",
      "[6, 8, 14, 11, 13, 42, 23, 12, 10, 9]\n",
      "###### 976 batch Train loss:0.6794 acc:0.8108 acc1:0.4715 mse:10189506 Test loss:0.8229 acc:0.7826 acc1:0.4400 mse:77312456\n",
      "\n",
      "2020-10-30 08:47:59\n",
      "[7, 20, 11, 13, 14, 82, 12, 10, 11, 11]\n",
      "[10, 9, 18, 22, 25, 36, 19, 10, 14, 11]\n",
      "###### 977 batch Train loss:0.7014 acc:0.7823 acc1:0.4599 mse:7518840 Test loss:0.8209 acc:0.7856 acc1:0.4448 mse:77906712\n",
      "\n",
      "2020-10-30 08:48:02\n",
      "[6, 9, 18, 13, 9, 45, 31, 12, 15, 10]\n",
      "[7, 7, 13, 13, 13, 44, 25, 13, 11, 9]\n",
      "###### 978 batch Train loss:0.9529 acc:0.7658 acc1:0.4701 mse:14703580 Test loss:0.8065 acc:0.7898 acc1:0.4527 mse:75069632\n",
      "\n",
      "2020-10-30 08:48:04\n",
      "[11, 11, 19, 12, 17, 45, 27, 28, 15, 11]\n",
      "[11, 8, 14, 12, 17, 45, 27, 18, 13, 11]\n",
      "###### 979 batch Train loss:0.8066 acc:0.7758 acc1:0.4878 mse:11477852 Test loss:0.8057 acc:0.7927 acc1:0.4582 mse:73064352\n",
      "\n",
      "2020-10-30 08:48:07\n",
      "[14, 7, 23, 17, 9, 40, 38, 22, 14, 12]\n",
      "[10, 7, 16, 11, 15, 38, 25, 16, 10, 11]\n",
      "###### 980 batch Train loss:0.6509 acc:0.8242 acc1:0.4855 mse:4817994 Test loss:0.8203 acc:0.7927 acc1:0.4576 mse:73643360\n",
      "\n",
      "2020-10-30 08:48:09\n",
      "[15, 10, 17, 14, 9, 25, 17, 8, 8, 8]\n",
      "[13, 8, 14, 16, 17, 31, 14, 8, 9, 10]\n",
      "###### 981 batch Train loss:0.7683 acc:0.7683 acc1:0.4918 mse:5996726 Test loss:0.8391 acc:0.7913 acc1:0.4546 mse:75732296\n",
      "\n",
      "2020-10-30 08:48:12\n",
      "[46, 17, 86, 53, 140, 282, 181, 113, 153, 177]\n",
      "[44, 18, 69, 52, 114, 234, 127, 105, 116, 133]\n",
      "###### 982 batch Train loss:1.0880 acc:0.7691 acc1:0.5016 mse:18356794 Test loss:0.8339 acc:0.7894 acc1:0.4526 mse:72755816\n",
      "\n",
      "2020-10-30 08:48:14\n",
      "[1, 2, 0, 0, 0, 0, 0, 1, 0, 0]\n",
      "[1, 2, 3, 2, 2, 9, 3, 5, 2, 3]\n",
      "###### 983 batch Train loss:0.8426 acc:0.8154 acc1:0.4980 mse:11342056 Test loss:0.8186 acc:0.7873 acc1:0.4511 mse:68568360\n",
      "\n",
      "2020-10-30 08:48:16\n",
      "[11, 6, 14, 18, 11, 31, 13, 6, 10, 9]\n",
      "[13, 7, 14, 16, 17, 31, 14, 8, 8, 9]\n",
      "###### 984 batch Train loss:1.2161 acc:0.7750 acc1:0.5277 mse:16108114 Test loss:0.8156 acc:0.7806 acc1:0.4406 mse:66925688\n",
      "\n",
      "2020-10-30 08:48:19\n",
      "[17, 9, 15, 8, 16, 39, 24, 15, 11, 13]\n",
      "[8, 9, 16, 14, 15, 46, 27, 15, 12, 11]\n",
      "###### 985 batch Train loss:0.7419 acc:0.7569 acc1:0.4576 mse:6467613 Test loss:0.8212 acc:0.7769 acc1:0.4346 mse:67960608\n",
      "\n",
      "2020-10-30 08:48:21\n",
      "[27, 34, 101, 76, 117, 209, 179, 104, 116, 110]\n",
      "[35, 40, 109, 74, 137, 214, 196, 122, 107, 103]\n",
      "###### 986 batch Train loss:0.9589 acc:0.7807 acc1:0.4799 mse:14969096 Test loss:0.8107 acc:0.7777 acc1:0.4376 mse:65968444\n",
      "\n",
      "2020-10-30 08:48:24\n",
      "[14, 18, 39, 21, 24, 76, 62, 38, 30, 72]\n",
      "[17, 13, 38, 24, 34, 92, 57, 34, 38, 33]\n",
      "###### 987 batch Train loss:0.7501 acc:0.7627 acc1:0.4469 mse:7325360 Test loss:0.8013 acc:0.7804 acc1:0.4428 mse:64873468\n",
      "\n",
      "2020-10-30 08:48:27\n",
      "[22, 6, 13, 10, 15, 35, 28, 18, 8, 13]\n",
      "[11, 6, 19, 12, 17, 40, 29, 18, 10, 12]\n",
      "###### 988 batch Train loss:0.7457 acc:0.7673 acc1:0.4494 mse:6785090 Test loss:0.7928 acc:0.7850 acc1:0.4504 mse:65052740\n",
      "\n",
      "2020-10-30 08:48:29\n",
      "[8, 1, 3, 10, 6, 10, 6, 24, 21, 8]\n",
      "[6, 2, 6, 7, 6, 15, 9, 22, 15, 10]\n",
      "###### 989 batch Train loss:0.7141 acc:0.7916 acc1:0.4754 mse:8247716 Test loss:0.7993 acc:0.7863 acc1:0.4510 mse:67407856\n",
      "\n",
      "2020-10-30 08:48:31\n",
      "[9, 15, 30, 15, 29, 72, 52, 39, 41, 29]\n",
      "[17, 16, 41, 26, 40, 86, 64, 41, 42, 39]\n",
      "###### 990 batch Train loss:0.8206 acc:0.7824 acc1:0.5055 mse:8410225 Test loss:0.8105 acc:0.7856 acc1:0.4481 mse:69939192\n",
      "\n",
      "2020-10-30 08:48:34\n",
      "[32, 5, 30, 37, 52, 103, 54, 61, 74, 79]\n",
      "[32, 5, 29, 29, 53, 131, 55, 69, 85, 102]\n",
      "###### 991 batch Train loss:1.0660 acc:0.7515 acc1:0.4871 mse:3034348 Test loss:0.7973 acc:0.7882 acc1:0.4538 mse:69448984\n",
      "\n",
      "2020-10-30 08:48:38\n",
      "[5, 3, 18, 14, 10, 34, 10, 6, 6, 3]\n",
      "[7, 9, 18, 9, 16, 21, 9, 4, 4, 5]\n",
      "###### 992 batch Train loss:0.6523 acc:0.8728 acc1:0.5384 mse:11419222 Test loss:0.7922 acc:0.7888 acc1:0.4554 mse:68507592\n",
      "\n",
      "2020-10-30 08:48:40\n",
      "[13, 7, 13, 14, 24, 48, 39, 23, 11, 14]\n",
      "[11, 7, 13, 10, 17, 40, 25, 18, 13, 12]\n",
      "###### 993 batch Train loss:0.8237 acc:0.7774 acc1:0.4965 mse:9774625 Test loss:0.7965 acc:0.7881 acc1:0.4542 mse:68412256\n",
      "\n",
      "2020-10-30 08:48:43\n",
      "[18, 10, 13, 18, 18, 33, 16, 9, 15, 4]\n",
      "[13, 7, 12, 14, 16, 29, 14, 7, 9, 9]\n",
      "###### 994 batch Train loss:1.0982 acc:0.7696 acc1:0.5090 mse:14117030 Test loss:0.7992 acc:0.7855 acc1:0.4498 mse:66447400\n",
      "\n",
      "2020-10-30 08:48:45\n",
      "[7, 8, 17, 12, 13, 42, 26, 20, 10, 8]\n",
      "[7, 7, 10, 9, 13, 30, 22, 11, 10, 8]\n",
      "###### 995 batch Train loss:0.7142 acc:0.7701 acc1:0.4912 mse:5601286 Test loss:0.8066 acc:0.7829 acc1:0.4450 mse:66031056\n",
      "\n",
      "2020-10-30 08:48:48\n",
      "[10, 5, 11, 10, 29, 62, 39, 19, 11, 5]\n",
      "[7, 6, 15, 9, 13, 52, 19, 14, 10, 7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### 996 batch Train loss:0.7388 acc:0.7751 acc1:0.4821 mse:7085174 Test loss:0.8177 acc:0.7796 acc1:0.4390 mse:66798800\n",
      "\n",
      "2020-10-30 08:48:50\n",
      "[10, 10, 40, 53, 50, 55, 41, 12, 17, 21]\n",
      "[10, 10, 39, 38, 46, 58, 38, 13, 16, 15]\n",
      "###### 997 batch Train loss:0.7379 acc:0.7650 acc1:0.4813 mse:4991622 Test loss:0.8123 acc:0.7804 acc1:0.4413 mse:65941672\n",
      "\n",
      "2020-10-30 08:48:53\n",
      "[9, 7, 16, 13, 10, 24, 5, 4, 2, 10]\n",
      "[5, 7, 10, 8, 12, 21, 7, 2, 3, 2]\n",
      "###### 998 batch Train loss:0.7353 acc:0.7898 acc1:0.4502 mse:7415824 Test loss:0.7937 acc:0.7853 acc1:0.4512 mse:63891324\n",
      "\n",
      "2020-10-30 08:48:55\n",
      "[1, 8, 2, 0, 1, 4, 1, 6, 2, 1]\n",
      "[0, 3, 1, 1, 2, 7, 4, 3, 2, 1]\n",
      "###### 999 batch Train loss:0.5727 acc:0.8333 acc1:0.4707 mse:5806778 Test loss:0.7902 acc:0.7879 acc1:0.4551 mse:64824692\n",
      "\n",
      "2020-10-30 08:48:58\n",
      "[22, 6, 13, 10, 15, 35, 28, 18, 8, 13]\n",
      "[10, 6, 13, 10, 14, 42, 25, 13, 10, 10]\n",
      "###### 1000 batch Train loss:0.8099 acc:0.7589 acc1:0.4871 mse:6954806 Test loss:0.7950 acc:0.7887 acc1:0.4557 mse:67182768\n",
      "\n",
      "2020-10-30 08:49:00\n",
      "[11, 20, 47, 40, 35, 45, 29, 16, 7, 10]\n",
      "[7, 15, 34, 33, 34, 48, 31, 14, 13, 9]\n",
      "###### 1001 batch Train loss:0.7320 acc:0.7808 acc1:0.5002 mse:7474175 Test loss:0.8022 acc:0.7881 acc1:0.4537 mse:69442088\n",
      "\n",
      "2020-10-30 08:49:03\n",
      "[7, 11, 12, 8, 21, 27, 17, 11, 13, 7]\n",
      "[7, 8, 10, 11, 13, 41, 26, 12, 11, 9]\n",
      "###### 1002 batch Train loss:0.6750 acc:0.7963 acc1:0.4917 mse:6952890 Test loss:0.8109 acc:0.7869 acc1:0.4508 mse:71432760\n",
      "\n",
      "2020-10-30 08:49:05\n",
      "[2, 3, 12, 9, 11, 23, 11, 6, 2, 5]\n",
      "[5, 7, 7, 9, 10, 14, 11, 4, 3, 3]\n",
      "###### 1003 batch Train loss:0.8163 acc:0.7831 acc1:0.4885 mse:12629253 Test loss:0.8129 acc:0.7865 acc1:0.4494 mse:71014040\n",
      "\n",
      "2020-10-30 08:49:08\n",
      "[0, 1, 0, 0, 0, 0, 0, 2, 0, 0]\n",
      "[1, 1, 2, 2, 1, 9, 4, 5, 3, 3]\n",
      "###### 1004 batch Train loss:0.4837 acc:0.8271 acc1:0.4832 mse:3767852 Test loss:0.8173 acc:0.7858 acc1:0.4473 mse:71137576\n",
      "\n",
      "2020-10-30 08:49:10\n",
      "[4, 11, 16, 14, 20, 38, 29, 17, 20, 9]\n",
      "[10, 8, 12, 10, 16, 38, 25, 19, 12, 10]\n",
      "###### 1005 batch Train loss:0.6204 acc:0.7818 acc1:0.4931 mse:4722823 Test loss:0.8173 acc:0.7861 acc1:0.4475 mse:70595136\n",
      "\n",
      "2020-10-30 08:49:12\n",
      "[24, 7, 16, 31, 47, 132, 57, 89, 73, 83]\n",
      "[24, 6, 19, 23, 31, 54, 31, 43, 59, 56]\n",
      "###### 1006 batch Train loss:1.3483 acc:0.7545 acc1:0.5297 mse:19496964 Test loss:0.8104 acc:0.7847 acc1:0.4457 mse:68991424\n",
      "\n",
      "2020-10-30 08:49:15\n",
      "[13, 10, 13, 22, 18, 26, 14, 4, 4, 4]\n",
      "[6, 10, 16, 12, 14, 23, 9, 5, 6, 4]\n",
      "###### 1007 batch Train loss:0.5587 acc:0.8077 acc1:0.4514 mse:4484684 Test loss:0.8197 acc:0.7823 acc1:0.4410 mse:71855280\n",
      "\n",
      "2020-10-30 08:49:17\n",
      "[13, 12, 42, 56, 50, 79, 38, 13, 15, 19]\n",
      "[11, 14, 39, 41, 45, 58, 37, 17, 18, 16]\n",
      "###### 1008 batch Train loss:1.0337 acc:0.8194 acc1:0.5455 mse:14111587 Test loss:0.8223 acc:0.7793 acc1:0.4359 mse:70763504\n",
      "\n",
      "2020-10-30 08:49:20\n",
      "[7, 6, 17, 14, 15, 46, 23, 19, 18, 17]\n",
      "[10, 7, 19, 13, 13, 54, 26, 18, 12, 10]\n",
      "###### 1009 batch Train loss:0.6334 acc:0.7827 acc1:0.4512 mse:3707522 Test loss:0.8319 acc:0.7764 acc1:0.4300 mse:71305072\n",
      "\n",
      "2020-10-30 08:49:22\n",
      "[8, 4, 9, 10, 4, 29, 24, 18, 13, 7]\n",
      "[7, 8, 11, 12, 14, 34, 27, 13, 11, 8]\n",
      "###### 1010 batch Train loss:0.7496 acc:0.7402 acc1:0.4056 mse:4981958 Test loss:0.8170 acc:0.7798 acc1:0.4376 mse:70172520\n",
      "\n",
      "2020-10-30 08:49:25\n",
      "[6, 4, 6, 9, 14, 13, 4, 4, 3, 1]\n",
      "[5, 7, 9, 10, 12, 14, 10, 7, 5, 4]\n",
      "###### 1011 batch Train loss:0.7145 acc:0.7545 acc1:0.4283 mse:4768177 Test loss:0.8060 acc:0.7852 acc1:0.4484 mse:70866296\n",
      "\n",
      "2020-10-30 08:49:27\n",
      "[17, 12, 32, 16, 28, 79, 36, 43, 32, 27]\n",
      "[14, 13, 33, 23, 32, 75, 49, 34, 35, 28]\n",
      "###### 1012 batch Train loss:0.9918 acc:0.7737 acc1:0.4714 mse:18325652 Test loss:0.8048 acc:0.7882 acc1:0.4538 mse:72141328\n",
      "\n",
      "2020-10-30 08:49:30\n",
      "[14, 11, 13, 11, 15, 46, 27, 7, 13, 18]\n",
      "[11, 7, 16, 11, 15, 33, 28, 17, 10, 12]\n",
      "###### 1013 batch Train loss:0.9907 acc:0.7671 acc1:0.5131 mse:16655469 Test loss:0.8052 acc:0.7901 acc1:0.4568 mse:71806216\n",
      "\n",
      "2020-10-30 08:49:32\n",
      "[10, 17, 39, 38, 46, 53, 24, 3, 16, 9]\n",
      "[7, 17, 41, 39, 39, 46, 35, 15, 13, 10]\n",
      "###### 1014 batch Train loss:0.7359 acc:0.7856 acc1:0.4429 mse:7339120 Test loss:0.8108 acc:0.7919 acc1:0.4592 mse:72174480\n",
      "\n",
      "2020-10-30 08:49:35\n",
      "[5, 16, 38, 30, 40, 41, 25, 12, 15, 12]\n",
      "[8, 17, 40, 39, 39, 46, 34, 15, 13, 11]\n",
      "###### 1015 batch Train loss:0.8779 acc:0.7892 acc1:0.5012 mse:11595305 Test loss:0.8082 acc:0.7922 acc1:0.4593 mse:70857512\n",
      "\n",
      "2020-10-30 08:49:37\n",
      "[0, 0, 1, 0, 0, 0, 1, 0, 2, 0]\n",
      "[1, 1, 2, 2, 2, 8, 4, 5, 3, 2]\n",
      "###### 1016 batch Train loss:0.6496 acc:0.8198 acc1:0.4972 mse:9803259 Test loss:0.8060 acc:0.7917 acc1:0.4581 mse:69862912\n",
      "\n",
      "2020-10-30 08:49:40\n",
      "[10, 7, 18, 10, 17, 15, 14, 2, 9, 2]\n",
      "[6, 9, 17, 12, 17, 22, 10, 5, 6, 4]\n",
      "###### 1017 batch Train loss:0.9047 acc:0.7694 acc1:0.4961 mse:10726634 Test loss:0.8002 acc:0.7913 acc1:0.4580 mse:68089368\n",
      "\n",
      "2020-10-30 08:49:42\n",
      "[7, 9, 5, 6, 7, 13, 8, 3, 1, 1]\n",
      "[3, 5, 6, 8, 12, 13, 7, 3, 2, 1]\n",
      "###### 1018 batch Train loss:0.6570 acc:0.8092 acc1:0.4863 mse:10258983 Test loss:0.7978 acc:0.7910 acc1:0.4576 mse:66776640\n",
      "\n",
      "2020-10-30 08:49:45\n",
      "[12, 5, 12, 13, 21, 53, 25, 25, 15, 9]\n",
      "[10, 7, 11, 11, 18, 44, 30, 21, 15, 11]\n",
      "###### 1019 batch Train loss:0.8338 acc:0.7900 acc1:0.5014 mse:16091826 Test loss:0.8070 acc:0.7887 acc1:0.4531 mse:67703440\n",
      "\n",
      "2020-10-30 08:49:47\n",
      "[2, 7, 8, 8, 8, 7, 7, 5, 1, 3]\n",
      "[4, 6, 7, 8, 13, 13, 9, 4, 4, 4]\n",
      "###### 1020 batch Train loss:0.7532 acc:0.7964 acc1:0.4831 mse:8088443 Test loss:0.8185 acc:0.7860 acc1:0.4478 mse:69048096\n",
      "\n",
      "2020-10-30 08:49:50\n",
      "[8, 7, 13, 17, 27, 25, 23, 9, 5, 14]\n",
      "[6, 8, 10, 10, 14, 31, 23, 11, 10, 8]\n",
      "###### 1021 batch Train loss:0.9061 acc:0.8031 acc1:0.5090 mse:14777016 Test loss:0.8141 acc:0.7861 acc1:0.4489 mse:68141056\n",
      "\n",
      "2020-10-30 08:49:52\n",
      "[21, 11, 19, 17, 17, 33, 11, 9, 10, 9]\n",
      "[11, 8, 14, 14, 17, 30, 16, 6, 11, 11]\n",
      "###### 1022 batch Train loss:0.7710 acc:0.7439 acc1:0.4681 mse:1440418 Test loss:0.8178 acc:0.7872 acc1:0.4514 mse:70564576\n",
      "\n",
      "2020-10-30 08:49:56\n",
      "[8, 8, 30, 8, 19, 49, 40, 30, 8, 13]\n",
      "[9, 7, 18, 10, 16, 36, 28, 17, 11, 12]\n",
      "###### 1023 batch Train loss:1.0342 acc:0.7641 acc1:0.5297 mse:15785758 Test loss:0.8172 acc:0.7874 acc1:0.4521 mse:71066192\n",
      "\n",
      "2020-10-30 08:49:58\n",
      "[13, 7, 10, 11, 8, 29, 13, 9, 9, 12]\n",
      "[12, 8, 14, 15, 17, 29, 17, 9, 11, 11]\n",
      "###### 1024 batch Train loss:0.5617 acc:0.8058 acc1:0.4638 mse:4001379 Test loss:0.8185 acc:0.7878 acc1:0.4528 mse:71769392\n",
      "\n",
      "2020-10-30 08:50:01\n",
      "[10, 5, 11, 10, 29, 62, 39, 19, 11, 5]\n",
      "[7, 6, 20, 12, 15, 57, 24, 19, 12, 10]\n",
      "###### 1025 batch Train loss:0.6963 acc:0.7846 acc1:0.4865 mse:9509107 Test loss:0.8173 acc:0.7884 acc1:0.4537 mse:71639336\n",
      "\n",
      "2020-10-30 08:50:03\n",
      "[14, 17, 38, 41, 32, 45, 37, 12, 15, 14]\n",
      "[9, 15, 37, 34, 37, 45, 32, 13, 13, 11]\n",
      "###### 1026 batch Train loss:0.7084 acc:0.7875 acc1:0.4915 mse:7086110 Test loss:0.8125 acc:0.7887 acc1:0.4542 mse:69964504\n",
      "\n",
      "2020-10-30 08:50:06\n",
      "[35, 36, 111, 76, 138, 228, 172, 111, 103, 105]\n",
      "[32, 36, 113, 68, 134, 237, 191, 109, 121, 136]\n",
      "###### 1027 batch Train loss:1.0277 acc:0.7862 acc1:0.5505 mse:16894870 Test loss:0.8016 acc:0.7877 acc1:0.4531 mse:66661404\n",
      "\n",
      "2020-10-30 08:50:08\n",
      "[11, 11, 19, 12, 17, 45, 27, 28, 15, 11]\n",
      "[11, 9, 14, 11, 18, 45, 28, 18, 13, 11]\n",
      "###### 1028 batch Train loss:0.6952 acc:0.8187 acc1:0.5116 mse:6881696 Test loss:0.7970 acc:0.7858 acc1:0.4500 mse:65270484\n",
      "\n",
      "2020-10-30 08:50:11\n",
      "[3, 2, 1, 2, 2, 1, 0, 0, 0, 0]\n",
      "[1, 2, 3, 2, 2, 8, 3, 4, 2, 2]\n",
      "###### 1029 batch Train loss:0.6786 acc:0.7975 acc1:0.5113 mse:5904696 Test loss:0.8045 acc:0.7823 acc1:0.4431 mse:66877564\n",
      "\n",
      "2020-10-30 08:50:13\n",
      "[8, 5, 26, 16, 11, 96, 29, 14, 3, 10]\n",
      "[9, 5, 17, 12, 14, 55, 26, 19, 11, 8]\n",
      "###### 1030 batch Train loss:0.5461 acc:0.7890 acc1:0.4380 mse:3496306 Test loss:0.8185 acc:0.7793 acc1:0.4364 mse:70687888\n",
      "\n",
      "2020-10-30 08:50:16\n",
      "[13, 15, 22, 15, 16, 19, 5, 8, 7, 4]\n",
      "[6, 10, 18, 10, 15, 20, 7, 3, 3, 2]\n",
      "###### 1031 batch Train loss:0.7463 acc:0.7776 acc1:0.4710 mse:10941998 Test loss:0.8159 acc:0.7802 acc1:0.4377 mse:70346376\n",
      "\n",
      "2020-10-30 08:50:18\n",
      "[14, 10, 7, 25, 19, 34, 14, 14, 7, 13]\n",
      "[13, 8, 14, 15, 16, 29, 15, 7, 8, 8]\n",
      "###### 1032 batch Train loss:0.9500 acc:0.7773 acc1:0.5034 mse:12828441 Test loss:0.7911 acc:0.7842 acc1:0.4465 mse:63599064\n",
      "\n",
      "2020-10-30 08:50:20\n",
      "[12, 14, 10, 20, 19, 42, 16, 10, 14, 12]\n",
      "[10, 10, 22, 24, 30, 38, 21, 10, 11, 9]\n",
      "###### 1033 batch Train loss:0.7620 acc:0.7611 acc1:0.4890 mse:6545840 Test loss:0.7794 acc:0.7863 acc1:0.4509 mse:60841324\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-30 08:50:23\n",
      "[15, 12, 15, 12, 15, 40, 27, 16, 12, 11]\n",
      "[11, 7, 17, 11, 15, 38, 28, 17, 9, 10]\n",
      "###### 1034 batch Train loss:0.9654 acc:0.7778 acc1:0.5289 mse:11870805 Test loss:0.7774 acc:0.7858 acc1:0.4502 mse:59917456\n",
      "\n",
      "2020-10-30 08:50:25\n",
      "[12, 16, 45, 40, 52, 44, 39, 14, 15, 16]\n",
      "[12, 11, 46, 41, 51, 56, 38, 15, 13, 14]\n",
      "###### 1035 batch Train loss:0.9729 acc:0.7577 acc1:0.5016 mse:12105086 Test loss:0.7796 acc:0.7854 acc1:0.4498 mse:60274664\n",
      "\n",
      "2020-10-30 08:50:28\n",
      "[1, 2, 0, 1, 0, 0, 0, 1, 1, 0]\n",
      "[2, 1, 2, 2, 2, 9, 4, 5, 2, 1]\n",
      "###### 1036 batch Train loss:0.5685 acc:0.8020 acc1:0.4508 mse:4311142 Test loss:0.7805 acc:0.7865 acc1:0.4523 mse:61302404\n",
      "\n",
      "2020-10-30 08:50:30\n",
      "[1, 8, 2, 0, 1, 4, 1, 6, 2, 1]\n",
      "[1, 3, 1, 1, 1, 7, 3, 4, 2, 1]\n",
      "###### 1037 batch Train loss:0.7920 acc:0.7918 acc1:0.4878 mse:9744116 Test loss:0.7786 acc:0.7873 acc1:0.4544 mse:61362648\n",
      "\n",
      "2020-10-30 08:50:33\n",
      "[8, 10, 40, 41, 39, 61, 40, 19, 17, 17]\n",
      "[12, 11, 46, 43, 53, 57, 42, 15, 15, 15]\n",
      "###### 1038 batch Train loss:0.8003 acc:0.7928 acc1:0.4826 mse:11263602 Test loss:0.7712 acc:0.7893 acc1:0.4584 mse:60243724\n",
      "\n",
      "2020-10-30 08:50:35\n",
      "[6, 2, 1, 9, 8, 6, 8, 0, 2, 4]\n",
      "[4, 4, 5, 4, 7, 7, 8, 3, 1, 1]\n",
      "###### 1039 batch Train loss:0.4520 acc:0.8286 acc1:0.4469 mse:2745628 Test loss:0.7718 acc:0.7908 acc1:0.4612 mse:60734664\n",
      "\n",
      "2020-10-30 08:50:38\n",
      "[7, 26, 33, 43, 32, 52, 25, 18, 11, 11]\n",
      "[10, 17, 42, 37, 37, 46, 34, 15, 14, 11]\n",
      "###### 1040 batch Train loss:0.8397 acc:0.7821 acc1:0.5215 mse:7735308 Test loss:0.7743 acc:0.7916 acc1:0.4630 mse:61079980\n",
      "\n",
      "2020-10-30 08:50:40\n",
      "[16, 11, 54, 45, 44, 59, 47, 14, 13, 22]\n",
      "[13, 12, 42, 41, 49, 57, 40, 15, 17, 16]\n",
      "###### 1041 batch Train loss:0.7945 acc:0.8065 acc1:0.5105 mse:7181636 Test loss:0.7734 acc:0.7916 acc1:0.4634 mse:61277760\n",
      "\n",
      "2020-10-30 08:50:43\n",
      "[4, 1, 6, 10, 6, 21, 5, 22, 16, 13]\n",
      "[5, 4, 6, 7, 5, 17, 8, 16, 12, 9]\n",
      "###### 1042 batch Train loss:0.5292 acc:0.8284 acc1:0.4678 mse:5034318 Test loss:0.7765 acc:0.7908 acc1:0.4614 mse:62865308\n",
      "\n",
      "2020-10-30 08:50:45\n",
      "[7, 8, 10, 9, 13, 35, 27, 13, 5, 6]\n",
      "[7, 6, 11, 14, 12, 51, 25, 13, 12, 10]\n",
      "###### 1043 batch Train loss:0.7129 acc:0.8153 acc1:0.4807 mse:9307960 Test loss:0.7732 acc:0.7906 acc1:0.4609 mse:63077556\n",
      "\n",
      "2020-10-30 08:50:47\n",
      "[24, 8, 23, 40, 40, 128, 60, 60, 95, 81]\n",
      "[31, 5, 28, 32, 49, 123, 62, 81, 83, 95]\n",
      "###### 1044 batch Train loss:0.6036 acc:0.7716 acc1:0.4692 mse:3209005 Test loss:0.7718 acc:0.7904 acc1:0.4604 mse:63807220\n",
      "\n",
      "2020-10-30 08:50:50\n",
      "[5, 9, 14, 14, 15, 40, 24, 19, 14, 7]\n",
      "[6, 7, 12, 12, 12, 47, 22, 13, 11, 9]\n",
      "###### 1045 batch Train loss:0.6724 acc:0.7864 acc1:0.5088 mse:5261678 Test loss:0.7714 acc:0.7896 acc1:0.4589 mse:63841048\n",
      "\n",
      "2020-10-30 08:50:52\n",
      "[6, 9, 18, 13, 9, 45, 31, 12, 15, 10]\n",
      "[7, 7, 11, 15, 12, 52, 25, 13, 13, 10]\n",
      "###### 1046 batch Train loss:0.8967 acc:0.7719 acc1:0.5222 mse:10157095 Test loss:0.7729 acc:0.7872 acc1:0.4545 mse:61725376\n",
      "\n",
      "2020-10-30 08:50:55\n",
      "[17, 12, 34, 15, 37, 79, 38, 27, 28, 37]\n",
      "[15, 13, 28, 22, 23, 85, 47, 34, 33, 28]\n",
      "###### 1047 batch Train loss:0.8104 acc:0.8379 acc1:0.5368 mse:14942332 Test loss:0.7845 acc:0.7836 acc1:0.4475 mse:61773436\n",
      "\n",
      "2020-10-30 08:50:57\n",
      "[15, 8, 19, 12, 12, 61, 30, 26, 16, 12]\n",
      "[12, 8, 13, 13, 17, 51, 31, 21, 17, 12]\n",
      "###### 1048 batch Train loss:0.6368 acc:0.7575 acc1:0.4547 mse:3792592 Test loss:0.8008 acc:0.7815 acc1:0.4424 mse:64270680\n",
      "\n",
      "2020-10-30 08:51:00\n",
      "[14, 7, 23, 17, 9, 40, 38, 22, 14, 12]\n",
      "[10, 8, 16, 13, 15, 43, 26, 16, 12, 13]\n",
      "###### 1049 batch Train loss:0.8121 acc:0.7655 acc1:0.4650 mse:13849827 Test loss:0.7996 acc:0.7828 acc1:0.4443 mse:63677448\n",
      "\n",
      "2020-10-30 08:51:02\n",
      "[7, 9, 5, 6, 7, 13, 8, 3, 1, 1]\n",
      "[5, 5, 7, 9, 11, 13, 9, 3, 3, 3]\n",
      "###### 1050 batch Train loss:0.7043 acc:0.8028 acc1:0.4763 mse:8952004 Test loss:0.7876 acc:0.7865 acc1:0.4510 mse:61863152\n",
      "\n",
      "2020-10-30 08:51:05\n",
      "[10, 9, 14, 27, 27, 46, 40, 19, 11, 12]\n",
      "[12, 9, 13, 13, 17, 49, 30, 20, 16, 13]\n",
      "###### 1051 batch Train loss:0.4457 acc:0.8301 acc1:0.4591 mse:2532955 Test loss:0.7796 acc:0.7901 acc1:0.4577 mse:61920884\n",
      "\n",
      "2020-10-30 08:51:07\n",
      "[46, 21, 92, 61, 137, 282, 140, 115, 134, 178]\n",
      "[47, 18, 81, 55, 125, 263, 135, 107, 136, 168]\n",
      "###### 1052 batch Train loss:0.9562 acc:0.7736 acc1:0.5253 mse:10640656 Test loss:0.7764 acc:0.7905 acc1:0.4584 mse:61555544\n",
      "\n",
      "2020-10-30 08:51:09\n",
      "[15, 15, 28, 19, 27, 73, 44, 30, 29, 30]\n",
      "[16, 15, 37, 26, 29, 85, 58, 35, 38, 30]\n",
      "###### 1053 batch Train loss:1.0674 acc:0.7710 acc1:0.5276 mse:3336398 Test loss:0.7615 acc:0.7902 acc1:0.4589 mse:57605128\n",
      "\n",
      "2020-10-30 08:51:13\n",
      "[15, 15, 28, 19, 27, 73, 44, 30, 29, 30]\n",
      "[15, 14, 35, 25, 27, 84, 53, 33, 36, 29]\n",
      "###### 1054 batch Train loss:0.8172 acc:0.7920 acc1:0.5246 mse:7857318 Test loss:0.7627 acc:0.7874 acc1:0.4542 mse:56955924\n",
      "\n",
      "2020-10-30 08:51:16\n",
      "[8, 4, 9, 10, 4, 29, 24, 18, 13, 7]\n",
      "[7, 7, 10, 11, 13, 31, 25, 11, 10, 8]\n",
      "###### 1055 batch Train loss:0.7276 acc:0.7985 acc1:0.5123 mse:12644650 Test loss:0.7780 acc:0.7830 acc1:0.4453 mse:58770152\n",
      "\n",
      "2020-10-30 08:51:18\n",
      "[8, 8, 30, 8, 19, 49, 40, 30, 8, 13]\n",
      "[9, 8, 17, 10, 15, 35, 24, 15, 9, 11]\n",
      "###### 1056 batch Train loss:0.6889 acc:0.7674 acc1:0.4937 mse:5098032 Test loss:0.7949 acc:0.7793 acc1:0.4376 mse:61687492\n",
      "\n",
      "2020-10-30 08:51:21\n",
      "[17, 4, 14, 14, 23, 55, 20, 19, 19, 8]\n",
      "[8, 7, 18, 13, 14, 54, 23, 17, 12, 10]\n",
      "###### 1057 batch Train loss:0.5888 acc:0.7802 acc1:0.4484 mse:3590002 Test loss:0.7996 acc:0.7793 acc1:0.4372 mse:63768544\n",
      "\n",
      "2020-10-30 08:51:23\n",
      "[49, 5, 33, 34, 50, 109, 45, 60, 91, 81]\n",
      "[27, 4, 19, 30, 47, 129, 45, 57, 72, 75]\n",
      "###### 1058 batch Train loss:0.8339 acc:0.7759 acc1:0.4860 mse:11143247 Test loss:0.7802 acc:0.7854 acc1:0.4493 mse:62029532\n",
      "\n",
      "2020-10-30 08:51:26\n",
      "[4, 1, 2, 6, 7, 21, 4, 28, 10, 14]\n",
      "[4, 2, 5, 7, 5, 16, 8, 15, 15, 8]\n",
      "###### 1059 batch Train loss:0.6536 acc:0.8132 acc1:0.4742 mse:7236168 Test loss:0.7722 acc:0.7895 acc1:0.4569 mse:61959976\n",
      "\n",
      "2020-10-30 08:51:28\n",
      "[36, 10, 28, 31, 44, 118, 51, 72, 61, 79]\n",
      "[31, 4, 27, 32, 51, 131, 50, 66, 82, 90]\n",
      "###### 1060 batch Train loss:0.6080 acc:0.7871 acc1:0.4801 mse:4125217 Test loss:0.7759 acc:0.7920 acc1:0.4610 mse:63504548\n",
      "\n",
      "2020-10-30 08:51:31\n",
      "[2, 3, 3, 2, 1, 2, 4, 0, 0, 0]\n",
      "[0, 4, 3, 1, 2, 6, 3, 2, 1, 2]\n",
      "###### 1061 batch Train loss:0.7877 acc:0.8004 acc1:0.5154 mse:10182710 Test loss:0.7810 acc:0.7918 acc1:0.4605 mse:64469296\n",
      "\n",
      "2020-10-30 08:51:33\n",
      "[4, 1, 3, 7, 5, 16, 7, 20, 16, 10]\n",
      "[4, 4, 7, 7, 5, 16, 7, 13, 10, 9]\n",
      "###### 1062 batch Train loss:0.8167 acc:0.7822 acc1:0.5126 mse:8821945 Test loss:0.7807 acc:0.7907 acc1:0.4583 mse:63143144\n",
      "\n",
      "2020-10-30 08:51:36\n",
      "[4, 2, 6, 8, 2, 10, 7, 22, 18, 10]\n",
      "[4, 3, 6, 9, 5, 16, 8, 15, 12, 9]\n",
      "###### 1063 batch Train loss:1.1141 acc:0.7942 acc1:0.5613 mse:20942930 Test loss:0.7825 acc:0.7872 acc1:0.4516 mse:60368108\n",
      "\n",
      "2020-10-30 08:51:38\n",
      "[15, 6, 11, 7, 20, 30, 17, 6, 10, 13]\n",
      "[13, 8, 14, 16, 17, 32, 15, 8, 9, 9]\n",
      "###### 1064 batch Train loss:0.4972 acc:0.8110 acc1:0.4611 mse:2875584 Test loss:0.8010 acc:0.7826 acc1:0.4419 mse:61441132\n",
      "\n",
      "2020-10-30 08:51:41\n",
      "[13, 12, 42, 56, 50, 79, 38, 13, 15, 19]\n",
      "[11, 12, 50, 43, 52, 64, 44, 15, 15, 18]\n",
      "###### 1065 batch Train loss:0.8192 acc:0.7660 acc1:0.5025 mse:8737016 Test loss:0.8089 acc:0.7801 acc1:0.4367 mse:61487684\n",
      "\n",
      "2020-10-30 08:51:43\n",
      "[15, 19, 42, 36, 26, 62, 31, 10, 10, 10]\n",
      "[7, 17, 42, 36, 37, 49, 31, 11, 11, 10]\n",
      "###### 1066 batch Train loss:0.7783 acc:0.8103 acc1:0.5206 mse:8239050 Test loss:0.8066 acc:0.7788 acc1:0.4348 mse:60270168\n",
      "\n",
      "2020-10-30 08:51:46\n",
      "[35, 40, 127, 76, 149, 239, 187, 140, 93, 114]\n",
      "[29, 39, 111, 73, 130, 202, 198, 113, 104, 112]\n",
      "###### 1067 batch Train loss:0.9409 acc:0.8200 acc1:0.5377 mse:18440884 Test loss:0.7789 acc:0.7820 acc1:0.4426 mse:55593632\n",
      "\n",
      "2020-10-30 08:51:48\n",
      "[0, 2, 0, 0, 0, 1, 0, 0, 1, 0]\n",
      "[1, 2, 2, 2, 2, 8, 3, 4, 2, 2]\n",
      "###### 1068 batch Train loss:0.5098 acc:0.8104 acc1:0.4366 mse:3155966 Test loss:0.7682 acc:0.7858 acc1:0.4503 mse:54960964\n",
      "\n",
      "2020-10-30 08:51:51\n",
      "[1, 8, 2, 0, 1, 4, 1, 6, 2, 1]\n",
      "[0, 3, 1, 1, 2, 6, 3, 4, 1, 1]\n",
      "###### 1069 batch Train loss:0.6797 acc:0.7946 acc1:0.5023 mse:5280616 Test loss:0.7694 acc:0.7883 acc1:0.4549 mse:56517480\n",
      "\n",
      "2020-10-30 08:51:53\n",
      "[10, 8, 21, 19, 9, 103, 25, 15, 16, 11]\n",
      "[9, 6, 17, 12, 14, 51, 25, 19, 11, 10]\n",
      "###### 1070 batch Train loss:0.6509 acc:0.8117 acc1:0.5133 mse:6011278 Test loss:0.7710 acc:0.7900 acc1:0.4578 mse:58396408\n",
      "\n",
      "2020-10-30 08:51:56\n",
      "[5, 8, 24, 10, 16, 38, 24, 8, 9, 9]\n",
      "[11, 6, 15, 11, 15, 34, 27, 17, 9, 11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### 1071 batch Train loss:0.7291 acc:0.7984 acc1:0.4742 mse:8821536 Test loss:0.7695 acc:0.7902 acc1:0.4576 mse:60730688\n",
      "\n",
      "2020-10-30 08:51:58\n",
      "[6, 2, 1, 9, 8, 6, 8, 0, 2, 4]\n",
      "[2, 4, 5, 4, 7, 5, 8, 2, 0, 1]\n",
      "###### 1072 batch Train loss:0.8019 acc:0.8054 acc1:0.5211 mse:11392616 Test loss:0.7647 acc:0.7895 acc1:0.4559 mse:61789168\n",
      "\n",
      "2020-10-30 08:52:00\n",
      "[12, 5, 16, 16, 12, 33, 25, 6, 11, 12]\n",
      "[8, 8, 13, 14, 13, 41, 26, 14, 11, 10]\n",
      "###### 1073 batch Train loss:0.6896 acc:0.7829 acc1:0.4666 mse:5643780 Test loss:0.7616 acc:0.7899 acc1:0.4568 mse:62031144\n",
      "\n",
      "2020-10-30 08:52:03\n",
      "[10, 11, 14, 12, 18, 37, 33, 21, 15, 12]\n",
      "[11, 8, 18, 12, 15, 38, 28, 17, 10, 13]\n",
      "###### 1074 batch Train loss:0.8588 acc:0.7686 acc1:0.5120 mse:7500106 Test loss:0.7577 acc:0.7901 acc1:0.4574 mse:59565752\n",
      "\n",
      "2020-10-30 08:52:05\n",
      "[3, 0, 4, 7, 3, 6, 4, 13, 13, 12]\n",
      "[7, 3, 6, 7, 6, 15, 8, 23, 21, 12]\n",
      "###### 1075 batch Train loss:0.7035 acc:0.7896 acc1:0.4661 mse:6773168 Test loss:0.7529 acc:0.7921 acc1:0.4616 mse:57202536\n",
      "\n",
      "2020-10-30 08:52:08\n",
      "[9, 1, 3, 7, 8, 15, 4, 24, 16, 9]\n",
      "[6, 2, 4, 8, 6, 18, 9, 23, 19, 9]\n",
      "###### 1076 batch Train loss:0.7411 acc:0.7702 acc1:0.4521 mse:5032578 Test loss:0.7540 acc:0.7931 acc1:0.4631 mse:56847060\n",
      "\n",
      "2020-10-30 08:52:10\n",
      "[47, 20, 98, 40, 149, 249, 162, 113, 133, 173]\n",
      "[50, 20, 83, 58, 141, 257, 158, 118, 139, 172]\n",
      "###### 1077 batch Train loss:0.7665 acc:0.8084 acc1:0.5242 mse:8176098 Test loss:0.7563 acc:0.7932 acc1:0.4629 mse:57262412\n",
      "\n",
      "2020-10-30 08:52:13\n",
      "[4, 9, 11, 9, 12, 35, 28, 14, 11, 7]\n",
      "[7, 8, 11, 12, 13, 32, 25, 12, 10, 9]\n",
      "###### 1078 batch Train loss:0.7672 acc:0.7774 acc1:0.5164 mse:5909624 Test loss:0.7581 acc:0.7925 acc1:0.4618 mse:57789728\n",
      "\n",
      "2020-10-30 08:52:15\n",
      "[7, 9, 5, 6, 7, 13, 8, 3, 1, 1]\n",
      "[4, 5, 6, 6, 9, 11, 6, 3, 1, 1]\n",
      "###### 1079 batch Train loss:0.7124 acc:0.8206 acc1:0.5156 mse:7967938 Test loss:0.7588 acc:0.7912 acc1:0.4598 mse:57158872\n",
      "\n",
      "2020-10-30 08:52:18\n",
      "[6, 5, 15, 13, 14, 56, 24, 14, 8, 10]\n",
      "[9, 7, 17, 12, 13, 51, 26, 18, 12, 10]\n",
      "###### 1080 batch Train loss:0.9068 acc:0.7609 acc1:0.5026 mse:8967263 Test loss:0.7561 acc:0.7907 acc1:0.4598 mse:55750884\n",
      "\n",
      "2020-10-30 08:52:20\n",
      "[5, 11, 2, 14, 12, 47, 25, 13, 15, 12]\n",
      "[7, 7, 10, 10, 12, 32, 26, 11, 10, 8]\n",
      "###### 1081 batch Train loss:0.7722 acc:0.7667 acc1:0.4805 mse:9091983 Test loss:0.7530 acc:0.7913 acc1:0.4617 mse:54298968\n",
      "\n",
      "2020-10-30 08:52:23\n",
      "[8, 7, 3, 9, 12, 16, 6, 3, 4, 6]\n",
      "[5, 6, 6, 7, 10, 12, 9, 3, 3, 2]\n",
      "###### 1082 batch Train loss:0.7234 acc:0.7835 acc1:0.4861 mse:8504794 Test loss:0.7512 acc:0.7929 acc1:0.4650 mse:53608988\n",
      "\n",
      "2020-10-30 08:52:25\n",
      "[3, 7, 3, 5, 5, 6, 9, 5, 3, 3]\n",
      "[4, 5, 5, 4, 6, 6, 7, 2, 2, 2]\n",
      "###### 1083 batch Train loss:0.5490 acc:0.7988 acc1:0.4546 mse:3259135 Test loss:0.7584 acc:0.7938 acc1:0.4664 mse:54985096\n",
      "\n",
      "2020-10-30 08:52:28\n",
      "[0, 0, 0, 0, 2, 0, 0, 0, 0, 0]\n",
      "[2, 2, 2, 2, 1, 8, 3, 3, 3, 2]\n",
      "###### 1084 batch Train loss:0.3899 acc:0.8679 acc1:0.4753 mse:835859 Test loss:0.7711 acc:0.7940 acc1:0.4662 mse:57648056\n",
      "\n",
      "2020-10-30 08:52:31\n",
      "[32, 30, 100, 63, 117, 209, 186, 117, 112, 121]\n",
      "[30, 34, 101, 70, 111, 191, 188, 106, 91, 93]\n",
      "###### 1085 batch Train loss:0.8354 acc:0.8363 acc1:0.5611 mse:13755129 Test loss:0.7799 acc:0.7927 acc1:0.4633 mse:58840700\n",
      "\n",
      "2020-10-30 08:52:34\n",
      "[10, 8, 13, 20, 17, 38, 23, 14, 17, 16]\n",
      "[9, 8, 12, 14, 13, 43, 26, 12, 12, 9]\n",
      "###### 1086 batch Train loss:0.6145 acc:0.8083 acc1:0.4930 mse:5405601 Test loss:0.7883 acc:0.7914 acc1:0.4603 mse:60862940\n",
      "\n",
      "2020-10-30 08:52:36\n",
      "[7, 20, 11, 13, 14, 82, 12, 10, 11, 11]\n",
      "[11, 10, 15, 18, 20, 36, 18, 10, 14, 9]\n",
      "###### 1087 batch Train loss:0.7843 acc:0.7757 acc1:0.4951 mse:5568170 Test loss:0.7882 acc:0.7899 acc1:0.4573 mse:61977692\n",
      "\n",
      "2020-10-30 08:52:39\n",
      "[0, 0, 0, 0, 2, 0, 0, 0, 0, 0]\n",
      "[2, 2, 2, 2, 1, 8, 3, 3, 3, 2]\n",
      "###### 1088 batch Train loss:0.3908 acc:0.8451 acc1:0.4667 mse:2150455 Test loss:0.7933 acc:0.7880 acc1:0.4536 mse:64538588\n",
      "\n",
      "2020-10-30 08:52:41\n",
      "[15, 14, 36, 17, 33, 95, 58, 29, 79, 23]\n",
      "[18, 19, 48, 29, 40, 110, 63, 38, 38, 33]\n",
      "###### 1089 batch Train loss:0.7121 acc:0.7777 acc1:0.4879 mse:8284919 Test loss:0.7844 acc:0.7888 acc1:0.4554 mse:63089888\n",
      "\n",
      "2020-10-30 08:52:44\n",
      "[28, 6, 24, 34, 51, 122, 44, 68, 76, 86]\n",
      "[26, 6, 21, 29, 28, 77, 35, 59, 61, 60]\n",
      "###### 1090 batch Train loss:0.9182 acc:0.7791 acc1:0.5448 mse:12317061 Test loss:0.7778 acc:0.7884 acc1:0.4554 mse:60104292\n",
      "\n",
      "2020-10-30 08:52:46\n",
      "[16, 9, 54, 51, 54, 59, 43, 5, 16, 16]\n",
      "[12, 12, 39, 43, 44, 59, 34, 12, 17, 14]\n",
      "###### 1091 batch Train loss:0.8007 acc:0.7790 acc1:0.5106 mse:8869215 Test loss:0.7680 acc:0.7879 acc1:0.4556 mse:56433376\n",
      "\n",
      "2020-10-30 08:52:49\n",
      "[1, 8, 2, 0, 1, 4, 1, 6, 2, 1]\n",
      "[1, 4, 2, 1, 2, 6, 3, 3, 2, 1]\n",
      "###### 1092 batch Train loss:0.7324 acc:0.7951 acc1:0.5121 mse:7453138 Test loss:0.7636 acc:0.7868 acc1:0.4539 mse:53884248\n",
      "\n",
      "2020-10-30 08:52:51\n",
      "[5, 8, 24, 10, 16, 38, 24, 8, 9, 9]\n",
      "[12, 6, 16, 12, 15, 37, 25, 16, 11, 10]\n",
      "###### 1093 batch Train loss:0.6283 acc:0.8019 acc1:0.5139 mse:5548060 Test loss:0.7635 acc:0.7859 acc1:0.4524 mse:52897956\n",
      "\n",
      "2020-10-30 08:52:53\n",
      "[59, 19, 75, 47, 161, 251, 162, 122, 129, 173]\n",
      "[52, 21, 96, 61, 165, 316, 187, 124, 149, 191]\n",
      "###### 1094 batch Train loss:0.8380 acc:0.8109 acc1:0.5517 mse:9697657 Test loss:0.7597 acc:0.7853 acc1:0.4515 mse:52033164\n",
      "\n",
      "2020-10-30 08:52:56\n",
      "[25, 36, 106, 85, 123, 195, 209, 111, 84, 103]\n",
      "[34, 35, 105, 69, 132, 239, 196, 108, 106, 113]\n",
      "###### 1095 batch Train loss:0.8573 acc:0.7682 acc1:0.5204 mse:10114368 Test loss:0.7520 acc:0.7868 acc1:0.4546 mse:51542636\n",
      "\n",
      "2020-10-30 08:52:58\n",
      "[4, 9, 11, 9, 12, 35, 28, 14, 11, 7]\n",
      "[8, 8, 11, 12, 14, 34, 23, 11, 11, 8]\n",
      "###### 1096 batch Train loss:0.8342 acc:0.7660 acc1:0.5150 mse:6732780 Test loss:0.7464 acc:0.7889 acc1:0.4588 mse:51987816\n",
      "\n",
      "2020-10-30 08:53:01\n",
      "[35, 40, 127, 76, 149, 239, 187, 140, 93, 114]\n",
      "[29, 31, 91, 59, 110, 186, 176, 94, 92, 95]\n",
      "###### 1097 batch Train loss:0.7267 acc:0.7795 acc1:0.4939 mse:11370173 Test loss:0.7486 acc:0.7895 acc1:0.4595 mse:53255660\n",
      "\n",
      "2020-10-30 08:53:03\n",
      "[10, 6, 24, 7, 15, 45, 38, 15, 10, 18]\n",
      "[11, 8, 17, 9, 16, 37, 24, 16, 10, 10]\n",
      "###### 1098 batch Train loss:0.6643 acc:0.7673 acc1:0.4668 mse:4518058 Test loss:0.7533 acc:0.7914 acc1:0.4623 mse:55627220\n",
      "\n",
      "2020-10-30 08:53:06\n",
      "[4, 1, 3, 7, 5, 16, 7, 20, 16, 10]\n",
      "[4, 3, 6, 7, 6, 16, 7, 14, 12, 8]\n",
      "###### 1099 batch Train loss:0.5244 acc:0.8250 acc1:0.4865 mse:3623123 Test loss:0.7594 acc:0.7922 acc1:0.4629 mse:57808048\n",
      "\n",
      "2020-10-30 08:53:08\n",
      "[3, 2, 1, 2, 2, 1, 0, 0, 0, 0]\n",
      "[2, 2, 2, 1, 2, 8, 2, 3, 3, 2]\n",
      "###### 1100 batch Train loss:0.4468 acc:0.8378 acc1:0.4495 mse:3578080 Test loss:0.7655 acc:0.7933 acc1:0.4636 mse:59990216\n",
      "\n",
      "2020-10-30 08:53:11\n",
      "[11, 22, 42, 28, 33, 90, 53, 35, 23, 26]\n",
      "[15, 11, 27, 18, 22, 66, 44, 26, 30, 24]\n",
      "###### 1101 batch Train loss:0.8778 acc:0.7670 acc1:0.4922 mse:12151826 Test loss:0.7603 acc:0.7957 acc1:0.4679 mse:58477072\n",
      "\n",
      "2020-10-30 08:53:13\n",
      "[13, 7, 10, 11, 8, 29, 13, 9, 9, 12]\n",
      "[14, 8, 13, 15, 17, 30, 14, 8, 9, 9]\n",
      "###### 1102 batch Train loss:0.4693 acc:0.8206 acc1:0.4617 mse:2556778 Test loss:0.7645 acc:0.7968 acc1:0.4692 mse:58839776\n",
      "\n",
      "2020-10-30 08:53:16\n",
      "[3, 0, 6, 9, 8, 7, 6, 19, 14, 10]\n",
      "[5, 2, 4, 7, 6, 14, 8, 16, 12, 8]\n",
      "###### 1103 batch Train loss:0.8510 acc:0.7878 acc1:0.4919 mse:10374779 Test loss:0.7655 acc:0.7967 acc1:0.4687 mse:58675472\n",
      "\n",
      "2020-10-30 08:53:18\n",
      "[5, 2, 5, 11, 10, 28, 39, 14, 9, 8]\n",
      "[8, 8, 10, 11, 14, 34, 25, 11, 10, 8]\n",
      "###### 1104 batch Train loss:0.6531 acc:0.7901 acc1:0.4957 mse:4221499 Test loss:0.7641 acc:0.7958 acc1:0.4672 mse:57974064\n",
      "\n",
      "2020-10-30 08:53:21\n",
      "[2, 3, 1, 1, 3, 3, 11, 2, 4, 4]\n",
      "[1, 4, 2, 1, 3, 5, 4, 2, 1, 1]\n",
      "###### 1105 batch Train loss:0.5120 acc:0.8112 acc1:0.4700 mse:2782178 Test loss:0.7666 acc:0.7951 acc1:0.4659 mse:58432604\n",
      "\n",
      "2020-10-30 08:53:23\n",
      "[5, 12, 23, 16, 23, 29, 13, 7, 6, 3]\n",
      "[8, 8, 15, 10, 15, 23, 11, 4, 4, 4]\n",
      "###### 1106 batch Train loss:0.9477 acc:0.7766 acc1:0.5283 mse:11261294 Test loss:0.7664 acc:0.7928 acc1:0.4621 mse:58313388\n",
      "\n",
      "2020-10-30 08:53:26\n",
      "[15, 12, 15, 12, 15, 40, 27, 16, 12, 11]\n",
      "[11, 7, 17, 11, 16, 41, 28, 18, 10, 12]\n",
      "###### 1107 batch Train loss:0.6093 acc:0.7688 acc1:0.4712 mse:3389566 Test loss:0.7758 acc:0.7900 acc1:0.4567 mse:60521400\n",
      "\n",
      "2020-10-30 08:53:28\n",
      "[37, 12, 91, 52, 124, 265, 142, 115, 139, 151]\n",
      "[49, 21, 91, 57, 151, 288, 181, 121, 143, 171]\n",
      "###### 1108 batch Train loss:0.7952 acc:0.7779 acc1:0.4888 mse:7442750 Test loss:0.7749 acc:0.7891 acc1:0.4555 mse:59529784\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-30 08:53:30\n",
      "[8, 10, 40, 41, 39, 61, 40, 19, 17, 17]\n",
      "[12, 11, 42, 44, 50, 65, 41, 14, 15, 19]\n",
      "###### 1109 batch Train loss:0.9961 acc:0.7861 acc1:0.5281 mse:14335330 Test loss:0.7537 acc:0.7904 acc1:0.4596 mse:53761416\n",
      "\n",
      "2020-10-30 08:53:33\n",
      "[4, 22, 47, 30, 35, 70, 36, 15, 11, 13]\n",
      "[9, 17, 38, 38, 35, 50, 31, 13, 12, 11]\n",
      "###### 1110 batch Train loss:0.7206 acc:0.8266 acc1:0.5187 mse:6871194 Test loss:0.7440 acc:0.7891 acc1:0.4582 mse:50777912\n",
      "\n",
      "2020-10-30 08:53:35\n",
      "[42, 12, 30, 34, 50, 114, 49, 76, 75, 83]\n",
      "[36, 5, 25, 38, 50, 134, 55, 76, 84, 90]\n",
      "###### 1111 batch Train loss:0.5624 acc:0.7928 acc1:0.4340 mse:3675987 Test loss:0.7388 acc:0.7909 acc1:0.4621 mse:50316384\n",
      "\n",
      "2020-10-30 08:53:38\n",
      "[6, 9, 18, 13, 9, 45, 31, 12, 15, 10]\n",
      "[7, 8, 13, 13, 13, 46, 27, 15, 11, 11]\n",
      "###### 1112 batch Train loss:0.6945 acc:0.8279 acc1:0.5304 mse:6523389 Test loss:0.7465 acc:0.7901 acc1:0.4608 mse:52397100\n",
      "\n",
      "2020-10-30 08:53:40\n",
      "[10, 10, 40, 53, 50, 55, 41, 12, 17, 21]\n",
      "[12, 13, 48, 47, 54, 66, 46, 15, 16, 19]\n",
      "###### 1113 batch Train loss:0.8263 acc:0.7839 acc1:0.5319 mse:6866318 Test loss:0.7496 acc:0.7906 acc1:0.4624 mse:54679524\n",
      "\n",
      "2020-10-30 08:53:43\n",
      "[2, 3, 12, 9, 11, 23, 11, 6, 2, 5]\n",
      "[4, 6, 8, 9, 11, 14, 9, 4, 2, 3]\n",
      "###### 1114 batch Train loss:0.7129 acc:0.8149 acc1:0.5176 mse:9209694 Test loss:0.7497 acc:0.7909 acc1:0.4633 mse:55821608\n",
      "\n",
      "2020-10-30 08:53:45\n",
      "[10, 15, 42, 37, 40, 45, 39, 16, 25, 9]\n",
      "[9, 18, 40, 39, 36, 50, 35, 15, 13, 12]\n",
      "###### 1115 batch Train loss:0.8788 acc:0.7608 acc1:0.4968 mse:2507578 Test loss:0.7477 acc:0.7931 acc1:0.4678 mse:56609936\n",
      "\n",
      "2020-10-30 08:53:49\n",
      "[32, 30, 100, 63, 117, 209, 186, 117, 112, 121]\n",
      "[29, 33, 90, 62, 106, 195, 185, 101, 92, 83]\n",
      "###### 1116 batch Train loss:0.8839 acc:0.7799 acc1:0.5389 mse:11550481 Test loss:0.7482 acc:0.7940 acc1:0.4700 mse:56351956\n",
      "\n",
      "2020-10-30 08:53:51\n",
      "[32, 5, 30, 37, 52, 103, 54, 61, 74, 79]\n",
      "[28, 6, 19, 27, 38, 101, 46, 60, 71, 66]\n",
      "###### 1117 batch Train loss:0.8429 acc:0.7889 acc1:0.5596 mse:10135474 Test loss:0.7492 acc:0.7928 acc1:0.4679 mse:54806592\n",
      "\n",
      "2020-10-30 08:53:54\n",
      "[11, 22, 42, 28, 33, 90, 53, 35, 23, 26]\n",
      "[15, 14, 34, 23, 32, 75, 58, 35, 36, 28]\n",
      "###### 1118 batch Train loss:0.7216 acc:0.8086 acc1:0.5323 mse:9968438 Test loss:0.7521 acc:0.7909 acc1:0.4639 mse:52597204\n",
      "\n",
      "2020-10-30 08:53:56\n",
      "[14, 17, 38, 41, 32, 45, 37, 12, 15, 14]\n",
      "[9, 17, 40, 36, 36, 48, 35, 15, 15, 11]\n",
      "###### 1119 batch Train loss:0.8780 acc:0.7957 acc1:0.5477 mse:11721418 Test loss:0.7640 acc:0.7869 acc1:0.4553 mse:51951960\n",
      "\n",
      "2020-10-30 08:53:59\n",
      "[10, 11, 14, 12, 18, 37, 33, 21, 15, 12]\n",
      "[11, 8, 19, 13, 16, 42, 28, 16, 12, 12]\n",
      "###### 1120 batch Train loss:0.4552 acc:0.8215 acc1:0.4764 mse:2672754 Test loss:0.7910 acc:0.7825 acc1:0.4447 mse:56315460\n",
      "\n",
      "2020-10-30 08:54:01\n",
      "[42, 29, 108, 77, 133, 234, 205, 111, 96, 96]\n",
      "[35, 38, 111, 74, 144, 223, 207, 119, 119, 109]\n",
      "###### 1121 batch Train loss:0.8189 acc:0.7674 acc1:0.5012 mse:8817281 Test loss:0.7969 acc:0.7829 acc1:0.4440 mse:58675028\n",
      "\n",
      "2020-10-30 08:54:04\n",
      "[8, 7, 3, 9, 12, 16, 6, 3, 4, 6]\n",
      "[5, 7, 9, 10, 13, 14, 12, 4, 4, 3]\n",
      "###### 1122 batch Train loss:0.6048 acc:0.7691 acc1:0.4930 mse:3791496 Test loss:0.8029 acc:0.7839 acc1:0.4441 mse:61144524\n",
      "\n",
      "2020-10-30 08:54:06\n",
      "[59, 19, 75, 47, 161, 251, 162, 122, 129, 173]\n",
      "[53, 23, 100, 65, 170, 288, 188, 127, 157, 171]\n",
      "###### 1123 batch Train loss:0.8426 acc:0.7882 acc1:0.4910 mse:9193482 Test loss:0.7743 acc:0.7897 acc1:0.4558 mse:55993048\n",
      "\n",
      "2020-10-30 08:54:08\n",
      "[22, 6, 13, 10, 15, 35, 28, 18, 8, 13]\n",
      "[10, 6, 16, 12, 15, 36, 28, 15, 11, 11]\n",
      "###### 1124 batch Train loss:0.5382 acc:0.8045 acc1:0.4602 mse:2790594 Test loss:0.7645 acc:0.7930 acc1:0.4619 mse:54742864\n",
      "\n",
      "2020-10-30 08:54:11\n",
      "[7, 10, 14, 11, 18, 19, 13, 6, 9, 9]\n",
      "[8, 9, 16, 12, 16, 20, 10, 4, 6, 4]\n",
      "###### 1125 batch Train loss:0.6921 acc:0.8075 acc1:0.5070 mse:7616872 Test loss:0.7654 acc:0.7942 acc1:0.4633 mse:55644116\n",
      "\n",
      "2020-10-30 08:54:13\n",
      "[7, 26, 33, 43, 32, 52, 25, 18, 11, 11]\n",
      "[10, 15, 39, 34, 37, 44, 33, 12, 14, 10]\n",
      "###### 1126 batch Train loss:0.7467 acc:0.7997 acc1:0.5018 mse:6679928 Test loss:0.7635 acc:0.7956 acc1:0.4657 mse:55291840\n",
      "\n",
      "2020-10-30 08:54:16\n",
      "[5, 11, 2, 14, 12, 47, 25, 13, 15, 12]\n",
      "[7, 6, 10, 10, 13, 31, 25, 10, 10, 8]\n",
      "###### 1127 batch Train loss:0.5634 acc:0.7836 acc1:0.4912 mse:2844180 Test loss:0.7673 acc:0.7963 acc1:0.4671 mse:56569484\n",
      "\n",
      "2020-10-30 08:54:18\n",
      "[2, 7, 8, 8, 8, 7, 7, 5, 1, 3]\n",
      "[6, 6, 7, 9, 11, 13, 9, 3, 4, 4]\n",
      "###### 1128 batch Train loss:0.6525 acc:0.7743 acc1:0.4827 mse:4495130 Test loss:0.7740 acc:0.7966 acc1:0.4679 mse:58332848\n",
      "\n",
      "2020-10-30 08:54:21\n",
      "[4, 22, 47, 30, 35, 70, 36, 15, 11, 13]\n",
      "[10, 14, 36, 33, 34, 43, 30, 10, 12, 9]\n",
      "###### 1129 batch Train loss:0.8980 acc:0.8058 acc1:0.5213 mse:11914395 Test loss:0.7638 acc:0.7962 acc1:0.4685 mse:56465644\n",
      "\n",
      "2020-10-30 08:54:23\n",
      "[6, 9, 18, 13, 9, 45, 31, 12, 15, 10]\n",
      "[8, 7, 13, 13, 13, 41, 26, 13, 13, 10]\n",
      "###### 1130 batch Train loss:1.0482 acc:0.7801 acc1:0.5351 mse:12088456 Test loss:0.7465 acc:0.7938 acc1:0.4654 mse:52643712\n",
      "\n",
      "2020-10-30 08:54:26\n",
      "[6, 14, 11, 18, 13, 44, 17, 10, 9, 7]\n",
      "[6, 7, 11, 10, 12, 31, 22, 11, 9, 7]\n",
      "###### 1131 batch Train loss:0.5955 acc:0.7771 acc1:0.4852 mse:3466878 Test loss:0.7471 acc:0.7901 acc1:0.4591 mse:51477520\n",
      "\n",
      "2020-10-30 08:54:28\n",
      "[5, 2, 5, 11, 10, 28, 39, 14, 9, 8]\n",
      "[8, 8, 11, 12, 14, 34, 25, 11, 11, 9]\n",
      "###### 1132 batch Train loss:0.6922 acc:0.7880 acc1:0.4700 mse:11680906 Test loss:0.7563 acc:0.7866 acc1:0.4515 mse:51452392\n",
      "\n",
      "2020-10-30 08:54:31\n",
      "[10, 5, 11, 10, 29, 62, 39, 19, 11, 5]\n",
      "[7, 6, 20, 11, 14, 55, 23, 18, 12, 9]\n",
      "###### 1133 batch Train loss:0.8060 acc:0.7747 acc1:0.5267 mse:8242214 Test loss:0.7677 acc:0.7833 acc1:0.4445 mse:51734336\n",
      "\n",
      "2020-10-30 08:54:33\n",
      "[19, 7, 13, 11, 19, 61, 32, 20, 14, 10]\n",
      "[10, 7, 13, 11, 18, 46, 29, 22, 14, 10]\n",
      "###### 1134 batch Train loss:0.8562 acc:0.7823 acc1:0.5377 mse:8505370 Test loss:0.7725 acc:0.7812 acc1:0.4403 mse:51101560\n",
      "\n",
      "2020-10-30 08:54:35\n",
      "[1, 2, 0, 1, 0, 0, 0, 1, 1, 0]\n",
      "[1, 1, 2, 1, 2, 7, 3, 4, 3, 2]\n",
      "###### 1135 batch Train loss:0.7565 acc:0.7868 acc1:0.4620 mse:6558554 Test loss:0.7556 acc:0.7849 acc1:0.4483 mse:49540476\n",
      "\n",
      "2020-10-30 08:54:38\n",
      "[47, 20, 98, 40, 149, 249, 162, 113, 133, 173]\n",
      "[50, 19, 88, 55, 143, 254, 161, 118, 151, 175]\n",
      "###### 1136 batch Train loss:0.8662 acc:0.7800 acc1:0.5321 mse:6816442 Test loss:0.7427 acc:0.7884 acc1:0.4560 mse:48992524\n",
      "\n",
      "2020-10-30 08:54:40\n",
      "[5, 8, 24, 10, 16, 38, 24, 8, 9, 9]\n",
      "[9, 6, 16, 11, 14, 38, 28, 18, 10, 11]\n",
      "###### 1137 batch Train loss:0.8145 acc:0.8186 acc1:0.5258 mse:8804554 Test loss:0.7449 acc:0.7885 acc1:0.4565 mse:50161964\n",
      "\n",
      "2020-10-30 08:54:43\n",
      "[54, 21, 87, 59, 142, 245, 167, 123, 135, 156]\n",
      "[48, 20, 87, 54, 148, 270, 156, 118, 148, 174]\n",
      "###### 1138 batch Train loss:0.7883 acc:0.8161 acc1:0.5491 mse:7928812 Test loss:0.7514 acc:0.7869 acc1:0.4534 mse:50883744\n",
      "\n",
      "2020-10-30 08:54:45\n",
      "[17, 4, 14, 14, 23, 55, 20, 19, 19, 8]\n",
      "[7, 7, 18, 12, 14, 55, 25, 18, 12, 10]\n",
      "###### 1139 batch Train loss:0.4669 acc:0.8148 acc1:0.4564 mse:2359406 Test loss:0.7636 acc:0.7848 acc1:0.4490 mse:52586436\n",
      "\n",
      "2020-10-30 08:54:48\n",
      "[4, 4, 11, 5, 7, 13, 11, 2, 1, 2]\n",
      "[3, 5, 6, 7, 10, 11, 7, 3, 2, 1]\n",
      "###### 1140 batch Train loss:0.7649 acc:0.7917 acc1:0.4926 mse:9037332 Test loss:0.7592 acc:0.7863 acc1:0.4519 mse:51005548\n",
      "\n",
      "2020-10-30 08:54:50\n",
      "[12, 8, 17, 19, 23, 35, 39, 20, 14, 15]\n",
      "[9, 6, 16, 10, 14, 37, 28, 17, 10, 11]\n",
      "###### 1141 batch Train loss:0.7670 acc:0.7714 acc1:0.4700 mse:5428118 Test loss:0.7532 acc:0.7892 acc1:0.4574 mse:50313556\n",
      "\n",
      "2020-10-30 08:54:53\n",
      "[6, 2, 1, 9, 8, 6, 8, 0, 2, 4]\n",
      "[2, 4, 4, 4, 6, 7, 7, 2, 1, 1]\n",
      "###### 1142 batch Train loss:0.4549 acc:0.8396 acc1:0.4590 mse:3277386 Test loss:0.7541 acc:0.7915 acc1:0.4611 mse:51435160\n",
      "\n",
      "2020-10-30 08:54:55\n",
      "[7, 20, 11, 13, 14, 82, 12, 10, 11, 11]\n",
      "[8, 9, 15, 17, 24, 33, 17, 10, 13, 9]\n",
      "###### 1143 batch Train loss:0.6392 acc:0.7801 acc1:0.4662 mse:4287566 Test loss:0.7578 acc:0.7935 acc1:0.4641 mse:52858032\n",
      "\n",
      "2020-10-30 08:54:58\n",
      "[5, 9, 14, 14, 15, 40, 24, 19, 14, 7]\n",
      "[5, 8, 12, 10, 13, 39, 22, 12, 9, 8]\n",
      "###### 1144 batch Train loss:0.3485 acc:0.8573 acc1:0.4116 mse:2064205 Test loss:0.7668 acc:0.7948 acc1:0.4650 mse:55182124\n",
      "\n",
      "2020-10-30 08:55:00\n",
      "[30, 41, 99, 82, 134, 202, 228, 92, 115, 102]\n",
      "[30, 36, 106, 69, 141, 210, 187, 114, 99, 110]\n",
      "###### 1145 batch Train loss:0.8110 acc:0.7680 acc1:0.4845 mse:8531361 Test loss:0.7713 acc:0.7961 acc1:0.4667 mse:56532844\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-30 08:55:02\n",
      "[3, 2, 1, 2, 2, 1, 0, 0, 0, 0]\n",
      "[1, 2, 2, 2, 1, 8, 3, 3, 2, 2]\n",
      "###### 1146 batch Train loss:0.1706 acc:0.9274 acc1:0.3715 mse:567114 Test loss:0.7805 acc:0.7968 acc1:0.4665 mse:58684696\n",
      "\n",
      "2020-10-30 08:55:06\n",
      "[37, 12, 91, 52, 124, 265, 142, 115, 139, 151]\n",
      "[42, 20, 84, 55, 140, 260, 157, 113, 124, 166]\n",
      "###### 1147 batch Train loss:0.7083 acc:0.8040 acc1:0.5284 mse:7050012 Test loss:0.7827 acc:0.7973 acc1:0.4669 mse:59205672\n",
      "\n",
      "2020-10-30 08:55:09\n",
      "[13, 12, 42, 56, 50, 79, 38, 13, 15, 19]\n",
      "[10, 11, 32, 35, 39, 51, 33, 12, 15, 13]\n",
      "###### 1148 batch Train loss:0.7509 acc:0.8088 acc1:0.5273 mse:7491967 Test loss:0.7710 acc:0.7976 acc1:0.4679 mse:57023844\n",
      "\n",
      "2020-10-30 08:55:11\n",
      "[0, 0, 0, 0, 2, 0, 0, 0, 0, 0]\n",
      "[1, 2, 2, 2, 1, 7, 3, 3, 2, 2]\n",
      "###### 1149 batch Train loss:0.6623 acc:0.8377 acc1:0.5266 mse:10339424 Test loss:0.7629 acc:0.7966 acc1:0.4669 mse:54582444\n",
      "\n",
      "2020-10-30 08:55:13\n",
      "[7, 9, 5, 6, 7, 13, 8, 3, 1, 1]\n",
      "[4, 6, 6, 7, 10, 12, 10, 2, 2, 1]\n",
      "###### 1150 batch Train loss:0.5082 acc:0.8242 acc1:0.4804 mse:3624488 Test loss:0.7602 acc:0.7957 acc1:0.4657 mse:53372632\n",
      "\n",
      "2020-10-30 08:55:16\n",
      "[11, 6, 14, 18, 11, 31, 13, 6, 10, 9]\n",
      "[12, 8, 12, 15, 15, 30, 13, 6, 9, 8]\n",
      "###### 1151 batch Train loss:0.7427 acc:0.7966 acc1:0.5046 mse:5831647 Test loss:0.7602 acc:0.7931 acc1:0.4616 mse:52705096\n",
      "\n",
      "2020-10-30 08:55:18\n",
      "[10, 13, 45, 45, 56, 75, 51, 12, 25, 17]\n",
      "[10, 12, 35, 39, 41, 55, 35, 11, 16, 14]\n",
      "###### 1152 batch Train loss:0.8922 acc:0.7841 acc1:0.5249 mse:8317165 Test loss:0.7725 acc:0.7877 acc1:0.4514 mse:54725692\n",
      "\n",
      "2020-10-30 08:55:21\n",
      "[6, 9, 5, 17, 26, 38, 29, 13, 13, 10]\n",
      "[7, 8, 13, 14, 12, 45, 26, 13, 12, 9]\n",
      "###### 1153 batch Train loss:0.9939 acc:0.8024 acc1:0.5398 mse:14146951 Test loss:0.7742 acc:0.7832 acc1:0.4436 mse:54810932\n",
      "\n",
      "2020-10-30 08:55:23\n",
      "[8, 8, 30, 8, 19, 49, 40, 30, 8, 13]\n",
      "[11, 8, 19, 10, 15, 39, 27, 17, 11, 11]\n",
      "###### 1154 batch Train loss:0.7824 acc:0.7670 acc1:0.4985 mse:7137469 Test loss:0.7699 acc:0.7823 acc1:0.4430 mse:53083504\n",
      "\n",
      "2020-10-30 08:55:26\n",
      "[53, 21, 101, 51, 127, 249, 163, 115, 150, 178]\n",
      "[42, 20, 88, 57, 134, 228, 152, 117, 138, 170]\n",
      "###### 1155 batch Train loss:0.9006 acc:0.7795 acc1:0.5331 mse:8546114 Test loss:0.7739 acc:0.7803 acc1:0.4400 mse:52316672\n",
      "\n",
      "2020-10-30 08:55:28\n",
      "[6, 5, 15, 13, 14, 56, 24, 14, 8, 10]\n",
      "[9, 7, 20, 14, 13, 57, 25, 18, 13, 10]\n",
      "###### 1156 batch Train loss:0.6860 acc:0.7947 acc1:0.4804 mse:5116614 Test loss:0.7670 acc:0.7812 acc1:0.4426 mse:49820924\n",
      "\n",
      "2020-10-30 08:55:31\n",
      "[10, 9, 22, 11, 11, 105, 22, 23, 12, 9]\n",
      "[8, 7, 21, 12, 14, 57, 23, 17, 12, 9]\n",
      "###### 1157 batch Train loss:0.6822 acc:0.7772 acc1:0.5003 mse:4990676 Test loss:0.7574 acc:0.7833 acc1:0.4476 mse:48063464\n",
      "\n",
      "2020-10-30 08:55:33\n",
      "[9, 8, 18, 17, 27, 87, 15, 7, 23, 7]\n",
      "[10, 10, 26, 31, 31, 45, 26, 12, 17, 14]\n",
      "###### 1158 batch Train loss:0.8721 acc:0.7646 acc1:0.4904 mse:10369151 Test loss:0.7429 acc:0.7886 acc1:0.4587 mse:47213888\n",
      "\n",
      "2020-10-30 08:55:36\n",
      "[11, 7, 16, 11, 22, 57, 32, 25, 11, 12]\n",
      "[10, 9, 15, 11, 17, 43, 27, 19, 13, 10]\n",
      "###### 1159 batch Train loss:0.6418 acc:0.7715 acc1:0.4781 mse:4226448 Test loss:0.7426 acc:0.7930 acc1:0.4671 mse:49172784\n",
      "\n",
      "2020-10-30 08:55:38\n",
      "[14, 11, 13, 11, 15, 46, 27, 7, 13, 18]\n",
      "[10, 7, 18, 12, 14, 34, 28, 16, 11, 12]\n",
      "###### 1160 batch Train loss:0.7504 acc:0.7776 acc1:0.5035 mse:10561801 Test loss:0.7536 acc:0.7950 acc1:0.4700 mse:52515720\n",
      "\n",
      "2020-10-30 08:55:40\n",
      "[10, 11, 14, 12, 18, 37, 33, 21, 15, 12]\n",
      "[10, 8, 19, 12, 15, 37, 28, 16, 11, 12]\n",
      "###### 1161 batch Train loss:0.6961 acc:0.7819 acc1:0.4903 mse:5523628 Test loss:0.7647 acc:0.7958 acc1:0.4705 mse:55345820\n",
      "\n",
      "2020-10-30 08:55:43\n",
      "[11, 22, 42, 28, 33, 90, 53, 35, 23, 26]\n",
      "[17, 13, 34, 22, 32, 76, 56, 32, 34, 28]\n",
      "###### 1162 batch Train loss:0.8224 acc:0.7774 acc1:0.5227 mse:7592388 Test loss:0.7640 acc:0.7963 acc1:0.4713 mse:54972964\n",
      "\n",
      "2020-10-30 08:55:45\n",
      "[1, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 0, 1, 1, 2, 7, 3, 3, 3, 2]\n",
      "###### 1163 batch Train loss:0.7655 acc:0.8244 acc1:0.5305 mse:8196938 Test loss:0.7534 acc:0.7960 acc1:0.4713 mse:52537724\n",
      "\n",
      "2020-10-30 08:55:48\n",
      "[4, 4, 9, 9, 8, 13, 8, 2, 4, 5]\n",
      "[4, 6, 6, 5, 7, 7, 8, 0, 2, 3]\n",
      "###### 1164 batch Train loss:0.4914 acc:0.8191 acc1:0.4810 mse:2801036 Test loss:0.7478 acc:0.7955 acc1:0.4708 mse:51812464\n",
      "\n",
      "2020-10-30 08:55:50\n",
      "[7, 8, 17, 12, 13, 42, 26, 20, 10, 8]\n",
      "[8, 8, 11, 11, 14, 31, 26, 11, 11, 9]\n",
      "###### 1165 batch Train loss:0.5274 acc:0.8075 acc1:0.4673 mse:3243637 Test loss:0.7458 acc:0.7950 acc1:0.4701 mse:51892328\n",
      "\n",
      "2020-10-30 08:55:53\n",
      "[3, 7, 3, 5, 5, 6, 9, 5, 3, 3]\n",
      "[4, 5, 6, 4, 7, 7, 8, 1, 1, 2]\n",
      "###### 1166 batch Train loss:0.6538 acc:0.7967 acc1:0.5100 mse:6449002 Test loss:0.7440 acc:0.7941 acc1:0.4688 mse:52222848\n",
      "\n",
      "2020-10-30 08:55:55\n",
      "[1, 8, 2, 0, 1, 4, 1, 6, 2, 1]\n",
      "[1, 4, 1, 0, 1, 6, 2, 1, 1, 1]\n",
      "###### 1167 batch Train loss:0.7202 acc:0.7983 acc1:0.5134 mse:8044389 Test loss:0.7402 acc:0.7932 acc1:0.4674 mse:51300344\n",
      "\n",
      "2020-10-30 08:55:58\n",
      "[15, 8, 19, 12, 12, 61, 30, 26, 16, 12]\n",
      "[13, 8, 13, 12, 19, 50, 31, 19, 15, 11]\n",
      "###### 1168 batch Train loss:0.6027 acc:0.7927 acc1:0.4788 mse:3584790 Test loss:0.7410 acc:0.7921 acc1:0.4650 mse:50841948\n",
      "\n",
      "2020-10-30 08:56:00\n",
      "[14, 10, 7, 25, 19, 34, 14, 14, 7, 13]\n",
      "[13, 8, 13, 14, 16, 32, 15, 7, 10, 10]\n",
      "###### 1169 batch Train loss:0.7105 acc:0.8125 acc1:0.5065 mse:7139780 Test loss:0.7389 acc:0.7916 acc1:0.4639 mse:49463648\n",
      "\n",
      "2020-10-30 08:56:03\n",
      "[8, 1, 3, 10, 6, 10, 6, 24, 21, 8]\n",
      "[6, 2, 5, 8, 6, 17, 7, 20, 23, 9]\n",
      "###### 1170 batch Train loss:0.4270 acc:0.8183 acc1:0.4280 mse:2255176 Test loss:0.7374 acc:0.7920 acc1:0.4640 mse:48449940\n",
      "\n",
      "2020-10-30 08:56:05\n",
      "[2, 7, 8, 8, 8, 7, 7, 5, 1, 3]\n",
      "[5, 7, 7, 8, 11, 13, 9, 3, 3, 4]\n",
      "###### 1171 batch Train loss:0.5145 acc:0.8209 acc1:0.4839 mse:3738622 Test loss:0.7352 acc:0.7930 acc1:0.4649 mse:47433944\n",
      "\n",
      "2020-10-30 08:56:08\n",
      "[46, 17, 86, 53, 140, 282, 181, 113, 153, 177]\n",
      "[43, 16, 80, 54, 143, 284, 159, 109, 139, 172]\n",
      "###### 1172 batch Train loss:0.8786 acc:0.7873 acc1:0.5322 mse:7601639 Test loss:0.7278 acc:0.7944 acc1:0.4674 mse:46634248\n",
      "\n",
      "2020-10-30 08:56:10\n",
      "[5, 3, 18, 14, 10, 34, 10, 6, 6, 3]\n",
      "[7, 10, 16, 10, 16, 21, 8, 4, 4, 4]\n",
      "###### 1173 batch Train loss:0.7166 acc:0.8179 acc1:0.5241 mse:7432922 Test loss:0.7231 acc:0.7952 acc1:0.4685 mse:46617320\n",
      "\n",
      "2020-10-30 08:56:12\n",
      "[16, 3, 15, 7, 13, 45, 23, 15, 16, 8]\n",
      "[6, 8, 13, 12, 13, 43, 23, 13, 10, 9]\n",
      "###### 1174 batch Train loss:0.5584 acc:0.7829 acc1:0.4676 mse:3277081 Test loss:0.7247 acc:0.7958 acc1:0.4690 mse:48106632\n",
      "\n",
      "2020-10-30 08:56:15\n",
      "[10, 7, 11, 20, 11, 93, 28, 13, 6, 14]\n",
      "[8, 9, 13, 14, 14, 42, 26, 14, 12, 11]\n",
      "###### 1175 batch Train loss:0.7667 acc:0.7962 acc1:0.5405 mse:8146758 Test loss:0.7276 acc:0.7948 acc1:0.4667 mse:48688868\n",
      "\n",
      "2020-10-30 08:56:17\n",
      "[0, 2, 0, 0, 0, 1, 0, 0, 1, 0]\n",
      "[1, 1, 2, 2, 2, 7, 2, 3, 1, 2]\n",
      "###### 1176 batch Train loss:0.7719 acc:0.8147 acc1:0.5230 mse:9726718 Test loss:0.7336 acc:0.7935 acc1:0.4638 mse:49410436\n",
      "\n",
      "2020-10-30 08:56:20\n",
      "[5, 2, 5, 11, 10, 28, 39, 14, 9, 8]\n",
      "[7, 7, 9, 12, 14, 33, 24, 12, 10, 8]\n",
      "###### 1177 batch Train loss:0.7283 acc:0.7476 acc1:0.4610 mse:1474109 Test loss:0.7461 acc:0.7931 acc1:0.4625 mse:52821748\n",
      "\n",
      "2020-10-30 08:56:23\n",
      "[14, 10, 7, 25, 19, 34, 14, 14, 7, 13]\n",
      "[13, 8, 12, 16, 16, 31, 13, 8, 9, 9]\n",
      "###### 1178 batch Train loss:0.4851 acc:0.8432 acc1:0.5057 mse:3939132 Test loss:0.7609 acc:0.7924 acc1:0.4609 mse:56785152\n",
      "\n",
      "2020-10-30 08:56:26\n",
      "[6, 15, 30, 32, 33, 44, 34, 13, 12, 6]\n",
      "[7, 14, 35, 36, 36, 44, 32, 12, 11, 9]\n",
      "###### 1179 batch Train loss:0.6956 acc:0.8144 acc1:0.5260 mse:7692580 Test loss:0.7647 acc:0.7913 acc1:0.4588 mse:56458420\n",
      "\n",
      "2020-10-30 08:56:28\n",
      "[9, 15, 30, 15, 29, 72, 52, 39, 41, 29]\n",
      "[15, 14, 35, 25, 35, 79, 57, 40, 39, 32]\n",
      "###### 1180 batch Train loss:0.7356 acc:0.7853 acc1:0.4935 mse:6002971 Test loss:0.7578 acc:0.7915 acc1:0.4596 mse:53355728\n",
      "\n",
      "2020-10-30 08:56:31\n",
      "[10, 15, 42, 37, 40, 45, 39, 16, 25, 9]\n",
      "[9, 15, 38, 37, 38, 44, 35, 16, 13, 11]\n",
      "###### 1181 batch Train loss:0.7001 acc:0.7843 acc1:0.5053 mse:6145642 Test loss:0.7510 acc:0.7914 acc1:0.4598 mse:51094764\n",
      "\n",
      "2020-10-30 08:56:33\n",
      "[16, 3, 15, 7, 13, 45, 23, 15, 16, 8]\n",
      "[6, 7, 13, 11, 13, 41, 22, 14, 9, 9]\n",
      "###### 1182 batch Train loss:0.6117 acc:0.7732 acc1:0.4809 mse:3246536 Test loss:0.7531 acc:0.7911 acc1:0.4592 mse:52266532\n",
      "\n",
      "2020-10-30 08:56:36\n",
      "[2, 3, 3, 2, 1, 2, 4, 0, 0, 0]\n",
      "[1, 4, 2, 1, 2, 4, 2, 2, 1, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### 1183 batch Train loss:0.6454 acc:0.8265 acc1:0.5256 mse:8437366 Test loss:0.7559 acc:0.7907 acc1:0.4584 mse:54607232\n",
      "\n",
      "2020-10-30 08:56:38\n",
      "[2, 3, 1, 1, 3, 3, 11, 2, 4, 4]\n",
      "[1, 4, 2, 1, 2, 4, 3, 2, 1, 1]\n",
      "###### 1184 batch Train loss:0.7142 acc:0.7868 acc1:0.4723 mse:8864072 Test loss:0.7600 acc:0.7906 acc1:0.4583 mse:58074080\n",
      "\n",
      "2020-10-30 08:56:41\n",
      "[4, 4, 9, 9, 8, 13, 8, 2, 4, 5]\n",
      "[4, 6, 6, 7, 8, 8, 10, 1, 1, 3]\n",
      "###### 1185 batch Train loss:0.5058 acc:0.8544 acc1:0.5248 mse:5331421 Test loss:0.7700 acc:0.7895 acc1:0.4560 mse:62962192\n",
      "\n",
      "2020-10-30 08:56:43\n",
      "[16, 9, 54, 51, 54, 59, 43, 5, 16, 16]\n",
      "[12, 12, 46, 46, 52, 57, 41, 14, 16, 16]\n",
      "###### 1186 batch Train loss:0.9675 acc:0.7629 acc1:0.5033 mse:11141244 Test loss:0.7503 acc:0.7924 acc1:0.4631 mse:57947904\n",
      "\n",
      "2020-10-30 08:56:46\n",
      "[14, 18, 39, 21, 24, 76, 62, 38, 30, 72]\n",
      "[16, 11, 29, 18, 21, 79, 36, 29, 29, 20]\n",
      "###### 1187 batch Train loss:0.8035 acc:0.7849 acc1:0.5449 mse:10028354 Test loss:0.7382 acc:0.7931 acc1:0.4657 mse:53638932\n",
      "\n",
      "2020-10-30 08:56:48\n",
      "[7, 8, 10, 9, 13, 35, 27, 13, 5, 6]\n",
      "[7, 7, 11, 13, 13, 44, 25, 13, 11, 9]\n",
      "###### 1188 batch Train loss:0.6923 acc:0.7920 acc1:0.5041 mse:6974748 Test loss:0.7440 acc:0.7911 acc1:0.4618 mse:53175296\n",
      "\n",
      "2020-10-30 08:56:51\n",
      "[10, 9, 22, 11, 11, 105, 22, 23, 12, 9]\n",
      "[9, 6, 20, 12, 14, 57, 21, 17, 10, 8]\n",
      "###### 1189 batch Train loss:0.8480 acc:0.7759 acc1:0.5176 mse:9726900 Test loss:0.7489 acc:0.7900 acc1:0.4597 mse:52527980\n",
      "\n",
      "2020-10-30 08:56:53\n",
      "[6, 1, 3, 7, 8, 13, 3, 22, 12, 8]\n",
      "[5, 1, 4, 7, 7, 13, 8, 21, 12, 8]\n",
      "###### 1190 batch Train loss:0.5769 acc:0.7897 acc1:0.4620 mse:3993996 Test loss:0.7498 acc:0.7911 acc1:0.4617 mse:52198224\n",
      "\n",
      "2020-10-30 08:56:56\n",
      "[7, 11, 13, 23, 23, 61, 34, 11, 22, 18]\n",
      "[8, 9, 14, 15, 13, 45, 26, 14, 12, 10]\n",
      "###### 1191 batch Train loss:0.4104 acc:0.8381 acc1:0.4521 mse:2377530 Test loss:0.7561 acc:0.7922 acc1:0.4630 mse:53633788\n",
      "\n",
      "2020-10-30 08:56:58\n",
      "[35, 40, 127, 76, 149, 239, 187, 140, 93, 114]\n",
      "[31, 35, 104, 69, 122, 185, 190, 103, 97, 95]\n",
      "###### 1192 batch Train loss:0.7976 acc:0.7794 acc1:0.5062 mse:10759841 Test loss:0.7566 acc:0.7934 acc1:0.4647 mse:54054672\n",
      "\n",
      "2020-10-30 08:57:01\n",
      "[13, 15, 22, 15, 16, 19, 5, 8, 7, 4]\n",
      "[6, 11, 18, 13, 16, 21, 10, 4, 4, 4]\n",
      "###### 1193 batch Train loss:0.7213 acc:0.7915 acc1:0.5089 mse:7778308 Test loss:0.7510 acc:0.7953 acc1:0.4682 mse:52613940\n",
      "\n",
      "2020-10-30 08:57:03\n",
      "[38, 22, 91, 51, 139, 283, 164, 102, 133, 185]\n",
      "[49, 19, 101, 58, 155, 282, 176, 119, 138, 185]\n",
      "###### 1194 batch Train loss:0.5575 acc:0.8352 acc1:0.5156 mse:4756661 Test loss:0.7467 acc:0.7968 acc1:0.4712 mse:51816444\n",
      "\n",
      "2020-10-30 08:57:06\n",
      "[21, 12, 38, 23, 35, 106, 60, 26, 31, 23]\n",
      "[14, 11, 30, 23, 26, 88, 47, 28, 32, 27]\n",
      "###### 1195 batch Train loss:0.9285 acc:0.7812 acc1:0.5428 mse:9371389 Test loss:0.7368 acc:0.7975 acc1:0.4731 mse:50042588\n",
      "\n",
      "2020-10-30 08:57:08\n",
      "[12, 16, 45, 40, 52, 44, 39, 14, 15, 16]\n",
      "[11, 11, 40, 40, 45, 58, 38, 13, 15, 16]\n",
      "###### 1196 batch Train loss:0.7792 acc:0.8086 acc1:0.5199 mse:8720055 Test loss:0.7270 acc:0.7967 acc1:0.4720 mse:47580384\n",
      "\n",
      "2020-10-30 08:57:10\n",
      "[3, 0, 4, 7, 3, 6, 4, 13, 13, 12]\n",
      "[4, 3, 5, 7, 6, 15, 7, 21, 13, 8]\n",
      "###### 1197 batch Train loss:0.7151 acc:0.8182 acc1:0.5339 mse:9052214 Test loss:0.7234 acc:0.7951 acc1:0.4689 mse:45802180\n",
      "\n",
      "2020-10-30 08:57:13\n",
      "[5, 11, 2, 14, 12, 47, 25, 13, 15, 12]\n",
      "[6, 7, 9, 10, 12, 29, 25, 12, 10, 7]\n",
      "###### 1198 batch Train loss:0.5205 acc:0.7995 acc1:0.4788 mse:2944875 Test loss:0.7329 acc:0.7923 acc1:0.4634 mse:46815184\n",
      "\n",
      "2020-10-30 08:57:15\n",
      "[5, 9, 14, 14, 15, 40, 24, 19, 14, 7]\n",
      "[6, 8, 13, 11, 13, 37, 23, 13, 10, 9]\n",
      "###### 1199 batch Train loss:0.9819 acc:0.7694 acc1:0.5432 mse:9429319 Test loss:0.7322 acc:0.7918 acc1:0.4632 mse:47022704\n",
      "\n",
      "2020-10-30 08:57:18\n",
      "[15, 16, 45, 22, 20, 96, 43, 38, 33, 32]\n",
      "[13, 10, 20, 11, 16, 56, 31, 27, 21, 17]\n",
      "###### 1200 batch Train loss:0.7185 acc:0.7692 acc1:0.4749 mse:5306896 Test loss:0.7320 acc:0.7922 acc1:0.4644 mse:47929692\n",
      "\n",
      "2020-10-30 08:57:20\n",
      "[53, 21, 101, 51, 127, 249, 163, 115, 150, 178]\n",
      "[45, 18, 76, 50, 118, 219, 138, 108, 122, 164]\n",
      "###### 1201 batch Train loss:0.7819 acc:0.7780 acc1:0.5190 mse:7801593 Test loss:0.7374 acc:0.7917 acc1:0.4638 mse:49848444\n",
      "\n",
      "2020-10-30 08:57:23\n",
      "[4, 1, 3, 7, 5, 16, 7, 20, 16, 10]\n",
      "[4, 4, 6, 8, 5, 17, 7, 17, 11, 9]\n",
      "###### 1202 batch Train loss:0.7381 acc:0.7769 acc1:0.5034 mse:6331928 Test loss:0.7424 acc:0.7921 acc1:0.4641 mse:51702948\n",
      "\n",
      "2020-10-30 08:57:25\n",
      "[9, 7, 16, 13, 10, 24, 5, 4, 2, 10]\n",
      "[5, 10, 11, 9, 10, 23, 7, 4, 4, 3]\n",
      "###### 1203 batch Train loss:0.7259 acc:0.8191 acc1:0.5403 mse:8365350 Test loss:0.7428 acc:0.7927 acc1:0.4650 mse:51601952\n",
      "\n",
      "2020-10-30 08:57:28\n",
      "[32, 5, 30, 37, 52, 103, 54, 61, 74, 79]\n",
      "[35, 7, 24, 30, 45, 112, 49, 72, 80, 83]\n",
      "###### 1204 batch Train loss:0.7566 acc:0.7687 acc1:0.5023 mse:6043480 Test loss:0.7378 acc:0.7945 acc1:0.4685 mse:50210512\n",
      "\n",
      "2020-10-30 08:57:30\n",
      "[6, 10, 21, 13, 17, 47, 18, 19, 11, 9]\n",
      "[9, 7, 17, 13, 14, 55, 26, 20, 14, 11]\n",
      "###### 1205 batch Train loss:0.4847 acc:0.8240 acc1:0.4697 mse:2784978 Test loss:0.7416 acc:0.7954 acc1:0.4696 mse:51250864\n",
      "\n",
      "2020-10-30 08:57:33\n",
      "[3, 4, 17, 10, 14, 94, 25, 21, 13, 8]\n",
      "[8, 6, 16, 13, 13, 55, 26, 19, 13, 10]\n",
      "###### 1206 batch Train loss:0.6983 acc:0.7934 acc1:0.5043 mse:4888632 Test loss:0.7406 acc:0.7962 acc1:0.4711 mse:52002692\n",
      "\n",
      "2020-10-30 08:57:35\n",
      "[8, 7, 3, 9, 12, 16, 6, 3, 4, 6]\n",
      "[3, 7, 7, 8, 8, 15, 9, 4, 4, 2]\n",
      "###### 1207 batch Train loss:0.6297 acc:0.8151 acc1:0.5055 mse:4133164 Test loss:0.7356 acc:0.7974 acc1:0.4738 mse:52302840\n",
      "\n",
      "2020-10-30 08:57:37\n",
      "[46, 17, 86, 53, 140, 282, 181, 113, 153, 177]\n",
      "[46, 18, 83, 55, 141, 278, 159, 120, 143, 172]\n",
      "###### 1208 batch Train loss:0.7706 acc:0.8469 acc1:0.5502 mse:3053343 Test loss:0.7299 acc:0.7969 acc1:0.4737 mse:51264080\n",
      "\n",
      "2020-10-30 08:57:41\n",
      "[12, 5, 12, 13, 21, 53, 25, 25, 15, 9]\n",
      "[10, 7, 12, 11, 17, 49, 32, 21, 15, 10]\n",
      "###### 1209 batch Train loss:0.5068 acc:0.8255 acc1:0.4882 mse:4495409 Test loss:0.7333 acc:0.7953 acc1:0.4709 mse:51900072\n",
      "\n",
      "2020-10-30 08:57:44\n",
      "[6, 2, 1, 9, 8, 6, 8, 0, 2, 4]\n",
      "[2, 4, 4, 4, 5, 8, 7, 1, 2, 1]\n",
      "###### 1210 batch Train loss:0.5236 acc:0.8394 acc1:0.5216 mse:4303052 Test loss:0.7447 acc:0.7917 acc1:0.4641 mse:53425740\n",
      "\n",
      "2020-10-30 08:57:46\n",
      "[10, 17, 39, 38, 46, 53, 24, 3, 16, 9]\n",
      "[8, 16, 42, 38, 36, 51, 35, 12, 13, 10]\n",
      "###### 1211 batch Train loss:0.6765 acc:0.8127 acc1:0.5232 mse:5440648 Test loss:0.7568 acc:0.7874 acc1:0.4558 mse:54346384\n",
      "\n",
      "2020-10-30 08:57:49\n",
      "[53, 21, 101, 51, 127, 249, 163, 115, 150, 178]\n",
      "[45, 17, 83, 55, 122, 247, 150, 113, 146, 176]\n",
      "###### 1212 batch Train loss:0.7385 acc:0.8133 acc1:0.5457 mse:8818555 Test loss:0.7723 acc:0.7824 acc1:0.4455 mse:56024760\n",
      "\n",
      "2020-10-30 08:57:51\n",
      "[3, 12, 5, 4, 5, 8, 10, 5, 7, 5]\n",
      "[3, 5, 6, 5, 7, 8, 7, 3, 4, 2]\n",
      "###### 1213 batch Train loss:0.5772 acc:0.8492 acc1:0.5164 mse:6587808 Test loss:0.7931 acc:0.7775 acc1:0.4352 mse:58645160\n",
      "\n",
      "2020-10-30 08:57:54\n",
      "[20, 7, 12, 33, 23, 27, 22, 11, 16, 11]\n",
      "[8, 10, 16, 23, 28, 40, 20, 8, 15, 11]\n",
      "###### 1214 batch Train loss:0.5748 acc:0.7777 acc1:0.4508 mse:3122782 Test loss:0.8083 acc:0.7759 acc1:0.4308 mse:62441272\n",
      "\n",
      "2020-10-30 08:57:56\n",
      "[25, 8, 21, 36, 44, 128, 52, 75, 85, 84]\n",
      "[32, 4, 38, 35, 57, 136, 60, 79, 101, 109]\n",
      "###### 1215 batch Train loss:1.0428 acc:0.7306 acc1:0.4489 mse:13836979 Test loss:0.7614 acc:0.7853 acc1:0.4506 mse:55868472\n",
      "\n",
      "2020-10-30 08:57:58\n",
      "[8, 7, 13, 17, 27, 25, 23, 9, 5, 14]\n",
      "[6, 7, 10, 10, 13, 35, 21, 10, 9, 7]\n",
      "###### 1216 batch Train loss:0.7088 acc:0.7662 acc1:0.4713 mse:5289285 Test loss:0.7351 acc:0.7934 acc1:0.4663 mse:50383288\n",
      "\n",
      "2020-10-30 08:58:01\n",
      "[7, 9, 5, 6, 7, 13, 8, 3, 1, 1]\n",
      "[5, 6, 8, 8, 10, 15, 8, 1, 2, 1]\n",
      "###### 1217 batch Train loss:0.7265 acc:0.7862 acc1:0.5099 mse:10330763 Test loss:0.7378 acc:0.7971 acc1:0.4720 mse:49981228\n",
      "\n",
      "2020-10-30 08:58:03\n",
      "[16, 11, 54, 45, 44, 59, 47, 14, 13, 22]\n",
      "[11, 12, 40, 43, 47, 62, 40, 11, 16, 18]\n",
      "###### 1218 batch Train loss:0.7101 acc:0.7991 acc1:0.5246 mse:5468984 Test loss:0.7443 acc:0.7984 acc1:0.4733 mse:50487232\n",
      "\n",
      "2020-10-30 08:58:06\n",
      "[1, 2, 0, 1, 0, 0, 0, 1, 1, 0]\n",
      "[1, 1, 1, 1, 1, 7, 2, 2, 2, 2]\n",
      "###### 1219 batch Train loss:0.5312 acc:0.8105 acc1:0.4899 mse:3219260 Test loss:0.7558 acc:0.7990 acc1:0.4732 mse:52597484\n",
      "\n",
      "2020-10-30 08:58:08\n",
      "[7, 11, 13, 23, 23, 61, 34, 11, 22, 18]\n",
      "[7, 9, 13, 13, 12, 46, 24, 12, 12, 11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### 1220 batch Train loss:0.6919 acc:0.8186 acc1:0.5249 mse:7547267 Test loss:0.7586 acc:0.7989 acc1:0.4730 mse:53460900\n",
      "\n",
      "2020-10-30 08:58:11\n",
      "[9, 15, 30, 15, 29, 72, 52, 39, 41, 29]\n",
      "[15, 13, 31, 22, 27, 83, 39, 29, 31, 27]\n",
      "###### 1221 batch Train loss:0.9356 acc:0.7851 acc1:0.5301 mse:12475332 Test loss:0.7505 acc:0.7979 acc1:0.4718 mse:52116744\n",
      "\n",
      "2020-10-30 08:58:13\n",
      "[14, 18, 39, 21, 24, 76, 62, 38, 30, 72]\n",
      "[15, 11, 29, 18, 18, 87, 35, 26, 25, 21]\n",
      "###### 1222 batch Train loss:0.8883 acc:0.7844 acc1:0.5471 mse:9242958 Test loss:0.7451 acc:0.7958 acc1:0.4688 mse:50600404\n",
      "\n",
      "2020-10-30 08:58:16\n",
      "[3, 0, 4, 7, 3, 6, 4, 13, 13, 12]\n",
      "[4, 3, 5, 7, 6, 16, 7, 19, 13, 9]\n",
      "###### 1223 batch Train loss:0.6192 acc:0.7973 acc1:0.5024 mse:4614970 Test loss:0.7561 acc:0.7919 acc1:0.4614 mse:51811772\n",
      "\n",
      "2020-10-30 08:58:18\n",
      "[15, 14, 36, 17, 33, 95, 58, 29, 79, 23]\n",
      "[16, 18, 43, 27, 36, 105, 58, 33, 35, 33]\n",
      "###### 1224 batch Train loss:0.7607 acc:0.7699 acc1:0.5053 mse:6233764 Test loss:0.7744 acc:0.7877 acc1:0.4529 mse:54054372\n",
      "\n",
      "2020-10-30 08:58:21\n",
      "[5, 6, 8, 1, 2, 2, 5, 5, 3, 3]\n",
      "[1, 6, 4, 1, 2, 4, 2, 1, 0, 3]\n",
      "###### 1225 batch Train loss:0.4983 acc:0.8219 acc1:0.4509 mse:3285301 Test loss:0.7849 acc:0.7854 acc1:0.4484 mse:55453556\n",
      "\n",
      "2020-10-30 08:58:23\n",
      "[2, 3, 1, 1, 3, 3, 11, 2, 4, 4]\n",
      "[1, 5, 3, 1, 2, 3, 3, 1, 0, 2]\n",
      "###### 1226 batch Train loss:0.7024 acc:0.7966 acc1:0.5083 mse:5165106 Test loss:0.7847 acc:0.7846 acc1:0.4475 mse:54843660\n",
      "\n",
      "2020-10-30 08:58:25\n",
      "[12, 8, 45, 41, 54, 77, 50, 17, 12, 18]\n",
      "[13, 11, 42, 47, 48, 56, 44, 12, 16, 19]\n",
      "###### 1227 batch Train loss:0.5427 acc:0.8183 acc1:0.4962 mse:3548050 Test loss:0.7830 acc:0.7844 acc1:0.4471 mse:54637712\n",
      "\n",
      "2020-10-30 08:58:28\n",
      "[16, 10, 29, 16, 18, 86, 53, 41, 35, 30]\n",
      "[15, 11, 24, 16, 19, 63, 35, 27, 23, 21]\n",
      "###### 1228 batch Train loss:0.8183 acc:0.7760 acc1:0.4759 mse:7917924 Test loss:0.7602 acc:0.7886 acc1:0.4564 mse:52299452\n",
      "\n",
      "2020-10-30 08:58:30\n",
      "[11, 22, 42, 28, 33, 90, 53, 35, 23, 26]\n",
      "[17, 15, 38, 26, 36, 85, 64, 37, 37, 35]\n",
      "###### 1229 batch Train loss:0.8008 acc:0.8068 acc1:0.5038 mse:11719420 Test loss:0.7296 acc:0.7948 acc1:0.4697 mse:48420460\n",
      "\n",
      "2020-10-30 08:58:33\n",
      "[30, 41, 99, 82, 134, 202, 228, 92, 115, 102]\n",
      "[36, 36, 106, 69, 137, 221, 212, 113, 112, 122]\n",
      "###### 1230 batch Train loss:0.7295 acc:0.7958 acc1:0.5173 mse:7905658 Test loss:0.7303 acc:0.7986 acc1:0.4771 mse:49911772\n",
      "\n",
      "2020-10-30 08:58:35\n",
      "[2, 3, 3, 2, 1, 2, 4, 0, 0, 0]\n",
      "[1, 5, 3, 1, 2, 3, 3, 1, 0, 2]\n",
      "###### 1231 batch Train loss:0.7050 acc:0.8155 acc1:0.5194 mse:5945740 Test loss:0.7492 acc:0.7995 acc1:0.4782 mse:54201860\n",
      "\n",
      "2020-10-30 08:58:38\n",
      "[10, 5, 11, 10, 29, 62, 39, 19, 11, 5]\n",
      "[9, 6, 19, 11, 15, 51, 23, 18, 11, 9]\n",
      "###### 1232 batch Train loss:0.8313 acc:0.7728 acc1:0.5153 mse:6912610 Test loss:0.7657 acc:0.7990 acc1:0.4765 mse:57485200\n",
      "\n",
      "2020-10-30 08:58:40\n",
      "[6, 4, 6, 9, 14, 13, 4, 4, 3, 1]\n",
      "[5, 6, 7, 7, 9, 10, 11, 5, 4, 4]\n",
      "###### 1233 batch Train loss:0.8246 acc:0.7936 acc1:0.5206 mse:8571090 Test loss:0.7647 acc:0.7983 acc1:0.4752 mse:55793464\n",
      "\n",
      "2020-10-30 08:58:43\n",
      "[7, 7, 15, 22, 19, 26, 16, 6, 15, 7]\n",
      "[9, 8, 13, 20, 25, 35, 18, 10, 13, 9]\n",
      "###### 1234 batch Train loss:0.6120 acc:0.7825 acc1:0.4539 mse:4293919 Test loss:0.7629 acc:0.7983 acc1:0.4752 mse:53728024\n",
      "\n",
      "2020-10-30 08:58:45\n",
      "[7, 8, 17, 12, 13, 42, 26, 20, 10, 8]\n",
      "[7, 8, 10, 11, 14, 29, 26, 12, 10, 8]\n",
      "###### 1235 batch Train loss:0.7356 acc:0.8329 acc1:0.5296 mse:6105960 Test loss:0.7551 acc:0.7968 acc1:0.4729 mse:51601604\n",
      "\n",
      "2020-10-30 08:58:47\n",
      "[7, 11, 12, 8, 21, 27, 17, 11, 13, 7]\n",
      "[7, 8, 10, 11, 14, 31, 26, 12, 10, 8]\n",
      "###### 1236 batch Train loss:0.9814 acc:0.7818 acc1:0.5409 mse:11996101 Test loss:0.7368 acc:0.7939 acc1:0.4683 mse:47130372\n",
      "\n",
      "2020-10-30 08:58:50\n",
      "[11, 20, 47, 40, 35, 45, 29, 16, 7, 10]\n",
      "[8, 16, 42, 36, 34, 48, 34, 15, 12, 9]\n",
      "###### 1237 batch Train loss:0.6745 acc:0.7926 acc1:0.5109 mse:5641376 Test loss:0.7462 acc:0.7885 acc1:0.4575 mse:47492216\n",
      "\n",
      "2020-10-30 08:58:52\n",
      "[10, 6, 24, 7, 15, 45, 38, 15, 10, 18]\n",
      "[10, 7, 17, 9, 17, 37, 26, 18, 10, 9]\n",
      "###### 1238 batch Train loss:0.6210 acc:0.7780 acc1:0.4589 mse:3381258 Test loss:0.7762 acc:0.7825 acc1:0.4446 mse:52044208\n",
      "\n",
      "2020-10-30 08:58:55\n",
      "[24, 43, 105, 77, 126, 203, 199, 121, 111, 115]\n",
      "[32, 37, 105, 67, 114, 218, 209, 114, 116, 124]\n",
      "###### 1239 batch Train loss:1.2634 acc:0.7674 acc1:0.5492 mse:5568968 Test loss:0.7569 acc:0.7848 acc1:0.4507 mse:48424292\n",
      "\n",
      "2020-10-30 08:58:58\n",
      "[11, 22, 42, 28, 33, 90, 53, 35, 23, 26]\n",
      "[14, 14, 33, 22, 26, 75, 50, 32, 33, 24]\n",
      "###### 1240 batch Train loss:0.5783 acc:0.8203 acc1:0.5217 mse:4635499 Test loss:0.7436 acc:0.7873 acc1:0.4565 mse:46419624\n",
      "\n",
      "2020-10-30 08:59:01\n",
      "[1, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 1, 0, 2, 7, 3, 5, 2, 0]\n",
      "###### 1241 batch Train loss:0.6112 acc:0.8142 acc1:0.4930 mse:4884702 Test loss:0.7420 acc:0.7904 acc1:0.4626 mse:46657892\n",
      "\n",
      "2020-10-30 08:59:03\n",
      "[6, 4, 6, 9, 14, 13, 4, 4, 3, 1]\n",
      "[5, 6, 9, 8, 12, 13, 11, 7, 4, 3]\n",
      "###### 1242 batch Train loss:0.8490 acc:0.7888 acc1:0.5518 mse:7610821 Test loss:0.7441 acc:0.7937 acc1:0.4690 mse:47554408\n",
      "\n",
      "2020-10-30 08:59:06\n",
      "[4, 1, 6, 10, 6, 21, 5, 22, 16, 13]\n",
      "[4, 3, 7, 10, 7, 18, 7, 18, 14, 8]\n",
      "###### 1243 batch Train loss:0.6758 acc:0.7861 acc1:0.5080 mse:4962114 Test loss:0.7590 acc:0.7967 acc1:0.4744 mse:51598948\n",
      "\n",
      "2020-10-30 08:59:08\n",
      "[5, 11, 2, 14, 12, 47, 25, 13, 15, 12]\n",
      "[5, 6, 9, 9, 13, 32, 23, 12, 9, 5]\n",
      "###### 1244 batch Train loss:0.8170 acc:0.8109 acc1:0.5366 mse:7327220 Test loss:0.7637 acc:0.7974 acc1:0.4753 mse:52857576\n",
      "\n",
      "2020-10-30 08:59:11\n",
      "[4, 1, 2, 6, 7, 21, 4, 28, 10, 14]\n",
      "[4, 2, 5, 9, 7, 16, 7, 18, 13, 6]\n",
      "###### 1245 batch Train loss:0.6500 acc:0.8047 acc1:0.4895 mse:6196828 Test loss:0.7652 acc:0.7973 acc1:0.4747 mse:52794264\n",
      "\n",
      "2020-10-30 08:59:13\n",
      "[27, 34, 101, 76, 117, 209, 179, 104, 116, 110]\n",
      "[24, 34, 85, 63, 114, 166, 161, 101, 85, 81]\n",
      "###### 1246 batch Train loss:0.8924 acc:0.7804 acc1:0.5259 mse:10384953 Test loss:0.7545 acc:0.7963 acc1:0.4728 mse:49680024\n",
      "\n",
      "2020-10-30 08:59:16\n",
      "[5, 7, 7, 12, 10, 19, 14, 7, 4, 3]\n",
      "[4, 7, 9, 8, 11, 15, 7, 2, 1, 1]\n",
      "###### 1247 batch Train loss:0.7130 acc:0.7969 acc1:0.5112 mse:5549766 Test loss:0.7428 acc:0.7946 acc1:0.4697 mse:46619012\n",
      "\n",
      "2020-10-30 08:59:18\n",
      "[7, 10, 21, 9, 8, 20, 6, 7, 5, 5]\n",
      "[6, 9, 19, 12, 17, 22, 10, 7, 5, 3]\n",
      "###### 1248 batch Train loss:0.6282 acc:0.7853 acc1:0.4962 mse:4233498 Test loss:0.7394 acc:0.7928 acc1:0.4659 mse:45551576\n",
      "\n",
      "2020-10-30 08:59:21\n",
      "[4, 4, 8, 13, 13, 7, 7, 3, 7, 3]\n",
      "[3, 5, 6, 4, 8, 6, 7, 3, 0, 0]\n",
      "###### 1249 batch Train loss:0.8862 acc:0.8088 acc1:0.5213 mse:12629607 Test loss:0.7483 acc:0.7876 acc1:0.4549 mse:47352720\n",
      "\n",
      "2020-10-30 08:59:23\n",
      "[35, 36, 111, 76, 138, 228, 172, 111, 103, 105]\n",
      "[26, 42, 106, 73, 140, 217, 189, 120, 103, 111]\n",
      "###### 1250 batch Train loss:0.6215 acc:0.8334 acc1:0.5114 mse:5887608 Test loss:0.7652 acc:0.7839 acc1:0.4465 mse:50069180\n",
      "\n",
      "2020-10-30 08:59:26\n",
      "[2, 6, 4, 1, 2, 2, 4, 2, 1, 4]\n",
      "[0, 4, 3, 1, 3, 5, 2, 2, 0, 0]\n",
      "###### 1251 batch Train loss:0.4177 acc:0.8556 acc1:0.4725 mse:3299542 Test loss:0.7900 acc:0.7808 acc1:0.4384 mse:54179632\n",
      "\n",
      "2020-10-30 08:59:28\n",
      "[8, 5, 26, 16, 11, 96, 29, 14, 3, 10]\n",
      "[9, 6, 19, 12, 14, 61, 23, 19, 11, 8]\n",
      "###### 1252 batch Train loss:0.7332 acc:0.7460 acc1:0.4312 mse:4961130 Test loss:0.7858 acc:0.7836 acc1:0.4435 mse:54148028\n",
      "\n",
      "2020-10-30 08:59:31\n",
      "[15, 19, 42, 36, 26, 62, 31, 10, 10, 10]\n",
      "[10, 20, 47, 42, 37, 58, 29, 13, 11, 9]\n",
      "###### 1253 batch Train loss:0.8570 acc:0.7845 acc1:0.5152 mse:8118064 Test loss:0.7568 acc:0.7895 acc1:0.4562 mse:49589472\n",
      "\n",
      "2020-10-30 08:59:33\n",
      "[17, 9, 15, 8, 16, 39, 24, 15, 11, 13]\n",
      "[9, 9, 15, 15, 14, 50, 27, 15, 12, 10]\n",
      "###### 1254 batch Train loss:0.5482 acc:0.7901 acc1:0.4685 mse:2792494 Test loss:0.7453 acc:0.7933 acc1:0.4636 mse:48838816\n",
      "\n",
      "2020-10-30 08:59:36\n",
      "[2, 3, 12, 9, 11, 23, 11, 6, 2, 5]\n",
      "[6, 7, 9, 10, 12, 17, 9, 4, 2, 2]\n",
      "###### 1255 batch Train loss:0.7353 acc:0.7875 acc1:0.5317 mse:4453560 Test loss:0.7430 acc:0.7955 acc1:0.4682 mse:50596472\n",
      "\n",
      "2020-10-30 08:59:38\n",
      "[7, 9, 24, 11, 21, 32, 14, 12, 14, 10]\n",
      "[11, 11, 19, 23, 27, 43, 17, 12, 14, 11]\n",
      "###### 1256 batch Train loss:0.7757 acc:0.7847 acc1:0.4983 mse:8022623 Test loss:0.7473 acc:0.7971 acc1:0.4712 mse:52818844\n",
      "\n",
      "2020-10-30 08:59:41\n",
      "[54, 21, 87, 59, 142, 245, 167, 123, 135, 156]\n",
      "[45, 26, 102, 66, 153, 272, 174, 129, 133, 160]\n",
      "###### 1257 batch Train loss:0.7629 acc:0.7939 acc1:0.5222 mse:6848915 Test loss:0.7472 acc:0.7981 acc1:0.4742 mse:53393128\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-30 08:59:43\n",
      "[3, 7, 3, 5, 5, 6, 9, 5, 3, 3]\n",
      "[4, 5, 6, 4, 7, 7, 8, 2, 1, 2]\n",
      "###### 1258 batch Train loss:0.7463 acc:0.7825 acc1:0.5085 mse:6479518 Test loss:0.7467 acc:0.7986 acc1:0.4765 mse:53537392\n",
      "\n",
      "2020-10-30 08:59:46\n",
      "[12, 5, 12, 13, 21, 53, 25, 25, 15, 9]\n",
      "[11, 7, 13, 11, 19, 47, 31, 21, 13, 10]\n",
      "###### 1259 batch Train loss:0.7879 acc:0.7972 acc1:0.5145 mse:12303461 Test loss:0.7436 acc:0.7977 acc1:0.4760 mse:51873468\n",
      "\n",
      "2020-10-30 08:59:48\n",
      "[10, 8, 21, 19, 9, 103, 25, 15, 16, 11]\n",
      "[9, 6, 17, 12, 14, 58, 24, 17, 12, 10]\n",
      "###### 1260 batch Train loss:0.7149 acc:0.7978 acc1:0.5254 mse:8149314 Test loss:0.7465 acc:0.7957 acc1:0.4729 mse:50652016\n",
      "\n",
      "2020-10-30 08:59:51\n",
      "[0, 0, 1, 0, 0, 0, 1, 0, 2, 0]\n",
      "[1, 0, 1, 1, 2, 7, 2, 2, 1, 1]\n",
      "###### 1261 batch Train loss:0.4385 acc:0.8497 acc1:0.4606 mse:2962345 Test loss:0.7516 acc:0.7946 acc1:0.4712 mse:50940920\n",
      "\n",
      "2020-10-30 08:59:53\n",
      "[7, 7, 15, 22, 19, 26, 16, 6, 15, 7]\n",
      "[9, 8, 15, 17, 23, 39, 16, 9, 14, 10]\n",
      "###### 1262 batch Train loss:0.8751 acc:0.7748 acc1:0.5264 mse:7767872 Test loss:0.7478 acc:0.7931 acc1:0.4691 mse:50556900\n",
      "\n",
      "2020-10-30 08:59:56\n",
      "[8, 4, 9, 10, 4, 29, 24, 18, 13, 7]\n",
      "[7, 6, 8, 10, 13, 30, 25, 10, 10, 8]\n",
      "###### 1263 batch Train loss:0.6620 acc:0.7852 acc1:0.5062 mse:5325490 Test loss:0.7402 acc:0.7930 acc1:0.4693 mse:50122952\n",
      "\n",
      "2020-10-30 08:59:58\n",
      "[5, 7, 7, 13, 13, 13, 8, 2, 8, 2]\n",
      "[5, 6, 8, 8, 9, 14, 8, 0, 3, 3]\n",
      "###### 1264 batch Train loss:0.6179 acc:0.7694 acc1:0.4776 mse:3651099 Test loss:0.7375 acc:0.7931 acc1:0.4693 mse:50699844\n",
      "\n",
      "2020-10-30 09:00:01\n",
      "[3, 5, 4, 14, 13, 9, 6, 5, 3, 0]\n",
      "[3, 4, 4, 4, 7, 6, 10, 3, 4, 3]\n",
      "###### 1265 batch Train loss:0.7400 acc:0.7875 acc1:0.5229 mse:6458701 Test loss:0.7344 acc:0.7929 acc1:0.4687 mse:49146012\n",
      "\n",
      "2020-10-30 09:00:03\n",
      "[3, 0, 4, 7, 3, 6, 4, 13, 13, 12]\n",
      "[5, 2, 6, 8, 6, 18, 7, 20, 21, 9]\n",
      "###### 1266 batch Train loss:0.7632 acc:0.7873 acc1:0.5259 mse:6180226 Test loss:0.7272 acc:0.7926 acc1:0.4676 mse:46258888\n",
      "\n",
      "2020-10-30 09:00:06\n",
      "[14, 17, 38, 41, 32, 45, 37, 12, 15, 14]\n",
      "[10, 16, 40, 38, 35, 55, 34, 13, 15, 13]\n",
      "###### 1267 batch Train loss:0.6046 acc:0.8167 acc1:0.5122 mse:4327388 Test loss:0.7256 acc:0.7925 acc1:0.4667 mse:46213036\n",
      "\n",
      "2020-10-30 09:00:08\n",
      "[7, 20, 11, 13, 14, 82, 12, 10, 11, 11]\n",
      "[10, 9, 15, 21, 24, 41, 19, 10, 16, 11]\n",
      "###### 1268 batch Train loss:0.7059 acc:0.8009 acc1:0.5154 mse:6022566 Test loss:0.7265 acc:0.7925 acc1:0.4661 mse:47136320\n",
      "\n",
      "2020-10-30 09:00:11\n",
      "[6, 15, 30, 32, 33, 44, 34, 13, 12, 6]\n",
      "[8, 14, 37, 38, 35, 53, 33, 11, 12, 10]\n",
      "###### 1269 batch Train loss:0.6432 acc:0.8280 acc1:0.5196 mse:5813847 Test loss:0.7335 acc:0.7921 acc1:0.4645 mse:49182584\n",
      "\n",
      "2020-10-30 09:00:13\n",
      "[4, 2, 6, 8, 2, 10, 7, 22, 18, 10]\n",
      "[4, 2, 5, 8, 6, 19, 7, 17, 14, 10]\n",
      "###### 1270 batch Train loss:0.7025 acc:0.8238 acc1:0.5242 mse:3767008 Test loss:0.7366 acc:0.7922 acc1:0.4634 mse:49916940\n",
      "\n",
      "2020-10-30 09:00:17\n",
      "[12, 5, 12, 13, 21, 53, 25, 25, 15, 9]\n",
      "[11, 6, 12, 11, 18, 49, 34, 20, 15, 11]\n",
      "###### 1271 batch Train loss:0.7263 acc:0.7893 acc1:0.5150 mse:7940468 Test loss:0.7346 acc:0.7934 acc1:0.4645 mse:49608848\n",
      "\n",
      "2020-10-30 09:00:19\n",
      "[4, 1, 2, 6, 7, 21, 4, 28, 10, 14]\n",
      "[4, 2, 4, 6, 6, 17, 8, 18, 15, 8]\n",
      "###### 1272 batch Train loss:0.6578 acc:0.8148 acc1:0.5155 mse:5637021 Test loss:0.7290 acc:0.7951 acc1:0.4669 mse:47747192\n",
      "\n",
      "2020-10-30 09:00:22\n",
      "[10, 13, 45, 45, 56, 75, 51, 12, 25, 17]\n",
      "[11, 10, 37, 41, 43, 60, 35, 10, 17, 15]\n",
      "###### 1273 batch Train loss:0.7544 acc:0.8196 acc1:0.5384 mse:6442158 Test loss:0.7297 acc:0.7948 acc1:0.4655 mse:47284176\n",
      "\n",
      "2020-10-30 09:00:24\n",
      "[49, 5, 33, 34, 50, 109, 45, 60, 91, 81]\n",
      "[26, 4, 17, 28, 42, 107, 47, 64, 78, 78]\n",
      "###### 1274 batch Train loss:0.7986 acc:0.7797 acc1:0.5197 mse:6924072 Test loss:0.7276 acc:0.7950 acc1:0.4657 mse:46435248\n",
      "\n",
      "2020-10-30 09:00:27\n",
      "[13, 7, 13, 14, 24, 48, 39, 23, 11, 14]\n",
      "[12, 8, 13, 12, 17, 46, 36, 21, 17, 11]\n",
      "###### 1275 batch Train loss:0.5800 acc:0.8229 acc1:0.5116 mse:5120740 Test loss:0.7275 acc:0.7949 acc1:0.4657 mse:46580740\n",
      "\n",
      "2020-10-30 09:00:29\n",
      "[7, 8, 10, 9, 13, 35, 27, 13, 5, 6]\n",
      "[7, 7, 10, 12, 12, 40, 28, 12, 14, 10]\n",
      "###### 1276 batch Train loss:0.6489 acc:0.7867 acc1:0.4933 mse:5349341 Test loss:0.7302 acc:0.7950 acc1:0.4663 mse:47658768\n",
      "\n",
      "2020-10-30 09:00:31\n",
      "[12, 8, 17, 19, 23, 35, 39, 20, 14, 15]\n",
      "[9, 6, 14, 11, 14, 35, 29, 15, 13, 12]\n",
      "###### 1277 batch Train loss:0.6276 acc:0.7862 acc1:0.4975 mse:4529416 Test loss:0.7342 acc:0.7949 acc1:0.4665 mse:48841972\n",
      "\n",
      "2020-10-30 09:00:34\n",
      "[13, 10, 13, 22, 18, 26, 14, 4, 4, 4]\n",
      "[7, 9, 13, 11, 13, 19, 8, 5, 7, 4]\n",
      "###### 1278 batch Train loss:0.9272 acc:0.7771 acc1:0.5519 mse:10986923 Test loss:0.7284 acc:0.7957 acc1:0.4692 mse:46745672\n",
      "\n",
      "2020-10-30 09:00:36\n",
      "[14, 11, 13, 11, 15, 46, 27, 7, 13, 18]\n",
      "[10, 7, 16, 12, 15, 35, 30, 17, 14, 13]\n",
      "###### 1279 batch Train loss:0.6063 acc:0.7819 acc1:0.4895 mse:3450451 Test loss:0.7248 acc:0.7970 acc1:0.4730 mse:45524672\n",
      "\n",
      "2020-10-30 09:00:39\n",
      "[7, 20, 11, 13, 14, 82, 12, 10, 11, 11]\n",
      "[10, 10, 14, 21, 26, 36, 20, 12, 17, 11]\n",
      "###### 1280 batch Train loss:0.6916 acc:0.8092 acc1:0.5331 mse:6000418 Test loss:0.7223 acc:0.7972 acc1:0.4743 mse:43896348\n",
      "\n",
      "2020-10-30 09:00:41\n",
      "[0, 0, 0, 0, 2, 0, 0, 0, 0, 0]\n",
      "[1, 1, 2, 1, 1, 6, 3, 3, 4, 3]\n",
      "###### 1281 batch Train loss:0.6765 acc:0.8140 acc1:0.5192 mse:6005010 Test loss:0.7245 acc:0.7958 acc1:0.4723 mse:43237988\n",
      "\n",
      "2020-10-30 09:00:44\n",
      "[12, 14, 10, 20, 19, 42, 16, 10, 14, 12]\n",
      "[10, 10, 16, 22, 26, 39, 19, 11, 16, 11]\n",
      "###### 1282 batch Train loss:0.5470 acc:0.8294 acc1:0.4987 mse:3833186 Test loss:0.7287 acc:0.7942 acc1:0.4696 mse:43368428\n",
      "\n",
      "2020-10-30 09:00:46\n",
      "[24, 43, 105, 77, 126, 203, 199, 121, 111, 115]\n",
      "[35, 37, 110, 69, 123, 221, 208, 115, 119, 109]\n",
      "###### 1283 batch Train loss:0.7543 acc:0.7975 acc1:0.5325 mse:7212352 Test loss:0.7259 acc:0.7934 acc1:0.4686 mse:43055440\n",
      "\n",
      "2020-10-30 09:00:49\n",
      "[11, 9, 22, 9, 11, 109, 22, 25, 11, 6]\n",
      "[9, 6, 17, 12, 14, 57, 26, 18, 14, 9]\n",
      "###### 1284 batch Train loss:0.7765 acc:0.7727 acc1:0.5169 mse:6153240 Test loss:0.7303 acc:0.7915 acc1:0.4649 mse:45578908\n",
      "\n",
      "2020-10-30 09:00:51\n",
      "[1, 2, 0, 1, 0, 0, 0, 1, 1, 0]\n",
      "[1, 1, 1, 1, 1, 6, 2, 3, 2, 2]\n",
      "###### 1285 batch Train loss:0.5012 acc:0.8298 acc1:0.4626 mse:3630572 Test loss:0.7303 acc:0.7913 acc1:0.4644 mse:46905776\n",
      "\n",
      "2020-10-30 09:00:54\n",
      "[7, 8, 17, 12, 13, 42, 26, 20, 10, 8]\n",
      "[7, 9, 11, 11, 14, 31, 26, 14, 12, 9]\n",
      "###### 1286 batch Train loss:0.7511 acc:0.8123 acc1:0.5524 mse:6883435 Test loss:0.7204 acc:0.7926 acc1:0.4673 mse:44663436\n",
      "\n",
      "2020-10-30 09:00:56\n",
      "[10, 5, 11, 10, 29, 62, 39, 19, 11, 5]\n",
      "[8, 7, 20, 11, 15, 59, 23, 19, 12, 9]\n",
      "###### 1287 batch Train loss:0.6201 acc:0.7980 acc1:0.5078 mse:4343764 Test loss:0.7138 acc:0.7940 acc1:0.4697 mse:42089764\n",
      "\n",
      "2020-10-30 09:00:58\n",
      "[17, 13, 45, 41, 50, 83, 34, 18, 22, 14]\n",
      "[11, 13, 45, 44, 49, 63, 36, 13, 14, 17]\n",
      "###### 1288 batch Train loss:0.7875 acc:0.8110 acc1:0.5425 mse:7380834 Test loss:0.7074 acc:0.7954 acc1:0.4724 mse:39867120\n",
      "\n",
      "2020-10-30 09:01:01\n",
      "[5, 2, 5, 11, 10, 28, 39, 14, 9, 8]\n",
      "[7, 9, 10, 11, 14, 35, 24, 13, 11, 8]\n",
      "###### 1289 batch Train loss:0.7186 acc:0.7942 acc1:0.5447 mse:5135954 Test loss:0.7069 acc:0.7957 acc1:0.4730 mse:39443804\n",
      "\n",
      "2020-10-30 09:01:03\n",
      "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 0, 1, 0, 1, 6, 2, 3, 1, 1]\n",
      "###### 1290 batch Train loss:0.4708 acc:0.8208 acc1:0.4646 mse:2491404 Test loss:0.7097 acc:0.7965 acc1:0.4740 mse:40546692\n",
      "\n",
      "2020-10-30 09:01:06\n",
      "[9, 7, 16, 13, 10, 24, 5, 4, 2, 10]\n",
      "[6, 9, 11, 8, 12, 21, 5, 4, 1, 2]\n",
      "###### 1291 batch Train loss:0.6696 acc:0.8084 acc1:0.5088 mse:9261693 Test loss:0.7111 acc:0.7967 acc1:0.4737 mse:41176640\n",
      "\n",
      "2020-10-30 09:01:08\n",
      "[10, 17, 39, 38, 46, 53, 24, 3, 16, 9]\n",
      "[8, 16, 36, 35, 35, 45, 32, 14, 10, 9]\n",
      "###### 1292 batch Train loss:0.6622 acc:0.8071 acc1:0.5154 mse:5330954 Test loss:0.7088 acc:0.7969 acc1:0.4737 mse:40985092\n",
      "\n",
      "2020-10-30 09:01:11\n",
      "[11, 22, 42, 28, 33, 90, 53, 35, 23, 26]\n",
      "[15, 14, 33, 24, 33, 72, 46, 35, 31, 30]\n",
      "###### 1293 batch Train loss:0.6944 acc:0.8168 acc1:0.5300 mse:6963878 Test loss:0.7096 acc:0.7964 acc1:0.4721 mse:40998244\n",
      "\n",
      "2020-10-30 09:01:13\n",
      "[4, 9, 11, 9, 12, 35, 28, 14, 11, 7]\n",
      "[7, 8, 9, 11, 14, 34, 23, 13, 9, 7]\n",
      "###### 1294 batch Train loss:0.7405 acc:0.7759 acc1:0.5116 mse:4676814 Test loss:0.7180 acc:0.7947 acc1:0.4682 mse:42609220\n",
      "\n",
      "2020-10-30 09:01:16\n",
      "[4, 2, 6, 8, 2, 10, 7, 22, 18, 10]\n",
      "[4, 3, 5, 8, 6, 17, 6, 17, 11, 8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### 1295 batch Train loss:0.5243 acc:0.8301 acc1:0.4947 mse:4837182 Test loss:0.7253 acc:0.7938 acc1:0.4657 mse:44423228\n",
      "\n",
      "2020-10-30 09:01:18\n",
      "[13, 12, 42, 56, 50, 79, 38, 13, 15, 19]\n",
      "[12, 12, 46, 46, 51, 64, 41, 15, 15, 17]\n",
      "###### 1296 batch Train loss:0.6729 acc:0.8278 acc1:0.5435 mse:5308634 Test loss:0.7213 acc:0.7943 acc1:0.4667 mse:44084952\n",
      "\n",
      "2020-10-30 09:01:21\n",
      "[14, 6, 14, 4, 13, 32, 20, 13, 20, 9]\n",
      "[12, 9, 13, 17, 16, 32, 13, 8, 8, 8]\n",
      "###### 1297 batch Train loss:0.7230 acc:0.7802 acc1:0.4796 mse:4924272 Test loss:0.7163 acc:0.7965 acc1:0.4712 mse:43015460\n",
      "\n",
      "2020-10-30 09:01:23\n",
      "[3, 4, 17, 10, 14, 94, 25, 21, 13, 8]\n",
      "[8, 5, 17, 14, 14, 56, 23, 17, 11, 8]\n",
      "###### 1298 batch Train loss:0.5392 acc:0.7841 acc1:0.4646 mse:3046627 Test loss:0.7133 acc:0.7990 acc1:0.4761 mse:42487888\n",
      "\n",
      "2020-10-30 09:01:25\n",
      "[7, 9, 24, 11, 21, 32, 14, 12, 14, 10]\n",
      "[9, 10, 16, 20, 24, 34, 17, 11, 13, 10]\n",
      "###### 1299 batch Train loss:0.6386 acc:0.7868 acc1:0.5026 mse:3979021 Test loss:0.7155 acc:0.8010 acc1:0.4800 mse:42593532\n",
      "\n",
      "2020-10-30 09:01:28\n",
      "[11, 20, 47, 40, 35, 45, 29, 16, 7, 10]\n",
      "[8, 16, 37, 36, 33, 47, 31, 14, 10, 9]\n",
      "###### 1300 batch Train loss:0.8786 acc:0.7789 acc1:0.5257 mse:8172884 Test loss:0.7144 acc:0.8010 acc1:0.4804 mse:42421696\n",
      "\n",
      "2020-10-30 09:01:30\n",
      "[15, 8, 19, 12, 12, 61, 30, 26, 16, 12]\n",
      "[11, 8, 14, 13, 18, 48, 32, 22, 13, 10]\n",
      "###### 1301 batch Train loss:0.3923 acc:0.8417 acc1:0.4573 mse:643013 Test loss:0.7174 acc:0.8006 acc1:0.4801 mse:43576668\n",
      "\n",
      "2020-10-30 09:01:34\n",
      "[8, 8, 30, 8, 19, 49, 40, 30, 8, 13]\n",
      "[10, 7, 19, 10, 16, 38, 27, 17, 8, 11]\n",
      "###### 1302 batch Train loss:0.4485 acc:0.8263 acc1:0.5074 mse:2424416 Test loss:0.7210 acc:0.8001 acc1:0.4796 mse:45654608\n",
      "\n",
      "2020-10-30 09:01:36\n",
      "[34, 10, 19, 34, 40, 113, 54, 63, 86, 94]\n",
      "[31, 5, 19, 36, 37, 83, 39, 69, 71, 72]\n",
      "###### 1303 batch Train loss:0.6778 acc:0.7980 acc1:0.5371 mse:5153422 Test loss:0.7204 acc:0.7987 acc1:0.4779 mse:46410732\n",
      "\n",
      "2020-10-30 09:01:39\n",
      "[11, 22, 42, 28, 33, 90, 53, 35, 23, 26]\n",
      "[16, 12, 34, 24, 26, 78, 46, 32, 31, 26]\n",
      "###### 1304 batch Train loss:0.6975 acc:0.8220 acc1:0.5413 mse:8165081 Test loss:0.7196 acc:0.7959 acc1:0.4734 mse:45414700\n",
      "\n",
      "2020-10-30 09:01:41\n",
      "[7, 9, 5, 6, 7, 13, 8, 3, 1, 1]\n",
      "[4, 4, 7, 8, 10, 13, 8, 1, 1, 1]\n",
      "###### 1305 batch Train loss:0.7460 acc:0.7861 acc1:0.5247 mse:5621652 Test loss:0.7178 acc:0.7939 acc1:0.4705 mse:43532612\n",
      "\n",
      "2020-10-30 09:01:44\n",
      "[0, 5, 3, 4, 3, 7, 2, 1, 1, 1]\n",
      "[0, 3, 3, 0, 2, 3, 3, 1, 1, 1]\n",
      "###### 1306 batch Train loss:0.5575 acc:0.8063 acc1:0.4839 mse:3175311 Test loss:0.7184 acc:0.7924 acc1:0.4677 mse:42684000\n",
      "\n",
      "2020-10-30 09:01:46\n",
      "[4, 6, 6, 3, 8, 10, 6, 1, 0, 2]\n",
      "[1, 5, 6, 3, 3, 5, 4, 2, 1, 2]\n",
      "###### 1307 batch Train loss:0.5096 acc:0.8501 acc1:0.4873 mse:5047482 Test loss:0.7145 acc:0.7932 acc1:0.4690 mse:41331456\n",
      "\n",
      "2020-10-30 09:01:49\n",
      "[8, 10, 13, 17, 12, 44, 33, 17, 13, 11]\n",
      "[12, 8, 16, 13, 19, 50, 34, 23, 14, 11]\n",
      "###### 1308 batch Train loss:0.5037 acc:0.8201 acc1:0.4928 mse:3025186 Test loss:0.7155 acc:0.7943 acc1:0.4704 mse:41346392\n",
      "\n",
      "2020-10-30 09:01:51\n",
      "[5, 11, 2, 14, 12, 47, 25, 13, 15, 12]\n",
      "[6, 6, 11, 11, 12, 34, 25, 12, 10, 8]\n",
      "###### 1309 batch Train loss:0.5987 acc:0.7910 acc1:0.5072 mse:3338395 Test loss:0.7198 acc:0.7952 acc1:0.4713 mse:42716340\n",
      "\n",
      "2020-10-30 09:01:54\n",
      "[1, 2, 0, 0, 0, 0, 0, 1, 0, 0]\n",
      "[2, 2, 4, 2, 2, 6, 3, 3, 1, 2]\n",
      "###### 1310 batch Train loss:0.5493 acc:0.8265 acc1:0.5130 mse:4123053 Test loss:0.7223 acc:0.7966 acc1:0.4732 mse:43904200\n",
      "\n",
      "2020-10-30 09:01:56\n",
      "[15, 8, 19, 12, 12, 61, 30, 26, 16, 12]\n",
      "[12, 8, 16, 13, 18, 50, 34, 22, 13, 11]\n",
      "###### 1311 batch Train loss:0.7315 acc:0.8019 acc1:0.5288 mse:6366962 Test loss:0.7206 acc:0.7967 acc1:0.4730 mse:43839240\n",
      "\n",
      "2020-10-30 09:01:59\n",
      "[7, 11, 13, 23, 23, 61, 34, 11, 22, 18]\n",
      "[8, 8, 15, 14, 13, 48, 27, 14, 13, 11]\n",
      "###### 1312 batch Train loss:0.5680 acc:0.8132 acc1:0.5099 mse:3718432 Test loss:0.7211 acc:0.7960 acc1:0.4712 mse:43711824\n",
      "\n",
      "2020-10-30 09:02:01\n",
      "[9, 15, 30, 15, 29, 72, 52, 39, 41, 29]\n",
      "[16, 16, 40, 26, 33, 92, 61, 39, 36, 31]\n",
      "###### 1313 batch Train loss:0.5550 acc:0.8348 acc1:0.5193 mse:3471884 Test loss:0.7205 acc:0.7951 acc1:0.4694 mse:43008176\n",
      "\n",
      "2020-10-30 09:02:04\n",
      "[5, 16, 38, 30, 40, 41, 25, 12, 15, 12]\n",
      "[9, 16, 41, 38, 35, 46, 34, 14, 12, 11]\n",
      "###### 1314 batch Train loss:0.8356 acc:0.8156 acc1:0.5480 mse:8262919 Test loss:0.7103 acc:0.7959 acc1:0.4715 mse:40390656\n",
      "\n",
      "2020-10-30 09:02:06\n",
      "[48, 23, 85, 46, 135, 292, 170, 112, 145, 173]\n",
      "[48, 23, 99, 63, 153, 274, 179, 125, 143, 172]\n",
      "###### 1315 batch Train loss:0.5039 acc:0.8572 acc1:0.5376 mse:4003498 Test loss:0.7048 acc:0.7959 acc1:0.4720 mse:38665124\n",
      "\n",
      "2020-10-30 09:02:09\n",
      "[4, 11, 16, 14, 20, 38, 29, 17, 20, 9]\n",
      "[10, 8, 16, 11, 17, 42, 28, 21, 12, 10]\n",
      "###### 1316 batch Train loss:0.8774 acc:0.7751 acc1:0.5439 mse:8512833 Test loss:0.7083 acc:0.7947 acc1:0.4700 mse:38299620\n",
      "\n",
      "2020-10-30 09:02:11\n",
      "[17, 9, 15, 8, 16, 39, 24, 15, 11, 13]\n",
      "[8, 9, 13, 14, 13, 43, 27, 13, 14, 11]\n",
      "###### 1317 batch Train loss:0.6168 acc:0.7858 acc1:0.5034 mse:3550081 Test loss:0.7187 acc:0.7933 acc1:0.4672 mse:39575096\n",
      "\n",
      "2020-10-30 09:02:14\n",
      "[7, 11, 12, 8, 21, 27, 17, 11, 13, 7]\n",
      "[7, 9, 11, 12, 14, 33, 26, 13, 12, 9]\n",
      "###### 1318 batch Train loss:0.6338 acc:0.7735 acc1:0.4812 mse:3871251 Test loss:0.7227 acc:0.7940 acc1:0.4686 mse:40588480\n",
      "\n",
      "2020-10-30 09:02:16\n",
      "[4, 9, 11, 9, 12, 35, 28, 14, 11, 7]\n",
      "[7, 8, 10, 12, 13, 31, 25, 12, 12, 9]\n",
      "###### 1319 batch Train loss:0.5140 acc:0.7920 acc1:0.4615 mse:2476762 Test loss:0.7270 acc:0.7952 acc1:0.4708 mse:42186924\n",
      "\n",
      "2020-10-30 09:02:19\n",
      "[3, 5, 4, 14, 13, 9, 6, 5, 3, 0]\n",
      "[3, 5, 4, 4, 9, 7, 10, 4, 4, 2]\n",
      "###### 1320 batch Train loss:0.5328 acc:0.8024 acc1:0.4774 mse:2932370 Test loss:0.7297 acc:0.7967 acc1:0.4737 mse:43836772\n",
      "\n",
      "2020-10-30 09:02:21\n",
      "[10, 10, 40, 53, 50, 55, 41, 12, 17, 21]\n",
      "[12, 11, 39, 42, 46, 57, 37, 13, 17, 17]\n",
      "###### 1321 batch Train loss:0.8739 acc:0.7844 acc1:0.5324 mse:7140808 Test loss:0.7215 acc:0.7983 acc1:0.4772 mse:42837132\n",
      "\n",
      "2020-10-30 09:02:24\n",
      "[3, 0, 4, 7, 3, 6, 4, 13, 13, 12]\n",
      "[4, 3, 5, 6, 6, 15, 7, 24, 20, 8]\n",
      "###### 1322 batch Train loss:0.6064 acc:0.8159 acc1:0.5101 mse:8476116 Test loss:0.7163 acc:0.7993 acc1:0.4790 mse:41799088\n",
      "\n",
      "2020-10-30 09:02:26\n",
      "[42, 29, 108, 77, 133, 234, 205, 111, 96, 96]\n",
      "[31, 37, 102, 72, 133, 199, 186, 116, 109, 107]\n",
      "###### 1323 batch Train loss:0.7382 acc:0.7918 acc1:0.5429 mse:5820930 Test loss:0.7101 acc:0.7996 acc1:0.4797 mse:40288616\n",
      "\n",
      "2020-10-30 09:02:29\n",
      "[4, 4, 11, 5, 7, 13, 11, 2, 1, 2]\n",
      "[4, 5, 6, 8, 12, 10, 8, 2, 2, 2]\n",
      "###### 1324 batch Train loss:0.5452 acc:0.8327 acc1:0.5097 mse:3800388 Test loss:0.7060 acc:0.7993 acc1:0.4791 mse:39281776\n",
      "\n",
      "2020-10-30 09:02:31\n",
      "[16, 11, 54, 45, 44, 59, 47, 14, 13, 22]\n",
      "[12, 12, 41, 45, 49, 56, 38, 13, 17, 18]\n",
      "###### 1325 batch Train loss:1.0332 acc:0.7816 acc1:0.5585 mse:9327185 Test loss:0.7054 acc:0.7963 acc1:0.4735 mse:38929004\n",
      "\n",
      "2020-10-30 09:02:34\n",
      "[9, 8, 18, 17, 27, 87, 15, 7, 23, 7]\n",
      "[9, 9, 17, 24, 27, 35, 19, 10, 15, 11]\n",
      "###### 1326 batch Train loss:0.8793 acc:0.7795 acc1:0.5457 mse:6876181 Test loss:0.7153 acc:0.7923 acc1:0.4658 mse:40502196\n",
      "\n",
      "2020-10-30 09:02:36\n",
      "[3, 7, 3, 5, 5, 6, 9, 5, 3, 3]\n",
      "[4, 5, 6, 5, 9, 6, 10, 2, 2, 2]\n",
      "###### 1327 batch Train loss:0.5648 acc:0.7962 acc1:0.4970 mse:3662014 Test loss:0.7280 acc:0.7890 acc1:0.4586 mse:43942468\n",
      "\n",
      "2020-10-30 09:02:38\n",
      "[12, 14, 10, 20, 19, 42, 16, 10, 14, 12]\n",
      "[10, 10, 18, 25, 31, 40, 22, 10, 15, 12]\n",
      "###### 1328 batch Train loss:0.7369 acc:0.7768 acc1:0.4993 mse:6136493 Test loss:0.7263 acc:0.7894 acc1:0.4590 mse:42025876\n",
      "\n",
      "2020-10-30 09:02:41\n",
      "[8, 4, 9, 10, 4, 29, 24, 18, 13, 7]\n",
      "[7, 6, 8, 10, 13, 27, 25, 11, 10, 7]\n",
      "###### 1329 batch Train loss:0.8007 acc:0.7753 acc1:0.5290 mse:6250464 Test loss:0.7164 acc:0.7919 acc1:0.4638 mse:39176732\n",
      "\n",
      "2020-10-30 09:02:43\n",
      "[7, 7, 15, 22, 19, 26, 16, 6, 15, 7]\n",
      "[10, 8, 14, 20, 28, 38, 19, 10, 15, 10]\n",
      "###### 1330 batch Train loss:0.8243 acc:0.7692 acc1:0.5122 mse:6641660 Test loss:0.7121 acc:0.7939 acc1:0.4674 mse:38988556\n",
      "\n",
      "2020-10-30 09:02:46\n",
      "[22, 6, 13, 10, 15, 35, 28, 18, 8, 13]\n",
      "[10, 6, 14, 10, 14, 36, 29, 15, 10, 11]\n",
      "###### 1331 batch Train loss:0.6275 acc:0.8019 acc1:0.4961 mse:4329786 Test loss:0.7092 acc:0.7962 acc1:0.4716 mse:39086532\n",
      "\n",
      "2020-10-30 09:02:48\n",
      "[15, 6, 11, 7, 20, 30, 17, 6, 10, 13]\n",
      "[13, 7, 12, 14, 16, 30, 15, 7, 11, 10]\n",
      "###### 1332 batch Train loss:0.8349 acc:0.7879 acc1:0.5630 mse:2108284 Test loss:0.7107 acc:0.7974 acc1:0.4739 mse:40348876\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-30 09:02:52\n",
      "[4, 22, 47, 30, 35, 70, 36, 15, 11, 13]\n",
      "[9, 16, 38, 35, 36, 47, 32, 12, 12, 10]\n",
      "###### 1333 batch Train loss:0.6698 acc:0.8334 acc1:0.5390 mse:5855011 Test loss:0.7165 acc:0.7976 acc1:0.4740 mse:42244252\n",
      "\n",
      "2020-10-30 09:02:55\n",
      "[0, 0, 0, 0, 2, 0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 0, 1, 5, 2, 3, 1, 2]\n",
      "###### 1334 batch Train loss:0.7412 acc:0.8130 acc1:0.5407 mse:7061765 Test loss:0.7236 acc:0.7971 acc1:0.4726 mse:43633432\n",
      "\n",
      "2020-10-30 09:02:57\n",
      "[4, 4, 9, 9, 8, 13, 8, 2, 4, 5]\n",
      "[3, 5, 5, 4, 6, 7, 7, 0, 2, 3]\n",
      "###### 1335 batch Train loss:0.6784 acc:0.7990 acc1:0.4966 mse:5526283 Test loss:0.7237 acc:0.7974 acc1:0.4732 mse:42275528\n",
      "\n",
      "2020-10-30 09:02:59\n",
      "[42, 12, 30, 34, 50, 114, 49, 76, 75, 83]\n",
      "[33, 5, 23, 28, 50, 119, 53, 68, 85, 87]\n",
      "###### 1336 batch Train loss:0.6626 acc:0.7805 acc1:0.5043 mse:4330120 Test loss:0.7220 acc:0.7985 acc1:0.4753 mse:41262984\n",
      "\n",
      "2020-10-30 09:03:02\n",
      "[1, 6, 6, 1, 3, 5, 2, 0, 0, 7]\n",
      "[1, 4, 2, 0, 1, 2, 1, 0, 0, 1]\n",
      "###### 1337 batch Train loss:0.3154 acc:0.8845 acc1:0.4789 mse:2161188 Test loss:0.7250 acc:0.7993 acc1:0.4768 mse:42162412\n",
      "\n",
      "2020-10-30 09:03:04\n",
      "[3, 12, 5, 4, 5, 8, 10, 5, 7, 5]\n",
      "[3, 4, 4, 3, 6, 6, 6, 2, 2, 2]\n",
      "###### 1338 batch Train loss:0.6195 acc:0.8018 acc1:0.5108 mse:3949710 Test loss:0.7290 acc:0.7993 acc1:0.4766 mse:43295248\n",
      "\n",
      "2020-10-30 09:03:07\n",
      "[47, 20, 98, 40, 149, 249, 162, 113, 133, 173]\n",
      "[42, 18, 81, 47, 131, 222, 143, 101, 127, 161]\n",
      "###### 1339 batch Train loss:0.8172 acc:0.8154 acc1:0.5688 mse:7066313 Test loss:0.7238 acc:0.7979 acc1:0.4746 mse:42492804\n",
      "\n",
      "2020-10-30 09:03:09\n",
      "[19, 7, 13, 11, 19, 61, 32, 20, 14, 10]\n",
      "[10, 7, 12, 9, 17, 46, 29, 19, 13, 10]\n",
      "###### 1340 batch Train loss:0.5530 acc:0.8020 acc1:0.4980 mse:3384569 Test loss:0.7237 acc:0.7960 acc1:0.4716 mse:41882196\n",
      "\n",
      "2020-10-30 09:03:12\n",
      "[10, 8, 16, 16, 15, 39, 13, 5, 9, 17]\n",
      "[12, 8, 14, 12, 17, 33, 13, 7, 8, 9]\n",
      "###### 1341 batch Train loss:0.3540 acc:0.8699 acc1:0.4820 mse:1926284 Test loss:0.7299 acc:0.7938 acc1:0.4673 mse:42582488\n",
      "\n",
      "2020-10-30 09:03:14\n",
      "[8, 5, 26, 16, 11, 96, 29, 14, 3, 10]\n",
      "[8, 5, 15, 11, 13, 53, 22, 14, 11, 8]\n",
      "###### 1342 batch Train loss:0.6315 acc:0.7882 acc1:0.4845 mse:3692232 Test loss:0.7313 acc:0.7928 acc1:0.4656 mse:43075524\n",
      "\n",
      "2020-10-30 09:03:17\n",
      "[10, 8, 13, 20, 17, 38, 23, 14, 17, 16]\n",
      "[8, 8, 12, 13, 14, 42, 24, 11, 11, 10]\n",
      "###### 1343 batch Train loss:0.6508 acc:0.7971 acc1:0.5131 mse:4693773 Test loss:0.7287 acc:0.7926 acc1:0.4656 mse:43687576\n",
      "\n",
      "2020-10-30 09:03:19\n",
      "[32, 30, 100, 63, 117, 209, 186, 117, 112, 121]\n",
      "[30, 36, 105, 67, 118, 193, 194, 101, 98, 96]\n",
      "###### 1344 batch Train loss:0.7979 acc:0.7873 acc1:0.5364 mse:7298089 Test loss:0.7199 acc:0.7933 acc1:0.4677 mse:42721024\n",
      "\n",
      "2020-10-30 09:03:22\n",
      "[10, 13, 45, 45, 56, 75, 51, 12, 25, 17]\n",
      "[12, 11, 47, 44, 50, 66, 38, 11, 15, 18]\n",
      "###### 1345 batch Train loss:0.6896 acc:0.8114 acc1:0.5328 mse:5243232 Test loss:0.7130 acc:0.7937 acc1:0.4693 mse:41715180\n",
      "\n",
      "2020-10-30 09:03:24\n",
      "[7, 10, 21, 9, 8, 20, 6, 7, 5, 5]\n",
      "[8, 9, 17, 10, 18, 21, 13, 6, 7, 5]\n",
      "###### 1346 batch Train loss:0.7862 acc:0.7808 acc1:0.5100 mse:9920152 Test loss:0.7101 acc:0.7943 acc1:0.4707 mse:40279908\n",
      "\n",
      "2020-10-30 09:03:27\n",
      "[2, 7, 8, 8, 8, 7, 7, 5, 1, 3]\n",
      "[5, 6, 6, 8, 12, 14, 11, 4, 4, 5]\n",
      "###### 1347 batch Train loss:0.7181 acc:0.7720 acc1:0.5081 mse:4352120 Test loss:0.7138 acc:0.7955 acc1:0.4730 mse:40479624\n",
      "\n",
      "2020-10-30 09:03:29\n",
      "[2, 3, 12, 9, 11, 23, 11, 6, 2, 5]\n",
      "[5, 5, 7, 8, 11, 13, 10, 3, 3, 3]\n",
      "###### 1348 batch Train loss:0.6217 acc:0.8213 acc1:0.5311 mse:3915923 Test loss:0.7209 acc:0.7960 acc1:0.4734 mse:41855364\n",
      "\n",
      "2020-10-30 09:03:32\n",
      "[5, 8, 24, 10, 16, 38, 24, 8, 9, 9]\n",
      "[11, 6, 15, 11, 15, 36, 28, 15, 10, 12]\n",
      "###### 1349 batch Train loss:0.7221 acc:0.7921 acc1:0.5250 mse:5955446 Test loss:0.7214 acc:0.7970 acc1:0.4748 mse:42257120\n",
      "\n",
      "2020-10-30 09:03:34\n",
      "[4, 6, 5, 4, 9, 4, 14, 1, 0, 0]\n",
      "[3, 5, 5, 4, 7, 6, 7, 3, 2, 3]\n",
      "###### 1350 batch Train loss:0.5399 acc:0.8065 acc1:0.4841 mse:3952922 Test loss:0.7245 acc:0.7979 acc1:0.4759 mse:43095360\n",
      "\n",
      "2020-10-30 09:03:37\n",
      "[24, 8, 23, 40, 40, 128, 60, 60, 95, 81]\n",
      "[37, 5, 30, 38, 55, 131, 57, 79, 96, 98]\n",
      "###### 1351 batch Train loss:0.7984 acc:0.7791 acc1:0.5309 mse:7033370 Test loss:0.7280 acc:0.7980 acc1:0.4754 mse:43773892\n",
      "\n",
      "2020-10-30 09:03:39\n",
      "[1, 4, 2, 1, 2, 4, 3, 0, 2, 2]\n",
      "[1, 3, 1, 0, 1, 2, 2, 1, 0, 0]\n",
      "###### 1352 batch Train loss:0.5263 acc:0.7985 acc1:0.4739 mse:2558514 Test loss:0.7351 acc:0.7977 acc1:0.4742 mse:45331504\n",
      "\n",
      "2020-10-30 09:03:42\n",
      "[7, 11, 13, 23, 23, 61, 34, 11, 22, 18]\n",
      "[8, 8, 13, 15, 14, 42, 27, 14, 13, 12]\n",
      "###### 1353 batch Train loss:0.5578 acc:0.7941 acc1:0.4737 mse:3837548 Test loss:0.7407 acc:0.7978 acc1:0.4738 mse:46172504\n",
      "\n",
      "2020-10-30 09:03:44\n",
      "[17, 9, 15, 8, 16, 39, 24, 15, 11, 13]\n",
      "[8, 8, 12, 15, 13, 40, 27, 13, 13, 11]\n",
      "###### 1354 batch Train loss:1.1594 acc:0.7893 acc1:0.5775 mse:13391367 Test loss:0.7216 acc:0.7971 acc1:0.4732 mse:41810320\n",
      "\n",
      "2020-10-30 09:03:46\n",
      "[9, 7, 16, 13, 10, 24, 5, 4, 2, 10]\n",
      "[7, 8, 11, 9, 12, 22, 6, 3, 2, 2]\n",
      "###### 1355 batch Train loss:0.7196 acc:0.7872 acc1:0.5171 mse:5835898 Test loss:0.7105 acc:0.7961 acc1:0.4718 mse:39206880\n",
      "\n",
      "2020-10-30 09:03:49\n",
      "[4, 1, 6, 10, 6, 21, 5, 22, 16, 13]\n",
      "[4, 3, 6, 6, 6, 18, 7, 16, 10, 9]\n",
      "###### 1356 batch Train loss:0.6386 acc:0.7909 acc1:0.5176 mse:4452580 Test loss:0.7112 acc:0.7946 acc1:0.4689 mse:39281752\n",
      "\n",
      "2020-10-30 09:03:51\n",
      "[46, 17, 86, 53, 140, 282, 181, 113, 153, 177]\n",
      "[43, 19, 84, 54, 149, 268, 154, 109, 128, 163]\n",
      "###### 1357 batch Train loss:0.5875 acc:0.7964 acc1:0.4990 mse:3455349 Test loss:0.7210 acc:0.7927 acc1:0.4647 mse:41608532\n",
      "\n",
      "2020-10-30 09:03:54\n",
      "[11, 7, 16, 11, 22, 57, 32, 25, 11, 12]\n",
      "[11, 8, 15, 12, 17, 44, 28, 22, 11, 10]\n",
      "###### 1358 batch Train loss:0.6078 acc:0.8030 acc1:0.5032 mse:3648984 Test loss:0.7312 acc:0.7910 acc1:0.4613 mse:44540128\n",
      "\n",
      "2020-10-30 09:03:56\n",
      "[5, 12, 23, 16, 23, 29, 13, 7, 6, 3]\n",
      "[7, 9, 17, 13, 16, 20, 10, 5, 4, 3]\n",
      "###### 1359 batch Train loss:0.8524 acc:0.7931 acc1:0.5312 mse:7919834 Test loss:0.7167 acc:0.7932 acc1:0.4665 mse:41253432\n",
      "\n",
      "2020-10-30 09:03:59\n",
      "[25, 8, 21, 36, 44, 128, 52, 75, 85, 84]\n",
      "[32, 4, 24, 33, 49, 113, 49, 68, 79, 85]\n",
      "###### 1360 batch Train loss:0.4984 acc:0.8174 acc1:0.4760 mse:2868422 Test loss:0.7072 acc:0.7956 acc1:0.4716 mse:39691076\n",
      "\n",
      "2020-10-30 09:04:01\n",
      "[8, 8, 30, 8, 19, 49, 40, 30, 8, 13]\n",
      "[11, 8, 19, 10, 15, 39, 27, 19, 10, 11]\n",
      "###### 1361 batch Train loss:0.7217 acc:0.7820 acc1:0.5205 mse:4723040 Test loss:0.7017 acc:0.7974 acc1:0.4755 mse:40023052\n",
      "\n",
      "2020-10-30 09:04:04\n",
      "[21, 12, 38, 23, 35, 106, 60, 26, 31, 23]\n",
      "[15, 12, 30, 22, 23, 90, 43, 33, 31, 25]\n",
      "###### 1362 batch Train loss:0.7606 acc:0.8205 acc1:0.5536 mse:8449230 Test loss:0.7026 acc:0.7966 acc1:0.4744 mse:40670348\n",
      "\n",
      "2020-10-30 09:04:06\n",
      "[27, 34, 101, 76, 117, 209, 179, 104, 116, 110]\n",
      "[32, 36, 98, 72, 123, 215, 196, 116, 104, 101]\n",
      "###### 1363 batch Train loss:1.0842 acc:0.7885 acc1:0.5783 mse:4506458 Test loss:0.7071 acc:0.7960 acc1:0.4737 mse:40369560\n",
      "\n",
      "2020-10-30 09:04:10\n",
      "[11, 7, 16, 11, 22, 57, 32, 25, 11, 12]\n",
      "[11, 8, 15, 13, 16, 47, 29, 24, 12, 10]\n",
      "###### 1364 batch Train loss:0.4401 acc:0.8660 acc1:0.5415 mse:3701038 Test loss:0.7230 acc:0.7946 acc1:0.4709 mse:42186636\n",
      "\n",
      "2020-10-30 09:04:12\n",
      "[10, 17, 39, 38, 46, 53, 24, 3, 16, 9]\n",
      "[8, 15, 39, 37, 33, 46, 32, 14, 13, 10]\n",
      "###### 1365 batch Train loss:0.8849 acc:0.7833 acc1:0.5571 mse:6255589 Test loss:0.7268 acc:0.7930 acc1:0.4679 mse:42592196\n",
      "\n",
      "2020-10-30 09:04:15\n",
      "[27, 34, 101, 76, 117, 209, 179, 104, 116, 110]\n",
      "[33, 36, 107, 76, 126, 239, 205, 124, 115, 120]\n",
      "###### 1366 batch Train loss:0.7865 acc:0.7955 acc1:0.5459 mse:7071992 Test loss:0.7225 acc:0.7930 acc1:0.4685 mse:43231032\n",
      "\n",
      "2020-10-30 09:04:17\n",
      "[2, 6, 4, 1, 2, 2, 4, 2, 1, 4]\n",
      "[0, 4, 3, 2, 2, 2, 3, 2, 1, 1]\n",
      "###### 1367 batch Train loss:0.6350 acc:0.8241 acc1:0.5519 mse:5294692 Test loss:0.7143 acc:0.7937 acc1:0.4701 mse:41926872\n",
      "\n",
      "2020-10-30 09:04:20\n",
      "[24, 43, 105, 77, 126, 203, 199, 121, 111, 115]\n",
      "[33, 35, 108, 74, 119, 235, 207, 119, 119, 127]\n",
      "###### 1368 batch Train loss:0.7057 acc:0.8160 acc1:0.5491 mse:5808814 Test loss:0.7073 acc:0.7952 acc1:0.4733 mse:39516892\n",
      "\n",
      "2020-10-30 09:04:22\n",
      "[4, 4, 8, 13, 13, 7, 7, 3, 7, 3]\n",
      "[3, 5, 6, 6, 7, 7, 9, 2, 3, 1]\n",
      "###### 1369 batch Train loss:0.6464 acc:0.7942 acc1:0.5111 mse:4400859 Test loss:0.7070 acc:0.7963 acc1:0.4751 mse:38615728\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-30 09:04:25\n",
      "[6, 5, 15, 13, 14, 56, 24, 14, 8, 10]\n",
      "[8, 6, 21, 13, 13, 58, 25, 20, 14, 9]\n",
      "###### 1370 batch Train loss:0.5574 acc:0.8009 acc1:0.4955 mse:3742255 Test loss:0.7130 acc:0.7973 acc1:0.4759 mse:39888376\n",
      "\n",
      "2020-10-30 09:04:27\n",
      "[10, 8, 13, 20, 17, 38, 23, 14, 17, 16]\n",
      "[8, 8, 14, 14, 12, 43, 25, 14, 14, 9]\n",
      "###### 1371 batch Train loss:0.5799 acc:0.7768 acc1:0.4957 mse:3229618 Test loss:0.7230 acc:0.7975 acc1:0.4753 mse:42418072\n",
      "\n",
      "2020-10-30 09:04:29\n",
      "[28, 6, 24, 34, 51, 122, 44, 68, 76, 86]\n",
      "[23, 6, 17, 23, 22, 75, 35, 46, 58, 49]\n",
      "###### 1372 batch Train loss:0.4215 acc:0.8783 acc1:0.5030 mse:3209665 Test loss:0.7320 acc:0.7973 acc1:0.4739 mse:45089904\n",
      "\n",
      "2020-10-30 09:04:32\n",
      "[7, 26, 33, 43, 32, 52, 25, 18, 11, 11]\n",
      "[8, 16, 41, 34, 35, 44, 32, 13, 14, 10]\n",
      "###### 1373 batch Train loss:1.1041 acc:0.7835 acc1:0.5666 mse:13561299 Test loss:0.7235 acc:0.7962 acc1:0.4724 mse:43755092\n",
      "\n",
      "2020-10-30 09:04:34\n",
      "[1, 2, 0, 0, 0, 0, 0, 1, 0, 0]\n",
      "[1, 2, 3, 1, 1, 5, 2, 3, 3, 2]\n",
      "###### 1374 batch Train loss:0.5145 acc:0.8244 acc1:0.5027 mse:3523115 Test loss:0.7225 acc:0.7948 acc1:0.4696 mse:43448912\n",
      "\n",
      "2020-10-30 09:04:37\n",
      "[11, 22, 42, 28, 33, 90, 53, 35, 23, 26]\n",
      "[14, 12, 35, 20, 25, 64, 50, 29, 34, 26]\n",
      "###### 1375 batch Train loss:0.6741 acc:0.7918 acc1:0.5028 mse:5269217 Test loss:0.7223 acc:0.7938 acc1:0.4676 mse:42894416\n",
      "\n",
      "2020-10-30 09:04:39\n",
      "[10, 9, 14, 27, 27, 46, 40, 19, 11, 12]\n",
      "[10, 9, 14, 11, 18, 47, 34, 22, 15, 11]\n",
      "###### 1376 batch Train loss:0.4570 acc:0.8156 acc1:0.4780 mse:2424380 Test loss:0.7284 acc:0.7924 acc1:0.4645 mse:43427420\n",
      "\n",
      "2020-10-30 09:04:42\n",
      "[32, 30, 100, 63, 117, 209, 186, 117, 112, 121]\n",
      "[27, 32, 98, 68, 106, 193, 188, 97, 102, 90]\n",
      "###### 1377 batch Train loss:0.6553 acc:0.8036 acc1:0.4961 mse:5654322 Test loss:0.7298 acc:0.7924 acc1:0.4645 mse:43262712\n",
      "\n",
      "2020-10-30 09:04:44\n",
      "[15, 14, 36, 17, 33, 95, 58, 29, 79, 23]\n",
      "[14, 16, 46, 23, 32, 90, 59, 33, 39, 29]\n",
      "###### 1378 batch Train loss:0.5387 acc:0.7856 acc1:0.4672 mse:2920819 Test loss:0.7278 acc:0.7936 acc1:0.4667 mse:43143476\n",
      "\n",
      "2020-10-30 09:04:47\n",
      "[10, 8, 10, 8, 20, 35, 25, 9, 7, 16]\n",
      "[6, 6, 8, 9, 13, 31, 24, 11, 10, 6]\n",
      "###### 1379 batch Train loss:0.6028 acc:0.8280 acc1:0.5273 mse:5233986 Test loss:0.7200 acc:0.7956 acc1:0.4707 mse:42403376\n",
      "\n",
      "2020-10-30 09:04:49\n",
      "[7, 9, 24, 11, 21, 32, 14, 12, 14, 10]\n",
      "[9, 10, 16, 17, 22, 34, 18, 10, 15, 10]\n",
      "###### 1380 batch Train loss:1.0035 acc:0.7691 acc1:0.5371 mse:7708070 Test loss:0.7053 acc:0.7969 acc1:0.4738 mse:40754504\n",
      "\n",
      "2020-10-30 09:04:52\n",
      "[8, 10, 13, 17, 12, 44, 33, 17, 13, 11]\n",
      "[11, 9, 14, 10, 19, 44, 36, 22, 15, 11]\n",
      "###### 1381 batch Train loss:0.7341 acc:0.7789 acc1:0.5186 mse:4787036 Test loss:0.6999 acc:0.7976 acc1:0.4754 mse:40554832\n",
      "\n",
      "2020-10-30 09:04:54\n",
      "[7, 8, 17, 12, 13, 42, 26, 20, 10, 8]\n",
      "[7, 9, 11, 10, 14, 31, 27, 13, 11, 8]\n",
      "###### 1382 batch Train loss:0.6984 acc:0.7827 acc1:0.5037 mse:6344451 Test loss:0.7015 acc:0.7974 acc1:0.4747 mse:40990584\n",
      "\n",
      "2020-10-30 09:04:57\n",
      "[3, 0, 6, 9, 8, 7, 6, 19, 14, 10]\n",
      "[4, 2, 4, 6, 6, 14, 7, 22, 17, 11]\n",
      "###### 1383 batch Train loss:0.6399 acc:0.8224 acc1:0.5316 mse:5737196 Test loss:0.7044 acc:0.7962 acc1:0.4722 mse:40811888\n",
      "\n",
      "2020-10-30 09:04:59\n",
      "[3, 2, 1, 2, 2, 1, 0, 0, 0, 0]\n",
      "[1, 2, 2, 1, 2, 6, 3, 3, 2, 2]\n",
      "###### 1384 batch Train loss:0.6314 acc:0.8221 acc1:0.5126 mse:8734127 Test loss:0.7118 acc:0.7943 acc1:0.4682 mse:40891336\n",
      "\n",
      "2020-10-30 09:05:02\n",
      "[25, 36, 106, 85, 123, 195, 209, 111, 84, 103]\n",
      "[32, 36, 111, 72, 116, 217, 191, 110, 108, 105]\n",
      "###### 1385 batch Train loss:0.8814 acc:0.7719 acc1:0.5263 mse:8691357 Test loss:0.7079 acc:0.7945 acc1:0.4687 mse:39284164\n",
      "\n",
      "2020-10-30 09:05:04\n",
      "[3, 0, 4, 7, 3, 6, 4, 13, 13, 12]\n",
      "[6, 3, 6, 6, 7, 18, 7, 25, 20, 12]\n",
      "###### 1386 batch Train loss:0.5309 acc:0.8049 acc1:0.4859 mse:2833978 Test loss:0.7072 acc:0.7948 acc1:0.4692 mse:39070640\n",
      "\n",
      "2020-10-30 09:05:07\n",
      "[2, 3, 1, 1, 3, 3, 11, 2, 4, 4]\n",
      "[1, 5, 3, 0, 3, 3, 4, 1, 0, 1]\n",
      "###### 1387 batch Train loss:0.7016 acc:0.8030 acc1:0.5380 mse:4836726 Test loss:0.7044 acc:0.7955 acc1:0.4707 mse:39382776\n",
      "\n",
      "2020-10-30 09:05:09\n",
      "[8, 4, 9, 10, 4, 29, 24, 18, 13, 7]\n",
      "[7, 7, 8, 10, 14, 28, 26, 11, 10, 8]\n",
      "###### 1388 batch Train loss:0.6335 acc:0.7941 acc1:0.4941 mse:3870518 Test loss:0.7009 acc:0.7971 acc1:0.4740 mse:39870372\n",
      "\n",
      "2020-10-30 09:05:12\n",
      "[32, 5, 30, 37, 52, 103, 54, 61, 74, 79]\n",
      "[34, 8, 22, 33, 43, 111, 54, 66, 75, 82]\n",
      "###### 1389 batch Train loss:0.5943 acc:0.7863 acc1:0.4975 mse:3641964 Test loss:0.7004 acc:0.7988 acc1:0.4775 mse:40056844\n",
      "\n",
      "2020-10-30 09:05:14\n",
      "[8, 10, 40, 41, 39, 61, 40, 19, 17, 17]\n",
      "[12, 11, 44, 45, 55, 60, 42, 12, 15, 17]\n",
      "###### 1390 batch Train loss:0.7340 acc:0.8173 acc1:0.5522 mse:5307734 Test loss:0.6992 acc:0.7998 acc1:0.4794 mse:39517808\n",
      "\n",
      "2020-10-30 09:05:17\n",
      "[15, 8, 19, 12, 12, 61, 30, 26, 16, 12]\n",
      "[12, 9, 14, 12, 20, 43, 35, 24, 13, 11]\n",
      "###### 1391 batch Train loss:0.5706 acc:0.7964 acc1:0.4804 mse:3471794 Test loss:0.7006 acc:0.8007 acc1:0.4813 mse:39271348\n",
      "\n",
      "2020-10-30 09:05:19\n",
      "[14, 10, 7, 25, 19, 34, 14, 14, 7, 13]\n",
      "[13, 8, 13, 15, 17, 31, 15, 7, 9, 9]\n",
      "###### 1392 batch Train loss:0.6336 acc:0.7848 acc1:0.5011 mse:3779434 Test loss:0.7043 acc:0.8013 acc1:0.4824 mse:39973188\n",
      "\n",
      "2020-10-30 09:05:22\n",
      "[1, 4, 2, 1, 2, 4, 3, 0, 2, 2]\n",
      "[1, 4, 2, 0, 2, 2, 2, 1, 0, 0]\n",
      "###### 1393 batch Train loss:0.6334 acc:0.8142 acc1:0.5146 mse:5398258 Test loss:0.7055 acc:0.8013 acc1:0.4824 mse:40355096\n",
      "\n",
      "2020-10-30 09:05:24\n",
      "[4, 4, 9, 9, 8, 13, 8, 2, 4, 5]\n",
      "[4, 6, 6, 5, 7, 9, 8, 1, 1, 2]\n",
      "###### 1394 batch Train loss:0.7249 acc:0.7951 acc1:0.5094 mse:1940630 Test loss:0.7083 acc:0.8003 acc1:0.4810 mse:40949208\n",
      "\n",
      "2020-10-30 09:05:28\n",
      "[8, 8, 17, 18, 17, 45, 21, 6, 5, 6]\n",
      "[13, 8, 14, 15, 18, 35, 12, 8, 7, 8]\n",
      "###### 1395 batch Train loss:0.5894 acc:0.8129 acc1:0.5280 mse:4079607 Test loss:0.7100 acc:0.7991 acc1:0.4793 mse:41245088\n",
      "\n",
      "2020-10-30 09:05:30\n",
      "[9, 15, 13, 23, 32, 35, 25, 13, 24, 16]\n",
      "[10, 10, 15, 19, 22, 38, 16, 9, 12, 10]\n",
      "###### 1396 batch Train loss:0.6469 acc:0.7825 acc1:0.5132 mse:3917182 Test loss:0.7107 acc:0.7982 acc1:0.4779 mse:40600336\n",
      "\n",
      "2020-10-30 09:05:33\n",
      "[35, 40, 127, 76, 149, 239, 187, 140, 93, 114]\n",
      "[30, 35, 97, 75, 109, 175, 181, 104, 90, 88]\n",
      "###### 1397 batch Train loss:0.8177 acc:0.8114 acc1:0.5554 mse:11244055 Test loss:0.7075 acc:0.7967 acc1:0.4757 mse:38816148\n",
      "\n",
      "2020-10-30 09:05:35\n",
      "[8, 10, 13, 17, 12, 44, 33, 17, 13, 11]\n",
      "[12, 8, 14, 13, 20, 50, 33, 24, 14, 11]\n",
      "###### 1398 batch Train loss:0.6961 acc:0.7891 acc1:0.5493 mse:5451613 Test loss:0.7086 acc:0.7952 acc1:0.4732 mse:38038624\n",
      "\n",
      "2020-10-30 09:05:38\n",
      "[6, 1, 3, 7, 8, 13, 3, 22, 12, 8]\n",
      "[4, 1, 3, 9, 6, 15, 6, 21, 13, 8]\n",
      "###### 1399 batch Train loss:0.3975 acc:0.8643 acc1:0.4988 mse:2822939 Test loss:0.7150 acc:0.7939 acc1:0.4701 mse:39811528\n",
      "\n",
      "2020-10-30 09:05:40\n",
      "[15, 19, 42, 36, 26, 62, 31, 10, 10, 10]\n",
      "[10, 17, 41, 39, 35, 53, 29, 12, 13, 10]\n",
      "###### 1400 batch Train loss:0.6329 acc:0.7938 acc1:0.5110 mse:3978589 Test loss:0.7242 acc:0.7926 acc1:0.4668 mse:42964740\n",
      "\n",
      "2020-10-30 09:05:43\n",
      "[1, 4, 2, 1, 2, 4, 3, 0, 2, 2]\n",
      "[1, 4, 2, 1, 2, 3, 3, 1, 1, 1]\n",
      "###### 1401 batch Train loss:0.5792 acc:0.8042 acc1:0.5104 mse:3717351 Test loss:0.7291 acc:0.7921 acc1:0.4651 mse:45231140\n",
      "\n",
      "2020-10-30 09:05:45\n",
      "[10, 7, 11, 20, 11, 93, 28, 13, 6, 14]\n",
      "[9, 9, 12, 17, 13, 44, 25, 14, 13, 12]\n",
      "###### 1402 batch Train loss:0.6045 acc:0.7922 acc1:0.4912 mse:5141548 Test loss:0.7288 acc:0.7933 acc1:0.4663 mse:44987616\n",
      "\n",
      "2020-10-30 09:05:48\n",
      "[11, 7, 16, 11, 22, 57, 32, 25, 11, 12]\n",
      "[11, 9, 16, 13, 19, 53, 29, 23, 12, 11]\n",
      "###### 1403 batch Train loss:0.8318 acc:0.7825 acc1:0.5448 mse:6238488 Test loss:0.7218 acc:0.7938 acc1:0.4671 mse:42013328\n",
      "\n",
      "2020-10-30 09:05:50\n",
      "[15, 8, 19, 12, 12, 61, 30, 26, 16, 12]\n",
      "[12, 9, 15, 14, 19, 55, 34, 25, 15, 12]\n",
      "###### 1404 batch Train loss:0.6636 acc:0.7889 acc1:0.5065 mse:4375302 Test loss:0.7149 acc:0.7949 acc1:0.4689 mse:40086556\n",
      "\n",
      "2020-10-30 09:05:53\n",
      "[7, 9, 5, 6, 7, 13, 8, 3, 1, 1]\n",
      "[4, 5, 5, 8, 10, 15, 6, 2, 2, 2]\n",
      "###### 1405 batch Train loss:0.5624 acc:0.8276 acc1:0.5038 mse:5717326 Test loss:0.7102 acc:0.7958 acc1:0.4700 mse:39358624\n",
      "\n",
      "2020-10-30 09:05:55\n",
      "[37, 46, 119, 70, 157, 235, 203, 151, 101, 126]\n",
      "[32, 38, 110, 77, 125, 200, 188, 113, 100, 96]\n",
      "###### 1406 batch Train loss:0.7285 acc:0.7800 acc1:0.5209 mse:6109838 Test loss:0.7095 acc:0.7960 acc1:0.4696 mse:39502504\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-30 09:05:57\n",
      "[5, 8, 24, 10, 16, 38, 24, 8, 9, 9]\n",
      "[11, 6, 15, 12, 14, 35, 28, 17, 10, 11]\n",
      "###### 1407 batch Train loss:0.7243 acc:0.7786 acc1:0.4991 mse:5569634 Test loss:0.7062 acc:0.7969 acc1:0.4709 mse:39047680\n",
      "\n",
      "2020-10-30 09:06:00\n",
      "[6, 9, 5, 17, 26, 38, 29, 13, 13, 10]\n",
      "[8, 6, 11, 13, 11, 40, 25, 13, 12, 10]\n",
      "###### 1408 batch Train loss:0.5134 acc:0.8232 acc1:0.5089 mse:3675573 Test loss:0.7068 acc:0.7972 acc1:0.4712 mse:39364236\n",
      "\n",
      "2020-10-30 09:06:02\n",
      "[13, 15, 22, 15, 16, 19, 5, 8, 7, 4]\n",
      "[7, 11, 17, 12, 15, 25, 9, 4, 4, 4]\n",
      "###### 1409 batch Train loss:0.6842 acc:0.8073 acc1:0.5291 mse:4815642 Test loss:0.7114 acc:0.7963 acc1:0.4699 mse:40424056\n",
      "\n",
      "2020-10-30 09:06:05\n",
      "[1, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 0, 0, 0, 1, 8, 2, 3, 1, 1]\n",
      "###### 1410 batch Train loss:0.6564 acc:0.8136 acc1:0.5180 mse:4333532 Test loss:0.7162 acc:0.7954 acc1:0.4688 mse:41648816\n",
      "\n",
      "2020-10-30 09:06:07\n",
      "[53, 21, 101, 51, 127, 249, 163, 115, 150, 178]\n",
      "[45, 19, 83, 50, 130, 252, 150, 110, 133, 170]\n",
      "###### 1411 batch Train loss:0.8128 acc:0.8144 acc1:0.5583 mse:6750063 Test loss:0.7267 acc:0.7937 acc1:0.4661 mse:44140632\n",
      "\n",
      "2020-10-30 09:06:10\n",
      "[32, 5, 30, 37, 52, 103, 54, 61, 74, 79]\n",
      "[34, 8, 25, 30, 46, 126, 60, 66, 78, 83]\n",
      "###### 1412 batch Train loss:0.4976 acc:0.8046 acc1:0.4729 mse:2461804 Test loss:0.7338 acc:0.7933 acc1:0.4658 mse:46818476\n",
      "\n",
      "2020-10-30 09:06:12\n",
      "[54, 21, 87, 59, 142, 245, 167, 123, 135, 156]\n",
      "[48, 22, 94, 53, 144, 282, 174, 117, 143, 179]\n",
      "###### 1413 batch Train loss:0.6516 acc:0.8136 acc1:0.5201 mse:5239212 Test loss:0.7295 acc:0.7944 acc1:0.4687 mse:46937976\n",
      "\n",
      "2020-10-30 09:06:15\n",
      "[21, 12, 38, 23, 35, 106, 60, 26, 31, 23]\n",
      "[15, 13, 37, 20, 27, 105, 53, 32, 33, 28]\n",
      "###### 1414 batch Train loss:0.6412 acc:0.8090 acc1:0.4915 mse:6368748 Test loss:0.7157 acc:0.7969 acc1:0.4743 mse:43915300\n",
      "\n",
      "2020-10-30 09:06:17\n",
      "[3, 7, 3, 5, 5, 6, 9, 5, 3, 3]\n",
      "[3, 5, 6, 4, 7, 6, 8, 1, 2, 2]\n",
      "###### 1415 batch Train loss:0.6663 acc:0.8159 acc1:0.5415 mse:4677096 Test loss:0.7062 acc:0.7984 acc1:0.4777 mse:41745192\n",
      "\n",
      "2020-10-30 09:06:20\n",
      "[11, 20, 47, 40, 35, 45, 29, 16, 7, 10]\n",
      "[8, 16, 40, 30, 33, 49, 31, 13, 11, 9]\n",
      "###### 1416 batch Train loss:1.0175 acc:0.7880 acc1:0.5774 mse:10773614 Test loss:0.6959 acc:0.7990 acc1:0.4795 mse:38135436\n",
      "\n",
      "2020-10-30 09:06:22\n",
      "[10, 9, 14, 27, 27, 46, 40, 19, 11, 12]\n",
      "[11, 8, 15, 11, 19, 52, 33, 22, 13, 11]\n",
      "###### 1417 batch Train loss:0.6860 acc:0.8219 acc1:0.5514 mse:4905212 Test loss:0.6957 acc:0.7980 acc1:0.4778 mse:36896364\n",
      "\n",
      "2020-10-30 09:06:25\n",
      "[37, 12, 91, 52, 124, 265, 142, 115, 139, 151]\n",
      "[43, 18, 83, 49, 130, 250, 150, 110, 129, 162]\n",
      "###### 1418 batch Train loss:0.7320 acc:0.8226 acc1:0.5774 mse:6160281 Test loss:0.6995 acc:0.7956 acc1:0.4730 mse:38163992\n",
      "\n",
      "2020-10-30 09:06:27\n",
      "[10, 8, 21, 19, 9, 103, 25, 15, 16, 11]\n",
      "[8, 6, 18, 12, 15, 55, 25, 19, 12, 9]\n",
      "###### 1419 batch Train loss:0.7329 acc:0.7748 acc1:0.5028 mse:5678424 Test loss:0.7190 acc:0.7914 acc1:0.4637 mse:44233136\n",
      "\n",
      "2020-10-30 09:06:29\n",
      "[14, 6, 14, 4, 13, 32, 20, 13, 20, 9]\n",
      "[12, 8, 15, 16, 17, 33, 12, 6, 10, 9]\n",
      "###### 1420 batch Train loss:0.6146 acc:0.7776 acc1:0.4716 mse:4300491 Test loss:0.7388 acc:0.7893 acc1:0.4579 mse:49265452\n",
      "\n",
      "2020-10-30 09:06:32\n",
      "[7, 8, 10, 9, 13, 35, 27, 13, 5, 6]\n",
      "[7, 6, 10, 12, 13, 41, 25, 12, 11, 9]\n",
      "###### 1421 batch Train loss:0.6159 acc:0.8031 acc1:0.4748 mse:4462359 Test loss:0.7460 acc:0.7899 acc1:0.4578 mse:50595908\n",
      "\n",
      "2020-10-30 09:06:34\n",
      "[12, 5, 16, 16, 12, 33, 25, 6, 11, 12]\n",
      "[7, 8, 13, 15, 14, 44, 27, 13, 12, 11]\n",
      "###### 1422 batch Train loss:0.5949 acc:0.8096 acc1:0.4972 mse:4349780 Test loss:0.7397 acc:0.7926 acc1:0.4626 mse:47805144\n",
      "\n",
      "2020-10-30 09:06:37\n",
      "[4, 6, 6, 3, 8, 10, 6, 1, 0, 2]\n",
      "[1, 5, 5, 2, 3, 2, 4, 1, 1, 2]\n",
      "###### 1423 batch Train loss:0.5178 acc:0.8070 acc1:0.4590 mse:2884937 Test loss:0.7369 acc:0.7951 acc1:0.4668 mse:46444520\n",
      "\n",
      "2020-10-30 09:06:39\n",
      "[49, 5, 33, 34, 50, 109, 45, 60, 91, 81]\n",
      "[28, 4, 21, 35, 49, 127, 53, 73, 82, 94]\n",
      "###### 1424 batch Train loss:0.7565 acc:0.7641 acc1:0.4747 mse:6737516 Test loss:0.7239 acc:0.7991 acc1:0.4747 mse:42708692\n",
      "\n",
      "2020-10-30 09:06:42\n",
      "[0, 0, 1, 0, 0, 0, 1, 0, 2, 0]\n",
      "[1, 0, 0, 0, 1, 4, 2, 2, 1, 1]\n",
      "###### 1425 batch Train loss:0.3980 acc:0.8766 acc1:0.4855 mse:801541 Test loss:0.7249 acc:0.8013 acc1:0.4783 mse:43367320\n",
      "\n",
      "2020-10-30 09:06:45\n",
      "[17, 12, 32, 16, 28, 79, 36, 43, 32, 27]\n",
      "[15, 12, 34, 24, 34, 74, 47, 32, 35, 31]\n",
      "###### 1426 batch Train loss:0.7443 acc:0.8247 acc1:0.5665 mse:7453292 Test loss:0.7268 acc:0.8026 acc1:0.4809 mse:44045944\n",
      "\n",
      "2020-10-30 09:06:48\n",
      "[30, 41, 99, 82, 134, 202, 228, 92, 115, 102]\n",
      "[34, 35, 105, 74, 137, 209, 195, 116, 109, 119]\n",
      "###### 1427 batch Train loss:0.5722 acc:0.8422 acc1:0.5470 mse:5215358 Test loss:0.7338 acc:0.8030 acc1:0.4819 mse:44975424\n",
      "\n",
      "2020-10-30 09:06:51\n",
      "[12, 8, 45, 41, 54, 77, 50, 17, 12, 18]\n",
      "[11, 9, 38, 40, 46, 57, 35, 10, 14, 14]\n",
      "###### 1428 batch Train loss:0.5662 acc:0.8201 acc1:0.5081 mse:3951201 Test loss:0.7369 acc:0.8027 acc1:0.4820 mse:45439964\n",
      "\n",
      "2020-10-30 09:06:53\n",
      "[4, 1, 2, 6, 7, 21, 4, 28, 10, 14]\n",
      "[4, 2, 4, 5, 5, 15, 6, 17, 9, 7]\n",
      "###### 1429 batch Train loss:0.4824 acc:0.8261 acc1:0.4944 mse:2592792 Test loss:0.7404 acc:0.8020 acc1:0.4812 mse:46496792\n",
      "\n",
      "2020-10-30 09:06:56\n",
      "[6, 5, 15, 13, 14, 56, 24, 14, 8, 10]\n",
      "[9, 6, 18, 12, 13, 56, 24, 17, 12, 9]\n",
      "###### 1430 batch Train loss:0.6609 acc:0.8102 acc1:0.5256 mse:5309500 Test loss:0.7363 acc:0.8009 acc1:0.4801 mse:46099900\n",
      "\n",
      "2020-10-30 09:06:58\n",
      "[49, 5, 33, 34, 50, 109, 45, 60, 91, 81]\n",
      "[26, 4, 16, 25, 34, 103, 46, 54, 61, 65]\n",
      "###### 1431 batch Train loss:0.4710 acc:0.8264 acc1:0.4906 mse:2635312 Test loss:0.7342 acc:0.7997 acc1:0.4786 mse:46553072\n",
      "\n",
      "2020-10-30 09:07:01\n",
      "[32, 30, 100, 63, 117, 209, 186, 117, 112, 121]\n",
      "[29, 30, 90, 65, 101, 192, 173, 98, 88, 86]\n",
      "###### 1432 batch Train loss:0.5820 acc:0.8526 acc1:0.5326 mse:5697828 Test loss:0.7270 acc:0.7988 acc1:0.4776 mse:45569400\n",
      "\n",
      "2020-10-30 09:07:03\n",
      "[6, 15, 30, 32, 33, 44, 34, 13, 12, 6]\n",
      "[8, 15, 37, 34, 33, 45, 29, 11, 12, 8]\n",
      "###### 1433 batch Train loss:0.6828 acc:0.7977 acc1:0.5249 mse:5811698 Test loss:0.7205 acc:0.7969 acc1:0.4751 mse:43587056\n",
      "\n",
      "2020-10-30 09:07:06\n",
      "[5, 11, 13, 10, 17, 17, 9, 3, 7, 7]\n",
      "[8, 8, 14, 12, 15, 20, 11, 6, 7, 5]\n",
      "###### 1434 batch Train loss:0.6313 acc:0.7787 acc1:0.4951 mse:3923455 Test loss:0.7172 acc:0.7956 acc1:0.4731 mse:41804588\n",
      "\n",
      "2020-10-30 09:07:08\n",
      "[7, 11, 12, 8, 21, 27, 17, 11, 13, 7]\n",
      "[7, 9, 10, 13, 13, 36, 26, 14, 13, 10]\n",
      "###### 1435 batch Train loss:0.7838 acc:0.8181 acc1:0.5567 mse:6745068 Test loss:0.7086 acc:0.7955 acc1:0.4739 mse:39720340\n",
      "\n",
      "2020-10-30 09:07:11\n",
      "[6, 4, 6, 9, 14, 13, 4, 4, 3, 1]\n",
      "[5, 6, 7, 11, 12, 14, 11, 5, 6, 4]\n",
      "###### 1436 batch Train loss:0.6139 acc:0.7979 acc1:0.5105 mse:4041102 Test loss:0.7031 acc:0.7961 acc1:0.4754 mse:39169188\n",
      "\n",
      "2020-10-30 09:07:13\n",
      "[4, 4, 8, 13, 13, 7, 7, 3, 7, 3]\n",
      "[3, 5, 4, 7, 8, 8, 9, 2, 4, 3]\n",
      "###### 1437 batch Train loss:0.7518 acc:0.7933 acc1:0.5388 mse:5247110 Test loss:0.6992 acc:0.7965 acc1:0.4766 mse:38766320\n",
      "\n",
      "2020-10-30 09:07:16\n",
      "[13, 7, 13, 14, 24, 48, 39, 23, 11, 14]\n",
      "[12, 9, 14, 12, 19, 47, 33, 25, 16, 12]\n",
      "###### 1438 batch Train loss:0.6880 acc:0.7731 acc1:0.5119 mse:4489610 Test loss:0.6980 acc:0.7968 acc1:0.4773 mse:38746592\n",
      "\n",
      "2020-10-30 09:07:18\n",
      "[14, 10, 7, 25, 19, 34, 14, 14, 7, 13]\n",
      "[12, 9, 12, 15, 15, 36, 15, 10, 12, 11]\n",
      "###### 1439 batch Train loss:0.7316 acc:0.7935 acc1:0.5528 mse:4860134 Test loss:0.6991 acc:0.7960 acc1:0.4757 mse:38603480\n",
      "\n",
      "2020-10-30 09:07:21\n",
      "[47, 20, 98, 40, 149, 249, 162, 113, 133, 173]\n",
      "[45, 18, 82, 49, 130, 232, 156, 112, 138, 165]\n",
      "###### 1440 batch Train loss:0.6744 acc:0.8026 acc1:0.5519 mse:5319238 Test loss:0.7011 acc:0.7953 acc1:0.4738 mse:38360292\n",
      "\n",
      "2020-10-30 09:07:23\n",
      "[12, 16, 45, 40, 52, 44, 39, 14, 15, 16]\n",
      "[11, 12, 48, 46, 54, 71, 43, 17, 18, 18]\n",
      "###### 1441 batch Train loss:0.8185 acc:0.7932 acc1:0.5465 mse:7509528 Test loss:0.7158 acc:0.7916 acc1:0.4655 mse:39490520\n",
      "\n",
      "2020-10-30 09:07:26\n",
      "[1, 2, 0, 1, 0, 0, 0, 1, 1, 0]\n",
      "[1, 1, 0, 1, 1, 5, 1, 3, 2, 2]\n",
      "###### 1442 batch Train loss:0.5756 acc:0.8283 acc1:0.5259 mse:4208022 Test loss:0.7278 acc:0.7889 acc1:0.4592 mse:40344800\n",
      "\n",
      "2020-10-30 09:07:28\n",
      "[37, 46, 119, 70, 157, 235, 203, 151, 101, 126]\n",
      "[31, 39, 101, 72, 127, 175, 195, 114, 98, 99]\n",
      "###### 1443 batch Train loss:0.6200 acc:0.8494 acc1:0.5434 mse:5880410 Test loss:0.7340 acc:0.7879 acc1:0.4562 mse:40651404\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-30 09:07:30\n",
      "[16, 9, 54, 51, 54, 59, 43, 5, 16, 16]\n",
      "[12, 14, 48, 48, 56, 73, 45, 16, 18, 20]\n",
      "###### 1444 batch Train loss:0.9516 acc:0.7786 acc1:0.5511 mse:11388727 Test loss:0.7201 acc:0.7910 acc1:0.4621 mse:38948444\n",
      "\n",
      "2020-10-30 09:07:33\n",
      "[5, 12, 23, 16, 23, 29, 13, 7, 6, 3]\n",
      "[7, 11, 17, 12, 19, 22, 11, 7, 7, 5]\n",
      "###### 1445 batch Train loss:0.7046 acc:0.7762 acc1:0.5075 mse:4729356 Test loss:0.7067 acc:0.7953 acc1:0.4703 mse:37803536\n",
      "\n",
      "2020-10-30 09:07:35\n",
      "[10, 8, 21, 19, 9, 103, 25, 15, 16, 11]\n",
      "[8, 8, 16, 13, 14, 60, 24, 19, 13, 11]\n",
      "###### 1446 batch Train loss:0.3484 acc:0.8714 acc1:0.4760 mse:1936619 Test loss:0.7105 acc:0.7976 acc1:0.4739 mse:39536324\n",
      "\n",
      "2020-10-30 09:07:38\n",
      "[5, 16, 38, 30, 40, 41, 25, 12, 15, 12]\n",
      "[9, 18, 37, 34, 35, 47, 30, 15, 13, 10]\n",
      "###### 1447 batch Train loss:0.7681 acc:0.7812 acc1:0.5317 mse:5495190 Test loss:0.7180 acc:0.7986 acc1:0.4752 mse:41514080\n",
      "\n",
      "2020-10-30 09:07:40\n",
      "[32, 5, 30, 37, 52, 103, 54, 61, 74, 79]\n",
      "[33, 9, 29, 34, 54, 133, 50, 76, 80, 89]\n",
      "###### 1448 batch Train loss:0.6136 acc:0.7728 acc1:0.4777 mse:3326470 Test loss:0.7214 acc:0.8005 acc1:0.4785 mse:43145104\n",
      "\n",
      "2020-10-30 09:07:43\n",
      "[14, 6, 14, 4, 13, 32, 20, 13, 20, 9]\n",
      "[14, 9, 13, 16, 15, 34, 11, 7, 10, 10]\n",
      "###### 1449 batch Train loss:0.6545 acc:0.7715 acc1:0.4858 mse:4319084 Test loss:0.7300 acc:0.8015 acc1:0.4799 mse:45344792\n",
      "\n",
      "2020-10-30 09:07:45\n",
      "[4, 22, 47, 30, 35, 70, 36, 15, 11, 13]\n",
      "[10, 17, 36, 34, 32, 45, 26, 11, 11, 9]\n",
      "###### 1450 batch Train loss:0.8312 acc:0.7934 acc1:0.5332 mse:5933636 Test loss:0.7284 acc:0.8013 acc1:0.4800 mse:45934064\n",
      "\n",
      "2020-10-30 09:07:48\n",
      "[24, 8, 23, 40, 40, 128, 60, 60, 95, 81]\n",
      "[37, 7, 32, 39, 61, 140, 48, 84, 87, 102]\n",
      "###### 1451 batch Train loss:0.6192 acc:0.7861 acc1:0.4987 mse:3663436 Test loss:0.7243 acc:0.8011 acc1:0.4804 mse:45434712\n",
      "\n",
      "2020-10-30 09:07:50\n",
      "[8, 7, 13, 17, 27, 25, 23, 9, 5, 14]\n",
      "[7, 7, 11, 10, 12, 31, 20, 11, 8, 7]\n",
      "###### 1452 batch Train loss:0.6804 acc:0.7905 acc1:0.5174 mse:5077560 Test loss:0.7203 acc:0.7998 acc1:0.4791 mse:44797032\n",
      "\n",
      "2020-10-30 09:07:53\n",
      "[16, 3, 15, 7, 13, 45, 23, 15, 16, 8]\n",
      "[7, 8, 14, 12, 13, 43, 23, 12, 10, 10]\n",
      "###### 1453 batch Train loss:0.5820 acc:0.8091 acc1:0.4939 mse:4971442 Test loss:0.7160 acc:0.7984 acc1:0.4770 mse:43371208\n",
      "\n",
      "2020-10-30 09:07:55\n",
      "[4, 11, 16, 14, 20, 38, 29, 17, 20, 9]\n",
      "[11, 8, 15, 11, 18, 40, 26, 20, 10, 10]\n",
      "###### 1454 batch Train loss:0.6672 acc:0.8050 acc1:0.5146 mse:6926669 Test loss:0.7177 acc:0.7957 acc1:0.4722 mse:42782464\n",
      "\n",
      "2020-10-30 09:07:58\n",
      "[10, 9, 22, 11, 11, 105, 22, 23, 12, 9]\n",
      "[10, 6, 21, 12, 14, 58, 24, 16, 10, 9]\n",
      "###### 1455 batch Train loss:0.7028 acc:0.7811 acc1:0.5086 mse:4752232 Test loss:0.7214 acc:0.7932 acc1:0.4674 mse:42525952\n",
      "\n",
      "2020-10-30 09:08:00\n",
      "[1, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 0, 0, 0, 1, 6, 1, 2, 1, 1]\n",
      "###### 1456 batch Train loss:0.3426 acc:0.8922 acc1:0.5263 mse:807402 Test loss:0.7201 acc:0.7926 acc1:0.4663 mse:42577220\n",
      "\n",
      "2020-10-30 09:08:04\n",
      "[28, 6, 24, 34, 51, 122, 44, 68, 76, 86]\n",
      "[28, 7, 25, 32, 36, 98, 42, 64, 75, 73]\n",
      "###### 1457 batch Train loss:0.5730 acc:0.7775 acc1:0.4997 mse:2718566 Test loss:0.7236 acc:0.7919 acc1:0.4643 mse:43748552\n",
      "\n",
      "2020-10-30 09:08:06\n",
      "[10, 11, 14, 12, 18, 37, 33, 21, 15, 12]\n",
      "[12, 8, 21, 13, 15, 41, 30, 16, 11, 12]\n",
      "###### 1458 batch Train loss:0.5798 acc:0.7810 acc1:0.4798 mse:3191451 Test loss:0.7185 acc:0.7935 acc1:0.4669 mse:44181360\n",
      "\n",
      "2020-10-30 09:08:09\n",
      "[6, 4, 6, 9, 14, 13, 4, 4, 3, 1]\n",
      "[5, 5, 10, 9, 10, 11, 12, 5, 3, 4]\n",
      "###### 1459 batch Train loss:0.5535 acc:0.8342 acc1:0.5178 mse:4616693 Test loss:0.7095 acc:0.7959 acc1:0.4712 mse:42965764\n",
      "\n",
      "2020-10-30 09:08:11\n",
      "[16, 10, 29, 16, 18, 86, 53, 41, 35, 30]\n",
      "[15, 10, 24, 14, 20, 71, 40, 30, 21, 18]\n",
      "###### 1460 batch Train loss:0.5562 acc:0.8155 acc1:0.5047 mse:4168330 Test loss:0.7036 acc:0.7978 acc1:0.4746 mse:41216872\n",
      "\n",
      "2020-10-30 09:08:14\n",
      "[13, 10, 13, 22, 18, 26, 14, 4, 4, 4]\n",
      "[7, 9, 18, 13, 14, 19, 9, 3, 4, 3]\n",
      "###### 1461 batch Train loss:0.5117 acc:0.8374 acc1:0.5156 mse:3686667 Test loss:0.7020 acc:0.7987 acc1:0.4759 mse:40109340\n",
      "\n",
      "2020-10-30 09:08:16\n",
      "[13, 15, 22, 15, 16, 19, 5, 8, 7, 4]\n",
      "[7, 10, 20, 13, 15, 18, 10, 3, 4, 3]\n",
      "###### 1462 batch Train loss:0.5966 acc:0.7840 acc1:0.4899 mse:3687406 Test loss:0.7029 acc:0.7993 acc1:0.4766 mse:39835100\n",
      "\n",
      "2020-10-30 09:08:19\n",
      "[12, 5, 12, 13, 21, 53, 25, 25, 15, 9]\n",
      "[10, 6, 12, 10, 17, 42, 34, 21, 13, 10]\n",
      "###### 1463 batch Train loss:0.6719 acc:0.7837 acc1:0.5189 mse:4543831 Test loss:0.7020 acc:0.7999 acc1:0.4778 mse:39169664\n",
      "\n",
      "2020-10-30 09:08:21\n",
      "[9, 1, 3, 7, 8, 15, 4, 24, 16, 9]\n",
      "[3, 1, 3, 5, 6, 17, 6, 24, 15, 8]\n",
      "###### 1464 batch Train loss:0.6477 acc:0.8104 acc1:0.5256 mse:5968782 Test loss:0.6996 acc:0.7996 acc1:0.4774 mse:38328012\n",
      "\n",
      "2020-10-30 09:08:24\n",
      "[38, 22, 91, 51, 139, 283, 164, 102, 133, 185]\n",
      "[48, 19, 93, 53, 151, 269, 164, 118, 136, 178]\n",
      "###### 1465 batch Train loss:0.7317 acc:0.8344 acc1:0.5821 mse:6361111 Test loss:0.6980 acc:0.7986 acc1:0.4761 mse:37712444\n",
      "\n",
      "2020-10-30 09:08:26\n",
      "[15, 12, 15, 12, 15, 40, 27, 16, 12, 11]\n",
      "[9, 8, 17, 11, 15, 36, 28, 16, 12, 11]\n",
      "###### 1466 batch Train loss:0.6364 acc:0.8139 acc1:0.5299 mse:4700198 Test loss:0.7029 acc:0.7967 acc1:0.4727 mse:38131808\n",
      "\n",
      "2020-10-30 09:08:28\n",
      "[4, 8, 7, 5, 7, 22, 12, 3, 6, 1]\n",
      "[3, 5, 5, 4, 7, 9, 8, 3, 3, 2]\n",
      "###### 1467 batch Train loss:0.4471 acc:0.8452 acc1:0.4972 mse:2590324 Test loss:0.7111 acc:0.7947 acc1:0.4687 mse:39203608\n",
      "\n",
      "2020-10-30 09:08:31\n",
      "[6, 2, 1, 9, 8, 6, 8, 0, 2, 4]\n",
      "[2, 4, 4, 4, 7, 7, 8, 1, 2, 1]\n",
      "###### 1468 batch Train loss:0.5862 acc:0.8068 acc1:0.5105 mse:3897625 Test loss:0.7194 acc:0.7931 acc1:0.4654 mse:40660640\n",
      "\n",
      "2020-10-30 09:08:33\n",
      "[14, 6, 14, 4, 13, 32, 20, 13, 20, 9]\n",
      "[11, 9, 13, 16, 15, 32, 13, 8, 12, 10]\n",
      "###### 1469 batch Train loss:0.7263 acc:0.7824 acc1:0.5183 mse:5130876 Test loss:0.7138 acc:0.7942 acc1:0.4680 mse:39972844\n",
      "\n",
      "2020-10-30 09:08:36\n",
      "[36, 10, 28, 31, 44, 118, 51, 72, 61, 79]\n",
      "[32, 7, 34, 34, 57, 130, 60, 82, 101, 113]\n",
      "###### 1470 batch Train loss:0.7095 acc:0.7997 acc1:0.5227 mse:4833241 Test loss:0.7049 acc:0.7961 acc1:0.4721 mse:38789088\n",
      "\n",
      "2020-10-30 09:08:38\n",
      "[14, 8, 16, 26, 34, 23, 15, 10, 11, 8]\n",
      "[9, 9, 13, 18, 25, 35, 16, 10, 15, 10]\n",
      "###### 1471 batch Train loss:0.7249 acc:0.7711 acc1:0.4948 mse:4882388 Test loss:0.6940 acc:0.7993 acc1:0.4787 mse:37082488\n",
      "\n",
      "2020-10-30 09:08:41\n",
      "[7, 9, 5, 6, 7, 13, 8, 3, 1, 1]\n",
      "[4, 5, 5, 7, 11, 13, 7, 1, 2, 1]\n",
      "###### 1472 batch Train loss:0.5021 acc:0.8249 acc1:0.5049 mse:2808445 Test loss:0.6966 acc:0.8009 acc1:0.4816 mse:37746940\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#####################################训练#####################################\n",
    "from utils.common import get_time\n",
    "###图初始化\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "# sess=tf.Session(config=config)\n",
    "sess=tf.Session()\n",
    "init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "sess.run(init_op)\n",
    "\n",
    "\n",
    "##设置batch数据\n",
    "\"\"\"\n",
    "#由于tensor超过2G报错，遂改用自写的生成器\n",
    "ds = tf.data.Dataset.from_tensor_slices((x,y))\n",
    "ds = ds.repeat().shuffle(3).batch(3)\n",
    "iterator= ds.make_one_shot_iterator()\n",
    "next_element=iterator.get_next()\n",
    "\"\"\"\n",
    "\n",
    "def Batch_iter(x,y,x_cha,y_cha,batch_size,epochs,shuffle=True):\n",
    "    data_count=len(x)  \n",
    "    index=np.arange(data_count)\n",
    "    iter_times= int(data_count/batch_size) if  data_count%batch_size==0 else int(data_count/batch_size)+1\n",
    "    for epoch in range(epochs):\n",
    "        if shuffle :\n",
    "            np.random.shuffle(index)\n",
    "            x=x[index]\n",
    "            y=y[index]\n",
    "            x_cha=x_cha[index]\n",
    "            y_cha=y_cha[index]\n",
    "        for it in range(iter_times):\n",
    "            start_index=batch_size*it\n",
    "            end_index=min(batch_size*(it+1),data_count)\n",
    "            x_batch=x[start_index:end_index]\n",
    "            y_batch=y[start_index:end_index] \n",
    "            x_cha_batch=x_cha[start_index:end_index] \n",
    "            y_cha_batch=y_cha[start_index:end_index] \n",
    "            yield x_batch,y_batch,x_cha_batch,y_cha_batch\n",
    "            \n",
    "epochs=100\n",
    "batch_size=6\n",
    "batch_iter=Batch_iter(train_x,train_y,train_x_cha,train_y_cha,batch_size,epochs)\n",
    "\n",
    "###训练\n",
    "loss_list=[[],[]]\n",
    "acc_list=[[],[]]\n",
    "acc1_list=[[],[]]\n",
    "mse_list=[[],[]]\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "for i,(train_x_batch,train_y_batch,train_x_cha_batch,train_y_cha_batch) in enumerate(batch_iter):    \n",
    "\n",
    "#     if i%100==0:\n",
    "#         [ls,acc] = sess.run([loss,accurancy],feed_dict={x:x_batch,y:y_batch})\n",
    "\n",
    "    \n",
    "    \n",
    "#     sess.run(train,feed_dict={img_batch:x,lab_batch:l,out_batch:o})\n",
    "    _,train_loss,train_acc,train_acc1,train_output,train_mse = sess.run([train,loss,accurancy,accurancy1,output,mse],\\\n",
    "                                                    feed_dict={x_batch:train_x_batch,y_batch:train_y_batch,\\\n",
    "                                                               x_cha_batch:train_x_cha_batch,y_cha_batch:train_y_cha_batch,\\\n",
    "                                                               A_:A,is_training:True})\n",
    "    print(get_time())\n",
    "#     print(ima)\n",
    "    print(train_y_batch[0,0,:10,0].astype(int).tolist())\n",
    "    print(train_output[0,0,:10,0].astype(int).tolist())\n",
    "    \n",
    "    test_loss,test_acc,test_acc1,test_mse= sess.run([loss,accurancy,accurancy1,mse],\\\n",
    "                                                  feed_dict={x_batch:test_x,y_batch:test_y,\\\n",
    "                                                             x_cha_batch:test_x_cha,y_cha_batch:test_y_cha, \\\n",
    "                                                             A_:A,is_training:False})\n",
    "    \n",
    "    print('###### %s batch Train loss:%0.4f acc:%0.4f acc1:%0.4f mse:%0.0f Test loss:%0.4f acc:%0.4f acc1:%0.4f mse:%0.0f\\n'%\\\n",
    "                  (int(i),train_loss,train_acc,train_acc1,train_mse,test_loss,test_acc,test_acc1,test_mse))\n",
    "    \n",
    "    loss_list[0].append(train_loss); loss_list[1].append(test_loss)\n",
    "    acc_list[0].append(train_acc); acc_list[1].append(test_acc)\n",
    "    acc1_list[0].append(train_acc1); acc1_list[1].append(test_acc1)\n",
    "    mse_list[0].append(train_mse); mse_list[1].append(test_mse)\n",
    "    if test_acc>=0.80 and test_mse<=38000000 and (train_acc-test_acc)<0.1:\n",
    "        tf.add_to_collection('x_batch',x_batch)\n",
    "        tf.add_to_collection('y_batch',y_batch)\n",
    "        tf.add_to_collection('x_cha_batch',x_cha_batch)\n",
    "        tf.add_to_collection('y_cha_batch',y_cha_batch)\n",
    "        tf.add_to_collection('A_',A_)\n",
    "        tf.add_to_collection('is_training',is_training)\n",
    "        tf.add_to_collection('A_',A_)\n",
    "        \n",
    "        tf.add_to_collection('stgcn_pred',output)\n",
    "        tf.add_to_collection('loss',loss);tf.add_to_collection('accurancy',accurancy)\n",
    "        tf.add_to_collection('accurancy1',accurancy1);tf.add_to_collection('mse',mse)\n",
    "        \n",
    "        saver.save(sess, 'save/stgcn')\n",
    "        break\n",
    "#     if i==3:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导出结果到文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_prepare import get_data\n",
    "import numpy as np\n",
    "from utils.metrics import compute_acc\n",
    "A=np.load(\"A.npy\")\n",
    "train_x,train_y,train_x_cha,train_y_cha, test_x,test_y,test_x_cha,test_y_cha = \\\n",
    "    get_data(19,road_od_file=\"./road_od_array.npy\",chara_file=\"./chara_array_week_period.npy\")\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='3'\n",
    "\n",
    "sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True))\n",
    "\n",
    "#先加载图和参数变量\n",
    "saver = tf.train.import_meta_graph('save/stgcn.meta')\n",
    "saver.restore(sess,tf.train.latest_checkpoint('save'))      \n",
    "graph = tf.get_default_graph()\n",
    "\n",
    "# 访问placeholders变量，并且创建feed-dict来作为placeholders的新值\n",
    "output=tf.get_collection('stgcn_pred')[0] \n",
    "x_batch=tf.get_collection('x_batch')[0] \n",
    "y_batch=tf.get_collection('y_batch')[0] \n",
    "x_cha_batch=tf.get_collection('x_cha_batch')[0] \n",
    "y_cha_batch=tf.get_collection('y_cha_batch')[0] \n",
    "A_=tf.get_collection('A_')[0] \n",
    "is_training=tf.get_collection('is_training')[0] \n",
    "out = tf.get_collection(\"stgcn_pred\")[0] \n",
    "loss=tf.get_collection('loss')[0]\n",
    "accurancy=tf.get_collection('accurancy')[0]\n",
    "accurancy1=tf.get_collection('accurancy1')[0]\n",
    "mse=tf.get_collection('mse')[0]\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import pickle as pl\n",
    "def get_od_map():\n",
    "    station_id_map=pl.load(open(\"station_id_map.pkl\",'rb'))\n",
    "    station_id_map['divideLine']=1\n",
    "\n",
    "    station_od_map = pd.merge(station_id_map,station_id_map,on='divideLine')\n",
    "    station_od_map=station_od_map.rename\\\n",
    "                    (columns={'station_id_x':'O站ID','station_name_x':'O站名称','line_id_x':'O站线路ID','line_name_x':'O站线路名称',\\\n",
    "                              'station_id_y':'D站ID','station_name_y':'D站名称','line_id_y':'D站线路ID','line_name_y':'D站线路名称'})\n",
    "    station_od_map=station_od_map.drop(columns=['divideLine'])\n",
    "    return station_od_map\n",
    "\n",
    "station_od_map=get_od_map()\n",
    "test_out=sess.run(out,feed_dict={x_batch:test_x,y_batch:test_y,\\\n",
    "                                     x_cha_batch:test_x_cha,y_cha_batch:test_y_cha, \\\n",
    "                                     A_:A,is_training:False})\n",
    "\n",
    "time_mark=[ '%s_%02d:00-%02d:00'%(d,h,h+1) for d in ['20180917','20180918','20180919'] for h in list(range(5,24))]\n",
    "time_mark=time_mark[-46:]\n",
    "\n",
    "for y_,out_,time_mark_ in zip(test_y,test_out,time_mark):\n",
    "    y_=y_.reshape(-1,1)\n",
    "    out_=out_.reshape(-1,1)\n",
    "    ori_pre=np.concatenate((out_,y_),1)\n",
    "    ori_pre=pd.DataFrame(ori_pre,columns=['预测值','实际值'])\n",
    "    inf_detail=pd.concat([station_od_map,ori_pre],axis=1)\n",
    "    inf_detail['预测值'] = inf_detail['预测值'].astype(int)\n",
    "    inf_detail['实际值'] = inf_detail['实际值'].astype(int)\n",
    "    inf_detail['预测差值']=inf_detail['预测值']-inf_detail['实际值']\n",
    "    inf_detail['预测差异率'] = inf_detail[['预测差值','实际值']].apply(lambda x: x['预测差值']/x['实际值'] if x['实际值']!=0 else 0,axis=1)\n",
    "    inf_detail['预测精度'] = inf_detail['预测差异率'].apply(lambda x: (1-abs(x)))\n",
    "    inf_detail.to_excel('output/STAGCN模型预测(%s).xlsx'%time_mark_,index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"Placeholder_1:0\", shape=(?, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"Placeholder_2:0\", shape=(?, 19, 1), dtype=float32)\n",
      "Tensor(\"Placeholder_3:0\", shape=(?, 1), dtype=float32)\n",
      "Tensor(\"Placeholder_4:0\", shape=(40, 370, 370), dtype=float32)\n",
      "Tensor(\"Placeholder_5:0\", dtype=bool)\n",
      "Tensor(\"gcn_block_O_vision/ones/shape_as_tensor:0\", shape=(3,), dtype=int32)\n",
      "Tensor(\"gcn_block_O_vision/ones/Const:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/ones:0\", shape=(40, 370, 370), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/Variable:0\", shape=(40, 370, 370), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/Variable/Assign:0\", shape=(40, 370, 370), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/Variable/read:0\", shape=(40, 370, 370), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/mul:0\", shape=(40, 370, 370), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/einsum/Einsum:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/zeros/shape_as_tensor:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gcn_block_O_vision/zeros/Const:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/zeros:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/Variable_1:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/Variable_1/Assign:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/Variable_1/read:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/add:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/gamma/Initializer/ones:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/gamma:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/gamma/Assign:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/gamma/read:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/beta/Initializer/zeros:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/beta:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/beta/Assign:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/beta/read:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/moving_mean/Initializer/zeros:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/moving_mean:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/moving_mean/Assign:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/moving_mean/read:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/moving_variance/Initializer/ones:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/moving_variance:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/moving_variance/Assign:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/moving_variance/read:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/moments/mean/reduction_indices:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/moments/mean:0\", shape=(1, 1, 1, 1, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/moments/StopGradient:0\", shape=(1, 1, 1, 1, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/moments/SquaredDifference:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/moments/variance/reduction_indices:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/moments/variance:0\", shape=(1, 1, 1, 1, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/moments/Squeeze:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/moments/Squeeze_1:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/cond/Switch:0\", dtype=bool)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/cond/switch_t:0\", dtype=bool)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/cond/switch_f:0\", dtype=bool)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/cond/pred_id:0\", dtype=bool)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/cond/Switch_1:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/cond/Switch_2:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/cond/Merge:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/cond_1/Switch:0\", dtype=bool)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/cond_1/switch_t:0\", dtype=bool)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/cond_1/switch_f:0\", dtype=bool)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/cond_1/pred_id:0\", dtype=bool)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/cond_1/Switch_1:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/cond_1/Switch_2:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/cond_1/Merge:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/cond_2/Switch:0\", dtype=bool)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/cond_2/switch_t:0\", dtype=bool)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/cond_2/switch_f:0\", dtype=bool)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/cond_2/pred_id:0\", dtype=bool)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/cond_2/AssignMovingAvg/decay:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/cond_2/AssignMovingAvg/sub:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/cond_2/AssignMovingAvg/sub/Switch:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/cond_2/AssignMovingAvg/sub/Switch_1:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/cond_2/AssignMovingAvg/mul:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/cond_2/AssignMovingAvg:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/cond_2/AssignMovingAvg/Switch:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/cond_2/Switch_1:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/cond_2/Merge:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/cond_3/Switch:0\", dtype=bool)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/cond_3/switch_t:0\", dtype=bool)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/cond_3/switch_f:0\", dtype=bool)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/cond_3/pred_id:0\", dtype=bool)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/cond_3/AssignMovingAvg/decay:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/cond_3/AssignMovingAvg/sub:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/cond_3/AssignMovingAvg/sub/Switch:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/cond_3/AssignMovingAvg/sub/Switch_1:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/cond_3/AssignMovingAvg/mul:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/cond_3/AssignMovingAvg:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/cond_3/AssignMovingAvg/Switch:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/cond_3/Switch_1:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/cond_3/Merge:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/batchnorm/add/y:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/batchnorm/add:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/batchnorm/Rsqrt:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/batchnorm/mul:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/batchnorm/mul_1:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/batchnorm/mul_2:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/batchnorm/sub:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/batchnorm/add_1:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d/kernel/Initializer/random_uniform/shape:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d/kernel/Initializer/random_uniform/min:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d/kernel/Initializer/random_uniform/max:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d/kernel/Initializer/random_uniform/RandomUniform:0\", shape=(1, 370, 1, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d/kernel/Initializer/random_uniform/sub:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d/kernel/Initializer/random_uniform/mul:0\", shape=(1, 370, 1, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d/kernel/Initializer/random_uniform:0\", shape=(1, 370, 1, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d/kernel:0\", shape=(1, 370, 1, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/conv2d/kernel/Assign:0\", shape=(1, 370, 1, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/conv2d/kernel/read:0\", shape=(1, 370, 1, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d/bias/Initializer/zeros:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d/bias:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/conv2d/bias/Assign:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/conv2d/bias/read:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d/Conv2D/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d/Conv2D/strided_slice/stack:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d/Conv2D/strided_slice/stack_1:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d/Conv2D/strided_slice/stack_2:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d/Conv2D/strided_slice:0\", shape=(2,), dtype=int32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d/Conv2D/Reshape/shape:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d/Conv2D/Reshape:0\", shape=(?, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d/Conv2D/Conv2D:0\", shape=(?, 370, 1, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d/Conv2D/concat/values_1:0\", shape=(3,), dtype=int32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d/Conv2D/concat/axis:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d/Conv2D/concat:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d/Conv2D/Reshape_1:0\", shape=(?, 19, 370, 1, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d/squeeze_batch_dims/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d/squeeze_batch_dims/strided_slice/stack:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d/squeeze_batch_dims/strided_slice/stack_1:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d/squeeze_batch_dims/strided_slice/stack_2:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d/squeeze_batch_dims/strided_slice:0\", shape=(2,), dtype=int32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d/squeeze_batch_dims/Reshape/shape:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d/squeeze_batch_dims/Reshape:0\", shape=(?, 370, 1, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d/squeeze_batch_dims/BiasAdd:0\", shape=(?, 370, 1, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d/squeeze_batch_dims/concat/values_1:0\", shape=(3,), dtype=int32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d/squeeze_batch_dims/concat/axis:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d/squeeze_batch_dims/concat:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d/squeeze_batch_dims/Reshape_1:0\", shape=(?, 19, 370, 1, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d/Relu:0\", shape=(?, 19, 370, 1, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/Tile/multiples:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gcn_block_O_vision/Tile:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/ones_1/shape_as_tensor:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gcn_block_O_vision/ones_1/Const:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/ones_1:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/Variable_2:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/Variable_2/Assign:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/Variable_2/read:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/einsum_1/Einsum:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/zeros_1/shape_as_tensor:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gcn_block_O_vision/zeros_1/Const:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/zeros_1:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/Variable_3:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/Variable_3/Assign:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/Variable_3/read:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/add_1:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d_1/kernel/Initializer/random_uniform/shape:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d_1/kernel/Initializer/random_uniform/min:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d_1/kernel/Initializer/random_uniform/max:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d_1/kernel/Initializer/random_uniform/RandomUniform:0\", shape=(370, 1, 1, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d_1/kernel/Initializer/random_uniform/sub:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d_1/kernel/Initializer/random_uniform/mul:0\", shape=(370, 1, 1, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d_1/kernel/Initializer/random_uniform:0\", shape=(370, 1, 1, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d_1/kernel:0\", shape=(370, 1, 1, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/conv2d_1/kernel/Assign:0\", shape=(370, 1, 1, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/conv2d_1/kernel/read:0\", shape=(370, 1, 1, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d_1/bias/Initializer/zeros:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d_1/bias:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/conv2d_1/bias/Assign:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/conv2d_1/bias/read:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d_1/Conv2D/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d_1/Conv2D/strided_slice/stack:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d_1/Conv2D/strided_slice/stack_1:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d_1/Conv2D/strided_slice/stack_2:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d_1/Conv2D/strided_slice:0\", shape=(2,), dtype=int32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d_1/Conv2D/Reshape/shape:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d_1/Conv2D/Reshape:0\", shape=(?, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d_1/Conv2D/Conv2D:0\", shape=(?, 1, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d_1/Conv2D/concat/values_1:0\", shape=(3,), dtype=int32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d_1/Conv2D/concat/axis:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d_1/Conv2D/concat:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d_1/Conv2D/Reshape_1:0\", shape=(?, 19, 1, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d_1/squeeze_batch_dims/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d_1/squeeze_batch_dims/strided_slice/stack:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d_1/squeeze_batch_dims/strided_slice/stack_1:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d_1/squeeze_batch_dims/strided_slice/stack_2:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d_1/squeeze_batch_dims/strided_slice:0\", shape=(2,), dtype=int32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d_1/squeeze_batch_dims/Reshape/shape:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d_1/squeeze_batch_dims/Reshape:0\", shape=(?, 1, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d_1/squeeze_batch_dims/BiasAdd:0\", shape=(?, 1, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d_1/squeeze_batch_dims/concat/values_1:0\", shape=(3,), dtype=int32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d_1/squeeze_batch_dims/concat/axis:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d_1/squeeze_batch_dims/concat:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d_1/squeeze_batch_dims/Reshape_1:0\", shape=(?, 19, 1, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d_1/Relu:0\", shape=(?, 19, 1, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/Tile_1/multiples:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gcn_block_O_vision/Tile_1:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/ones_2/shape_as_tensor:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gcn_block_O_vision/ones_2/Const:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/ones_2:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/Variable_4:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/Variable_4/Assign:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/Variable_4/read:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/einsum_2/Einsum:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/zeros_2/shape_as_tensor:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gcn_block_O_vision/zeros_2/Const:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/zeros_2:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/Variable_5:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/Variable_5/Assign:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/Variable_5/read:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/add_2:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/Add_3:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/Relu:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"dropout/Const:0\", shape=(), dtype=float32)\n",
      "Tensor(\"dropout/Mul:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"dropout/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"dropout/random_uniform/RandomUniform:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"dropout/GreaterEqual/y:0\", shape=(), dtype=float32)\n",
      "Tensor(\"dropout/GreaterEqual:0\", shape=(?, 19, 370, 370, 1), dtype=bool)\n",
      "Tensor(\"dropout/Cast:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"dropout/Mul_1:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"transpose/perm:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"transpose:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/ones/shape_as_tensor:0\", shape=(3,), dtype=int32)\n",
      "Tensor(\"gcn_block_D_vision/ones/Const:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/ones:0\", shape=(40, 370, 370), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/Variable:0\", shape=(40, 370, 370), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/Variable/Assign:0\", shape=(40, 370, 370), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/Variable/read:0\", shape=(40, 370, 370), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/mul:0\", shape=(40, 370, 370), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/einsum/Einsum:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/zeros/shape_as_tensor:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gcn_block_D_vision/zeros/Const:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/zeros:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/Variable_1:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/Variable_1/Assign:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/Variable_1/read:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/add:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/gamma/Initializer/ones:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/gamma:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/gamma/Assign:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/gamma/read:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/beta/Initializer/zeros:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/beta:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/beta/Assign:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/beta/read:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/moving_mean/Initializer/zeros:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/moving_mean:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/moving_mean/Assign:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/moving_mean/read:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/moving_variance/Initializer/ones:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/moving_variance:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/moving_variance/Assign:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/moving_variance/read:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/moments/mean/reduction_indices:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/moments/mean:0\", shape=(1, 1, 1, 1, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/moments/StopGradient:0\", shape=(1, 1, 1, 1, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/moments/SquaredDifference:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/moments/variance/reduction_indices:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/moments/variance:0\", shape=(1, 1, 1, 1, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/moments/Squeeze:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/moments/Squeeze_1:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/cond/Switch:0\", dtype=bool)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/cond/switch_t:0\", dtype=bool)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/cond/switch_f:0\", dtype=bool)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/cond/pred_id:0\", dtype=bool)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/cond/Switch_1:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/cond/Switch_2:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/cond/Merge:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/cond_1/Switch:0\", dtype=bool)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/cond_1/switch_t:0\", dtype=bool)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/cond_1/switch_f:0\", dtype=bool)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/cond_1/pred_id:0\", dtype=bool)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/cond_1/Switch_1:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/cond_1/Switch_2:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/cond_1/Merge:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/cond_2/Switch:0\", dtype=bool)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/cond_2/switch_t:0\", dtype=bool)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/cond_2/switch_f:0\", dtype=bool)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/cond_2/pred_id:0\", dtype=bool)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/cond_2/AssignMovingAvg/decay:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/cond_2/AssignMovingAvg/sub:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/cond_2/AssignMovingAvg/sub/Switch:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/cond_2/AssignMovingAvg/sub/Switch_1:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/cond_2/AssignMovingAvg/mul:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/cond_2/AssignMovingAvg:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/cond_2/AssignMovingAvg/Switch:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/cond_2/Switch_1:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/cond_2/Merge:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/cond_3/Switch:0\", dtype=bool)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/cond_3/switch_t:0\", dtype=bool)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/cond_3/switch_f:0\", dtype=bool)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/cond_3/pred_id:0\", dtype=bool)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/cond_3/AssignMovingAvg/decay:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/cond_3/AssignMovingAvg/sub:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/cond_3/AssignMovingAvg/sub/Switch:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/cond_3/AssignMovingAvg/sub/Switch_1:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/cond_3/AssignMovingAvg/mul:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/cond_3/AssignMovingAvg:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/cond_3/AssignMovingAvg/Switch:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/cond_3/Switch_1:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/cond_3/Merge:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/batchnorm/add/y:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/batchnorm/add:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/batchnorm/Rsqrt:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/batchnorm/mul:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/batchnorm/mul_1:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/batchnorm/mul_2:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/batchnorm/sub:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/batchnorm/add_1:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d/kernel/Initializer/random_uniform/shape:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d/kernel/Initializer/random_uniform/min:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d/kernel/Initializer/random_uniform/max:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d/kernel/Initializer/random_uniform/RandomUniform:0\", shape=(1, 370, 1, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d/kernel/Initializer/random_uniform/sub:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d/kernel/Initializer/random_uniform/mul:0\", shape=(1, 370, 1, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d/kernel/Initializer/random_uniform:0\", shape=(1, 370, 1, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d/kernel:0\", shape=(1, 370, 1, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/conv2d/kernel/Assign:0\", shape=(1, 370, 1, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/conv2d/kernel/read:0\", shape=(1, 370, 1, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d/bias/Initializer/zeros:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d/bias:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/conv2d/bias/Assign:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/conv2d/bias/read:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d/Conv2D/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d/Conv2D/strided_slice/stack:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d/Conv2D/strided_slice/stack_1:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d/Conv2D/strided_slice/stack_2:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d/Conv2D/strided_slice:0\", shape=(2,), dtype=int32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d/Conv2D/Reshape/shape:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d/Conv2D/Reshape:0\", shape=(?, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d/Conv2D/Conv2D:0\", shape=(?, 370, 1, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d/Conv2D/concat/values_1:0\", shape=(3,), dtype=int32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d/Conv2D/concat/axis:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d/Conv2D/concat:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d/Conv2D/Reshape_1:0\", shape=(?, 19, 370, 1, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d/squeeze_batch_dims/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d/squeeze_batch_dims/strided_slice/stack:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d/squeeze_batch_dims/strided_slice/stack_1:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d/squeeze_batch_dims/strided_slice/stack_2:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d/squeeze_batch_dims/strided_slice:0\", shape=(2,), dtype=int32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d/squeeze_batch_dims/Reshape/shape:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d/squeeze_batch_dims/Reshape:0\", shape=(?, 370, 1, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d/squeeze_batch_dims/BiasAdd:0\", shape=(?, 370, 1, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d/squeeze_batch_dims/concat/values_1:0\", shape=(3,), dtype=int32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d/squeeze_batch_dims/concat/axis:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d/squeeze_batch_dims/concat:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d/squeeze_batch_dims/Reshape_1:0\", shape=(?, 19, 370, 1, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d/Relu:0\", shape=(?, 19, 370, 1, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/Tile/multiples:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gcn_block_D_vision/Tile:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/ones_1/shape_as_tensor:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gcn_block_D_vision/ones_1/Const:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/ones_1:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/Variable_2:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/Variable_2/Assign:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/Variable_2/read:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/einsum_1/Einsum:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/zeros_1/shape_as_tensor:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gcn_block_D_vision/zeros_1/Const:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/zeros_1:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/Variable_3:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/Variable_3/Assign:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/Variable_3/read:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/add_1:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d_1/kernel/Initializer/random_uniform/shape:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d_1/kernel/Initializer/random_uniform/min:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d_1/kernel/Initializer/random_uniform/max:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d_1/kernel/Initializer/random_uniform/RandomUniform:0\", shape=(370, 1, 1, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d_1/kernel/Initializer/random_uniform/sub:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d_1/kernel/Initializer/random_uniform/mul:0\", shape=(370, 1, 1, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d_1/kernel/Initializer/random_uniform:0\", shape=(370, 1, 1, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d_1/kernel:0\", shape=(370, 1, 1, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/conv2d_1/kernel/Assign:0\", shape=(370, 1, 1, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/conv2d_1/kernel/read:0\", shape=(370, 1, 1, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d_1/bias/Initializer/zeros:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d_1/bias:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/conv2d_1/bias/Assign:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/conv2d_1/bias/read:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d_1/Conv2D/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d_1/Conv2D/strided_slice/stack:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d_1/Conv2D/strided_slice/stack_1:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d_1/Conv2D/strided_slice/stack_2:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d_1/Conv2D/strided_slice:0\", shape=(2,), dtype=int32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d_1/Conv2D/Reshape/shape:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d_1/Conv2D/Reshape:0\", shape=(?, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d_1/Conv2D/Conv2D:0\", shape=(?, 1, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d_1/Conv2D/concat/values_1:0\", shape=(3,), dtype=int32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d_1/Conv2D/concat/axis:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d_1/Conv2D/concat:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d_1/Conv2D/Reshape_1:0\", shape=(?, 19, 1, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d_1/squeeze_batch_dims/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d_1/squeeze_batch_dims/strided_slice/stack:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d_1/squeeze_batch_dims/strided_slice/stack_1:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d_1/squeeze_batch_dims/strided_slice/stack_2:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d_1/squeeze_batch_dims/strided_slice:0\", shape=(2,), dtype=int32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d_1/squeeze_batch_dims/Reshape/shape:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d_1/squeeze_batch_dims/Reshape:0\", shape=(?, 1, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d_1/squeeze_batch_dims/BiasAdd:0\", shape=(?, 1, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d_1/squeeze_batch_dims/concat/values_1:0\", shape=(3,), dtype=int32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d_1/squeeze_batch_dims/concat/axis:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d_1/squeeze_batch_dims/concat:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d_1/squeeze_batch_dims/Reshape_1:0\", shape=(?, 19, 1, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d_1/Relu:0\", shape=(?, 19, 1, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/Tile_1/multiples:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gcn_block_D_vision/Tile_1:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/ones_2/shape_as_tensor:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gcn_block_D_vision/ones_2/Const:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/ones_2:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/Variable_4:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/Variable_4/Assign:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/Variable_4/read:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/einsum_2/Einsum:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/zeros_2/shape_as_tensor:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gcn_block_D_vision/zeros_2/Const:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/zeros_2:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/Variable_5:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/Variable_5/Assign:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/Variable_5/read:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/add_2:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/Add_3:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/Relu:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"dropout_1/Const:0\", shape=(), dtype=float32)\n",
      "Tensor(\"dropout_1/Mul:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"dropout_1/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"dropout_1/random_uniform/RandomUniform:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"dropout_1/GreaterEqual/y:0\", shape=(), dtype=float32)\n",
      "Tensor(\"dropout_1/GreaterEqual:0\", shape=(?, 19, 370, 370, 1), dtype=bool)\n",
      "Tensor(\"dropout_1/Cast:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"dropout_1/Mul_1:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"Add:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"Relu:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"embed_his_chara_block/Reshape/shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"embed_his_chara_block/Reshape:0\", shape=(?, 19, 1, 1, 1), dtype=float32)\n",
      "Tensor(\"embed_his_chara_block/Tile/multiples:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"embed_his_chara_block/Tile:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"embed_his_chara_block/concat/axis:0\", shape=(), dtype=int32)\n",
      "Tensor(\"embed_his_chara_block/concat:0\", shape=(?, 19, 370, 370, 2), dtype=float32)\n",
      "Tensor(\"tcn_block0/batch_normalization/gamma/Initializer/ones:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"tcn_block0/batch_normalization/gamma:0\", shape=(2,), dtype=float32_ref)\n",
      "Tensor(\"tcn_block0/batch_normalization/gamma/Assign:0\", shape=(2,), dtype=float32_ref)\n",
      "Tensor(\"tcn_block0/batch_normalization/gamma/read:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"tcn_block0/batch_normalization/beta/Initializer/zeros:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"tcn_block0/batch_normalization/beta:0\", shape=(2,), dtype=float32_ref)\n",
      "Tensor(\"tcn_block0/batch_normalization/beta/Assign:0\", shape=(2,), dtype=float32_ref)\n",
      "Tensor(\"tcn_block0/batch_normalization/beta/read:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"tcn_block0/batch_normalization/moving_mean/Initializer/zeros:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"tcn_block0/batch_normalization/moving_mean:0\", shape=(2,), dtype=float32_ref)\n",
      "Tensor(\"tcn_block0/batch_normalization/moving_mean/Assign:0\", shape=(2,), dtype=float32_ref)\n",
      "Tensor(\"tcn_block0/batch_normalization/moving_mean/read:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"tcn_block0/batch_normalization/moving_variance/Initializer/ones:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"tcn_block0/batch_normalization/moving_variance:0\", shape=(2,), dtype=float32_ref)\n",
      "Tensor(\"tcn_block0/batch_normalization/moving_variance/Assign:0\", shape=(2,), dtype=float32_ref)\n",
      "Tensor(\"tcn_block0/batch_normalization/moving_variance/read:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"tcn_block0/batch_normalization/moments/mean/reduction_indices:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"tcn_block0/batch_normalization/moments/mean:0\", shape=(1, 1, 1, 1, 2), dtype=float32)\n",
      "Tensor(\"tcn_block0/batch_normalization/moments/StopGradient:0\", shape=(1, 1, 1, 1, 2), dtype=float32)\n",
      "Tensor(\"tcn_block0/batch_normalization/moments/SquaredDifference:0\", shape=(?, 19, 370, 370, 2), dtype=float32)\n",
      "Tensor(\"tcn_block0/batch_normalization/moments/variance/reduction_indices:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"tcn_block0/batch_normalization/moments/variance:0\", shape=(1, 1, 1, 1, 2), dtype=float32)\n",
      "Tensor(\"tcn_block0/batch_normalization/moments/Squeeze:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"tcn_block0/batch_normalization/moments/Squeeze_1:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"tcn_block0/batch_normalization/cond/Switch:0\", dtype=bool)\n",
      "Tensor(\"tcn_block0/batch_normalization/cond/switch_t:0\", dtype=bool)\n",
      "Tensor(\"tcn_block0/batch_normalization/cond/switch_f:0\", dtype=bool)\n",
      "Tensor(\"tcn_block0/batch_normalization/cond/pred_id:0\", dtype=bool)\n",
      "Tensor(\"tcn_block0/batch_normalization/cond/Switch_1:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"tcn_block0/batch_normalization/cond/Switch_2:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"tcn_block0/batch_normalization/cond/Merge:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"tcn_block0/batch_normalization/cond_1/Switch:0\", dtype=bool)\n",
      "Tensor(\"tcn_block0/batch_normalization/cond_1/switch_t:0\", dtype=bool)\n",
      "Tensor(\"tcn_block0/batch_normalization/cond_1/switch_f:0\", dtype=bool)\n",
      "Tensor(\"tcn_block0/batch_normalization/cond_1/pred_id:0\", dtype=bool)\n",
      "Tensor(\"tcn_block0/batch_normalization/cond_1/Switch_1:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"tcn_block0/batch_normalization/cond_1/Switch_2:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"tcn_block0/batch_normalization/cond_1/Merge:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"tcn_block0/batch_normalization/cond_2/Switch:0\", dtype=bool)\n",
      "Tensor(\"tcn_block0/batch_normalization/cond_2/switch_t:0\", dtype=bool)\n",
      "Tensor(\"tcn_block0/batch_normalization/cond_2/switch_f:0\", dtype=bool)\n",
      "Tensor(\"tcn_block0/batch_normalization/cond_2/pred_id:0\", dtype=bool)\n",
      "Tensor(\"tcn_block0/batch_normalization/cond_2/AssignMovingAvg/decay:0\", shape=(), dtype=float32)\n",
      "Tensor(\"tcn_block0/batch_normalization/cond_2/AssignMovingAvg/sub:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"tcn_block0/batch_normalization/cond_2/AssignMovingAvg/sub/Switch:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"tcn_block0/batch_normalization/cond_2/AssignMovingAvg/sub/Switch_1:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"tcn_block0/batch_normalization/cond_2/AssignMovingAvg/mul:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"tcn_block0/batch_normalization/cond_2/AssignMovingAvg:0\", shape=(2,), dtype=float32_ref)\n",
      "Tensor(\"tcn_block0/batch_normalization/cond_2/AssignMovingAvg/Switch:0\", shape=(2,), dtype=float32_ref)\n",
      "Tensor(\"tcn_block0/batch_normalization/cond_2/Switch_1:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"tcn_block0/batch_normalization/cond_2/Merge:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"tcn_block0/batch_normalization/cond_3/Switch:0\", dtype=bool)\n",
      "Tensor(\"tcn_block0/batch_normalization/cond_3/switch_t:0\", dtype=bool)\n",
      "Tensor(\"tcn_block0/batch_normalization/cond_3/switch_f:0\", dtype=bool)\n",
      "Tensor(\"tcn_block0/batch_normalization/cond_3/pred_id:0\", dtype=bool)\n",
      "Tensor(\"tcn_block0/batch_normalization/cond_3/AssignMovingAvg/decay:0\", shape=(), dtype=float32)\n",
      "Tensor(\"tcn_block0/batch_normalization/cond_3/AssignMovingAvg/sub:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"tcn_block0/batch_normalization/cond_3/AssignMovingAvg/sub/Switch:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"tcn_block0/batch_normalization/cond_3/AssignMovingAvg/sub/Switch_1:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"tcn_block0/batch_normalization/cond_3/AssignMovingAvg/mul:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"tcn_block0/batch_normalization/cond_3/AssignMovingAvg:0\", shape=(2,), dtype=float32_ref)\n",
      "Tensor(\"tcn_block0/batch_normalization/cond_3/AssignMovingAvg/Switch:0\", shape=(2,), dtype=float32_ref)\n",
      "Tensor(\"tcn_block0/batch_normalization/cond_3/Switch_1:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"tcn_block0/batch_normalization/cond_3/Merge:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"tcn_block0/batch_normalization/batchnorm/add/y:0\", shape=(), dtype=float32)\n",
      "Tensor(\"tcn_block0/batch_normalization/batchnorm/add:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"tcn_block0/batch_normalization/batchnorm/Rsqrt:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"tcn_block0/batch_normalization/batchnorm/mul:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"tcn_block0/batch_normalization/batchnorm/mul_1:0\", shape=(?, 19, 370, 370, 2), dtype=float32)\n",
      "Tensor(\"tcn_block0/batch_normalization/batchnorm/mul_2:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"tcn_block0/batch_normalization/batchnorm/sub:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"tcn_block0/batch_normalization/batchnorm/add_1:0\", shape=(?, 19, 370, 370, 2), dtype=float32)\n",
      "Tensor(\"tcn_block0/conv3d/kernel/Initializer/random_uniform/shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"tcn_block0/conv3d/kernel/Initializer/random_uniform/min:0\", shape=(), dtype=float32)\n",
      "Tensor(\"tcn_block0/conv3d/kernel/Initializer/random_uniform/max:0\", shape=(), dtype=float32)\n",
      "Tensor(\"tcn_block0/conv3d/kernel/Initializer/random_uniform/RandomUniform:0\", shape=(19, 1, 1, 2, 3), dtype=float32)\n",
      "Tensor(\"tcn_block0/conv3d/kernel/Initializer/random_uniform/sub:0\", shape=(), dtype=float32)\n",
      "Tensor(\"tcn_block0/conv3d/kernel/Initializer/random_uniform/mul:0\", shape=(19, 1, 1, 2, 3), dtype=float32)\n",
      "Tensor(\"tcn_block0/conv3d/kernel/Initializer/random_uniform:0\", shape=(19, 1, 1, 2, 3), dtype=float32)\n",
      "Tensor(\"tcn_block0/conv3d/kernel:0\", shape=(), dtype=resource)\n",
      "Tensor(\"tcn_block0/conv3d/kernel/IsInitialized/VarIsInitializedOp:0\", shape=(), dtype=bool)\n",
      "tcn_block0/conv3d/kernel/Assign has 0 outputs\n",
      "Tensor(\"tcn_block0/conv3d/kernel/Read/ReadVariableOp:0\", shape=(19, 1, 1, 2, 3), dtype=float32)\n",
      "Tensor(\"tcn_block0/conv3d/bias/Initializer/zeros:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"tcn_block0/conv3d/bias:0\", shape=(), dtype=resource)\n",
      "Tensor(\"tcn_block0/conv3d/bias/IsInitialized/VarIsInitializedOp:0\", shape=(), dtype=bool)\n",
      "tcn_block0/conv3d/bias/Assign has 0 outputs\n",
      "Tensor(\"tcn_block0/conv3d/bias/Read/ReadVariableOp:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"tcn_block0/conv3d/Conv3D/ReadVariableOp:0\", shape=(19, 1, 1, 2, 3), dtype=float32)\n",
      "Tensor(\"tcn_block0/conv3d/Conv3D:0\", shape=(?, 19, 370, 370, 3), dtype=float32)\n",
      "Tensor(\"tcn_block0/conv3d/BiasAdd/ReadVariableOp:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"tcn_block0/conv3d/BiasAdd:0\", shape=(?, 19, 370, 370, 3), dtype=float32)\n",
      "Tensor(\"tcn_block0/Relu:0\", shape=(?, 19, 370, 370, 3), dtype=float32)\n",
      "Tensor(\"dropout_2/Const:0\", shape=(), dtype=float32)\n",
      "Tensor(\"dropout_2/Mul:0\", shape=(?, 19, 370, 370, 3), dtype=float32)\n",
      "Tensor(\"dropout_2/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"dropout_2/random_uniform/RandomUniform:0\", shape=(?, 19, 370, 370, 3), dtype=float32)\n",
      "Tensor(\"dropout_2/GreaterEqual/y:0\", shape=(), dtype=float32)\n",
      "Tensor(\"dropout_2/GreaterEqual:0\", shape=(?, 19, 370, 370, 3), dtype=bool)\n",
      "Tensor(\"dropout_2/Cast:0\", shape=(?, 19, 370, 370, 3), dtype=float32)\n",
      "Tensor(\"dropout_2/Mul_1:0\", shape=(?, 19, 370, 370, 3), dtype=float32)\n",
      "Tensor(\"tcn_block1/batch_normalization/gamma/Initializer/ones:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"tcn_block1/batch_normalization/gamma:0\", shape=(3,), dtype=float32_ref)\n",
      "Tensor(\"tcn_block1/batch_normalization/gamma/Assign:0\", shape=(3,), dtype=float32_ref)\n",
      "Tensor(\"tcn_block1/batch_normalization/gamma/read:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"tcn_block1/batch_normalization/beta/Initializer/zeros:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"tcn_block1/batch_normalization/beta:0\", shape=(3,), dtype=float32_ref)\n",
      "Tensor(\"tcn_block1/batch_normalization/beta/Assign:0\", shape=(3,), dtype=float32_ref)\n",
      "Tensor(\"tcn_block1/batch_normalization/beta/read:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"tcn_block1/batch_normalization/moving_mean/Initializer/zeros:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"tcn_block1/batch_normalization/moving_mean:0\", shape=(3,), dtype=float32_ref)\n",
      "Tensor(\"tcn_block1/batch_normalization/moving_mean/Assign:0\", shape=(3,), dtype=float32_ref)\n",
      "Tensor(\"tcn_block1/batch_normalization/moving_mean/read:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"tcn_block1/batch_normalization/moving_variance/Initializer/ones:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"tcn_block1/batch_normalization/moving_variance:0\", shape=(3,), dtype=float32_ref)\n",
      "Tensor(\"tcn_block1/batch_normalization/moving_variance/Assign:0\", shape=(3,), dtype=float32_ref)\n",
      "Tensor(\"tcn_block1/batch_normalization/moving_variance/read:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"tcn_block1/batch_normalization/moments/mean/reduction_indices:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"tcn_block1/batch_normalization/moments/mean:0\", shape=(1, 1, 1, 1, 3), dtype=float32)\n",
      "Tensor(\"tcn_block1/batch_normalization/moments/StopGradient:0\", shape=(1, 1, 1, 1, 3), dtype=float32)\n",
      "Tensor(\"tcn_block1/batch_normalization/moments/SquaredDifference:0\", shape=(?, 19, 370, 370, 3), dtype=float32)\n",
      "Tensor(\"tcn_block1/batch_normalization/moments/variance/reduction_indices:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"tcn_block1/batch_normalization/moments/variance:0\", shape=(1, 1, 1, 1, 3), dtype=float32)\n",
      "Tensor(\"tcn_block1/batch_normalization/moments/Squeeze:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"tcn_block1/batch_normalization/moments/Squeeze_1:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"tcn_block1/batch_normalization/cond/Switch:0\", dtype=bool)\n",
      "Tensor(\"tcn_block1/batch_normalization/cond/switch_t:0\", dtype=bool)\n",
      "Tensor(\"tcn_block1/batch_normalization/cond/switch_f:0\", dtype=bool)\n",
      "Tensor(\"tcn_block1/batch_normalization/cond/pred_id:0\", dtype=bool)\n",
      "Tensor(\"tcn_block1/batch_normalization/cond/Switch_1:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"tcn_block1/batch_normalization/cond/Switch_2:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"tcn_block1/batch_normalization/cond/Merge:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"tcn_block1/batch_normalization/cond_1/Switch:0\", dtype=bool)\n",
      "Tensor(\"tcn_block1/batch_normalization/cond_1/switch_t:0\", dtype=bool)\n",
      "Tensor(\"tcn_block1/batch_normalization/cond_1/switch_f:0\", dtype=bool)\n",
      "Tensor(\"tcn_block1/batch_normalization/cond_1/pred_id:0\", dtype=bool)\n",
      "Tensor(\"tcn_block1/batch_normalization/cond_1/Switch_1:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"tcn_block1/batch_normalization/cond_1/Switch_2:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"tcn_block1/batch_normalization/cond_1/Merge:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"tcn_block1/batch_normalization/cond_2/Switch:0\", dtype=bool)\n",
      "Tensor(\"tcn_block1/batch_normalization/cond_2/switch_t:0\", dtype=bool)\n",
      "Tensor(\"tcn_block1/batch_normalization/cond_2/switch_f:0\", dtype=bool)\n",
      "Tensor(\"tcn_block1/batch_normalization/cond_2/pred_id:0\", dtype=bool)\n",
      "Tensor(\"tcn_block1/batch_normalization/cond_2/AssignMovingAvg/decay:0\", shape=(), dtype=float32)\n",
      "Tensor(\"tcn_block1/batch_normalization/cond_2/AssignMovingAvg/sub:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"tcn_block1/batch_normalization/cond_2/AssignMovingAvg/sub/Switch:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"tcn_block1/batch_normalization/cond_2/AssignMovingAvg/sub/Switch_1:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"tcn_block1/batch_normalization/cond_2/AssignMovingAvg/mul:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"tcn_block1/batch_normalization/cond_2/AssignMovingAvg:0\", shape=(3,), dtype=float32_ref)\n",
      "Tensor(\"tcn_block1/batch_normalization/cond_2/AssignMovingAvg/Switch:0\", shape=(3,), dtype=float32_ref)\n",
      "Tensor(\"tcn_block1/batch_normalization/cond_2/Switch_1:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"tcn_block1/batch_normalization/cond_2/Merge:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"tcn_block1/batch_normalization/cond_3/Switch:0\", dtype=bool)\n",
      "Tensor(\"tcn_block1/batch_normalization/cond_3/switch_t:0\", dtype=bool)\n",
      "Tensor(\"tcn_block1/batch_normalization/cond_3/switch_f:0\", dtype=bool)\n",
      "Tensor(\"tcn_block1/batch_normalization/cond_3/pred_id:0\", dtype=bool)\n",
      "Tensor(\"tcn_block1/batch_normalization/cond_3/AssignMovingAvg/decay:0\", shape=(), dtype=float32)\n",
      "Tensor(\"tcn_block1/batch_normalization/cond_3/AssignMovingAvg/sub:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"tcn_block1/batch_normalization/cond_3/AssignMovingAvg/sub/Switch:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"tcn_block1/batch_normalization/cond_3/AssignMovingAvg/sub/Switch_1:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"tcn_block1/batch_normalization/cond_3/AssignMovingAvg/mul:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"tcn_block1/batch_normalization/cond_3/AssignMovingAvg:0\", shape=(3,), dtype=float32_ref)\n",
      "Tensor(\"tcn_block1/batch_normalization/cond_3/AssignMovingAvg/Switch:0\", shape=(3,), dtype=float32_ref)\n",
      "Tensor(\"tcn_block1/batch_normalization/cond_3/Switch_1:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"tcn_block1/batch_normalization/cond_3/Merge:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"tcn_block1/batch_normalization/batchnorm/add/y:0\", shape=(), dtype=float32)\n",
      "Tensor(\"tcn_block1/batch_normalization/batchnorm/add:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"tcn_block1/batch_normalization/batchnorm/Rsqrt:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"tcn_block1/batch_normalization/batchnorm/mul:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"tcn_block1/batch_normalization/batchnorm/mul_1:0\", shape=(?, 19, 370, 370, 3), dtype=float32)\n",
      "Tensor(\"tcn_block1/batch_normalization/batchnorm/mul_2:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"tcn_block1/batch_normalization/batchnorm/sub:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"tcn_block1/batch_normalization/batchnorm/add_1:0\", shape=(?, 19, 370, 370, 3), dtype=float32)\n",
      "Tensor(\"tcn_block1/conv3d_1/kernel/Initializer/random_uniform/shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"tcn_block1/conv3d_1/kernel/Initializer/random_uniform/min:0\", shape=(), dtype=float32)\n",
      "Tensor(\"tcn_block1/conv3d_1/kernel/Initializer/random_uniform/max:0\", shape=(), dtype=float32)\n",
      "Tensor(\"tcn_block1/conv3d_1/kernel/Initializer/random_uniform/RandomUniform:0\", shape=(19, 1, 1, 3, 1), dtype=float32)\n",
      "Tensor(\"tcn_block1/conv3d_1/kernel/Initializer/random_uniform/sub:0\", shape=(), dtype=float32)\n",
      "Tensor(\"tcn_block1/conv3d_1/kernel/Initializer/random_uniform/mul:0\", shape=(19, 1, 1, 3, 1), dtype=float32)\n",
      "Tensor(\"tcn_block1/conv3d_1/kernel/Initializer/random_uniform:0\", shape=(19, 1, 1, 3, 1), dtype=float32)\n",
      "Tensor(\"tcn_block1/conv3d_1/kernel:0\", shape=(), dtype=resource)\n",
      "Tensor(\"tcn_block1/conv3d_1/kernel/IsInitialized/VarIsInitializedOp:0\", shape=(), dtype=bool)\n",
      "tcn_block1/conv3d_1/kernel/Assign has 0 outputs\n",
      "Tensor(\"tcn_block1/conv3d_1/kernel/Read/ReadVariableOp:0\", shape=(19, 1, 1, 3, 1), dtype=float32)\n",
      "Tensor(\"tcn_block1/conv3d_1/bias/Initializer/zeros:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"tcn_block1/conv3d_1/bias:0\", shape=(), dtype=resource)\n",
      "Tensor(\"tcn_block1/conv3d_1/bias/IsInitialized/VarIsInitializedOp:0\", shape=(), dtype=bool)\n",
      "tcn_block1/conv3d_1/bias/Assign has 0 outputs\n",
      "Tensor(\"tcn_block1/conv3d_1/bias/Read/ReadVariableOp:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"tcn_block1/conv3d_1/Conv3D/ReadVariableOp:0\", shape=(19, 1, 1, 3, 1), dtype=float32)\n",
      "Tensor(\"tcn_block1/conv3d_1/Conv3D:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"tcn_block1/conv3d_1/BiasAdd/ReadVariableOp:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"tcn_block1/conv3d_1/BiasAdd:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"tcn_block1/Relu:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"dropout_3/Const:0\", shape=(), dtype=float32)\n",
      "Tensor(\"dropout_3/Mul:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"dropout_3/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"dropout_3/random_uniform/RandomUniform:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"dropout_3/GreaterEqual/y:0\", shape=(), dtype=float32)\n",
      "Tensor(\"dropout_3/GreaterEqual:0\", shape=(?, 19, 370, 370, 1), dtype=bool)\n",
      "Tensor(\"dropout_3/Cast:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"dropout_3/Mul_1:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"embed_fur_chara_block/Reshape/shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"embed_fur_chara_block/Reshape:0\", shape=(?, 1, 1, 1, 1), dtype=float32)\n",
      "Tensor(\"embed_fur_chara_block/Tile/multiples:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"embed_fur_chara_block/Tile:0\", shape=(?, 1, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"embed_fur_chara_block/concat/axis:0\", shape=(), dtype=int32)\n",
      "Tensor(\"embed_fur_chara_block/concat:0\", shape=(?, 20, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"tcn_block2/batch_normalization/gamma/Initializer/ones:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"tcn_block2/batch_normalization/gamma:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"tcn_block2/batch_normalization/gamma/Assign:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"tcn_block2/batch_normalization/gamma/read:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"tcn_block2/batch_normalization/beta/Initializer/zeros:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"tcn_block2/batch_normalization/beta:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"tcn_block2/batch_normalization/beta/Assign:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"tcn_block2/batch_normalization/beta/read:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"tcn_block2/batch_normalization/moving_mean/Initializer/zeros:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"tcn_block2/batch_normalization/moving_mean:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"tcn_block2/batch_normalization/moving_mean/Assign:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"tcn_block2/batch_normalization/moving_mean/read:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"tcn_block2/batch_normalization/moving_variance/Initializer/ones:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"tcn_block2/batch_normalization/moving_variance:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"tcn_block2/batch_normalization/moving_variance/Assign:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"tcn_block2/batch_normalization/moving_variance/read:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"tcn_block2/batch_normalization/moments/mean/reduction_indices:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"tcn_block2/batch_normalization/moments/mean:0\", shape=(1, 1, 1, 1, 1), dtype=float32)\n",
      "Tensor(\"tcn_block2/batch_normalization/moments/StopGradient:0\", shape=(1, 1, 1, 1, 1), dtype=float32)\n",
      "Tensor(\"tcn_block2/batch_normalization/moments/SquaredDifference:0\", shape=(?, 20, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"tcn_block2/batch_normalization/moments/variance/reduction_indices:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"tcn_block2/batch_normalization/moments/variance:0\", shape=(1, 1, 1, 1, 1), dtype=float32)\n",
      "Tensor(\"tcn_block2/batch_normalization/moments/Squeeze:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"tcn_block2/batch_normalization/moments/Squeeze_1:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"tcn_block2/batch_normalization/cond/Switch:0\", dtype=bool)\n",
      "Tensor(\"tcn_block2/batch_normalization/cond/switch_t:0\", dtype=bool)\n",
      "Tensor(\"tcn_block2/batch_normalization/cond/switch_f:0\", dtype=bool)\n",
      "Tensor(\"tcn_block2/batch_normalization/cond/pred_id:0\", dtype=bool)\n",
      "Tensor(\"tcn_block2/batch_normalization/cond/Switch_1:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"tcn_block2/batch_normalization/cond/Switch_2:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"tcn_block2/batch_normalization/cond/Merge:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"tcn_block2/batch_normalization/cond_1/Switch:0\", dtype=bool)\n",
      "Tensor(\"tcn_block2/batch_normalization/cond_1/switch_t:0\", dtype=bool)\n",
      "Tensor(\"tcn_block2/batch_normalization/cond_1/switch_f:0\", dtype=bool)\n",
      "Tensor(\"tcn_block2/batch_normalization/cond_1/pred_id:0\", dtype=bool)\n",
      "Tensor(\"tcn_block2/batch_normalization/cond_1/Switch_1:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"tcn_block2/batch_normalization/cond_1/Switch_2:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"tcn_block2/batch_normalization/cond_1/Merge:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"tcn_block2/batch_normalization/cond_2/Switch:0\", dtype=bool)\n",
      "Tensor(\"tcn_block2/batch_normalization/cond_2/switch_t:0\", dtype=bool)\n",
      "Tensor(\"tcn_block2/batch_normalization/cond_2/switch_f:0\", dtype=bool)\n",
      "Tensor(\"tcn_block2/batch_normalization/cond_2/pred_id:0\", dtype=bool)\n",
      "Tensor(\"tcn_block2/batch_normalization/cond_2/AssignMovingAvg/decay:0\", shape=(), dtype=float32)\n",
      "Tensor(\"tcn_block2/batch_normalization/cond_2/AssignMovingAvg/sub:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"tcn_block2/batch_normalization/cond_2/AssignMovingAvg/sub/Switch:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"tcn_block2/batch_normalization/cond_2/AssignMovingAvg/sub/Switch_1:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"tcn_block2/batch_normalization/cond_2/AssignMovingAvg/mul:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"tcn_block2/batch_normalization/cond_2/AssignMovingAvg:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"tcn_block2/batch_normalization/cond_2/AssignMovingAvg/Switch:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"tcn_block2/batch_normalization/cond_2/Switch_1:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"tcn_block2/batch_normalization/cond_2/Merge:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"tcn_block2/batch_normalization/cond_3/Switch:0\", dtype=bool)\n",
      "Tensor(\"tcn_block2/batch_normalization/cond_3/switch_t:0\", dtype=bool)\n",
      "Tensor(\"tcn_block2/batch_normalization/cond_3/switch_f:0\", dtype=bool)\n",
      "Tensor(\"tcn_block2/batch_normalization/cond_3/pred_id:0\", dtype=bool)\n",
      "Tensor(\"tcn_block2/batch_normalization/cond_3/AssignMovingAvg/decay:0\", shape=(), dtype=float32)\n",
      "Tensor(\"tcn_block2/batch_normalization/cond_3/AssignMovingAvg/sub:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"tcn_block2/batch_normalization/cond_3/AssignMovingAvg/sub/Switch:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"tcn_block2/batch_normalization/cond_3/AssignMovingAvg/sub/Switch_1:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"tcn_block2/batch_normalization/cond_3/AssignMovingAvg/mul:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"tcn_block2/batch_normalization/cond_3/AssignMovingAvg:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"tcn_block2/batch_normalization/cond_3/AssignMovingAvg/Switch:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"tcn_block2/batch_normalization/cond_3/Switch_1:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"tcn_block2/batch_normalization/cond_3/Merge:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"tcn_block2/batch_normalization/batchnorm/add/y:0\", shape=(), dtype=float32)\n",
      "Tensor(\"tcn_block2/batch_normalization/batchnorm/add:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"tcn_block2/batch_normalization/batchnorm/Rsqrt:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"tcn_block2/batch_normalization/batchnorm/mul:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"tcn_block2/batch_normalization/batchnorm/mul_1:0\", shape=(?, 20, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"tcn_block2/batch_normalization/batchnorm/mul_2:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"tcn_block2/batch_normalization/batchnorm/sub:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"tcn_block2/batch_normalization/batchnorm/add_1:0\", shape=(?, 20, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"tcn_block2/conv3d_2/kernel/Initializer/random_uniform/shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"tcn_block2/conv3d_2/kernel/Initializer/random_uniform/min:0\", shape=(), dtype=float32)\n",
      "Tensor(\"tcn_block2/conv3d_2/kernel/Initializer/random_uniform/max:0\", shape=(), dtype=float32)\n",
      "Tensor(\"tcn_block2/conv3d_2/kernel/Initializer/random_uniform/RandomUniform:0\", shape=(20, 1, 1, 1, 1), dtype=float32)\n",
      "Tensor(\"tcn_block2/conv3d_2/kernel/Initializer/random_uniform/sub:0\", shape=(), dtype=float32)\n",
      "Tensor(\"tcn_block2/conv3d_2/kernel/Initializer/random_uniform/mul:0\", shape=(20, 1, 1, 1, 1), dtype=float32)\n",
      "Tensor(\"tcn_block2/conv3d_2/kernel/Initializer/random_uniform:0\", shape=(20, 1, 1, 1, 1), dtype=float32)\n",
      "Tensor(\"tcn_block2/conv3d_2/kernel:0\", shape=(), dtype=resource)\n",
      "Tensor(\"tcn_block2/conv3d_2/kernel/IsInitialized/VarIsInitializedOp:0\", shape=(), dtype=bool)\n",
      "tcn_block2/conv3d_2/kernel/Assign has 0 outputs\n",
      "Tensor(\"tcn_block2/conv3d_2/kernel/Read/ReadVariableOp:0\", shape=(20, 1, 1, 1, 1), dtype=float32)\n",
      "Tensor(\"tcn_block2/conv3d_2/bias/Initializer/zeros:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"tcn_block2/conv3d_2/bias:0\", shape=(), dtype=resource)\n",
      "Tensor(\"tcn_block2/conv3d_2/bias/IsInitialized/VarIsInitializedOp:0\", shape=(), dtype=bool)\n",
      "tcn_block2/conv3d_2/bias/Assign has 0 outputs\n",
      "Tensor(\"tcn_block2/conv3d_2/bias/Read/ReadVariableOp:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"tcn_block2/conv3d_2/Conv3D/ReadVariableOp:0\", shape=(20, 1, 1, 1, 1), dtype=float32)\n",
      "Tensor(\"tcn_block2/conv3d_2/Conv3D:0\", shape=(?, 1, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"tcn_block2/conv3d_2/BiasAdd/ReadVariableOp:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"tcn_block2/conv3d_2/BiasAdd:0\", shape=(?, 1, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"tcn_block2/Relu:0\", shape=(?, 1, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"dropout_4/Const:0\", shape=(), dtype=float32)\n",
      "Tensor(\"dropout_4/Mul:0\", shape=(?, 1, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"dropout_4/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"dropout_4/random_uniform/RandomUniform:0\", shape=(?, 1, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"dropout_4/GreaterEqual/y:0\", shape=(), dtype=float32)\n",
      "Tensor(\"dropout_4/GreaterEqual:0\", shape=(?, 1, 370, 370, 1), dtype=bool)\n",
      "Tensor(\"dropout_4/Cast:0\", shape=(?, 1, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"dropout_4/Mul_1:0\", shape=(?, 1, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"Squeeze:0\", shape=(?, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"sub:0\", shape=(?, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"Square:0\", shape=(?, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"Const:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"Sum:0\", shape=(), dtype=float32)\n",
      "Tensor(\"Variable/initial_value:0\", shape=(), dtype=int32)\n",
      "Tensor(\"Variable:0\", shape=(), dtype=int32_ref)\n",
      "Tensor(\"Variable/Assign:0\", shape=(), dtype=int32_ref)\n",
      "Tensor(\"Variable/read:0\", shape=(), dtype=int32)\n",
      "Tensor(\"Const_1:0\", shape=(), dtype=int32)\n",
      "Tensor(\"Const_2:0\", shape=(), dtype=float32)\n",
      "Tensor(\"Const_3:0\", shape=(), dtype=float32)\n",
      "Tensor(\"PiecewiseConstant/LessEqual:0\", shape=(), dtype=bool)\n",
      "Tensor(\"PiecewiseConstant/Greater:0\", shape=(), dtype=bool)\n",
      "Tensor(\"PiecewiseConstant/case/preds_c:0\", shape=(2,), dtype=bool)\n",
      "Tensor(\"PiecewiseConstant/case/Cast:0\", shape=(2,), dtype=int32)\n",
      "Tensor(\"PiecewiseConstant/case/Const:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"PiecewiseConstant/case/num_true_conds:0\", shape=(), dtype=int32)\n",
      "Tensor(\"PiecewiseConstant/case/n_true_conds:0\", shape=(), dtype=int32)\n",
      "Tensor(\"PiecewiseConstant/case/LessEqual:0\", shape=(), dtype=bool)\n",
      "Tensor(\"PiecewiseConstant/case/Assert/Const:0\", shape=(), dtype=string)\n",
      "Tensor(\"PiecewiseConstant/case/Assert/AssertGuard/Switch:0\", shape=(), dtype=bool)\n",
      "Tensor(\"PiecewiseConstant/case/Assert/AssertGuard/switch_t:0\", shape=(), dtype=bool)\n",
      "Tensor(\"PiecewiseConstant/case/Assert/AssertGuard/switch_f:0\", shape=(), dtype=bool)\n",
      "Tensor(\"PiecewiseConstant/case/Assert/AssertGuard/pred_id:0\", shape=(), dtype=bool)\n",
      "PiecewiseConstant/case/Assert/AssertGuard/NoOp has 0 outputs\n",
      "Tensor(\"PiecewiseConstant/case/Assert/AssertGuard/control_dependency:0\", shape=(), dtype=bool)\n",
      "Tensor(\"PiecewiseConstant/case/Assert/AssertGuard/Assert/data_0:0\", shape=(), dtype=string)\n",
      "PiecewiseConstant/case/Assert/AssertGuard/Assert has 0 outputs\n",
      "Tensor(\"PiecewiseConstant/case/Assert/AssertGuard/Assert/Switch:0\", shape=(), dtype=bool)\n",
      "Tensor(\"PiecewiseConstant/case/Assert/AssertGuard/Assert/Switch_1:0\", shape=(2,), dtype=bool)\n",
      "Tensor(\"PiecewiseConstant/case/Assert/AssertGuard/control_dependency_1:0\", shape=(), dtype=bool)\n",
      "Tensor(\"PiecewiseConstant/case/Assert/AssertGuard/Merge:0\", shape=(), dtype=bool)\n",
      "Tensor(\"PiecewiseConstant/case/cond/Switch:0\", shape=(), dtype=bool)\n",
      "Tensor(\"PiecewiseConstant/case/cond/switch_t:0\", shape=(), dtype=bool)\n",
      "Tensor(\"PiecewiseConstant/case/cond/switch_f:0\", shape=(), dtype=bool)\n",
      "Tensor(\"PiecewiseConstant/case/cond/pred_id:0\", shape=(), dtype=bool)\n",
      "Tensor(\"PiecewiseConstant/case/cond/Switch_1:0\", shape=(), dtype=float32)\n",
      "Tensor(\"PiecewiseConstant/case/cond/cond/Switch:0\", shape=(), dtype=bool)\n",
      "Tensor(\"PiecewiseConstant/case/cond/cond/Switch/Switch:0\", shape=(), dtype=bool)\n",
      "Tensor(\"PiecewiseConstant/case/cond/cond/switch_t:0\", shape=(), dtype=bool)\n",
      "Tensor(\"PiecewiseConstant/case/cond/cond/switch_f:0\", shape=(), dtype=bool)\n",
      "Tensor(\"PiecewiseConstant/case/cond/cond/pred_id:0\", shape=(), dtype=bool)\n",
      "Tensor(\"PiecewiseConstant/case/cond/cond/Switch_1:0\", shape=(), dtype=float32)\n",
      "Tensor(\"PiecewiseConstant/case/cond/cond/Switch_2:0\", shape=(), dtype=float32)\n",
      "Tensor(\"PiecewiseConstant/case/cond/cond/Switch_3:0\", shape=(), dtype=float32)\n",
      "Tensor(\"PiecewiseConstant/case/cond/cond/Switch_4:0\", shape=(), dtype=float32)\n",
      "Tensor(\"PiecewiseConstant/case/cond/cond/Merge:0\", shape=(), dtype=float32)\n",
      "Tensor(\"PiecewiseConstant/case/cond/Merge:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gradients/Shape:0\", shape=(0,), dtype=int32)\n",
      "Tensor(\"gradients/grad_ys_0:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gradients/Fill:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gradients/Sum_grad/Reshape/shape:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gradients/Sum_grad/Reshape:0\", shape=(1, 1, 1, 1), dtype=float32)\n",
      "Tensor(\"gradients/Sum_grad/Shape:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gradients/Sum_grad/Tile:0\", shape=(?, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/Square_grad/Const:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gradients/Square_grad/Mul:0\", shape=(?, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/Square_grad/Mul_1:0\", shape=(?, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/sub_grad/Shape:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gradients/sub_grad/Shape_1:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gradients/sub_grad/BroadcastGradientArgs:0\", shape=(?,), dtype=int32)\n",
      "Tensor(\"gradients/sub_grad/Sum:0\", dtype=float32)\n",
      "Tensor(\"gradients/sub_grad/Reshape:0\", shape=(?, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/sub_grad/Neg:0\", shape=(?, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/sub_grad/Sum_1:0\", dtype=float32)\n",
      "Tensor(\"gradients/sub_grad/Reshape_1:0\", shape=(?, 370, 370, 1), dtype=float32)\n",
      "gradients/sub_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/sub_grad/tuple/control_dependency:0\", shape=(?, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/sub_grad/tuple/control_dependency_1:0\", shape=(?, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/Squeeze_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/Squeeze_grad/Reshape:0\", shape=(?, 1, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/dropout_4/Mul_1_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/dropout_4/Mul_1_grad/Shape_1:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/dropout_4/Mul_1_grad/BroadcastGradientArgs:0\", shape=(?,), dtype=int32)\n",
      "Tensor(\"gradients/dropout_4/Mul_1_grad/Mul:0\", shape=(?, 1, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/dropout_4/Mul_1_grad/Sum:0\", dtype=float32)\n",
      "Tensor(\"gradients/dropout_4/Mul_1_grad/Reshape:0\", shape=(?, 1, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/dropout_4/Mul_1_grad/Mul_1:0\", shape=(?, 1, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/dropout_4/Mul_1_grad/Sum_1:0\", dtype=float32)\n",
      "Tensor(\"gradients/dropout_4/Mul_1_grad/Reshape_1:0\", shape=(?, 1, 370, 370, 1), dtype=float32)\n",
      "gradients/dropout_4/Mul_1_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/dropout_4/Mul_1_grad/tuple/control_dependency:0\", shape=(?, 1, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/dropout_4/Mul_1_grad/tuple/control_dependency_1:0\", shape=(?, 1, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/dropout_4/Mul_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/dropout_4/Mul_grad/Shape_1:0\", shape=(0,), dtype=int32)\n",
      "Tensor(\"gradients/dropout_4/Mul_grad/BroadcastGradientArgs:0\", shape=(?,), dtype=int32)\n",
      "Tensor(\"gradients/dropout_4/Mul_grad/Mul:0\", shape=(?, 1, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/dropout_4/Mul_grad/Sum:0\", dtype=float32)\n",
      "Tensor(\"gradients/dropout_4/Mul_grad/Reshape:0\", shape=(?, 1, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/dropout_4/Mul_grad/Mul_1:0\", shape=(?, 1, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/dropout_4/Mul_grad/Sum_1:0\", dtype=float32)\n",
      "Tensor(\"gradients/dropout_4/Mul_grad/Reshape_1:0\", shape=(), dtype=float32)\n",
      "gradients/dropout_4/Mul_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/dropout_4/Mul_grad/tuple/control_dependency:0\", shape=(?, 1, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/dropout_4/Mul_grad/tuple/control_dependency_1:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block2/Relu_grad/ReluGrad:0\", shape=(?, 1, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block2/conv3d_2/BiasAdd_grad/BiasAddGrad:0\", shape=(1,), dtype=float32)\n",
      "gradients/tcn_block2/conv3d_2/BiasAdd_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/tcn_block2/conv3d_2/BiasAdd_grad/tuple/control_dependency:0\", shape=(?, 1, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block2/conv3d_2/BiasAdd_grad/tuple/control_dependency_1:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block2/conv3d_2/Conv3D_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block2/conv3d_2/Conv3D_grad/Conv3DBackpropInputV2:0\", shape=(?, 20, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block2/conv3d_2/Conv3D_grad/Shape_1:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block2/conv3d_2/Conv3D_grad/Conv3DBackpropFilterV2:0\", shape=(20, 1, 1, 1, 1), dtype=float32)\n",
      "gradients/tcn_block2/conv3d_2/Conv3D_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/tcn_block2/conv3d_2/Conv3D_grad/tuple/control_dependency:0\", shape=(?, 20, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block2/conv3d_2/Conv3D_grad/tuple/control_dependency_1:0\", shape=(20, 1, 1, 1, 1), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/batchnorm/add_1_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/batchnorm/add_1_grad/Shape_1:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/batchnorm/add_1_grad/BroadcastGradientArgs:0\", shape=(?,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/batchnorm/add_1_grad/Sum:0\", dtype=float32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/batchnorm/add_1_grad/Reshape:0\", shape=(?, 20, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/batchnorm/add_1_grad/Sum_1:0\", dtype=float32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/batchnorm/add_1_grad/Reshape_1:0\", shape=(1,), dtype=float32)\n",
      "gradients/tcn_block2/batch_normalization/batchnorm/add_1_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/batchnorm/add_1_grad/tuple/control_dependency:0\", shape=(?, 20, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/batchnorm/add_1_grad/tuple/control_dependency_1:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/batchnorm/mul_1_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/batchnorm/mul_1_grad/Shape_1:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/batchnorm/mul_1_grad/BroadcastGradientArgs:0\", shape=(?,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/batchnorm/mul_1_grad/Mul:0\", shape=(?, 20, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/batchnorm/mul_1_grad/Sum:0\", dtype=float32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/batchnorm/mul_1_grad/Reshape:0\", shape=(?, 20, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/batchnorm/mul_1_grad/Mul_1:0\", shape=(?, 20, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/batchnorm/mul_1_grad/Sum_1:0\", dtype=float32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/batchnorm/mul_1_grad/Reshape_1:0\", shape=(1,), dtype=float32)\n",
      "gradients/tcn_block2/batch_normalization/batchnorm/mul_1_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/batchnorm/mul_1_grad/tuple/control_dependency:0\", shape=(?, 20, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/batchnorm/mul_1_grad/tuple/control_dependency_1:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/batchnorm/sub_grad/Neg:0\", shape=(1,), dtype=float32)\n",
      "gradients/tcn_block2/batch_normalization/batchnorm/sub_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/batchnorm/sub_grad/tuple/control_dependency:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/batchnorm/sub_grad/tuple/control_dependency_1:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/batchnorm/mul_2_grad/Mul:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/batchnorm/mul_2_grad/Mul_1:0\", shape=(1,), dtype=float32)\n",
      "gradients/tcn_block2/batch_normalization/batchnorm/mul_2_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/batchnorm/mul_2_grad/tuple/control_dependency:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/batchnorm/mul_2_grad/tuple/control_dependency_1:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/cond/Merge_grad/cond_grad:0\", shape=(1,), dtype=float32)\n",
      "gradients/tcn_block2/batch_normalization/cond/Merge_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/cond/Merge_grad/tuple/control_dependency:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/cond/Merge_grad/tuple/control_dependency_1:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/AddN:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/batchnorm/mul_grad/Mul:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/batchnorm/mul_grad/Mul_1:0\", shape=(1,), dtype=float32)\n",
      "gradients/tcn_block2/batch_normalization/batchnorm/mul_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/batchnorm/mul_grad/tuple/control_dependency:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/batchnorm/mul_grad/tuple/control_dependency_1:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/Switch:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/Identity:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/Shape_1:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/zeros/Const:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gradients/zeros:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/cond/Switch_1_grad/cond_grad:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/batchnorm/Rsqrt_grad/RsqrtGrad:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/moments/Squeeze_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/moments/Squeeze_grad/Reshape:0\", shape=(1, 1, 1, 1, 1), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/batchnorm/add_grad/BroadcastGradientArgs/s0:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/batchnorm/add_grad/BroadcastGradientArgs/s1:0\", shape=(0,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/batchnorm/add_grad/BroadcastGradientArgs:0\", shape=(?,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/batchnorm/add_grad/Sum/reduction_indices:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/batchnorm/add_grad/Sum:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/batchnorm/add_grad/Reshape/shape:0\", shape=(0,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/batchnorm/add_grad/Reshape:0\", shape=(), dtype=float32)\n",
      "gradients/tcn_block2/batch_normalization/batchnorm/add_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/batchnorm/add_grad/tuple/control_dependency:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/batchnorm/add_grad/tuple/control_dependency_1:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/cond_1/Merge_grad/cond_grad:0\", shape=(1,), dtype=float32)\n",
      "gradients/tcn_block2/batch_normalization/cond_1/Merge_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/cond_1/Merge_grad/tuple/control_dependency:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/cond_1/Merge_grad/tuple/control_dependency_1:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/Switch_1:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/Identity_1:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/Shape_2:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/zeros_1/Const:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gradients/zeros_1:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/cond_1/Switch_1_grad/cond_grad:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/moments/Squeeze_1_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/moments/Squeeze_1_grad/Reshape:0\", shape=(1, 1, 1, 1, 1), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/moments/variance_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/moments/variance_grad/BroadcastTo:0\", shape=(?, 20, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/moments/variance_grad/Shape_1:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/moments/variance_grad/Shape_2:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/moments/variance_grad/Const:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/moments/variance_grad/Prod:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/moments/variance_grad/Const_1:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/moments/variance_grad/Prod_1:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/moments/variance_grad/Maximum/y:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/moments/variance_grad/Maximum:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/moments/variance_grad/floordiv:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/moments/variance_grad/Cast:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/moments/variance_grad/truediv:0\", shape=(?, 20, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/moments/SquaredDifference_grad/scalar:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/moments/SquaredDifference_grad/Mul:0\", shape=(?, 20, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/moments/SquaredDifference_grad/sub:0\", shape=(?, 20, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/moments/SquaredDifference_grad/mul_1:0\", shape=(?, 20, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/moments/SquaredDifference_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/moments/SquaredDifference_grad/Shape_1:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/moments/SquaredDifference_grad/BroadcastGradientArgs:0\", shape=(?,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/moments/SquaredDifference_grad/Sum:0\", dtype=float32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/moments/SquaredDifference_grad/Reshape:0\", shape=(?, 20, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/moments/SquaredDifference_grad/Sum_1:0\", dtype=float32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/moments/SquaredDifference_grad/Reshape_1:0\", shape=(1, 1, 1, 1, 1), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/moments/SquaredDifference_grad/Neg:0\", shape=(1, 1, 1, 1, 1), dtype=float32)\n",
      "gradients/tcn_block2/batch_normalization/moments/SquaredDifference_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/moments/SquaredDifference_grad/tuple/control_dependency:0\", shape=(?, 20, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/moments/SquaredDifference_grad/tuple/control_dependency_1:0\", shape=(1, 1, 1, 1, 1), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/moments/mean_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/moments/mean_grad/BroadcastTo:0\", shape=(?, 20, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/moments/mean_grad/Shape_1:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/moments/mean_grad/Shape_2:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/moments/mean_grad/Const:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/moments/mean_grad/Prod:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/moments/mean_grad/Const_1:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/moments/mean_grad/Prod_1:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/moments/mean_grad/Maximum/y:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/moments/mean_grad/Maximum:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/moments/mean_grad/floordiv:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/moments/mean_grad/Cast:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block2/batch_normalization/moments/mean_grad/truediv:0\", shape=(?, 20, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/AddN_1:0\", shape=(?, 20, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/embed_fur_chara_block/concat_grad/Rank:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/embed_fur_chara_block/concat_grad/mod:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/embed_fur_chara_block/concat_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/embed_fur_chara_block/concat_grad/ShapeN:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/embed_fur_chara_block/concat_grad/ConcatOffset:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/embed_fur_chara_block/concat_grad/Slice:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/embed_fur_chara_block/concat_grad/Slice_1:0\", shape=(?, 1, 370, 370, 1), dtype=float32)\n",
      "gradients/embed_fur_chara_block/concat_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/embed_fur_chara_block/concat_grad/tuple/control_dependency:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/embed_fur_chara_block/concat_grad/tuple/control_dependency_1:0\", shape=(?, 1, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/dropout_3/Mul_1_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/dropout_3/Mul_1_grad/Shape_1:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/dropout_3/Mul_1_grad/BroadcastGradientArgs:0\", shape=(?,), dtype=int32)\n",
      "Tensor(\"gradients/dropout_3/Mul_1_grad/Mul:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/dropout_3/Mul_1_grad/Sum:0\", dtype=float32)\n",
      "Tensor(\"gradients/dropout_3/Mul_1_grad/Reshape:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/dropout_3/Mul_1_grad/Mul_1:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/dropout_3/Mul_1_grad/Sum_1:0\", dtype=float32)\n",
      "Tensor(\"gradients/dropout_3/Mul_1_grad/Reshape_1:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "gradients/dropout_3/Mul_1_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/dropout_3/Mul_1_grad/tuple/control_dependency:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/dropout_3/Mul_1_grad/tuple/control_dependency_1:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/dropout_3/Mul_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/dropout_3/Mul_grad/Shape_1:0\", shape=(0,), dtype=int32)\n",
      "Tensor(\"gradients/dropout_3/Mul_grad/BroadcastGradientArgs:0\", shape=(?,), dtype=int32)\n",
      "Tensor(\"gradients/dropout_3/Mul_grad/Mul:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/dropout_3/Mul_grad/Sum:0\", dtype=float32)\n",
      "Tensor(\"gradients/dropout_3/Mul_grad/Reshape:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/dropout_3/Mul_grad/Mul_1:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/dropout_3/Mul_grad/Sum_1:0\", dtype=float32)\n",
      "Tensor(\"gradients/dropout_3/Mul_grad/Reshape_1:0\", shape=(), dtype=float32)\n",
      "gradients/dropout_3/Mul_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/dropout_3/Mul_grad/tuple/control_dependency:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/dropout_3/Mul_grad/tuple/control_dependency_1:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block1/Relu_grad/ReluGrad:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block1/conv3d_1/BiasAdd_grad/BiasAddGrad:0\", shape=(1,), dtype=float32)\n",
      "gradients/tcn_block1/conv3d_1/BiasAdd_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/tcn_block1/conv3d_1/BiasAdd_grad/tuple/control_dependency:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block1/conv3d_1/BiasAdd_grad/tuple/control_dependency_1:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block1/conv3d_1/Conv3D_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block1/conv3d_1/Conv3D_grad/Conv3DBackpropInputV2:0\", shape=(?, 19, 370, 370, 3), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block1/conv3d_1/Conv3D_grad/Shape_1:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block1/conv3d_1/Conv3D_grad/Conv3DBackpropFilterV2:0\", shape=(19, 1, 1, 3, 1), dtype=float32)\n",
      "gradients/tcn_block1/conv3d_1/Conv3D_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/tcn_block1/conv3d_1/Conv3D_grad/tuple/control_dependency:0\", shape=(?, 19, 370, 370, 3), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block1/conv3d_1/Conv3D_grad/tuple/control_dependency_1:0\", shape=(19, 1, 1, 3, 1), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/batchnorm/add_1_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/batchnorm/add_1_grad/Shape_1:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/batchnorm/add_1_grad/BroadcastGradientArgs:0\", shape=(?,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/batchnorm/add_1_grad/Sum:0\", dtype=float32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/batchnorm/add_1_grad/Reshape:0\", shape=(?, 19, 370, 370, 3), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/batchnorm/add_1_grad/Sum_1:0\", dtype=float32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/batchnorm/add_1_grad/Reshape_1:0\", shape=(3,), dtype=float32)\n",
      "gradients/tcn_block1/batch_normalization/batchnorm/add_1_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/batchnorm/add_1_grad/tuple/control_dependency:0\", shape=(?, 19, 370, 370, 3), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/batchnorm/add_1_grad/tuple/control_dependency_1:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/batchnorm/mul_1_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/batchnorm/mul_1_grad/Shape_1:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/batchnorm/mul_1_grad/BroadcastGradientArgs:0\", shape=(?,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/batchnorm/mul_1_grad/Mul:0\", shape=(?, 19, 370, 370, 3), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/batchnorm/mul_1_grad/Sum:0\", dtype=float32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/batchnorm/mul_1_grad/Reshape:0\", shape=(?, 19, 370, 370, 3), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/batchnorm/mul_1_grad/Mul_1:0\", shape=(?, 19, 370, 370, 3), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/batchnorm/mul_1_grad/Sum_1:0\", dtype=float32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/batchnorm/mul_1_grad/Reshape_1:0\", shape=(3,), dtype=float32)\n",
      "gradients/tcn_block1/batch_normalization/batchnorm/mul_1_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/batchnorm/mul_1_grad/tuple/control_dependency:0\", shape=(?, 19, 370, 370, 3), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/batchnorm/mul_1_grad/tuple/control_dependency_1:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/batchnorm/sub_grad/Neg:0\", shape=(3,), dtype=float32)\n",
      "gradients/tcn_block1/batch_normalization/batchnorm/sub_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/batchnorm/sub_grad/tuple/control_dependency:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/batchnorm/sub_grad/tuple/control_dependency_1:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/batchnorm/mul_2_grad/Mul:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/batchnorm/mul_2_grad/Mul_1:0\", shape=(3,), dtype=float32)\n",
      "gradients/tcn_block1/batch_normalization/batchnorm/mul_2_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/batchnorm/mul_2_grad/tuple/control_dependency:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/batchnorm/mul_2_grad/tuple/control_dependency_1:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/cond/Merge_grad/cond_grad:0\", shape=(3,), dtype=float32)\n",
      "gradients/tcn_block1/batch_normalization/cond/Merge_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/cond/Merge_grad/tuple/control_dependency:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/cond/Merge_grad/tuple/control_dependency_1:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"gradients/AddN_2:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/batchnorm/mul_grad/Mul:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/batchnorm/mul_grad/Mul_1:0\", shape=(3,), dtype=float32)\n",
      "gradients/tcn_block1/batch_normalization/batchnorm/mul_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/batchnorm/mul_grad/tuple/control_dependency:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/batchnorm/mul_grad/tuple/control_dependency_1:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"gradients/Switch_2:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"gradients/Identity_2:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"gradients/Shape_3:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/zeros_2/Const:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gradients/zeros_2:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/cond/Switch_1_grad/cond_grad:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/batchnorm/Rsqrt_grad/RsqrtGrad:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/moments/Squeeze_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/moments/Squeeze_grad/Reshape:0\", shape=(1, 1, 1, 1, 3), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/batchnorm/add_grad/BroadcastGradientArgs/s0:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/batchnorm/add_grad/BroadcastGradientArgs/s1:0\", shape=(0,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/batchnorm/add_grad/BroadcastGradientArgs:0\", shape=(?,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/batchnorm/add_grad/Sum/reduction_indices:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/batchnorm/add_grad/Sum:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/batchnorm/add_grad/Reshape/shape:0\", shape=(0,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/batchnorm/add_grad/Reshape:0\", shape=(), dtype=float32)\n",
      "gradients/tcn_block1/batch_normalization/batchnorm/add_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/batchnorm/add_grad/tuple/control_dependency:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/batchnorm/add_grad/tuple/control_dependency_1:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/cond_1/Merge_grad/cond_grad:0\", shape=(3,), dtype=float32)\n",
      "gradients/tcn_block1/batch_normalization/cond_1/Merge_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/cond_1/Merge_grad/tuple/control_dependency:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/cond_1/Merge_grad/tuple/control_dependency_1:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"gradients/Switch_3:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"gradients/Identity_3:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"gradients/Shape_4:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/zeros_3/Const:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gradients/zeros_3:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/cond_1/Switch_1_grad/cond_grad:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/moments/Squeeze_1_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/moments/Squeeze_1_grad/Reshape:0\", shape=(1, 1, 1, 1, 3), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/moments/variance_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/moments/variance_grad/BroadcastTo:0\", shape=(?, 19, 370, 370, 3), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/moments/variance_grad/Shape_1:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/moments/variance_grad/Shape_2:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/moments/variance_grad/Const:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/moments/variance_grad/Prod:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/moments/variance_grad/Const_1:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/moments/variance_grad/Prod_1:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/moments/variance_grad/Maximum/y:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/moments/variance_grad/Maximum:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/moments/variance_grad/floordiv:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/moments/variance_grad/Cast:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/moments/variance_grad/truediv:0\", shape=(?, 19, 370, 370, 3), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/moments/SquaredDifference_grad/scalar:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/moments/SquaredDifference_grad/Mul:0\", shape=(?, 19, 370, 370, 3), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/moments/SquaredDifference_grad/sub:0\", shape=(?, 19, 370, 370, 3), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/moments/SquaredDifference_grad/mul_1:0\", shape=(?, 19, 370, 370, 3), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/moments/SquaredDifference_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/moments/SquaredDifference_grad/Shape_1:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/moments/SquaredDifference_grad/BroadcastGradientArgs:0\", shape=(?,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/moments/SquaredDifference_grad/Sum:0\", dtype=float32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/moments/SquaredDifference_grad/Reshape:0\", shape=(?, 19, 370, 370, 3), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/moments/SquaredDifference_grad/Sum_1:0\", dtype=float32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/moments/SquaredDifference_grad/Reshape_1:0\", shape=(1, 1, 1, 1, 3), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/moments/SquaredDifference_grad/Neg:0\", shape=(1, 1, 1, 1, 3), dtype=float32)\n",
      "gradients/tcn_block1/batch_normalization/moments/SquaredDifference_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/moments/SquaredDifference_grad/tuple/control_dependency:0\", shape=(?, 19, 370, 370, 3), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/moments/SquaredDifference_grad/tuple/control_dependency_1:0\", shape=(1, 1, 1, 1, 3), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/moments/mean_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/moments/mean_grad/BroadcastTo:0\", shape=(?, 19, 370, 370, 3), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/moments/mean_grad/Shape_1:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/moments/mean_grad/Shape_2:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/moments/mean_grad/Const:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/moments/mean_grad/Prod:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/moments/mean_grad/Const_1:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/moments/mean_grad/Prod_1:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/moments/mean_grad/Maximum/y:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/moments/mean_grad/Maximum:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/moments/mean_grad/floordiv:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/moments/mean_grad/Cast:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block1/batch_normalization/moments/mean_grad/truediv:0\", shape=(?, 19, 370, 370, 3), dtype=float32)\n",
      "Tensor(\"gradients/AddN_3:0\", shape=(?, 19, 370, 370, 3), dtype=float32)\n",
      "Tensor(\"gradients/dropout_2/Mul_1_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/dropout_2/Mul_1_grad/Shape_1:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/dropout_2/Mul_1_grad/BroadcastGradientArgs:0\", shape=(?,), dtype=int32)\n",
      "Tensor(\"gradients/dropout_2/Mul_1_grad/Mul:0\", shape=(?, 19, 370, 370, 3), dtype=float32)\n",
      "Tensor(\"gradients/dropout_2/Mul_1_grad/Sum:0\", dtype=float32)\n",
      "Tensor(\"gradients/dropout_2/Mul_1_grad/Reshape:0\", shape=(?, 19, 370, 370, 3), dtype=float32)\n",
      "Tensor(\"gradients/dropout_2/Mul_1_grad/Mul_1:0\", shape=(?, 19, 370, 370, 3), dtype=float32)\n",
      "Tensor(\"gradients/dropout_2/Mul_1_grad/Sum_1:0\", dtype=float32)\n",
      "Tensor(\"gradients/dropout_2/Mul_1_grad/Reshape_1:0\", shape=(?, 19, 370, 370, 3), dtype=float32)\n",
      "gradients/dropout_2/Mul_1_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/dropout_2/Mul_1_grad/tuple/control_dependency:0\", shape=(?, 19, 370, 370, 3), dtype=float32)\n",
      "Tensor(\"gradients/dropout_2/Mul_1_grad/tuple/control_dependency_1:0\", shape=(?, 19, 370, 370, 3), dtype=float32)\n",
      "Tensor(\"gradients/dropout_2/Mul_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/dropout_2/Mul_grad/Shape_1:0\", shape=(0,), dtype=int32)\n",
      "Tensor(\"gradients/dropout_2/Mul_grad/BroadcastGradientArgs:0\", shape=(?,), dtype=int32)\n",
      "Tensor(\"gradients/dropout_2/Mul_grad/Mul:0\", shape=(?, 19, 370, 370, 3), dtype=float32)\n",
      "Tensor(\"gradients/dropout_2/Mul_grad/Sum:0\", dtype=float32)\n",
      "Tensor(\"gradients/dropout_2/Mul_grad/Reshape:0\", shape=(?, 19, 370, 370, 3), dtype=float32)\n",
      "Tensor(\"gradients/dropout_2/Mul_grad/Mul_1:0\", shape=(?, 19, 370, 370, 3), dtype=float32)\n",
      "Tensor(\"gradients/dropout_2/Mul_grad/Sum_1:0\", dtype=float32)\n",
      "Tensor(\"gradients/dropout_2/Mul_grad/Reshape_1:0\", shape=(), dtype=float32)\n",
      "gradients/dropout_2/Mul_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/dropout_2/Mul_grad/tuple/control_dependency:0\", shape=(?, 19, 370, 370, 3), dtype=float32)\n",
      "Tensor(\"gradients/dropout_2/Mul_grad/tuple/control_dependency_1:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block0/Relu_grad/ReluGrad:0\", shape=(?, 19, 370, 370, 3), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block0/conv3d/BiasAdd_grad/BiasAddGrad:0\", shape=(3,), dtype=float32)\n",
      "gradients/tcn_block0/conv3d/BiasAdd_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/tcn_block0/conv3d/BiasAdd_grad/tuple/control_dependency:0\", shape=(?, 19, 370, 370, 3), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block0/conv3d/BiasAdd_grad/tuple/control_dependency_1:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block0/conv3d/Conv3D_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block0/conv3d/Conv3D_grad/Conv3DBackpropInputV2:0\", shape=(?, 19, 370, 370, 2), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block0/conv3d/Conv3D_grad/Shape_1:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block0/conv3d/Conv3D_grad/Conv3DBackpropFilterV2:0\", shape=(19, 1, 1, 2, 3), dtype=float32)\n",
      "gradients/tcn_block0/conv3d/Conv3D_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/tcn_block0/conv3d/Conv3D_grad/tuple/control_dependency:0\", shape=(?, 19, 370, 370, 2), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block0/conv3d/Conv3D_grad/tuple/control_dependency_1:0\", shape=(19, 1, 1, 2, 3), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/batchnorm/add_1_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/batchnorm/add_1_grad/Shape_1:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/batchnorm/add_1_grad/BroadcastGradientArgs:0\", shape=(?,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/batchnorm/add_1_grad/Sum:0\", dtype=float32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/batchnorm/add_1_grad/Reshape:0\", shape=(?, 19, 370, 370, 2), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/batchnorm/add_1_grad/Sum_1:0\", dtype=float32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/batchnorm/add_1_grad/Reshape_1:0\", shape=(2,), dtype=float32)\n",
      "gradients/tcn_block0/batch_normalization/batchnorm/add_1_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/batchnorm/add_1_grad/tuple/control_dependency:0\", shape=(?, 19, 370, 370, 2), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/batchnorm/add_1_grad/tuple/control_dependency_1:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/batchnorm/mul_1_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/batchnorm/mul_1_grad/Shape_1:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/batchnorm/mul_1_grad/BroadcastGradientArgs:0\", shape=(?,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/batchnorm/mul_1_grad/Mul:0\", shape=(?, 19, 370, 370, 2), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/batchnorm/mul_1_grad/Sum:0\", dtype=float32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/batchnorm/mul_1_grad/Reshape:0\", shape=(?, 19, 370, 370, 2), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/batchnorm/mul_1_grad/Mul_1:0\", shape=(?, 19, 370, 370, 2), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/batchnorm/mul_1_grad/Sum_1:0\", dtype=float32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/batchnorm/mul_1_grad/Reshape_1:0\", shape=(2,), dtype=float32)\n",
      "gradients/tcn_block0/batch_normalization/batchnorm/mul_1_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/batchnorm/mul_1_grad/tuple/control_dependency:0\", shape=(?, 19, 370, 370, 2), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/batchnorm/mul_1_grad/tuple/control_dependency_1:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/batchnorm/sub_grad/Neg:0\", shape=(2,), dtype=float32)\n",
      "gradients/tcn_block0/batch_normalization/batchnorm/sub_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/batchnorm/sub_grad/tuple/control_dependency:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/batchnorm/sub_grad/tuple/control_dependency_1:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/batchnorm/mul_2_grad/Mul:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/batchnorm/mul_2_grad/Mul_1:0\", shape=(2,), dtype=float32)\n",
      "gradients/tcn_block0/batch_normalization/batchnorm/mul_2_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/batchnorm/mul_2_grad/tuple/control_dependency:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/batchnorm/mul_2_grad/tuple/control_dependency_1:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/cond/Merge_grad/cond_grad:0\", shape=(2,), dtype=float32)\n",
      "gradients/tcn_block0/batch_normalization/cond/Merge_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/cond/Merge_grad/tuple/control_dependency:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/cond/Merge_grad/tuple/control_dependency_1:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"gradients/AddN_4:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/batchnorm/mul_grad/Mul:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/batchnorm/mul_grad/Mul_1:0\", shape=(2,), dtype=float32)\n",
      "gradients/tcn_block0/batch_normalization/batchnorm/mul_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/batchnorm/mul_grad/tuple/control_dependency:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/batchnorm/mul_grad/tuple/control_dependency_1:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"gradients/Switch_4:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"gradients/Identity_4:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"gradients/Shape_5:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/zeros_4/Const:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gradients/zeros_4:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/cond/Switch_1_grad/cond_grad:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/batchnorm/Rsqrt_grad/RsqrtGrad:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/moments/Squeeze_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/moments/Squeeze_grad/Reshape:0\", shape=(1, 1, 1, 1, 2), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/batchnorm/add_grad/BroadcastGradientArgs/s0:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/batchnorm/add_grad/BroadcastGradientArgs/s1:0\", shape=(0,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/batchnorm/add_grad/BroadcastGradientArgs:0\", shape=(?,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/batchnorm/add_grad/Sum/reduction_indices:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/batchnorm/add_grad/Sum:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/batchnorm/add_grad/Reshape/shape:0\", shape=(0,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/batchnorm/add_grad/Reshape:0\", shape=(), dtype=float32)\n",
      "gradients/tcn_block0/batch_normalization/batchnorm/add_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/batchnorm/add_grad/tuple/control_dependency:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/batchnorm/add_grad/tuple/control_dependency_1:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/cond_1/Merge_grad/cond_grad:0\", shape=(2,), dtype=float32)\n",
      "gradients/tcn_block0/batch_normalization/cond_1/Merge_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/cond_1/Merge_grad/tuple/control_dependency:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/cond_1/Merge_grad/tuple/control_dependency_1:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"gradients/Switch_5:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"gradients/Identity_5:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"gradients/Shape_6:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/zeros_5/Const:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gradients/zeros_5:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/cond_1/Switch_1_grad/cond_grad:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/moments/Squeeze_1_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/moments/Squeeze_1_grad/Reshape:0\", shape=(1, 1, 1, 1, 2), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/moments/variance_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/moments/variance_grad/BroadcastTo:0\", shape=(?, 19, 370, 370, 2), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/moments/variance_grad/Shape_1:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/moments/variance_grad/Shape_2:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/moments/variance_grad/Const:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/moments/variance_grad/Prod:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/moments/variance_grad/Const_1:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/moments/variance_grad/Prod_1:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/moments/variance_grad/Maximum/y:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/moments/variance_grad/Maximum:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/moments/variance_grad/floordiv:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/moments/variance_grad/Cast:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/moments/variance_grad/truediv:0\", shape=(?, 19, 370, 370, 2), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/moments/SquaredDifference_grad/scalar:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/moments/SquaredDifference_grad/Mul:0\", shape=(?, 19, 370, 370, 2), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/moments/SquaredDifference_grad/sub:0\", shape=(?, 19, 370, 370, 2), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/moments/SquaredDifference_grad/mul_1:0\", shape=(?, 19, 370, 370, 2), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/moments/SquaredDifference_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/moments/SquaredDifference_grad/Shape_1:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/moments/SquaredDifference_grad/BroadcastGradientArgs:0\", shape=(?,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/moments/SquaredDifference_grad/Sum:0\", dtype=float32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/moments/SquaredDifference_grad/Reshape:0\", shape=(?, 19, 370, 370, 2), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/moments/SquaredDifference_grad/Sum_1:0\", dtype=float32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/moments/SquaredDifference_grad/Reshape_1:0\", shape=(1, 1, 1, 1, 2), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/moments/SquaredDifference_grad/Neg:0\", shape=(1, 1, 1, 1, 2), dtype=float32)\n",
      "gradients/tcn_block0/batch_normalization/moments/SquaredDifference_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/moments/SquaredDifference_grad/tuple/control_dependency:0\", shape=(?, 19, 370, 370, 2), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/moments/SquaredDifference_grad/tuple/control_dependency_1:0\", shape=(1, 1, 1, 1, 2), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/moments/mean_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/moments/mean_grad/BroadcastTo:0\", shape=(?, 19, 370, 370, 2), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/moments/mean_grad/Shape_1:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/moments/mean_grad/Shape_2:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/moments/mean_grad/Const:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/moments/mean_grad/Prod:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/moments/mean_grad/Const_1:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/moments/mean_grad/Prod_1:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/moments/mean_grad/Maximum/y:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/moments/mean_grad/Maximum:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/moments/mean_grad/floordiv:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/moments/mean_grad/Cast:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gradients/tcn_block0/batch_normalization/moments/mean_grad/truediv:0\", shape=(?, 19, 370, 370, 2), dtype=float32)\n",
      "Tensor(\"gradients/AddN_5:0\", shape=(?, 19, 370, 370, 2), dtype=float32)\n",
      "Tensor(\"gradients/embed_his_chara_block/concat_grad/Rank:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/embed_his_chara_block/concat_grad/mod:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/embed_his_chara_block/concat_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/embed_his_chara_block/concat_grad/ShapeN:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/embed_his_chara_block/concat_grad/ConcatOffset:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/embed_his_chara_block/concat_grad/Slice:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/embed_his_chara_block/concat_grad/Slice_1:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "gradients/embed_his_chara_block/concat_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/embed_his_chara_block/concat_grad/tuple/control_dependency:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/embed_his_chara_block/concat_grad/tuple/control_dependency_1:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/Relu_grad/ReluGrad:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/Add_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/Add_grad/Shape_1:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/Add_grad/BroadcastGradientArgs:0\", shape=(?,), dtype=int32)\n",
      "Tensor(\"gradients/Add_grad/Sum:0\", dtype=float32)\n",
      "Tensor(\"gradients/Add_grad/Reshape:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/Add_grad/Sum_1:0\", dtype=float32)\n",
      "Tensor(\"gradients/Add_grad/Reshape_1:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "gradients/Add_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/Add_grad/tuple/control_dependency:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/Add_grad/tuple/control_dependency_1:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/dropout_1/Mul_1_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/dropout_1/Mul_1_grad/Shape_1:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/dropout_1/Mul_1_grad/BroadcastGradientArgs:0\", shape=(?,), dtype=int32)\n",
      "Tensor(\"gradients/dropout_1/Mul_1_grad/Mul:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/dropout_1/Mul_1_grad/Sum:0\", dtype=float32)\n",
      "Tensor(\"gradients/dropout_1/Mul_1_grad/Reshape:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/dropout_1/Mul_1_grad/Mul_1:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/dropout_1/Mul_1_grad/Sum_1:0\", dtype=float32)\n",
      "Tensor(\"gradients/dropout_1/Mul_1_grad/Reshape_1:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "gradients/dropout_1/Mul_1_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/dropout_1/Mul_1_grad/tuple/control_dependency:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/dropout_1/Mul_1_grad/tuple/control_dependency_1:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/Relu_grad/ReluGrad:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/dropout_1/Mul_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/dropout_1/Mul_grad/Shape_1:0\", shape=(0,), dtype=int32)\n",
      "Tensor(\"gradients/dropout_1/Mul_grad/BroadcastGradientArgs:0\", shape=(?,), dtype=int32)\n",
      "Tensor(\"gradients/dropout_1/Mul_grad/Mul:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/dropout_1/Mul_grad/Sum:0\", dtype=float32)\n",
      "Tensor(\"gradients/dropout_1/Mul_grad/Reshape:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/dropout_1/Mul_grad/Mul_1:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/dropout_1/Mul_grad/Sum_1:0\", dtype=float32)\n",
      "Tensor(\"gradients/dropout_1/Mul_grad/Reshape_1:0\", shape=(), dtype=float32)\n",
      "gradients/dropout_1/Mul_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/dropout_1/Mul_grad/tuple/control_dependency:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/dropout_1/Mul_grad/tuple/control_dependency_1:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/Add_3_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/Add_3_grad/Shape_1:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/Add_3_grad/BroadcastGradientArgs:0\", shape=(?,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/Add_3_grad/Sum:0\", dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/Add_3_grad/Reshape:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/Add_3_grad/Sum_1:0\", dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/Add_3_grad/Reshape_1:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "gradients/gcn_block_D_vision/Add_3_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/gcn_block_D_vision/Add_3_grad/tuple/control_dependency:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/Add_3_grad/tuple/control_dependency_1:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/dropout/Mul_1_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/dropout/Mul_1_grad/Shape_1:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/dropout/Mul_1_grad/BroadcastGradientArgs:0\", shape=(?,), dtype=int32)\n",
      "Tensor(\"gradients/dropout/Mul_1_grad/Mul:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/dropout/Mul_1_grad/Sum:0\", dtype=float32)\n",
      "Tensor(\"gradients/dropout/Mul_1_grad/Reshape:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/dropout/Mul_1_grad/Mul_1:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/dropout/Mul_1_grad/Sum_1:0\", dtype=float32)\n",
      "Tensor(\"gradients/dropout/Mul_1_grad/Reshape_1:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "gradients/dropout/Mul_1_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/dropout/Mul_1_grad/tuple/control_dependency:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/dropout/Mul_1_grad/tuple/control_dependency_1:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/add_1_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/add_1_grad/Shape_1:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/add_1_grad/BroadcastGradientArgs:0\", shape=(?,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/add_1_grad/Sum:0\", dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/add_1_grad/Reshape:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/add_1_grad/Sum_1:0\", dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/add_1_grad/Reshape_1:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "gradients/gcn_block_D_vision/add_1_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/gcn_block_D_vision/add_1_grad/tuple/control_dependency:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/add_1_grad/tuple/control_dependency_1:0\", shape=(19, 370, 370, 1), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"gradients/gcn_block_D_vision/add_2_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/add_2_grad/Shape_1:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/add_2_grad/BroadcastGradientArgs:0\", shape=(?,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/add_2_grad/Sum:0\", dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/add_2_grad/Reshape:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/add_2_grad/Sum_1:0\", dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/add_2_grad/Reshape_1:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "gradients/gcn_block_D_vision/add_2_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/gcn_block_D_vision/add_2_grad/tuple/control_dependency:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/add_2_grad/tuple/control_dependency_1:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/dropout/Mul_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/dropout/Mul_grad/Shape_1:0\", shape=(0,), dtype=int32)\n",
      "Tensor(\"gradients/dropout/Mul_grad/BroadcastGradientArgs:0\", shape=(?,), dtype=int32)\n",
      "Tensor(\"gradients/dropout/Mul_grad/Mul:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/dropout/Mul_grad/Sum:0\", dtype=float32)\n",
      "Tensor(\"gradients/dropout/Mul_grad/Reshape:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/dropout/Mul_grad/Mul_1:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/dropout/Mul_grad/Sum_1:0\", dtype=float32)\n",
      "Tensor(\"gradients/dropout/Mul_grad/Reshape_1:0\", shape=(), dtype=float32)\n",
      "gradients/dropout/Mul_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/dropout/Mul_grad/tuple/control_dependency:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/dropout/Mul_grad/tuple/control_dependency_1:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/einsum_1/Einsum_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/einsum_1/Einsum_grad/Shape_1:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/einsum_1/Einsum_grad/Einsum:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/einsum_1/Einsum_grad/Einsum_1:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "gradients/gcn_block_D_vision/einsum_1/Einsum_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/gcn_block_D_vision/einsum_1/Einsum_grad/tuple/control_dependency:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/einsum_1/Einsum_grad/tuple/control_dependency_1:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/einsum_2/Einsum_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/einsum_2/Einsum_grad/Shape_1:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/einsum_2/Einsum_grad/Einsum:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/einsum_2/Einsum_grad/Einsum_1:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "gradients/gcn_block_D_vision/einsum_2/Einsum_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/gcn_block_D_vision/einsum_2/Einsum_grad/tuple/control_dependency:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/einsum_2/Einsum_grad/tuple/control_dependency_1:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/Relu_grad/ReluGrad:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/Tile_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/Tile_grad/stack:0\", shape=(2, 5), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/Tile_grad/transpose/perm:0\", shape=(2,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/Tile_grad/transpose:0\", shape=(5, 2), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/Tile_grad/Reshape/shape:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/Tile_grad/Reshape:0\", shape=(10,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/Tile_grad/Size:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/Tile_grad/range/start:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/Tile_grad/range/delta:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/Tile_grad/range:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/Tile_grad/Reshape_1:0\", shape=(?, ?, ?, ?, ?, ?, ?, ?, ?, ?), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/Tile_grad/Sum:0\", shape=(?, 19, 370, 1, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/Tile_1_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/Tile_1_grad/stack:0\", shape=(2, 5), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/Tile_1_grad/transpose/perm:0\", shape=(2,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/Tile_1_grad/transpose:0\", shape=(5, 2), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/Tile_1_grad/Reshape/shape:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/Tile_1_grad/Reshape:0\", shape=(10,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/Tile_1_grad/Size:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/Tile_1_grad/range/start:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/Tile_1_grad/range/delta:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/Tile_1_grad/range:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/Tile_1_grad/Reshape_1:0\", shape=(?, ?, ?, ?, ?, ?, ?, ?, ?, ?), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/Tile_1_grad/Sum:0\", shape=(?, 19, 1, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/Add_3_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/Add_3_grad/Shape_1:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/Add_3_grad/BroadcastGradientArgs:0\", shape=(?,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/Add_3_grad/Sum:0\", dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/Add_3_grad/Reshape:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/Add_3_grad/Sum_1:0\", dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/Add_3_grad/Reshape_1:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "gradients/gcn_block_O_vision/Add_3_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/gcn_block_O_vision/Add_3_grad/tuple/control_dependency:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/Add_3_grad/tuple/control_dependency_1:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/conv2d/Relu_grad/ReluGrad:0\", shape=(?, 19, 370, 1, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/conv2d_1/Relu_grad/ReluGrad:0\", shape=(?, 19, 1, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/add_1_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/add_1_grad/Shape_1:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/add_1_grad/BroadcastGradientArgs:0\", shape=(?,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/add_1_grad/Sum:0\", dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/add_1_grad/Reshape:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/add_1_grad/Sum_1:0\", dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/add_1_grad/Reshape_1:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "gradients/gcn_block_O_vision/add_1_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/gcn_block_O_vision/add_1_grad/tuple/control_dependency:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/add_1_grad/tuple/control_dependency_1:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/add_2_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/add_2_grad/Shape_1:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/add_2_grad/BroadcastGradientArgs:0\", shape=(?,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/add_2_grad/Sum:0\", dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/add_2_grad/Reshape:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/add_2_grad/Sum_1:0\", dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/add_2_grad/Reshape_1:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "gradients/gcn_block_O_vision/add_2_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/gcn_block_O_vision/add_2_grad/tuple/control_dependency:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/add_2_grad/tuple/control_dependency_1:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/conv2d/squeeze_batch_dims/Reshape_1_grad/Shape:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/conv2d/squeeze_batch_dims/Reshape_1_grad/Reshape:0\", shape=(?, 370, 1, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/conv2d_1/squeeze_batch_dims/Reshape_1_grad/Shape:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/conv2d_1/squeeze_batch_dims/Reshape_1_grad/Reshape:0\", shape=(?, 1, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/einsum_1/Einsum_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/einsum_1/Einsum_grad/Shape_1:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/einsum_1/Einsum_grad/Einsum:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/einsum_1/Einsum_grad/Einsum_1:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "gradients/gcn_block_O_vision/einsum_1/Einsum_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/gcn_block_O_vision/einsum_1/Einsum_grad/tuple/control_dependency:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/einsum_1/Einsum_grad/tuple/control_dependency_1:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/einsum_2/Einsum_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/einsum_2/Einsum_grad/Shape_1:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/einsum_2/Einsum_grad/Einsum:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/einsum_2/Einsum_grad/Einsum_1:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "gradients/gcn_block_O_vision/einsum_2/Einsum_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/gcn_block_O_vision/einsum_2/Einsum_grad/tuple/control_dependency:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/einsum_2/Einsum_grad/tuple/control_dependency_1:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/conv2d/squeeze_batch_dims/BiasAdd_grad/BiasAddGrad:0\", shape=(1,), dtype=float32)\n",
      "gradients/gcn_block_D_vision/conv2d/squeeze_batch_dims/BiasAdd_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/gcn_block_D_vision/conv2d/squeeze_batch_dims/BiasAdd_grad/tuple/control_dependency:0\", shape=(?, 370, 1, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/conv2d/squeeze_batch_dims/BiasAdd_grad/tuple/control_dependency_1:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/conv2d_1/squeeze_batch_dims/BiasAdd_grad/BiasAddGrad:0\", shape=(1,), dtype=float32)\n",
      "gradients/gcn_block_D_vision/conv2d_1/squeeze_batch_dims/BiasAdd_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/gcn_block_D_vision/conv2d_1/squeeze_batch_dims/BiasAdd_grad/tuple/control_dependency:0\", shape=(?, 1, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/conv2d_1/squeeze_batch_dims/BiasAdd_grad/tuple/control_dependency_1:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/Tile_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/Tile_grad/stack:0\", shape=(2, 5), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/Tile_grad/transpose/perm:0\", shape=(2,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/Tile_grad/transpose:0\", shape=(5, 2), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/Tile_grad/Reshape/shape:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/Tile_grad/Reshape:0\", shape=(10,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/Tile_grad/Size:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/Tile_grad/range/start:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/Tile_grad/range/delta:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/Tile_grad/range:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/Tile_grad/Reshape_1:0\", shape=(?, ?, ?, ?, ?, ?, ?, ?, ?, ?), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/Tile_grad/Sum:0\", shape=(?, 19, 370, 1, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/Tile_1_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/Tile_1_grad/stack:0\", shape=(2, 5), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/Tile_1_grad/transpose/perm:0\", shape=(2,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/Tile_1_grad/transpose:0\", shape=(5, 2), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/Tile_1_grad/Reshape/shape:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/Tile_1_grad/Reshape:0\", shape=(10,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/Tile_1_grad/Size:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/Tile_1_grad/range/start:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/Tile_1_grad/range/delta:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/Tile_1_grad/range:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/Tile_1_grad/Reshape_1:0\", shape=(?, ?, ?, ?, ?, ?, ?, ?, ?, ?), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/Tile_1_grad/Sum:0\", shape=(?, 19, 1, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/conv2d/squeeze_batch_dims/Reshape_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/conv2d/squeeze_batch_dims/Reshape_grad/Reshape:0\", shape=(?, 19, 370, 1, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/conv2d_1/squeeze_batch_dims/Reshape_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/conv2d_1/squeeze_batch_dims/Reshape_grad/Reshape:0\", shape=(?, 19, 1, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/conv2d/Relu_grad/ReluGrad:0\", shape=(?, 19, 370, 1, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/conv2d_1/Relu_grad/ReluGrad:0\", shape=(?, 19, 1, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/conv2d/Conv2D/Reshape_1_grad/Shape:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/conv2d/Conv2D/Reshape_1_grad/Reshape:0\", shape=(?, 370, 1, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/conv2d_1/Conv2D/Reshape_1_grad/Shape:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/conv2d_1/Conv2D/Reshape_1_grad/Reshape:0\", shape=(?, 1, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/conv2d/squeeze_batch_dims/Reshape_1_grad/Shape:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/conv2d/squeeze_batch_dims/Reshape_1_grad/Reshape:0\", shape=(?, 370, 1, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/conv2d_1/squeeze_batch_dims/Reshape_1_grad/Shape:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/conv2d_1/squeeze_batch_dims/Reshape_1_grad/Reshape:0\", shape=(?, 1, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/conv2d/Conv2D/Conv2D_grad/ShapeN:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/conv2d/Conv2D/Conv2D_grad/Conv2DBackpropInput:0\", shape=(?, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/conv2d/Conv2D/Conv2D_grad/Conv2DBackpropFilter:0\", shape=(1, 370, 1, 1), dtype=float32)\n",
      "gradients/gcn_block_D_vision/conv2d/Conv2D/Conv2D_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/gcn_block_D_vision/conv2d/Conv2D/Conv2D_grad/tuple/control_dependency:0\", shape=(?, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/conv2d/Conv2D/Conv2D_grad/tuple/control_dependency_1:0\", shape=(1, 370, 1, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/conv2d_1/Conv2D/Conv2D_grad/ShapeN:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/conv2d_1/Conv2D/Conv2D_grad/Conv2DBackpropInput:0\", shape=(?, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/conv2d_1/Conv2D/Conv2D_grad/Conv2DBackpropFilter:0\", shape=(370, 1, 1, 1), dtype=float32)\n",
      "gradients/gcn_block_D_vision/conv2d_1/Conv2D/Conv2D_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/gcn_block_D_vision/conv2d_1/Conv2D/Conv2D_grad/tuple/control_dependency:0\", shape=(?, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/conv2d_1/Conv2D/Conv2D_grad/tuple/control_dependency_1:0\", shape=(370, 1, 1, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/conv2d/squeeze_batch_dims/BiasAdd_grad/BiasAddGrad:0\", shape=(1,), dtype=float32)\n",
      "gradients/gcn_block_O_vision/conv2d/squeeze_batch_dims/BiasAdd_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/gcn_block_O_vision/conv2d/squeeze_batch_dims/BiasAdd_grad/tuple/control_dependency:0\", shape=(?, 370, 1, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/conv2d/squeeze_batch_dims/BiasAdd_grad/tuple/control_dependency_1:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/conv2d_1/squeeze_batch_dims/BiasAdd_grad/BiasAddGrad:0\", shape=(1,), dtype=float32)\n",
      "gradients/gcn_block_O_vision/conv2d_1/squeeze_batch_dims/BiasAdd_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/gcn_block_O_vision/conv2d_1/squeeze_batch_dims/BiasAdd_grad/tuple/control_dependency:0\", shape=(?, 1, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/conv2d_1/squeeze_batch_dims/BiasAdd_grad/tuple/control_dependency_1:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/conv2d/Conv2D/Reshape_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/conv2d/Conv2D/Reshape_grad/Reshape:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/conv2d_1/Conv2D/Reshape_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/conv2d_1/Conv2D/Reshape_grad/Reshape:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/conv2d/squeeze_batch_dims/Reshape_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/conv2d/squeeze_batch_dims/Reshape_grad/Reshape:0\", shape=(?, 19, 370, 1, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/conv2d_1/squeeze_batch_dims/Reshape_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/conv2d_1/squeeze_batch_dims/Reshape_grad/Reshape:0\", shape=(?, 19, 1, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/AddN_6:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/batchnorm/add_1_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/batchnorm/add_1_grad/Shape_1:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/batchnorm/add_1_grad/BroadcastGradientArgs:0\", shape=(?,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/batchnorm/add_1_grad/Sum:0\", dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/batchnorm/add_1_grad/Reshape:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/batchnorm/add_1_grad/Sum_1:0\", dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/batchnorm/add_1_grad/Reshape_1:0\", shape=(1,), dtype=float32)\n",
      "gradients/gcn_block_D_vision/batch_normalization/batchnorm/add_1_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/batchnorm/add_1_grad/tuple/control_dependency:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/batchnorm/add_1_grad/tuple/control_dependency_1:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/conv2d/Conv2D/Reshape_1_grad/Shape:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/conv2d/Conv2D/Reshape_1_grad/Reshape:0\", shape=(?, 370, 1, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/conv2d_1/Conv2D/Reshape_1_grad/Shape:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/conv2d_1/Conv2D/Reshape_1_grad/Reshape:0\", shape=(?, 1, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/batchnorm/mul_1_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/batchnorm/mul_1_grad/Shape_1:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/batchnorm/mul_1_grad/BroadcastGradientArgs:0\", shape=(?,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/batchnorm/mul_1_grad/Mul:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/batchnorm/mul_1_grad/Sum:0\", dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/batchnorm/mul_1_grad/Reshape:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/batchnorm/mul_1_grad/Mul_1:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/batchnorm/mul_1_grad/Sum_1:0\", dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/batchnorm/mul_1_grad/Reshape_1:0\", shape=(1,), dtype=float32)\n",
      "gradients/gcn_block_D_vision/batch_normalization/batchnorm/mul_1_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/batchnorm/mul_1_grad/tuple/control_dependency:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/batchnorm/mul_1_grad/tuple/control_dependency_1:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/batchnorm/sub_grad/Neg:0\", shape=(1,), dtype=float32)\n",
      "gradients/gcn_block_D_vision/batch_normalization/batchnorm/sub_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/batchnorm/sub_grad/tuple/control_dependency:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/batchnorm/sub_grad/tuple/control_dependency_1:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/conv2d/Conv2D/Conv2D_grad/ShapeN:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/conv2d/Conv2D/Conv2D_grad/Conv2DBackpropInput:0\", shape=(?, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/conv2d/Conv2D/Conv2D_grad/Conv2DBackpropFilter:0\", shape=(1, 370, 1, 1), dtype=float32)\n",
      "gradients/gcn_block_O_vision/conv2d/Conv2D/Conv2D_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/gcn_block_O_vision/conv2d/Conv2D/Conv2D_grad/tuple/control_dependency:0\", shape=(?, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/conv2d/Conv2D/Conv2D_grad/tuple/control_dependency_1:0\", shape=(1, 370, 1, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/conv2d_1/Conv2D/Conv2D_grad/ShapeN:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/conv2d_1/Conv2D/Conv2D_grad/Conv2DBackpropInput:0\", shape=(?, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/conv2d_1/Conv2D/Conv2D_grad/Conv2DBackpropFilter:0\", shape=(370, 1, 1, 1), dtype=float32)\n",
      "gradients/gcn_block_O_vision/conv2d_1/Conv2D/Conv2D_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/gcn_block_O_vision/conv2d_1/Conv2D/Conv2D_grad/tuple/control_dependency:0\", shape=(?, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/conv2d_1/Conv2D/Conv2D_grad/tuple/control_dependency_1:0\", shape=(370, 1, 1, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/batchnorm/mul_2_grad/Mul:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/batchnorm/mul_2_grad/Mul_1:0\", shape=(1,), dtype=float32)\n",
      "gradients/gcn_block_D_vision/batch_normalization/batchnorm/mul_2_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/batchnorm/mul_2_grad/tuple/control_dependency:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/batchnorm/mul_2_grad/tuple/control_dependency_1:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/conv2d/Conv2D/Reshape_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/conv2d/Conv2D/Reshape_grad/Reshape:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/conv2d_1/Conv2D/Reshape_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/conv2d_1/Conv2D/Reshape_grad/Reshape:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/cond/Merge_grad/cond_grad:0\", shape=(1,), dtype=float32)\n",
      "gradients/gcn_block_D_vision/batch_normalization/cond/Merge_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/cond/Merge_grad/tuple/control_dependency:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/cond/Merge_grad/tuple/control_dependency_1:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/AddN_7:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/batchnorm/mul_grad/Mul:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/batchnorm/mul_grad/Mul_1:0\", shape=(1,), dtype=float32)\n",
      "gradients/gcn_block_D_vision/batch_normalization/batchnorm/mul_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/batchnorm/mul_grad/tuple/control_dependency:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/batchnorm/mul_grad/tuple/control_dependency_1:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/AddN_8:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/batchnorm/add_1_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/batchnorm/add_1_grad/Shape_1:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/batchnorm/add_1_grad/BroadcastGradientArgs:0\", shape=(?,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/batchnorm/add_1_grad/Sum:0\", dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/batchnorm/add_1_grad/Reshape:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/batchnorm/add_1_grad/Sum_1:0\", dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/batchnorm/add_1_grad/Reshape_1:0\", shape=(1,), dtype=float32)\n",
      "gradients/gcn_block_O_vision/batch_normalization/batchnorm/add_1_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/batchnorm/add_1_grad/tuple/control_dependency:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/batchnorm/add_1_grad/tuple/control_dependency_1:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/Switch_6:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/Identity_6:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/Shape_7:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/zeros_6/Const:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gradients/zeros_6:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/cond/Switch_1_grad/cond_grad:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/batchnorm/Rsqrt_grad/RsqrtGrad:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/batchnorm/mul_1_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/batchnorm/mul_1_grad/Shape_1:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/batchnorm/mul_1_grad/BroadcastGradientArgs:0\", shape=(?,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/batchnorm/mul_1_grad/Mul:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/batchnorm/mul_1_grad/Sum:0\", dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/batchnorm/mul_1_grad/Reshape:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/batchnorm/mul_1_grad/Mul_1:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/batchnorm/mul_1_grad/Sum_1:0\", dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/batchnorm/mul_1_grad/Reshape_1:0\", shape=(1,), dtype=float32)\n",
      "gradients/gcn_block_O_vision/batch_normalization/batchnorm/mul_1_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/batchnorm/mul_1_grad/tuple/control_dependency:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/batchnorm/mul_1_grad/tuple/control_dependency_1:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/batchnorm/sub_grad/Neg:0\", shape=(1,), dtype=float32)\n",
      "gradients/gcn_block_O_vision/batch_normalization/batchnorm/sub_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/batchnorm/sub_grad/tuple/control_dependency:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/batchnorm/sub_grad/tuple/control_dependency_1:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/moments/Squeeze_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/moments/Squeeze_grad/Reshape:0\", shape=(1, 1, 1, 1, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/batchnorm/add_grad/Sum/reduction_indices:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/batchnorm/add_grad/Sum:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/batchnorm/add_grad/Reshape/shape:0\", shape=(0,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/batchnorm/add_grad/Reshape:0\", shape=(), dtype=float32)\n",
      "gradients/gcn_block_D_vision/batch_normalization/batchnorm/add_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/batchnorm/add_grad/tuple/control_dependency:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/batchnorm/add_grad/tuple/control_dependency_1:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/batchnorm/mul_2_grad/Mul:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/batchnorm/mul_2_grad/Mul_1:0\", shape=(1,), dtype=float32)\n",
      "gradients/gcn_block_O_vision/batch_normalization/batchnorm/mul_2_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/batchnorm/mul_2_grad/tuple/control_dependency:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/batchnorm/mul_2_grad/tuple/control_dependency_1:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/cond_1/Merge_grad/cond_grad:0\", shape=(1,), dtype=float32)\n",
      "gradients/gcn_block_D_vision/batch_normalization/cond_1/Merge_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/cond_1/Merge_grad/tuple/control_dependency:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/cond_1/Merge_grad/tuple/control_dependency_1:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/cond/Merge_grad/cond_grad:0\", shape=(1,), dtype=float32)\n",
      "gradients/gcn_block_O_vision/batch_normalization/cond/Merge_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/cond/Merge_grad/tuple/control_dependency:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/cond/Merge_grad/tuple/control_dependency_1:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/AddN_9:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/batchnorm/mul_grad/Mul:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/batchnorm/mul_grad/Mul_1:0\", shape=(1,), dtype=float32)\n",
      "gradients/gcn_block_O_vision/batch_normalization/batchnorm/mul_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/batchnorm/mul_grad/tuple/control_dependency:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/batchnorm/mul_grad/tuple/control_dependency_1:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/Switch_7:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/Identity_7:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/Shape_8:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/zeros_7/Const:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gradients/zeros_7:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/cond_1/Switch_1_grad/cond_grad:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/Switch_8:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/Identity_8:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/Shape_9:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/zeros_8/Const:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gradients/zeros_8:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/cond/Switch_1_grad/cond_grad:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/batchnorm/Rsqrt_grad/RsqrtGrad:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/moments/Squeeze_1_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/moments/Squeeze_1_grad/Reshape:0\", shape=(1, 1, 1, 1, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/moments/Squeeze_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/moments/Squeeze_grad/Reshape:0\", shape=(1, 1, 1, 1, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/batchnorm/add_grad/Sum/reduction_indices:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/batchnorm/add_grad/Sum:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/batchnorm/add_grad/Reshape/shape:0\", shape=(0,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/batchnorm/add_grad/Reshape:0\", shape=(), dtype=float32)\n",
      "gradients/gcn_block_O_vision/batch_normalization/batchnorm/add_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/batchnorm/add_grad/tuple/control_dependency:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/batchnorm/add_grad/tuple/control_dependency_1:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/moments/variance_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/moments/variance_grad/BroadcastTo:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/moments/variance_grad/Shape_1:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/moments/variance_grad/Shape_2:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/moments/variance_grad/Const:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/moments/variance_grad/Prod:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/moments/variance_grad/Const_1:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/moments/variance_grad/Prod_1:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/moments/variance_grad/Maximum/y:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/moments/variance_grad/Maximum:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/moments/variance_grad/floordiv:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/moments/variance_grad/Cast:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/moments/variance_grad/truediv:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/cond_1/Merge_grad/cond_grad:0\", shape=(1,), dtype=float32)\n",
      "gradients/gcn_block_O_vision/batch_normalization/cond_1/Merge_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/cond_1/Merge_grad/tuple/control_dependency:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/cond_1/Merge_grad/tuple/control_dependency_1:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/moments/SquaredDifference_grad/scalar:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/moments/SquaredDifference_grad/Mul:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/moments/SquaredDifference_grad/sub:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/moments/SquaredDifference_grad/mul_1:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/moments/SquaredDifference_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/moments/SquaredDifference_grad/Shape_1:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/moments/SquaredDifference_grad/BroadcastGradientArgs:0\", shape=(?,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/moments/SquaredDifference_grad/Sum:0\", dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/moments/SquaredDifference_grad/Reshape:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/moments/SquaredDifference_grad/Sum_1:0\", dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/moments/SquaredDifference_grad/Reshape_1:0\", shape=(1, 1, 1, 1, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/moments/SquaredDifference_grad/Neg:0\", shape=(1, 1, 1, 1, 1), dtype=float32)\n",
      "gradients/gcn_block_D_vision/batch_normalization/moments/SquaredDifference_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/moments/SquaredDifference_grad/tuple/control_dependency:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/moments/SquaredDifference_grad/tuple/control_dependency_1:0\", shape=(1, 1, 1, 1, 1), dtype=float32)\n",
      "Tensor(\"gradients/Switch_9:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/Identity_9:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/Shape_10:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/zeros_9/Const:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gradients/zeros_9:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/cond_1/Switch_1_grad/cond_grad:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/moments/Squeeze_1_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/moments/Squeeze_1_grad/Reshape:0\", shape=(1, 1, 1, 1, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/moments/mean_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/moments/mean_grad/BroadcastTo:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/moments/mean_grad/Shape_1:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/moments/mean_grad/Shape_2:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/moments/mean_grad/Const:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/moments/mean_grad/Prod:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/moments/mean_grad/Const_1:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/moments/mean_grad/Prod_1:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/moments/mean_grad/Maximum/y:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/moments/mean_grad/Maximum:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/moments/mean_grad/floordiv:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/moments/mean_grad/Cast:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/batch_normalization/moments/mean_grad/truediv:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/moments/variance_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/moments/variance_grad/BroadcastTo:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/moments/variance_grad/Shape_1:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/moments/variance_grad/Shape_2:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/moments/variance_grad/Const:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/moments/variance_grad/Prod:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/moments/variance_grad/Const_1:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/moments/variance_grad/Prod_1:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/moments/variance_grad/Maximum/y:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/moments/variance_grad/Maximum:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/moments/variance_grad/floordiv:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/moments/variance_grad/Cast:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/moments/variance_grad/truediv:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/AddN_10:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/add_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/add_grad/Shape_1:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/add_grad/BroadcastGradientArgs:0\", shape=(?,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/add_grad/Sum:0\", dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/add_grad/Reshape:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/add_grad/Sum_1:0\", dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/add_grad/Reshape_1:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "gradients/gcn_block_D_vision/add_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/gcn_block_D_vision/add_grad/tuple/control_dependency:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/add_grad/tuple/control_dependency_1:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/moments/SquaredDifference_grad/scalar:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/moments/SquaredDifference_grad/Mul:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/moments/SquaredDifference_grad/sub:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/moments/SquaredDifference_grad/mul_1:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/moments/SquaredDifference_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/moments/SquaredDifference_grad/Shape_1:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/moments/SquaredDifference_grad/BroadcastGradientArgs:0\", shape=(?,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/moments/SquaredDifference_grad/Sum:0\", dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/moments/SquaredDifference_grad/Reshape:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/moments/SquaredDifference_grad/Sum_1:0\", dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/moments/SquaredDifference_grad/Reshape_1:0\", shape=(1, 1, 1, 1, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/moments/SquaredDifference_grad/Neg:0\", shape=(1, 1, 1, 1, 1), dtype=float32)\n",
      "gradients/gcn_block_O_vision/batch_normalization/moments/SquaredDifference_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/moments/SquaredDifference_grad/tuple/control_dependency:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/moments/SquaredDifference_grad/tuple/control_dependency_1:0\", shape=(1, 1, 1, 1, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/einsum/Einsum_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/einsum/Einsum_grad/Shape_1:0\", shape=(3,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/einsum/Einsum_grad/Einsum:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/einsum/Einsum_grad/Einsum_1:0\", shape=(370, 370), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/einsum/Einsum_grad/strided_slice/stack:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/einsum/Einsum_grad/strided_slice/stack_1:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/einsum/Einsum_grad/strided_slice/stack_2:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/einsum/Einsum_grad/strided_slice:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/einsum/Einsum_grad/stack:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/einsum/Einsum_grad/Const:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/einsum/Einsum_grad/Size:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/einsum/Einsum_grad/add:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/einsum/Einsum_grad/mod:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/einsum/Einsum_grad/Shape_2:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/einsum/Einsum_grad/range/start:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/einsum/Einsum_grad/range/delta:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/einsum/Einsum_grad/range:0\", shape=(3,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/einsum/Einsum_grad/Fill/value:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/einsum/Einsum_grad/Fill:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/einsum/Einsum_grad/DynamicStitch:0\", shape=(3,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/einsum/Einsum_grad/Reshape:0\", shape=(1, 370, 370), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/einsum/Einsum_grad/BroadcastTo:0\", shape=(40, 370, 370), dtype=float32)\n",
      "gradients/gcn_block_D_vision/einsum/Einsum_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/gcn_block_D_vision/einsum/Einsum_grad/tuple/control_dependency:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/einsum/Einsum_grad/tuple/control_dependency_1:0\", shape=(40, 370, 370), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/mul_grad/Mul:0\", shape=(40, 370, 370), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/mul_grad/Mul_1:0\", shape=(40, 370, 370), dtype=float32)\n",
      "gradients/gcn_block_D_vision/mul_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/gcn_block_D_vision/mul_grad/tuple/control_dependency:0\", shape=(40, 370, 370), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_D_vision/mul_grad/tuple/control_dependency_1:0\", shape=(40, 370, 370), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/moments/mean_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/moments/mean_grad/BroadcastTo:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/moments/mean_grad/Shape_1:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/moments/mean_grad/Shape_2:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/moments/mean_grad/Const:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/moments/mean_grad/Prod:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/moments/mean_grad/Const_1:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/moments/mean_grad/Prod_1:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/moments/mean_grad/Maximum/y:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/moments/mean_grad/Maximum:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/moments/mean_grad/floordiv:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/moments/mean_grad/Cast:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/batch_normalization/moments/mean_grad/truediv:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/AddN_11:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/add_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/add_grad/Shape_1:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/add_grad/BroadcastGradientArgs:0\", shape=(?,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/add_grad/Sum:0\", dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/add_grad/Reshape:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/add_grad/Sum_1:0\", dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/add_grad/Reshape_1:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "gradients/gcn_block_O_vision/add_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/gcn_block_O_vision/add_grad/tuple/control_dependency:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/add_grad/tuple/control_dependency_1:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/einsum/Einsum_grad/Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/einsum/Einsum_grad/Shape_1:0\", shape=(3,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/einsum/Einsum_grad/Einsum:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/einsum/Einsum_grad/Einsum_1:0\", shape=(370, 370), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/einsum/Einsum_grad/strided_slice/stack:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/einsum/Einsum_grad/strided_slice/stack_1:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/einsum/Einsum_grad/strided_slice/stack_2:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/einsum/Einsum_grad/strided_slice:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/einsum/Einsum_grad/stack:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/einsum/Einsum_grad/Const:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/einsum/Einsum_grad/Size:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/einsum/Einsum_grad/add:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/einsum/Einsum_grad/mod:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/einsum/Einsum_grad/Shape_2:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/einsum/Einsum_grad/range/start:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/einsum/Einsum_grad/range/delta:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/einsum/Einsum_grad/range:0\", shape=(3,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/einsum/Einsum_grad/Fill/value:0\", shape=(), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/einsum/Einsum_grad/Fill:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/einsum/Einsum_grad/DynamicStitch:0\", shape=(3,), dtype=int32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/einsum/Einsum_grad/Reshape:0\", shape=(1, 370, 370), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/einsum/Einsum_grad/BroadcastTo:0\", shape=(40, 370, 370), dtype=float32)\n",
      "gradients/gcn_block_O_vision/einsum/Einsum_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/gcn_block_O_vision/einsum/Einsum_grad/tuple/control_dependency:0\", shape=(?, 19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/einsum/Einsum_grad/tuple/control_dependency_1:0\", shape=(40, 370, 370), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/mul_grad/Mul:0\", shape=(40, 370, 370), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/mul_grad/Mul_1:0\", shape=(40, 370, 370), dtype=float32)\n",
      "gradients/gcn_block_O_vision/mul_grad/tuple/group_deps has 0 outputs\n",
      "Tensor(\"gradients/gcn_block_O_vision/mul_grad/tuple/control_dependency:0\", shape=(40, 370, 370), dtype=float32)\n",
      "Tensor(\"gradients/gcn_block_O_vision/mul_grad/tuple/control_dependency_1:0\", shape=(40, 370, 370), dtype=float32)\n",
      "Tensor(\"beta1_power/initial_value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"beta1_power:0\", shape=(), dtype=float32_ref)\n",
      "Tensor(\"beta1_power/Assign:0\", shape=(), dtype=float32_ref)\n",
      "Tensor(\"beta1_power/read:0\", shape=(), dtype=float32)\n",
      "Tensor(\"beta2_power/initial_value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"beta2_power:0\", shape=(), dtype=float32_ref)\n",
      "Tensor(\"beta2_power/Assign:0\", shape=(), dtype=float32_ref)\n",
      "Tensor(\"beta2_power/read:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/Variable/Adam/Initializer/zeros/shape_as_tensor:0\", shape=(3,), dtype=int32)\n",
      "Tensor(\"gcn_block_O_vision/Variable/Adam/Initializer/zeros/Const:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/Variable/Adam/Initializer/zeros:0\", shape=(40, 370, 370), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/Variable/Adam:0\", shape=(40, 370, 370), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/Variable/Adam/Assign:0\", shape=(40, 370, 370), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/Variable/Adam/read:0\", shape=(40, 370, 370), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/Variable/Adam_1/Initializer/zeros/shape_as_tensor:0\", shape=(3,), dtype=int32)\n",
      "Tensor(\"gcn_block_O_vision/Variable/Adam_1/Initializer/zeros/Const:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/Variable/Adam_1/Initializer/zeros:0\", shape=(40, 370, 370), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/Variable/Adam_1:0\", shape=(40, 370, 370), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/Variable/Adam_1/Assign:0\", shape=(40, 370, 370), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/Variable/Adam_1/read:0\", shape=(40, 370, 370), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/Variable_1/Adam/Initializer/zeros/shape_as_tensor:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gcn_block_O_vision/Variable_1/Adam/Initializer/zeros/Const:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/Variable_1/Adam/Initializer/zeros:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/Variable_1/Adam:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/Variable_1/Adam/Assign:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/Variable_1/Adam/read:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/Variable_1/Adam_1/Initializer/zeros/shape_as_tensor:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gcn_block_O_vision/Variable_1/Adam_1/Initializer/zeros/Const:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/Variable_1/Adam_1/Initializer/zeros:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/Variable_1/Adam_1:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/Variable_1/Adam_1/Assign:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/Variable_1/Adam_1/read:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/gamma/Adam/Initializer/zeros:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/gamma/Adam:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/gamma/Adam/Assign:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/gamma/Adam/read:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/gamma/Adam_1/Initializer/zeros:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/gamma/Adam_1:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/gamma/Adam_1/Assign:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/gamma/Adam_1/read:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/beta/Adam/Initializer/zeros:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/beta/Adam:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/beta/Adam/Assign:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/beta/Adam/read:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/beta/Adam_1/Initializer/zeros:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/beta/Adam_1:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/beta/Adam_1/Assign:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/batch_normalization/beta/Adam_1/read:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d/kernel/Adam/Initializer/zeros:0\", shape=(1, 370, 1, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d/kernel/Adam:0\", shape=(1, 370, 1, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/conv2d/kernel/Adam/Assign:0\", shape=(1, 370, 1, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/conv2d/kernel/Adam/read:0\", shape=(1, 370, 1, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d/kernel/Adam_1/Initializer/zeros:0\", shape=(1, 370, 1, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d/kernel/Adam_1:0\", shape=(1, 370, 1, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/conv2d/kernel/Adam_1/Assign:0\", shape=(1, 370, 1, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/conv2d/kernel/Adam_1/read:0\", shape=(1, 370, 1, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d/bias/Adam/Initializer/zeros:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d/bias/Adam:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/conv2d/bias/Adam/Assign:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/conv2d/bias/Adam/read:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d/bias/Adam_1/Initializer/zeros:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d/bias/Adam_1:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/conv2d/bias/Adam_1/Assign:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/conv2d/bias/Adam_1/read:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/Variable_2/Adam/Initializer/zeros/shape_as_tensor:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gcn_block_O_vision/Variable_2/Adam/Initializer/zeros/Const:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/Variable_2/Adam/Initializer/zeros:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/Variable_2/Adam:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/Variable_2/Adam/Assign:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/Variable_2/Adam/read:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/Variable_2/Adam_1/Initializer/zeros/shape_as_tensor:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gcn_block_O_vision/Variable_2/Adam_1/Initializer/zeros/Const:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/Variable_2/Adam_1/Initializer/zeros:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/Variable_2/Adam_1:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/Variable_2/Adam_1/Assign:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/Variable_2/Adam_1/read:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/Variable_3/Adam/Initializer/zeros/shape_as_tensor:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gcn_block_O_vision/Variable_3/Adam/Initializer/zeros/Const:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/Variable_3/Adam/Initializer/zeros:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/Variable_3/Adam:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/Variable_3/Adam/Assign:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/Variable_3/Adam/read:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/Variable_3/Adam_1/Initializer/zeros/shape_as_tensor:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gcn_block_O_vision/Variable_3/Adam_1/Initializer/zeros/Const:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/Variable_3/Adam_1/Initializer/zeros:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/Variable_3/Adam_1:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/Variable_3/Adam_1/Assign:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/Variable_3/Adam_1/read:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d_1/kernel/Adam/Initializer/zeros:0\", shape=(370, 1, 1, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d_1/kernel/Adam:0\", shape=(370, 1, 1, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/conv2d_1/kernel/Adam/Assign:0\", shape=(370, 1, 1, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/conv2d_1/kernel/Adam/read:0\", shape=(370, 1, 1, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d_1/kernel/Adam_1/Initializer/zeros:0\", shape=(370, 1, 1, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d_1/kernel/Adam_1:0\", shape=(370, 1, 1, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/conv2d_1/kernel/Adam_1/Assign:0\", shape=(370, 1, 1, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/conv2d_1/kernel/Adam_1/read:0\", shape=(370, 1, 1, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d_1/bias/Adam/Initializer/zeros:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d_1/bias/Adam:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/conv2d_1/bias/Adam/Assign:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/conv2d_1/bias/Adam/read:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d_1/bias/Adam_1/Initializer/zeros:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/conv2d_1/bias/Adam_1:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/conv2d_1/bias/Adam_1/Assign:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/conv2d_1/bias/Adam_1/read:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/Variable_4/Adam/Initializer/zeros/shape_as_tensor:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gcn_block_O_vision/Variable_4/Adam/Initializer/zeros/Const:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/Variable_4/Adam/Initializer/zeros:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/Variable_4/Adam:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/Variable_4/Adam/Assign:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/Variable_4/Adam/read:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/Variable_4/Adam_1/Initializer/zeros/shape_as_tensor:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gcn_block_O_vision/Variable_4/Adam_1/Initializer/zeros/Const:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/Variable_4/Adam_1/Initializer/zeros:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/Variable_4/Adam_1:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/Variable_4/Adam_1/Assign:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/Variable_4/Adam_1/read:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/Variable_5/Adam/Initializer/zeros/shape_as_tensor:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gcn_block_O_vision/Variable_5/Adam/Initializer/zeros/Const:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/Variable_5/Adam/Initializer/zeros:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/Variable_5/Adam:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/Variable_5/Adam/Assign:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/Variable_5/Adam/read:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/Variable_5/Adam_1/Initializer/zeros/shape_as_tensor:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gcn_block_O_vision/Variable_5/Adam_1/Initializer/zeros/Const:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/Variable_5/Adam_1/Initializer/zeros:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_O_vision/Variable_5/Adam_1:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/Variable_5/Adam_1/Assign:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_O_vision/Variable_5/Adam_1/read:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/Variable/Adam/Initializer/zeros/shape_as_tensor:0\", shape=(3,), dtype=int32)\n",
      "Tensor(\"gcn_block_D_vision/Variable/Adam/Initializer/zeros/Const:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/Variable/Adam/Initializer/zeros:0\", shape=(40, 370, 370), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/Variable/Adam:0\", shape=(40, 370, 370), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/Variable/Adam/Assign:0\", shape=(40, 370, 370), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/Variable/Adam/read:0\", shape=(40, 370, 370), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/Variable/Adam_1/Initializer/zeros/shape_as_tensor:0\", shape=(3,), dtype=int32)\n",
      "Tensor(\"gcn_block_D_vision/Variable/Adam_1/Initializer/zeros/Const:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/Variable/Adam_1/Initializer/zeros:0\", shape=(40, 370, 370), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/Variable/Adam_1:0\", shape=(40, 370, 370), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/Variable/Adam_1/Assign:0\", shape=(40, 370, 370), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/Variable/Adam_1/read:0\", shape=(40, 370, 370), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/Variable_1/Adam/Initializer/zeros/shape_as_tensor:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gcn_block_D_vision/Variable_1/Adam/Initializer/zeros/Const:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/Variable_1/Adam/Initializer/zeros:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/Variable_1/Adam:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/Variable_1/Adam/Assign:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/Variable_1/Adam/read:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/Variable_1/Adam_1/Initializer/zeros/shape_as_tensor:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gcn_block_D_vision/Variable_1/Adam_1/Initializer/zeros/Const:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/Variable_1/Adam_1/Initializer/zeros:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/Variable_1/Adam_1:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/Variable_1/Adam_1/Assign:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/Variable_1/Adam_1/read:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/gamma/Adam/Initializer/zeros:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/gamma/Adam:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/gamma/Adam/Assign:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/gamma/Adam/read:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/gamma/Adam_1/Initializer/zeros:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/gamma/Adam_1:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/gamma/Adam_1/Assign:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/gamma/Adam_1/read:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/beta/Adam/Initializer/zeros:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/beta/Adam:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/beta/Adam/Assign:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/beta/Adam/read:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/beta/Adam_1/Initializer/zeros:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/beta/Adam_1:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/beta/Adam_1/Assign:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/batch_normalization/beta/Adam_1/read:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d/kernel/Adam/Initializer/zeros:0\", shape=(1, 370, 1, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d/kernel/Adam:0\", shape=(1, 370, 1, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/conv2d/kernel/Adam/Assign:0\", shape=(1, 370, 1, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/conv2d/kernel/Adam/read:0\", shape=(1, 370, 1, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d/kernel/Adam_1/Initializer/zeros:0\", shape=(1, 370, 1, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d/kernel/Adam_1:0\", shape=(1, 370, 1, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/conv2d/kernel/Adam_1/Assign:0\", shape=(1, 370, 1, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/conv2d/kernel/Adam_1/read:0\", shape=(1, 370, 1, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d/bias/Adam/Initializer/zeros:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d/bias/Adam:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/conv2d/bias/Adam/Assign:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/conv2d/bias/Adam/read:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d/bias/Adam_1/Initializer/zeros:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d/bias/Adam_1:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/conv2d/bias/Adam_1/Assign:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/conv2d/bias/Adam_1/read:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/Variable_2/Adam/Initializer/zeros/shape_as_tensor:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gcn_block_D_vision/Variable_2/Adam/Initializer/zeros/Const:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/Variable_2/Adam/Initializer/zeros:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/Variable_2/Adam:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/Variable_2/Adam/Assign:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/Variable_2/Adam/read:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/Variable_2/Adam_1/Initializer/zeros/shape_as_tensor:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gcn_block_D_vision/Variable_2/Adam_1/Initializer/zeros/Const:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/Variable_2/Adam_1/Initializer/zeros:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/Variable_2/Adam_1:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/Variable_2/Adam_1/Assign:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/Variable_2/Adam_1/read:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/Variable_3/Adam/Initializer/zeros/shape_as_tensor:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gcn_block_D_vision/Variable_3/Adam/Initializer/zeros/Const:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/Variable_3/Adam/Initializer/zeros:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/Variable_3/Adam:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/Variable_3/Adam/Assign:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/Variable_3/Adam/read:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/Variable_3/Adam_1/Initializer/zeros/shape_as_tensor:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gcn_block_D_vision/Variable_3/Adam_1/Initializer/zeros/Const:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/Variable_3/Adam_1/Initializer/zeros:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/Variable_3/Adam_1:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/Variable_3/Adam_1/Assign:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/Variable_3/Adam_1/read:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d_1/kernel/Adam/Initializer/zeros:0\", shape=(370, 1, 1, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d_1/kernel/Adam:0\", shape=(370, 1, 1, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/conv2d_1/kernel/Adam/Assign:0\", shape=(370, 1, 1, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/conv2d_1/kernel/Adam/read:0\", shape=(370, 1, 1, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d_1/kernel/Adam_1/Initializer/zeros:0\", shape=(370, 1, 1, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d_1/kernel/Adam_1:0\", shape=(370, 1, 1, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/conv2d_1/kernel/Adam_1/Assign:0\", shape=(370, 1, 1, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/conv2d_1/kernel/Adam_1/read:0\", shape=(370, 1, 1, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d_1/bias/Adam/Initializer/zeros:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d_1/bias/Adam:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/conv2d_1/bias/Adam/Assign:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/conv2d_1/bias/Adam/read:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d_1/bias/Adam_1/Initializer/zeros:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/conv2d_1/bias/Adam_1:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/conv2d_1/bias/Adam_1/Assign:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/conv2d_1/bias/Adam_1/read:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/Variable_4/Adam/Initializer/zeros/shape_as_tensor:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gcn_block_D_vision/Variable_4/Adam/Initializer/zeros/Const:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/Variable_4/Adam/Initializer/zeros:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/Variable_4/Adam:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/Variable_4/Adam/Assign:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/Variable_4/Adam/read:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/Variable_4/Adam_1/Initializer/zeros/shape_as_tensor:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gcn_block_D_vision/Variable_4/Adam_1/Initializer/zeros/Const:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/Variable_4/Adam_1/Initializer/zeros:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/Variable_4/Adam_1:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/Variable_4/Adam_1/Assign:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/Variable_4/Adam_1/read:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/Variable_5/Adam/Initializer/zeros/shape_as_tensor:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gcn_block_D_vision/Variable_5/Adam/Initializer/zeros/Const:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/Variable_5/Adam/Initializer/zeros:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/Variable_5/Adam:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/Variable_5/Adam/Assign:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/Variable_5/Adam/read:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/Variable_5/Adam_1/Initializer/zeros/shape_as_tensor:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"gcn_block_D_vision/Variable_5/Adam_1/Initializer/zeros/Const:0\", shape=(), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/Variable_5/Adam_1/Initializer/zeros:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"gcn_block_D_vision/Variable_5/Adam_1:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/Variable_5/Adam_1/Assign:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"gcn_block_D_vision/Variable_5/Adam_1/read:0\", shape=(19, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"tcn_block0/batch_normalization/gamma/Adam/Initializer/zeros:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"tcn_block0/batch_normalization/gamma/Adam:0\", shape=(2,), dtype=float32_ref)\n",
      "Tensor(\"tcn_block0/batch_normalization/gamma/Adam/Assign:0\", shape=(2,), dtype=float32_ref)\n",
      "Tensor(\"tcn_block0/batch_normalization/gamma/Adam/read:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"tcn_block0/batch_normalization/gamma/Adam_1/Initializer/zeros:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"tcn_block0/batch_normalization/gamma/Adam_1:0\", shape=(2,), dtype=float32_ref)\n",
      "Tensor(\"tcn_block0/batch_normalization/gamma/Adam_1/Assign:0\", shape=(2,), dtype=float32_ref)\n",
      "Tensor(\"tcn_block0/batch_normalization/gamma/Adam_1/read:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"tcn_block0/batch_normalization/beta/Adam/Initializer/zeros:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"tcn_block0/batch_normalization/beta/Adam:0\", shape=(2,), dtype=float32_ref)\n",
      "Tensor(\"tcn_block0/batch_normalization/beta/Adam/Assign:0\", shape=(2,), dtype=float32_ref)\n",
      "Tensor(\"tcn_block0/batch_normalization/beta/Adam/read:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"tcn_block0/batch_normalization/beta/Adam_1/Initializer/zeros:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"tcn_block0/batch_normalization/beta/Adam_1:0\", shape=(2,), dtype=float32_ref)\n",
      "Tensor(\"tcn_block0/batch_normalization/beta/Adam_1/Assign:0\", shape=(2,), dtype=float32_ref)\n",
      "Tensor(\"tcn_block0/batch_normalization/beta/Adam_1/read:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"tcn_block0/conv3d/kernel/Adam/Initializer/zeros:0\", shape=(19, 1, 1, 2, 3), dtype=float32)\n",
      "Tensor(\"tcn_block0/conv3d/kernel/Adam:0\", shape=(), dtype=resource)\n",
      "Tensor(\"tcn_block0/conv3d/kernel/Adam/IsInitialized/VarIsInitializedOp:0\", shape=(), dtype=bool)\n",
      "tcn_block0/conv3d/kernel/Adam/Assign has 0 outputs\n",
      "Tensor(\"tcn_block0/conv3d/kernel/Adam/Read/ReadVariableOp:0\", shape=(19, 1, 1, 2, 3), dtype=float32)\n",
      "Tensor(\"tcn_block0/conv3d/kernel/Adam_1/Initializer/zeros:0\", shape=(19, 1, 1, 2, 3), dtype=float32)\n",
      "Tensor(\"tcn_block0/conv3d/kernel/Adam_1:0\", shape=(), dtype=resource)\n",
      "Tensor(\"tcn_block0/conv3d/kernel/Adam_1/IsInitialized/VarIsInitializedOp:0\", shape=(), dtype=bool)\n",
      "tcn_block0/conv3d/kernel/Adam_1/Assign has 0 outputs\n",
      "Tensor(\"tcn_block0/conv3d/kernel/Adam_1/Read/ReadVariableOp:0\", shape=(19, 1, 1, 2, 3), dtype=float32)\n",
      "Tensor(\"tcn_block0/conv3d/bias/Adam/Initializer/zeros:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"tcn_block0/conv3d/bias/Adam:0\", shape=(), dtype=resource)\n",
      "Tensor(\"tcn_block0/conv3d/bias/Adam/IsInitialized/VarIsInitializedOp:0\", shape=(), dtype=bool)\n",
      "tcn_block0/conv3d/bias/Adam/Assign has 0 outputs\n",
      "Tensor(\"tcn_block0/conv3d/bias/Adam/Read/ReadVariableOp:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"tcn_block0/conv3d/bias/Adam_1/Initializer/zeros:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"tcn_block0/conv3d/bias/Adam_1:0\", shape=(), dtype=resource)\n",
      "Tensor(\"tcn_block0/conv3d/bias/Adam_1/IsInitialized/VarIsInitializedOp:0\", shape=(), dtype=bool)\n",
      "tcn_block0/conv3d/bias/Adam_1/Assign has 0 outputs\n",
      "Tensor(\"tcn_block0/conv3d/bias/Adam_1/Read/ReadVariableOp:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"tcn_block1/batch_normalization/gamma/Adam/Initializer/zeros:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"tcn_block1/batch_normalization/gamma/Adam:0\", shape=(3,), dtype=float32_ref)\n",
      "Tensor(\"tcn_block1/batch_normalization/gamma/Adam/Assign:0\", shape=(3,), dtype=float32_ref)\n",
      "Tensor(\"tcn_block1/batch_normalization/gamma/Adam/read:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"tcn_block1/batch_normalization/gamma/Adam_1/Initializer/zeros:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"tcn_block1/batch_normalization/gamma/Adam_1:0\", shape=(3,), dtype=float32_ref)\n",
      "Tensor(\"tcn_block1/batch_normalization/gamma/Adam_1/Assign:0\", shape=(3,), dtype=float32_ref)\n",
      "Tensor(\"tcn_block1/batch_normalization/gamma/Adam_1/read:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"tcn_block1/batch_normalization/beta/Adam/Initializer/zeros:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"tcn_block1/batch_normalization/beta/Adam:0\", shape=(3,), dtype=float32_ref)\n",
      "Tensor(\"tcn_block1/batch_normalization/beta/Adam/Assign:0\", shape=(3,), dtype=float32_ref)\n",
      "Tensor(\"tcn_block1/batch_normalization/beta/Adam/read:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"tcn_block1/batch_normalization/beta/Adam_1/Initializer/zeros:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"tcn_block1/batch_normalization/beta/Adam_1:0\", shape=(3,), dtype=float32_ref)\n",
      "Tensor(\"tcn_block1/batch_normalization/beta/Adam_1/Assign:0\", shape=(3,), dtype=float32_ref)\n",
      "Tensor(\"tcn_block1/batch_normalization/beta/Adam_1/read:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"tcn_block1/conv3d_1/kernel/Adam/Initializer/zeros:0\", shape=(19, 1, 1, 3, 1), dtype=float32)\n",
      "Tensor(\"tcn_block1/conv3d_1/kernel/Adam:0\", shape=(), dtype=resource)\n",
      "Tensor(\"tcn_block1/conv3d_1/kernel/Adam/IsInitialized/VarIsInitializedOp:0\", shape=(), dtype=bool)\n",
      "tcn_block1/conv3d_1/kernel/Adam/Assign has 0 outputs\n",
      "Tensor(\"tcn_block1/conv3d_1/kernel/Adam/Read/ReadVariableOp:0\", shape=(19, 1, 1, 3, 1), dtype=float32)\n",
      "Tensor(\"tcn_block1/conv3d_1/kernel/Adam_1/Initializer/zeros:0\", shape=(19, 1, 1, 3, 1), dtype=float32)\n",
      "Tensor(\"tcn_block1/conv3d_1/kernel/Adam_1:0\", shape=(), dtype=resource)\n",
      "Tensor(\"tcn_block1/conv3d_1/kernel/Adam_1/IsInitialized/VarIsInitializedOp:0\", shape=(), dtype=bool)\n",
      "tcn_block1/conv3d_1/kernel/Adam_1/Assign has 0 outputs\n",
      "Tensor(\"tcn_block1/conv3d_1/kernel/Adam_1/Read/ReadVariableOp:0\", shape=(19, 1, 1, 3, 1), dtype=float32)\n",
      "Tensor(\"tcn_block1/conv3d_1/bias/Adam/Initializer/zeros:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"tcn_block1/conv3d_1/bias/Adam:0\", shape=(), dtype=resource)\n",
      "Tensor(\"tcn_block1/conv3d_1/bias/Adam/IsInitialized/VarIsInitializedOp:0\", shape=(), dtype=bool)\n",
      "tcn_block1/conv3d_1/bias/Adam/Assign has 0 outputs\n",
      "Tensor(\"tcn_block1/conv3d_1/bias/Adam/Read/ReadVariableOp:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"tcn_block1/conv3d_1/bias/Adam_1/Initializer/zeros:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"tcn_block1/conv3d_1/bias/Adam_1:0\", shape=(), dtype=resource)\n",
      "Tensor(\"tcn_block1/conv3d_1/bias/Adam_1/IsInitialized/VarIsInitializedOp:0\", shape=(), dtype=bool)\n",
      "tcn_block1/conv3d_1/bias/Adam_1/Assign has 0 outputs\n",
      "Tensor(\"tcn_block1/conv3d_1/bias/Adam_1/Read/ReadVariableOp:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"tcn_block2/batch_normalization/gamma/Adam/Initializer/zeros:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"tcn_block2/batch_normalization/gamma/Adam:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"tcn_block2/batch_normalization/gamma/Adam/Assign:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"tcn_block2/batch_normalization/gamma/Adam/read:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"tcn_block2/batch_normalization/gamma/Adam_1/Initializer/zeros:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"tcn_block2/batch_normalization/gamma/Adam_1:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"tcn_block2/batch_normalization/gamma/Adam_1/Assign:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"tcn_block2/batch_normalization/gamma/Adam_1/read:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"tcn_block2/batch_normalization/beta/Adam/Initializer/zeros:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"tcn_block2/batch_normalization/beta/Adam:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"tcn_block2/batch_normalization/beta/Adam/Assign:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"tcn_block2/batch_normalization/beta/Adam/read:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"tcn_block2/batch_normalization/beta/Adam_1/Initializer/zeros:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"tcn_block2/batch_normalization/beta/Adam_1:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"tcn_block2/batch_normalization/beta/Adam_1/Assign:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"tcn_block2/batch_normalization/beta/Adam_1/read:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"tcn_block2/conv3d_2/kernel/Adam/Initializer/zeros:0\", shape=(20, 1, 1, 1, 1), dtype=float32)\n",
      "Tensor(\"tcn_block2/conv3d_2/kernel/Adam:0\", shape=(), dtype=resource)\n",
      "Tensor(\"tcn_block2/conv3d_2/kernel/Adam/IsInitialized/VarIsInitializedOp:0\", shape=(), dtype=bool)\n",
      "tcn_block2/conv3d_2/kernel/Adam/Assign has 0 outputs\n",
      "Tensor(\"tcn_block2/conv3d_2/kernel/Adam/Read/ReadVariableOp:0\", shape=(20, 1, 1, 1, 1), dtype=float32)\n",
      "Tensor(\"tcn_block2/conv3d_2/kernel/Adam_1/Initializer/zeros:0\", shape=(20, 1, 1, 1, 1), dtype=float32)\n",
      "Tensor(\"tcn_block2/conv3d_2/kernel/Adam_1:0\", shape=(), dtype=resource)\n",
      "Tensor(\"tcn_block2/conv3d_2/kernel/Adam_1/IsInitialized/VarIsInitializedOp:0\", shape=(), dtype=bool)\n",
      "tcn_block2/conv3d_2/kernel/Adam_1/Assign has 0 outputs\n",
      "Tensor(\"tcn_block2/conv3d_2/kernel/Adam_1/Read/ReadVariableOp:0\", shape=(20, 1, 1, 1, 1), dtype=float32)\n",
      "Tensor(\"tcn_block2/conv3d_2/bias/Adam/Initializer/zeros:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"tcn_block2/conv3d_2/bias/Adam:0\", shape=(), dtype=resource)\n",
      "Tensor(\"tcn_block2/conv3d_2/bias/Adam/IsInitialized/VarIsInitializedOp:0\", shape=(), dtype=bool)\n",
      "tcn_block2/conv3d_2/bias/Adam/Assign has 0 outputs\n",
      "Tensor(\"tcn_block2/conv3d_2/bias/Adam/Read/ReadVariableOp:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"tcn_block2/conv3d_2/bias/Adam_1/Initializer/zeros:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"tcn_block2/conv3d_2/bias/Adam_1:0\", shape=(), dtype=resource)\n",
      "Tensor(\"tcn_block2/conv3d_2/bias/Adam_1/IsInitialized/VarIsInitializedOp:0\", shape=(), dtype=bool)\n",
      "tcn_block2/conv3d_2/bias/Adam_1/Assign has 0 outputs\n",
      "Tensor(\"tcn_block2/conv3d_2/bias/Adam_1/Read/ReadVariableOp:0\", shape=(1,), dtype=float32)\n",
      "Tensor(\"Adam/beta1:0\", shape=(), dtype=float32)\n",
      "Tensor(\"Adam/beta2:0\", shape=(), dtype=float32)\n",
      "Tensor(\"Adam/epsilon:0\", shape=(), dtype=float32)\n",
      "Tensor(\"Adam/update_gcn_block_O_vision/Variable/ApplyAdam:0\", shape=(40, 370, 370), dtype=float32_ref)\n",
      "Tensor(\"Adam/update_gcn_block_O_vision/Variable_1/ApplyAdam:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"Adam/update_gcn_block_O_vision/batch_normalization/gamma/ApplyAdam:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"Adam/update_gcn_block_O_vision/batch_normalization/beta/ApplyAdam:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"Adam/update_gcn_block_O_vision/conv2d/kernel/ApplyAdam:0\", shape=(1, 370, 1, 1), dtype=float32_ref)\n",
      "Tensor(\"Adam/update_gcn_block_O_vision/conv2d/bias/ApplyAdam:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"Adam/update_gcn_block_O_vision/Variable_2/ApplyAdam:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"Adam/update_gcn_block_O_vision/Variable_3/ApplyAdam:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"Adam/update_gcn_block_O_vision/conv2d_1/kernel/ApplyAdam:0\", shape=(370, 1, 1, 1), dtype=float32_ref)\n",
      "Tensor(\"Adam/update_gcn_block_O_vision/conv2d_1/bias/ApplyAdam:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"Adam/update_gcn_block_O_vision/Variable_4/ApplyAdam:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"Adam/update_gcn_block_O_vision/Variable_5/ApplyAdam:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"Adam/update_gcn_block_D_vision/Variable/ApplyAdam:0\", shape=(40, 370, 370), dtype=float32_ref)\n",
      "Tensor(\"Adam/update_gcn_block_D_vision/Variable_1/ApplyAdam:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"Adam/update_gcn_block_D_vision/batch_normalization/gamma/ApplyAdam:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"Adam/update_gcn_block_D_vision/batch_normalization/beta/ApplyAdam:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"Adam/update_gcn_block_D_vision/conv2d/kernel/ApplyAdam:0\", shape=(1, 370, 1, 1), dtype=float32_ref)\n",
      "Tensor(\"Adam/update_gcn_block_D_vision/conv2d/bias/ApplyAdam:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"Adam/update_gcn_block_D_vision/Variable_2/ApplyAdam:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"Adam/update_gcn_block_D_vision/Variable_3/ApplyAdam:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"Adam/update_gcn_block_D_vision/conv2d_1/kernel/ApplyAdam:0\", shape=(370, 1, 1, 1), dtype=float32_ref)\n",
      "Tensor(\"Adam/update_gcn_block_D_vision/conv2d_1/bias/ApplyAdam:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"Adam/update_gcn_block_D_vision/Variable_4/ApplyAdam:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"Adam/update_gcn_block_D_vision/Variable_5/ApplyAdam:0\", shape=(19, 370, 370, 1), dtype=float32_ref)\n",
      "Tensor(\"Adam/update_tcn_block0/batch_normalization/gamma/ApplyAdam:0\", shape=(2,), dtype=float32_ref)\n",
      "Tensor(\"Adam/update_tcn_block0/batch_normalization/beta/ApplyAdam:0\", shape=(2,), dtype=float32_ref)\n",
      "Adam/update_tcn_block0/conv3d/kernel/ResourceApplyAdam has 0 outputs\n",
      "Adam/update_tcn_block0/conv3d/bias/ResourceApplyAdam has 0 outputs\n",
      "Tensor(\"Adam/update_tcn_block1/batch_normalization/gamma/ApplyAdam:0\", shape=(3,), dtype=float32_ref)\n",
      "Tensor(\"Adam/update_tcn_block1/batch_normalization/beta/ApplyAdam:0\", shape=(3,), dtype=float32_ref)\n",
      "Adam/update_tcn_block1/conv3d_1/kernel/ResourceApplyAdam has 0 outputs\n",
      "Adam/update_tcn_block1/conv3d_1/bias/ResourceApplyAdam has 0 outputs\n",
      "Tensor(\"Adam/update_tcn_block2/batch_normalization/gamma/ApplyAdam:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"Adam/update_tcn_block2/batch_normalization/beta/ApplyAdam:0\", shape=(1,), dtype=float32_ref)\n",
      "Adam/update_tcn_block2/conv3d_2/kernel/ResourceApplyAdam has 0 outputs\n",
      "Adam/update_tcn_block2/conv3d_2/bias/ResourceApplyAdam has 0 outputs\n",
      "Tensor(\"Adam/mul:0\", shape=(), dtype=float32)\n",
      "Tensor(\"Adam/Assign:0\", shape=(), dtype=float32_ref)\n",
      "Tensor(\"Adam/mul_1:0\", shape=(), dtype=float32)\n",
      "Tensor(\"Adam/Assign_1:0\", shape=(), dtype=float32_ref)\n",
      "Adam/update has 0 outputs\n",
      "Tensor(\"Adam/value:0\", shape=(), dtype=int32)\n",
      "Tensor(\"Adam:0\", shape=(), dtype=int32_ref)\n",
      "group_deps has 0 outputs\n",
      "Tensor(\"sub_1:0\", shape=(?, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"truediv:0\", shape=(?, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"Abs:0\", shape=(?, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"sub_2/x:0\", shape=(), dtype=float32)\n",
      "Tensor(\"sub_2:0\", shape=(?, 370, 370, 1), dtype=float32)\n",
      "Tensor(\"IsInf:0\", shape=(?, 370, 370, 1), dtype=bool)\n",
      "Tensor(\"LogicalNot:0\", shape=(?, 370, 370, 1), dtype=bool)\n",
      "Tensor(\"Where:0\", shape=(?, 4), dtype=int64)\n",
      "Tensor(\"GatherNd:0\", shape=(?,), dtype=float32)\n",
      "Tensor(\"IsNan:0\", shape=(?,), dtype=bool)\n",
      "Tensor(\"ones_like/Shape:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"ones_like/Const:0\", shape=(), dtype=float32)\n",
      "Tensor(\"ones_like:0\", shape=(?,), dtype=float32)\n",
      "Tensor(\"Select:0\", shape=(?,), dtype=float32)\n",
      "Tensor(\"Const_4:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"Mean:0\", shape=(), dtype=float32)\n",
      "Tensor(\"NotEqual/y:0\", shape=(), dtype=float32)\n",
      "Tensor(\"NotEqual:0\", shape=(?, 370, 370, 1), dtype=bool)\n",
      "Tensor(\"Where_1:0\", shape=(?, 4), dtype=int64)\n",
      "Tensor(\"GatherNd_1:0\", shape=(?,), dtype=float32)\n",
      "Tensor(\"GatherNd_2:0\", shape=(?,), dtype=float32)\n",
      "Tensor(\"sub_3:0\", shape=(?,), dtype=float32)\n",
      "Tensor(\"truediv_1:0\", shape=(?,), dtype=float32)\n",
      "Tensor(\"Abs_1:0\", shape=(?,), dtype=float32)\n",
      "Tensor(\"sub_4/x:0\", shape=(), dtype=float32)\n",
      "Tensor(\"sub_4:0\", shape=(?,), dtype=float32)\n",
      "Tensor(\"Const_5:0\", shape=(1,), dtype=int32)\n",
      "Tensor(\"Mean_1:0\", shape=(), dtype=float32)\n",
      "init has 0 outputs\n",
      "init_1 has 0 outputs\n",
      "group_deps_1 has 0 outputs\n"
     ]
    }
   ],
   "source": [
    "for n in tf.get_default_graph().as_graph_def().node:\n",
    "    try:\n",
    "        print(tf.get_default_graph().get_tensor_by_name(n.name+':0'))\n",
    "    except:\n",
    "        print(n.name, \"has 0 outputs\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Oct 29 03:36:45 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.31       Driver Version: 440.31       CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P40           Off  | 00000000:06:00.0 Off |                    0 |\n",
      "| N/A   33C    P0    49W / 250W |      0MiB / 22919MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla P40           Off  | 00000000:2F:00.0 Off |                    0 |\n",
      "| N/A   49C    P0   119W / 250W |  21751MiB / 22919MiB |    100%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla P40           Off  | 00000000:86:00.0 Off |                    0 |\n",
      "| N/A   32C    P0    48W / 250W |  21751MiB / 22919MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla P40           Off  | 00000000:D8:00.0 Off |                    0 |\n",
      "| N/A   29C    P0    46W / 250W |      0MiB / 22919MiB |      5%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train min 0.33630487\n",
      "test min 0.8383609\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot(array):\n",
    "    n=len(array[0])\n",
    "    plt.plot(np.arange(n),array[0],label='train')\n",
    "    plt.plot(np.arange(n),array[1],label='test')\n",
    "    plt.legend()\n",
    "print(\"train min\",min(loss_list[0]))\n",
    "print(\"test min\",min(loss_list[1]))\n",
    "plot(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146\n",
      "train max acc 0.91197723\n",
      "test  acc 0.7917268\n"
     ]
    }
   ],
   "source": [
    "accmax_index=np.argmax(acc_list[0])\n",
    "print(accmax_index)\n",
    "print(\"train max acc\",acc_list[0][accmax_index])\n",
    "print(\"test  acc\",acc_list[1][accmax_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train max 0.8716929\n",
      "test max 0.78410274\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAjU0lEQVR4nO3deXhc9X3v8fd3Fo0Wy7YsyQbbgI1xCLsJCoUGSAgQjJuwZSO9SUmbXKdt8jzpbZMbKC2X3CYtSZqN2wTiJvSmTVNCSQmkmGIgJtzSsMjGgI3Bso3B8iZZtiVrne17/5gz8lgeyYs0Gsnn83oePXPmd86c8/3NGc13fsucMXdHRETCK1LuAEREpLyUCEREQk6JQEQk5JQIRERCTolARCTkYuUO4Fg0NDT4vHnzyh2GiMiksmrVqt3u3ji0fFImgnnz5tHc3FzuMEREJhUze7NYubqGRERCTolARCTklAhEREJOiUBEJOSUCEREQk6JQEQk5JQIRERCTolA5DCyWadnIE1Xf+qIH7OnJ0ln35Fvf6QyWSedyR5Sns06qaD8rY5eegbSx7T/Nzt62NzeDUBvMk3Lrv1H9LhUJnvQMVt27WdTsJ+8/lSG/f0p9vQk2dXVf0j8z2zcTbHL4g8t6xlIk83myrr6UwykM4dsn8kW38++3iS7uwdIprMk0weex2Q6e8jzuvK1Nrbu6R2p2oP7zceYzR5Y7ktmcHf6U5lD9p3KZAe3c3e27+sbXPf6zv2D657e0M6bHT0MpDNF6zpWJuUXyia7/f0pdnb2s3BWLe7Onp4kGXeqK2JMScR4q6OXE6ZVDv6zbN3Ty/TqCmbUVFBXE2dPT5K127q4eEE9VfEofakML2/dx+zpVXT1p1jQOCV440rz6Cs7WLe9i6/ecDab2nt4bWcXJ0ytZPb0Kp57Yw/xqNGXzPCr19r4wScu4I3dPfz69TZe3LKbL/3OOXT1JamIgkWifPfJFj7+W6fQsmMP339qI39z4zms3trFH75nIV/9xSpmzZjKR945j1+tWktrXwWz62rpGUjS1Z/hJ8+9xUfPa6Sju5enNnUx0/Zy7fknY4mpdKVj/OSFbVSQ4uJTajn9hFp++txbNFZmqKuK8ubeJEuvOIvz5tTyVw+9xAlTq4halq27u+jsG8DdcIwsxtlzppHMGrGI8equHpJpJ4tx/sl1rHqrkyy5bf/q+nO4/Rcv02idpIjR6wmiEePasxs5tT7B/c+9wa5ep9oGmEIfvSTopwKA959zItOqotz//JtEyBLBiZKlvjpKV+8AUbJEyBIl98/fTwVXLTqVX6zZTiVJEuQShBlk3aisiLEvGSFKhkqS9FNBihhRslSQ4owTamjZ2YXhTLF+omTY6TMAA5wEKWbaPirIJx7DAccguC12n8H7uTLDGaCCbq9kivUzjR66qMKCPTpGhCzVDBAJ6mYFr+v8XgEyRMkQIUOENFHSwTMVIUsd3dRYP91eRWV1NZ29KaoYIG4Z/s2jmDnuRpIYlZZ7vrZ7PTNtH1UMDB7Dg3OZIka/x5luPXRRzYDHqbQkMTJBzH5QbIWGK8978jDbDr/f4sZiH4s/9CkuPP/8YdYeG5uMP0zT1NTk4/HN4r0v/pLkuofZvL2N7v1dxMkM/oNH7cA/e+E/ftEy88GyKBnipIlzILN7wT9k/v7QMopsM/SxxcoOfuzIx4ngTKebGBlilqXf4ySJM9V62ec1VJGkjwqq6R98kwPooZKpduATDUC/x6m0A5+I0x4hZod+khWRo7PvxvuYfu41x/RYM1vl7k1Dy9UiGMbeZ/6Busf/hL0+hVk+hamWIBW8vWeCTzdpjzJAfLAsX154myFC1iNkPEIGI0OUFDFSRAc/hcGB7G+HfF6j4P7BSbuwfLhth5ZTUD50mwpL0ek1dFPFgOcSwAzrYrs3MI0eeknQYF3s8VqyGOngU98M9rOHWqoZ4OrIC6zMLiJLhDhpdnkdddZNJUlavYE662autfOGn8ibPosp9JEgSYwsSWKkCl6SvSTIEiFGhioGyBIhGazPEjnoOcw/BxGyg7cMuZ+rc+4TfATHgXafTswyg58008G5yXiESksx4HH2MoVqBgo+yTtZt0POdxY75HUAUEmSGgYwsvSTYID44BkznAhZKkiTIUKsoopMspcYGTJESAYfP/I17PXcczLT9gZn0xggnqtHooqegTRXnzWL7Xt7eWN3D73J9JBz7Zw+a8pgl0/EnIaaCnZ3D+AYp9fH2b2ng15PcPmi03lzx0427OpmwcxaNrXtJ0sEq6hm9oxa3trTy5knTqWjJ8mCxhp2dydZvbUTw5lfl2Db3h4uW1AH2TSr32gbbFVceNZCTp3dyJpN2+ju7qKlrZcrz5uHRSvYvGsf9VMqWfn6LhKkqJs6lT++4u383YMrOXneAi4+Yz4tbd2kM1m6B9JURmHFK1upsgFuuuxcqrM9/PuLb1JVVcMnL1vI/S+8xSULZ9KXdrr601TGIsydXs33nmrhvW+fRW1ljOff3Es8EuGj7zyJ7fv6OLVxCi9s2cMTr+7iqrNO4Ibz5/Lqjk7WbeuiriYBwEWnzqA3mWHtti6a39zL779rHr98aTsRMz596Xyee2MPu7oGOKWhhs6eJKc01PD0hnYWn30CD6zezuWnN1BbGWfDrm5m1MSpiMVYv6OLq8+eRUNNgh2d/by6o4v6mgTxWIT6mgqS6SxTKmOcNmdW0fes0VCLoIhM1nnljneQIM21ya8c9OZ0JN79tkZ+vaEdgNpEjMve1sj7zprFD369mVd3dPHEn76bgXSGv33sdf77paeybV8fnX0pbrrwZHoG0tz1ZAuv7dzPnTeeQ2NtguWv7GRHZx/XLZrN3LpqKuNRAH7y7JucceJUdnb2c9nbGnhyfRvXLZpNOut09qWojEfZ25NkT0+S806aPhjfnp4kiViE6ooo/aksL27dSyIWoTIeJZuFk+ur6egeoL4mQSIeIR6NEI3k3rjSmSy/fHk71543BwO2d/bxqf/bzL8svYi66jjzb13Ony95O0svWwDAwy9t59w505jXUDN4/K7+FAOpLI21icGyZDpLRSxCz0Cax9bt5HfOPZFELDq4PpXJsmV3Dwtn1R7xOezsSzGjpuKozt3Ryv//mNkh5UPLRtKfylARjRCJHPljRuPFt/ZSWxnjtJlH9nzK8WG4FoESwRA/eup1Vjz/Mj/r/TR/k/oYP8h8AIBLFzbwD598Jz3JDP/th8/ylevP4frvPcPNF5/Ch5tO4uw500hlsvxny24uf/vMksQmIjIaSgRHYMv6Zqbddx11lpvtcOPAHcw88zIAvnPTosFP4iIik5HGCI7Arp99njqy/DT9XhKWYo2fxuZPXFDusERESqrkicDMFgPfBaLAD939ziHrE8A/AhcAHcBH3X1LqeM6xK51/BZr+ev0x1gWdAedNKNq3MMQERlvJf1CmZlFge8B1wBnAh8zszOHbPYpYK+7nwZ8G/haKWMaTutv/pWsGw9k3g3AH71nAQ/84W+XIxQRkXFV6hbBhcBGd98MYGb3AdcBrxZscx1wR7D8APB3ZmY+zoMX21Y/yl5OYQ9T+T8fO58PnDd7PA8vIlI2pb7ExBxga8H91qCs6DbungY6gfqhOzKzpWbWbGbN7e3tYxtlqp93WAvPZM/hrNlTlQREJFQmzbWG3H2Zuze5e1Nj4yG/vTwq2bb1xC3Dy9n5VGlmkIiETKkTwTbgpIL7c4OyotuYWQyYRm7QeNx0bH4RgPV+Cn994znjeWgRkbIrdSJ4AVhoZvPNrAK4CXh4yDYPAzcHyx8CfjXe4wOPPfkEfV7Bmz6Ltx3hN1dFRI4XJR0sdve0mX0OeIzc9NF73X2dmf1voNndHwZ+BPyTmW0E9pBLFuPq5MxbtNgcPn3ZaeN9aBGRsiv59wjcfTmwfEjZ7QXL/cCHSx3HSOZaO6/6PJ7ZuLucYYiIlMWkGSwumWyWObabrd7IuXOnlTsaEZFxp0SwfwcJS9Pqjdxx7VnljkZEZNyFPhFk9mwBYKs3HnTZYxGRsAh9Ikh2bAFgq+vS0SISTqFPBKnOnQB88N2HXJlVRCQUQp8IfP8uej3B7JkN5Q5FRKQsQv97BLt3biXmuV8XExEJo9Angl073iLBNDa2dZc7FBGRsgh911C9d7LbpxGLhv6pEJGQCvW7n7vTYPto92lceYZmDYlIOIU6EbR27KeObnYzjTNP1LeKRSScQp0IrHc3EXN2+zQqYqF+KkQkxEL97me9uYvM7fZpRCNW5mhERMoj1Ikg2t8JQCc1ZY5ERKR8Qp0ILJlLBF2uRCAi4RXuRDDYIqgucyQiIuUT6kTQ1rYLUItARMIt1IngyTUbyLqxn6pyhyIiUjahTgTT6KGLajzcT4OIhFzJrjVkZt8APgAkgU3A77v7viLbbQH2Axkg7e7jdj3oadZDl1fz50vePl6HFBGZcEr5Ufhx4Gx3PxfYANw6wraXu/ui8UwCAGfWOZ3UcPNvzxvPw4qITCglSwTuvsLd08HdZ4G5pTrWsar1bjq9hnhEXUMiEl7j9Q74B8Cjw6xzYIWZrTKzpeMUDwCJ9H46qcH0pWIRCbFRjRGY2RPACUVW3ebuDwXb3AakgX8eZjeXuPs2M5sJPG5mr7n700WOtRRYCnDyySePJuxBiXQX+5mHKROISIiNKhG4+5UjrTezTwLvB65wdx9mH9uC2zYzexC4EDgkEbj7MmAZQFNTU9F9Ha1ocj+dri+TiUi4laxryMwWA/8TuNbde4fZpsbMavPLwPuAtaWK6SDZDFWWpMf1HQIRCbdSjhH8HVBLrrtnjZndA2Bms81sebDNLOA/zewl4HngEXf/jxLGdEAy99OUPSTG5XAiIhNVyb5H4O6nDVO+HVgSLG8GzitVDCNK9gDQo28Vi0jIhXfe5ECuRdDrlWUORESkvMKbCNQ1JCIChDoR5LqG6mfUlzkQEZHyCnEiyLUI1ndkyxyIiEh5hTgR5FoEveoaEpGQC20i2NbWDkC3vkcgIiEX2kTwzLotAPSiWUMiEm6hTQQV2T5AXUMiIqFNBJXZXvq8ggzRcociIlJWoU0EFdk+etQtJCIS3kRQ6X30urqFRERCmwgS2V56qGLRSdPLHYqISFmFOBH000uCiH6TRkRCLrSJoML76fMKIvp1MhEJudAmgtpomn4q+OAFc8sdiohIWYU2EfT2dNNPBTecP6fcoYiIlFVoE0HCUgygriERkdAmgkqS9HkFUY0Wi0jIhToR9FOhWUMiEnqhTwSmriERCbmSJQIzu8PMtpnZmuBvyTDbLTaz181so5ndUqp4DpJJEbMs/V4xLocTEZnIYiXe/7fd/W+HW2lmUeB7wFVAK/CCmT3s7q+WNKpU7sqj/SgRiIiUu2voQmCju2929yRwH3BdyY+a7geUCEREoPSJ4HNm9rKZ3WtmdUXWzwG2FtxvDcoOYWZLzazZzJrb29tHF1XQIhggPrr9iIgcB0aVCMzsCTNbW+TvOuBuYAGwCNgBfHM0x3L3Ze7e5O5NjY2No9nVga4hjRGIiIxujMDdrzyS7czs74F/L7JqG3BSwf25QVlppTVGICKSV8pZQycW3L0BWFtksxeAhWY238wqgJuAh0sV06CUxghERPJKOWvo62a2CHBgC/AZADObDfzQ3Ze4e9rMPgc8BkSBe919XQljykmra0hEJK9kicDdPzFM+XZgScH95cDyUsVRlFoEIiKDyj19tDw0RiAiMiiUiSCbzCWCSEV1mSMRESm/UCaCjs5OAPYMhLL6IiIHCeU74etb2wB1DYmIQEgTwSnTooASgYgIhDQRRNL9ZNxIES13KCIiZRfKRGCZ/qA1oN8iEBEJZSKIpHOJIBELZfVFRA4SynfCSNAi+NHN7yx3KCIiZRfKRGCZJEmPEYuqa0hEJLyJgLhGCERECGkiiGSSJInph+tFRAhpIrBs0CJQHhARCWciiGSSJF1dQyIiENJEkGsRxNQiEBEhpIkgkhkgSQx9oUxEJKSJwLIptQhERAKhTAQRTR8VERkUykRg2WCwWE0CEZHS/Waxmf0MOD24Ox3Y5+6Limy3BdgPZIC0uzeVKqa8SH6wuNQHEhGZBEr54/UfzS+b2TeBzhE2v9zdd5cqlqHy3yyOqEUgIlL6riHL9b98BPiXUh/rSGVTuVlDrXt7yx2KiEjZjccYwaXALndvGWa9AyvMbJWZLR1uJ2a21Myazay5vb392KNxJ2FpksTJ+rHvRkTkeDGqriEzewI4ociq29z9oWD5Y4zcGrjE3beZ2UzgcTN7zd2fHrqRuy8DlgE0NTUd+1t4JgnAgMeIhnKoXETkYKNKBO5+5UjrzSwG3AhcMMI+tgW3bWb2IHAhcEgiGDPpAQBSpRseERGZVEr9mfhK4DV3by220sxqzKw2vwy8D1hb0oiCFkGSOJlsSY8kIjIplDoR3MSQbiEzm21my4O7s4D/NLOXgOeBR9z9P0oa0WAiiDG9Ol7SQ4mITAYl7R9x908WKdsOLAmWNwPnlTKGQwRdQ0mP867TGsb10CIiE1H4hksLWgQiIhLGRJBvEaBuIRERCGMiyE8fVYtARAQIYSLY390NqEUgIpIXukRw95PrAUi6WgQiIhDCRNDbl7u+0LnzZpY5EhGRiSF0iSBOCoCsqWtIRARCmAiingYgbRVljkREZGIIXSKIZ3OzhjIRtQhERCCMiSDoGlIiEBHJCV0iiHmQCNQ1JCIChDgRZKNKBCIiEOJEoMFiEZGc8CWCwemj0TJHIiIyMYQuEfT09jHgMR55ZWe5QxERmRBClwhiZEij1oCISJ4SgYhIyIUuEVSQ1o/SiIgUCF0iyLUIYiy97NRyhyIiMiGELxFYmrRHaZySKHcoIiITwqgTgZl92MzWmVnWzJqGrLvVzDaa2etmdvUwj59vZs8F2/3MrLQT/PNdQ9efP6eUhxERmTTGokWwFrgReLqw0MzOBG4CzgIWA983Kzp5/2vAt939NGAv8KkxiGlY+cHiRDx0jSERkaJG/W7o7uvd/fUiq64D7nP3AXd/A9gIXFi4gZkZ8F7ggaDox8D1o41pJJo1JCJysFJ+LJ4DbC243xqUFaoH9rkHPxJQfBsAzGypmTWbWXN7e/sxB1VBmhQx7Jj3ICJyfDmieZRm9gRwQpFVt7n7Q2MbUnHuvgxYBtDU1OTHup8YGVJqEYiIDDqiRODuVx7DvrcBJxXcnxuUFeoApptZLGgVFNtmTMUsQ9pj5HqlRESklF1DDwM3mVnCzOYDC4HnCzdwdwdWAh8Kim4GStrCyHUNqUUgIpI3FtNHbzCzVuBi4BEzewzA3dcB9wOvAv8BfNbdM8FjlpvZ7GAXXwL+1Mw2khsz+NFoYxpJTGMEIiIHGfW1Ftz9QeDBYdZ9FfhqkfIlBcubGTKbqJQ0a0hE5GChm0w/OGtITQIRESCEiSA/a8jUOSQiAoQxEViGtKtrSEQkL3SJQF1DIiIHC10i0BfKREQOFspEkNYP04iIDApdIsh3DYmISE7oEkEs+GaxxghERHLClQiyGaLmmjUkIlIgXIkgkwIILjGhJoGICIQtEWTziUAtAhGRvHAlgqBFkNYYgYjIoFAmAs0aEhE5IFyJIFs4RiAiIhC2RJDvGvKofqFMRCQQykSgriERkQPClQgKZg2pPSAikhOuRFAwa0hERHJCmQh0GWoRkQNGlQjM7MNmts7MsmbWVFB+lZmtMrNXgtv3DvP4O8xsm5mtCf6WFNtuzOgLZSIihxjtqOla4EbgB0PKdwMfcPftZnY28BgwZ5h9fNvd/3aUcRyZwVlDMc0aEhEJjCoRuPt64JA3VXd/seDuOqDKzBLuPjCa441aRi0CEZGhxmOM4IPA6hGSwOfM7GUzu9fM6obbiZktNbNmM2tub28/tkiCrqEli04+tseLiByHDpsIzOwJM1tb5O+6I3jsWcDXgM8Ms8ndwAJgEbAD+OZw+3L3Ze7e5O5NjY2Nhzt0cUGLIGv6HoGISN5h3xHd/cpj2bGZzQUeBH7P3TcNs+9dBdv/PfDvx3KsI5ZJ5m4sXtLDiIhMJiXpGjKz6cAjwC3u/swI251YcPcGcoPPpZNNA+ARjRGIiOSNdvroDWbWClwMPGJmjwWrPgecBtxeMDV0ZvCYHxZMNf16MMX0ZeBy4H+MJp7DyncNRdQiEBHJG+2soQfJdf8MLf8K8JVhHvPpguVPjOb4Ry3oGsqqa0hEZFC4vlkcdA1lIxosFhHJC1ciCLqGXC0CEZFBIUsEQddQVC0CEZG8cCWCfNeQvkcgIjIoXIkg6BrCNH1URCQvZIkgyYDHcP0sjYjIoFAlgtaOLtJE+eH/e6PcoYiITBihSgS9ff2kiZLMZMsdiojIhBGqRJCOxNnjteUOQ0RkQglVInhh4Z9yefLb5Q5DRGRCCVUiSGe93CGIiEw44UoEGhsQETlEqL5ZpRaBSHilUilaW1vp7+8vdyglV1lZydy5c4nHj+xyOqFKBO5KBCJh1draSm1tLfPmzTvkd9aPJ+5OR0cHra2tzJ8//4geE6quoZpELu+dNnNKmSMRkfHW399PfX39cZ0EAMyM+vr6o2r5hCoRzJ5eBcDXPnhOmSMRkXI43pNA3tHWM1SJIN81VF0Rqh4xEZERhSoR5MeKIyH5VCAiE8u+ffv4/ve/f9SPW7JkCfv27Rv7gAIhSwS5TKA8ICLlMFwiSKfTIz5u+fLlTJ8+vURRhW7WUO42okQgEmpf/uU6Xt3eNab7PHP2VP7XB84acZtbbrmFTZs2sWjRIuLxOJWVldTV1fHaa6+xYcMGrr/+erZu3Up/fz+f//znWbp0KQDz5s2jubmZ7u5urrnmGi655BL+67/+izlz5vDQQw9RVVU1qthH1SIwsw+b2Tozy5pZU0H5PDPrM7M1wd89wzx+hpk9bmYtwW3daOI5nAMtAmUCERl/d955JwsWLGDNmjV84xvfYPXq1Xz3u99lw4YNANx7772sWrWK5uZm7rrrLjo6Og7ZR0tLC5/97GdZt24d06dP5+c///mo4xpti2AtcCPwgyLrNrn7osM8/hbgSXe/08xuCe5/aZQxDcs1RiAicNhP7uPlwgsvPGiu/1133cWDDz4IwNatW2lpaaG+vv6gx8yfP59FixYBcMEFF7Bly5ZRxzGqRODu62FUn7CvA94TLP8YeIoSJoJ8i0BdQyIyEdTU1AwuP/XUUzzxxBP85je/obq6mve85z1FvwuQSCQGl6PRKH19faOOo5SDxfPN7EUz+7WZXTrMNrPcfUewvBOYNdzOzGypmTWbWXN7e/sxBaRZQyJSTrW1tezfv7/ous7OTurq6qiurua1117j2WefHbe4DtsiMLMngBOKrLrN3R8a5mE7gJPdvcPMLgB+YWZnufuwozPu7mY27DUg3H0ZsAygqanpmK4VcdeTLcfyMBGRMVFfX8+73vUuzj77bKqqqpg168Bn38WLF3PPPfdwxhlncPrpp3PRRReNW1yHTQTufuXR7tTdB4CBYHmVmW0C3gY0D9l0l5md6O47zOxEoO1oj3U02vbnmlkR9Q2JSJn89Kc/LVqeSCR49NFHi67LjwM0NDSwdu3awfIvfOELYxJTSbqGzKzRzKLB8qnAQmBzkU0fBm4Olm8GhmthjAlNHxUROdRop4/eYGatwMXAI2b2WLDqMuBlM1sDPAD8obvvCR7zw4KppncCV5lZC3BlcL/kNEYgInLAaGcNPQg8WKT850DRya3u/umC5Q7gitHEcDTyAwvKAyIiB4TqEhN5hjKBiEheqBJB/u1fYwQiIgeEKhHku4Y0RiAickCoEkGeEoGIlMOxXoYa4Dvf+Q69vb1jHFFOKBOBhbLWIlJuEzURhOoy1OgSEyIC8OgtsPOVsd3nCefANSPPgC+8DPVVV13FzJkzuf/++xkYGOCGG27gy1/+Mj09PXzkIx+htbWVTCbDX/7lX7Jr1y62b9/O5ZdfTkNDAytXrhzT0MOVCAJKAyJSDnfeeSdr165lzZo1rFixggceeIDnn38ed+faa6/l6aefpr29ndmzZ/PII48AuWsQTZs2jW9961usXLmShoaGMY8rXIkgyABqEYiE3GE+uY+HFStWsGLFCs4//3wAuru7aWlp4dJLL+XP/uzP+NKXvsT73/9+Lr10uGt2jp1wJYKga0h5QETKzd259dZb+cxnPnPIutWrV7N8+XL+4i/+giuuuILbb7+9pLGEcthUiUBEyqHwMtRXX3019957L93d3QBs27aNtrY2tm/fTnV1NR//+Mf54he/yOrVqw957FgLVYugOhEl2ZstdxgiElKFl6G+5ppr+N3f/V0uvvhiAKZMmcJPfvITNm7cyBe/+EUikQjxeJy7774bgKVLl7J48WJmz5495oPF5n5Ml/Yvq6amJm9uHnpF68Pb2NbNk+t38Zl3LyhBVCIyka1fv54zzjij3GGMm2L1NbNV7t40dNtQtQhOmzmF02ZOKXcYIiITSijHCERE5AAlAhEJjcnYFX4sjraeSgQiEgqVlZV0dHQc98nA3eno6KCysvKIHxOqMQIRCa+5c+fS2tpKe3t7uUMpucrKSubOnXvE2ysRiEgoxONx5s+fX+4wJiR1DYmIhJwSgYhIyCkRiIiE3KT8ZrGZtQNvHuPDG4DdYxhOOagOE8PxUAc4PuqhOhyZU9y9cWjhpEwEo2FmzcW+Yj2ZqA4Tw/FQBzg+6qE6jI66hkREQk6JQEQk5MKYCJaVO4AxoDpMDMdDHeD4qIfqMAqhGyMQEZGDhbFFICIiBZQIRERCLlSJwMwWm9nrZrbRzG4pdzwjMbMtZvaKma0xs+agbIaZPW5mLcFtXVBuZnZXUK+XzewdZYr5XjNrM7O1BWVHHbOZ3Rxs32JmN0+AOtxhZtuCc7HGzJYUrLs1qMPrZnZ1QXnZXmtmdpKZrTSzV81snZl9PiifNOdihDpMmnNhZpVm9ryZvRTU4ctB+Xwzey6I52dmVhGUJ4L7G4P18w5XtzHj7qH4A6LAJuBUoAJ4CTiz3HGNEO8WoGFI2deBW4LlW4CvBctLgEcBAy4CnitTzJcB7wDWHmvMwAxgc3BbFyzXlbkOdwBfKLLtmcHrKAHMD15f0XK/1oATgXcEy7XAhiDWSXMuRqjDpDkXwfM5JViOA88Fz+/9wE1B+T3AHwXLfwzcEyzfBPxspLqNZaxhahFcCGx0983ungTuA64rc0xH6zrgx8Hyj4HrC8r/0XOeBaab2YnjHZy7Pw3sGVJ8tDFfDTzu7nvcfS/wOLC45MEHhqnDcK4D7nP3AXd/A9hI7nVW1teau+9w99XB8n5gPTCHSXQuRqjDcCbcuQiez+7gbjz4c+C9wANB+dDzkD8/DwBXmJkxfN3GTJgSwRxga8H9VkZ+YZWbAyvMbJWZLQ3KZrn7jmB5JzArWJ7IdTvamCdqXT4XdJvcm+9SYRLUIeheOJ/cp9FJeS6G1AEm0bkws6iZrQHayCXSTcA+d08XiWcw1mB9J1DPONQhTIlgsrnE3d8BXAN81swuK1zpuTbjpJr7OxljDtwNLAAWATuAb5Y1miNkZlOAnwN/4u5dhesmy7koUodJdS7cPePui4C55D7Fv728ERUXpkSwDTip4P7coGxCcvdtwW0b8CC5F9GufJdPcNsWbD6R63a0MU+4urj7ruAfOgv8PQea5RO2DmYWJ/cG+s/u/m9B8aQ6F8XqMBnPBYC77wNWAheT63rL/yhYYTyDsQbrpwEdjEMdwpQIXgAWBiP2FeQGYx4uc0xFmVmNmdXml4H3AWvJxZufuXEz8FCw/DDwe8Hsj4uAzoIugHI72pgfA95nZnVBs/99QVnZDBlvuYHcuYBcHW4KZnvMBxYCz1Pm11rQr/wjYL27f6tg1aQ5F8PVYTKdCzNrNLPpwXIVcBW5sY6VwIeCzYaeh/z5+RDwq6DlNlzdxs54jJ5PlD9ysyM2kOunu63c8YwQ56nkZgm8BKzLx0quv/BJoAV4ApjhB2YnfC+o1ytAU5ni/hdyzfUUuX7MTx1LzMAfkBsQ2wj8/gSowz8FMb5M7p/yxILtbwvq8DpwzUR4rQGXkOv2eRlYE/wtmUznYoQ6TJpzAZwLvBjEuha4PSg/ldwb+UbgX4FEUF4Z3N8YrD/1cHUbqz9dYkJEJOTC1DUkIiJFKBGIiIScEoGISMgpEYiIhJwSgYhIyCkRiIiEnBKBiEjI/X85AewqOUmykgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"train max\",max(acc_list[0]))\n",
    "print(\"test max\",max(acc_list[1]))\n",
    "plot(acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train max acc</th>\n",
       "      <th>train    loss</th>\n",
       "      <th>test      acc</th>\n",
       "      <th>test     loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.85</td>\n",
       "      <td>6428710.0</td>\n",
       "      <td>0.73</td>\n",
       "      <td>66328316.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.85</td>\n",
       "      <td>1257862.0</td>\n",
       "      <td>0.71</td>\n",
       "      <td>70500832.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.85</td>\n",
       "      <td>1331636.0</td>\n",
       "      <td>0.71</td>\n",
       "      <td>64231668.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.86</td>\n",
       "      <td>5452740.0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>77691992.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.86</td>\n",
       "      <td>4945870.0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>68111576.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.87</td>\n",
       "      <td>4113154.0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>69786240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.87</td>\n",
       "      <td>1543880.0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>84195984.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.87</td>\n",
       "      <td>1122066.0</td>\n",
       "      <td>0.73</td>\n",
       "      <td>57227084.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.89</td>\n",
       "      <td>3447564.0</td>\n",
       "      <td>0.73</td>\n",
       "      <td>63784552.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.91</td>\n",
       "      <td>1945272.0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>164955712.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train max acc  train    loss  test      acc  test     loss\n",
       "0           0.85      6428710.0           0.73     66328316.0\n",
       "1           0.85      1257862.0           0.71     70500832.0\n",
       "2           0.85      1331636.0           0.71     64231668.0\n",
       "3           0.86      5452740.0           0.72     77691992.0\n",
       "4           0.86      4945870.0           0.72     68111576.0\n",
       "5           0.87      4113154.0           0.72     69786240.0\n",
       "6           0.87      1543880.0           0.72     84195984.0\n",
       "7           0.87      1122066.0           0.73     57227084.0\n",
       "8           0.89      3447564.0           0.73     63784552.0\n",
       "9           0.91      1945272.0           0.70    164955712.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "accmax_index=np.argsort(acc_list[0])[-10:]\n",
    "METRIC_topk_acc = pd.DataFrame([np.round(np.array(acc_list[0])[accmax_index],2),np.array(loss_list[0])[accmax_index].astype(int),\n",
    "             np.round(np.array(acc_list[1])[accmax_index],2),np.array(loss_list[1])[accmax_index].astype(int)]).T\n",
    "METRIC_topk_acc.columns=[\"train max acc\",\"train    loss\",\"test      acc\",\"test     loss\"]\n",
    "METRIC_topk_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train  acc</th>\n",
       "      <th>train  min  loss</th>\n",
       "      <th>test      acc</th>\n",
       "      <th>test     loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.87</td>\n",
       "      <td>1122066.0</td>\n",
       "      <td>0.73</td>\n",
       "      <td>57227084.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.79</td>\n",
       "      <td>1156050.0</td>\n",
       "      <td>0.71</td>\n",
       "      <td>57220172.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.85</td>\n",
       "      <td>1257862.0</td>\n",
       "      <td>0.71</td>\n",
       "      <td>70500832.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.85</td>\n",
       "      <td>1331636.0</td>\n",
       "      <td>0.71</td>\n",
       "      <td>64231668.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.87</td>\n",
       "      <td>1543880.0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>84195984.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.78</td>\n",
       "      <td>1560987.0</td>\n",
       "      <td>0.73</td>\n",
       "      <td>62429172.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.83</td>\n",
       "      <td>1572491.0</td>\n",
       "      <td>0.73</td>\n",
       "      <td>57536668.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.71</td>\n",
       "      <td>1844898.0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>55503104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.69</td>\n",
       "      <td>1859188.0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>63345684.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.91</td>\n",
       "      <td>1945272.0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>164955712.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train  acc  train  min  loss  test      acc  test     loss\n",
       "0        0.87         1122066.0           0.73     57227084.0\n",
       "1        0.79         1156050.0           0.71     57220172.0\n",
       "2        0.85         1257862.0           0.71     70500832.0\n",
       "3        0.85         1331636.0           0.71     64231668.0\n",
       "4        0.87         1543880.0           0.72     84195984.0\n",
       "5        0.78         1560987.0           0.73     62429172.0\n",
       "6        0.83         1572491.0           0.73     57536668.0\n",
       "7        0.71         1844898.0           0.72     55503104.0\n",
       "8        0.69         1859188.0           0.72     63345684.0\n",
       "9        0.91         1945272.0           0.70    164955712.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lossmin_index=np.argsort(loss_list[0])[:10]\n",
    "METRIC_topk_loss = pd.DataFrame([np.round(np.array(acc_list[0])[lossmin_index],2),np.array(loss_list[0])[lossmin_index].astype(int),\n",
    "             np.round(np.array(acc_list[1])[lossmin_index],2),np.array(loss_list[1])[lossmin_index].astype(int)]).T\n",
    "METRIC_topk_loss.columns=[\"train  acc\",\"train  min  loss\",\"test      acc\",\"test     loss\"]\n",
    "METRIC_topk_loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
